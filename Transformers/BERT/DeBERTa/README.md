# DeBERTa

TODO

## Additional Resources

[official)code](https://github.com/microsoft/DeBERTa),  [huggingface models](https://huggingface.co/models?search=deberta)

## References

[1] Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen. [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654)
