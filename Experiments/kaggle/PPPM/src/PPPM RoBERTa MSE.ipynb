{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654787028635,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"4wtXQc5eILks"},"outputs":[],"source":["# !pip install kaggle\n","# from google.colab import files\n","# files.upload()"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654787028635,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"9ybT-kPrIRRF"},"outputs":[],"source":["# !ls -1ha kaggle.json"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17637,"status":"ok","timestamp":1654787046267,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ngruL3LzILgG","outputId":"62b62a3f-5243-40bf-9429-bfdd10ccfd1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654787046268,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"t-pSk1HrImpC"},"outputs":[],"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# # Permission Warning 이 일어나지 않도록 \n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 본인이 참가한 모든 대회 보기 \n","# !kaggle competitions list"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10663,"status":"ok","timestamp":1654787056926,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"93TLgBfpILdp","outputId":"4f5c72da-35f2-4733-d369-e568647416e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 14.3 MB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.12.17-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 77.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 80.9 MB/s \n","\u001b[?25hRequirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds\u003e=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: protobuf\u003c4.0dev,\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: python-dateutil\u003e=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting GitPython\u003e=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 84.7 MB/s \n","\u001b[?25hCollecting sentry-sdk\u003e=1.0.0\n","  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 94.2 MB/s \n","\u001b[?25hRequirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting shortuuid\u003e=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.2.0)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n","\u001b[?25hCollecting smmap\u003c6,\u003e=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2022.5.18.1)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=976eddfaff7ff9a61317b310ea20f9783777f4071e3a7bf4143d0962870b18db\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb, tokenizers, sentencepiece\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentencepiece-0.1.96 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 tokenizers-0.12.1 wandb-0.12.17\n"]}],"source":["!pip3 install tokenizers wandb sentencepiece"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7288,"status":"ok","timestamp":1654787064207,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"dTDhaP31LevK","outputId":"45115389-9edb-4eee-bf41-273c7f28ad46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 4.7 MB/s \n","\u001b[?25hCollecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 85.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Installing collected packages: pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 transformers-4.19.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654787064207,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ABCV5MzcILYt"},"outputs":[],"source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654787064207,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"g8uVyeNzILWZ"},"outputs":[],"source":["OUTPUT_DIR = './pppm-roberta/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":667,"status":"ok","timestamp":1654787064871,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"B9XJVEp-ILTm","outputId":"e5aed1f0-5e02-49ff-fea7-5cc93b39cc18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jun  9 15:04:24 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') \u003e= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654787064871,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ad4bqKUJILRr"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    competition='PPPM'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"roberta-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=50 # [0, 50, 100]\n","    epochs=5\n","    encoder_lr=1.5e-5 #2e-5\n","    decoder_lr=1.5e-5 #2e-5\n","    min_lr=5e-7\n","    eps=5e-7\n","    betas=(0.9, 0.999)\n","    batch_size=10\n","    fc_dropout=0.15\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    train_all_index=20\n","    n_fold=15\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":11810,"status":"ok","timestamp":1654787076678,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qW8but_GILO1","outputId":"0a17ad23-ea71-49c1-cd5a-4d089502f51e"},"outputs":[{"name":"stdout","output_type":"stream","text":["login to wandb\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) =\u003e {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() =\u003e {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() =\u003e reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data =\u003e {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluehills\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.17"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/drive/My Drive/Kaggle/wandb/run-20220609_150431-g9kejmh7\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/bluehills/PPPM-MSE/runs/g9kejmh7\" target=\"_blank\"\u003eroberta-large\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/bluehills/PPPM-MSE\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    import wandb\n","    try:\n","        # from kaggle_secrets import UserSecretsClient\n","        # user_secrets = UserSecretsClient()\n","        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        # wandb.login(key=secret_value_0)\n","        print('login to wandb')\n","        wandb.login()\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W\u0026B account, go to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as wandb_api. \\nGet your W\u0026B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='PPPM-MSE', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"g_kIjiCGLHsk"},"source":["# Library"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6823,"status":"ok","timestamp":1654787083486,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"F3Ud6NtXILMj","outputId":"5e2b592a-58da-4cbb-a31f-6b878d3c4d33"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.19.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","import torch.cuda.amp as amp\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForTokenClassification\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"0N-UkOUGLMTx"},"source":["# Utils"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654787083487,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"FO_u0OIhILJo"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"6epV68-8Lrk7"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":637},"executionInfo":{"elapsed":603,"status":"ok","timestamp":1654787084086,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"-15eijrbILHp","outputId":"a1efc40c-0191-4f18-a880-8036a2654405"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (36473, 5)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-3386daad-580d-4527-8ea7-d8f3aea39d60\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3386daad-580d-4527-8ea7-d8f3aea39d60')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-3386daad-580d-4527-8ea7-d8f3aea39d60 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3386daad-580d-4527-8ea7-d8f3aea39d60');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-1c33d21e-2b50-4ea7-b51c-6fb0a78e615b\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c33d21e-2b50-4ea7-b51c-6fb0a78e615b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-1c33d21e-2b50-4ea7-b51c-6fb0a78e615b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1c33d21e-2b50-4ea7-b51c-6fb0a78e615b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-d6add275-2cf3-4d97-b78b-9d7ec35ccc46\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6add275-2cf3-4d97-b78b-9d7ec35ccc46')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-d6add275-2cf3-4d97-b78b-9d7ec35ccc46 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d6add275-2cf3-4d97-b78b-9d7ec35ccc46');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","submission = pd.read_csv('sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":5342,"status":"ok","timestamp":1654787089426,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"6T4B0z0yILFW","outputId":"496e71c2-fdb6-4042-8b78-2c386cedc994"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-df336e25-5b19-4d75-a13c-404bc8789841\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df336e25-5b19-4d75-a13c-404bc8789841')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-df336e25-5b19-4d75-a13c-404bc8789841 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df336e25-5b19-4d75-a13c-404bc8789841');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-fc3b73a5-8a46-48d1-971a-9e92461a40b3\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc3b73a5-8a46-48d1-971a-9e92461a40b3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-fc3b73a5-8a46-48d1-971a-9e92461a40b3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc3b73a5-8a46-48d1-971a-9e92461a40b3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('./CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'./CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","def get_cpc_texts_nakama():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('./CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'./CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","# cpc_texts = get_cpc_texts_nakama()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654787089426,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"46m7DZuOILDE","outputId":"4110288f-a0d8-43df-8d1f-b47c35f48c13"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-64bf36a8-5127-4009-b872-1b97188d47a8\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]abatement of pollution[SEP]HUMAN...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]act of abating[SEP]HUMAN NECESSI...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]active catalyst[SEP]HUMAN NECESS...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]eliminating process[SEP]HUMAN NE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]forest region[SEP]HUMAN NECESSIT...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64bf36a8-5127-4009-b872-1b97188d47a8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-64bf36a8-5127-4009-b872-1b97188d47a8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64bf36a8-5127-4009-b872-1b97188d47a8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text                                               text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]abatement of pollution[SEP]HUMAN...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]act of abating[SEP]HUMAN NECESSI...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]active catalyst[SEP]HUMAN NECESS...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]eliminating process[SEP]HUMAN NE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]forest region[SEP]HUMAN NECESSIT..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-5672e82a-082e-4750-971f-2d8bf447e1aa\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","      \u003ctd\u003eopc drum[SEP]inorganic photoconductor drum[SEP...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow[SEP]altering gas flow[SEP]MECH...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","      \u003ctd\u003elower trunnion[SEP]lower locating[SEP]PERFORMI...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","      \u003ctd\u003ecap component[SEP]upper portion[SEP]TEXTILES; ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation[SEP]artificial neural netwo...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5672e82a-082e-4750-971f-2d8bf447e1aa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-5672e82a-082e-4750-971f-2d8bf447e1aa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5672e82a-082e-4750-971f-2d8bf447e1aa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text                                               text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS  opc drum[SEP]inorganic photoconductor drum[SEP...\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...  adjust gas flow[SEP]altering gas flow[SEP]MECH...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...  lower trunnion[SEP]lower locating[SEP]PERFORMI...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...  cap component[SEP]upper portion[SEP]TEXTILES; ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  neural stimulation[SEP]artificial neural netwo..."]},"metadata":{},"output_type":"display_data"}],"source":["train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"isTSVEuINl2S"},"source":["# EDA"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":1018,"status":"ok","timestamp":1654787090438,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"3rsR5QFLILAq","outputId":"f749f134-e985-43f8-c1d8-c55f28f0bcad"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7f3a1f3e05d0\u003e"]},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1654787090439,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qco8TIYeIK-W","outputId":"ab6c1ae0-94a3-4d74-c11f-f18abf6cb297"},"outputs":[{"data":{"text/plain":["B    8019\n","H    6195\n","G    6013\n","C    5288\n","A    4094\n","F    4054\n","E    1531\n","D    1279\n","Name: context, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"0X9jmLp9NrEE"},"source":["# CV Split"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654787090439,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"rnm4sSJdIK73"},"outputs":[],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654787090439,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"QkVs3kLeKPx3"},"outputs":[],"source":["# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","\n","# encoder = LabelEncoder()\n","# train['anchor_map'] = encoder.fit_transform(train['anchor'])\n","\n","# kf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (_, valid_index) in enumerate(kf.split(train, train['score_map'], groups=train['anchor_map'])):\n","#     train.loc[valid_index, 'fold'] = int(n)\n","\n","# train['fold'] = train['fold'].astype(int)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1654787090439,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"v335JEfPbJJw"},"outputs":[],"source":["# titles = pd.read_csv('./titles.csv')\n","# train = train.merge(titles, left_on='context', right_on='code')\n","# train['fold'] = -1\n","# kf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","\n","# for f, (t_, v_) in enumerate(kf.split(X=train, y=train['anchor'], groups=train['anchor'])):\n","#     train.loc[v_, 'fold'] = f\n","\n","# train['fold'].hist()\n","# train['text'] = train['anchor'] + '[SEP]' + train['title'].apply(str.lower)\n","# train = train[['id','anchor', 'target', 'context', 'score', 'title', 'fold', 'text']]"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1799,"status":"ok","timestamp":1654787092230,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"Gd7lcdeGiEZU","outputId":"4647028a-1a3b-458e-cc39-c39fb2f818c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["684 49\n","684 49\n","684 49\n","684 49\n","684 49\n","684 49\n","684 49\n","684 49\n","685 48\n","684 49\n","684 49\n","684 49\n","684 49\n","684 49\n","685 48\n","1     2619\n","12    2572\n","6     2560\n","5     2541\n","3     2523\n","7     2498\n","8     2474\n","14    2422\n","2     2422\n","4     2404\n","11    2345\n","10    2330\n","9     2329\n","13    2291\n","0     2143\n","Name: fold, dtype: int64\n"]}],"source":["!pip3 install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train = train.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")\n","print(train.fold.value_counts())"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654787092230,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"67wpP1q7IK5L"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"bIqxWfHqNzR2"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"elapsed":9296,"status":"ok","timestamp":1654787101523,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"0LIvoPmoIFUv","outputId":"82f21488-09eb-4785-8ed6-647a8817dcab"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f3cdd611a9b45bb9f4490b08fd17121","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/482 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33304da53fd34f18ad9b65956251786f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27b61f51d13b43dcbd1644dead8e9709","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"570114504dce49e5b956e71d14697639","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"BvhCQypyN2nU"},"source":["# Dataset"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":6090,"status":"ok","timestamp":1654787107604,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"O9KbGQdeN195","outputId":"8aaa6fce-1263-46e8-fdbc-e5cea540781b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"651ca0fb08f046bc888ff0a7b1a3bfdc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"131182c4321648f18a2a4d341219f07a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ef1d2d5bc5e4c3484936d6be7266533","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_len: 175\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1654787107604,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"twc1qFyRN17n"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1654787107605,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"5iFhyETfN15V","outputId":"6d178f74-1ac8-4241-deba-19d2ca9c901a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"m1x8L7BQOKr2"},"source":["# Model"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1654787107605,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"GPMtgF_NbjBe"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","            # self.model = AutoModelForSequenceClassification.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","            # self.model = AutoModelForSequenceClassification.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        # self.fc = nn.Linear(self.config.num_labels, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output\n","\n"]},{"cell_type":"markdown","metadata":{"id":"N80Z0ZF9OcjW"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":615,"status":"ok","timestamp":1654787108212,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"IjzXaGwxN10f"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","\n","\n","        labels = labels.to(torch.float16)\n","        # print(y_preds.view(-1, 1).dtype)\n","        # print(labels.view(-1, 1).dtype)\n","        # loss = criterion(y_preds.sigmoid().view(-1, 1), labels.view(-1, 1))\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        # print(loss.dtype)\n","\n","        \n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        labels = labels.to(torch.float16)\n","        loss = criterion(y_preds.sigmoid().view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        # preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        preds.append(y_preds.to('cpu').numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        # preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        preds.append(y_preds.to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654787108213,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"K9fNekOSN1yT"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    if fold != CFG.train_all_index:\n","        train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    else:\n","        train_folds = folds\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model \u0026 optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    # criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    criterion = nn.MSELoss(reduction=\"mean\")\n","    # criterion = FocalLossV1().cuda()\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score \u003c score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    try:\n","        predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                                map_location=torch.device('cpu'))['predictions']\n","        valid_folds['pred'] = predictions\n","    except:\n","        valid_folds['pred'] = -1\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":659},"id":"GIQnVGWmN1vf"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1368ce0618a40158f528d504de4b2af","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.33G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3433] Elapsed 0m 0s (remain 40m 41s) Loss: 0.2330(0.2330) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3433] Elapsed 0m 18s (remain 10m 9s) Loss: 0.1504(0.1611) Grad: 27275.3574  LR: 0.00001500  \n","Epoch: [1][200/3433] Elapsed 0m 36s (remain 9m 42s) Loss: 0.0951(0.1536) Grad: 9578.1309  LR: 0.00001500  \n","Epoch: [1][300/3433] Elapsed 0m 54s (remain 9m 23s) Loss: 0.1868(0.1464) Grad: 25858.1758  LR: 0.00001499  \n","Epoch: [1][400/3433] Elapsed 1m 11s (remain 9m 4s) Loss: 0.1289(0.1418) Grad: 6622.7178  LR: 0.00001498  \n","Epoch: [1][500/3433] Elapsed 1m 29s (remain 8m 45s) Loss: 0.1583(0.1308) Grad: 9136.2314  LR: 0.00001497  \n","Epoch: [1][600/3433] Elapsed 1m 47s (remain 8m 27s) Loss: 0.1011(0.1248) Grad: 15697.0498  LR: 0.00001496  \n","Epoch: [1][700/3433] Elapsed 2m 5s (remain 8m 8s) Loss: 0.0244(0.1185) Grad: 1297.7610  LR: 0.00001495  \n","Epoch: [1][800/3433] Elapsed 2m 23s (remain 7m 50s) Loss: 0.0774(0.1128) Grad: 7449.1343  LR: 0.00001493  \n","Epoch: [1][900/3433] Elapsed 2m 41s (remain 7m 32s) Loss: 0.0375(0.1080) Grad: 5423.1699  LR: 0.00001491  \n","Epoch: [1][1000/3433] Elapsed 2m 58s (remain 7m 14s) Loss: 0.0420(0.1031) Grad: 1122.4154  LR: 0.00001489  \n","Epoch: [1][1100/3433] Elapsed 3m 16s (remain 6m 56s) Loss: 0.0340(0.1001) Grad: 1769.3036  LR: 0.00001486  \n","Epoch: [1][1200/3433] Elapsed 3m 34s (remain 6m 38s) Loss: 0.0566(0.0964) Grad: 10724.7383  LR: 0.00001483  \n","Epoch: [1][1300/3433] Elapsed 3m 51s (remain 6m 20s) Loss: 0.0863(0.0935) Grad: 19180.3516  LR: 0.00001480  \n","Epoch: [1][1400/3433] Elapsed 4m 9s (remain 6m 2s) Loss: 0.0588(0.0903) Grad: 9086.4521  LR: 0.00001477  \n","Epoch: [1][1500/3433] Elapsed 4m 27s (remain 5m 44s) Loss: 0.0386(0.0872) Grad: 5193.0977  LR: 0.00001474  \n","Epoch: [1][1600/3433] Elapsed 4m 45s (remain 5m 27s) Loss: 0.0244(0.0844) Grad: 5673.1416  LR: 0.00001470  \n","Epoch: [1][1700/3433] Elapsed 5m 4s (remain 5m 9s) Loss: 0.0284(0.0820) Grad: 8715.6484  LR: 0.00001466  \n","Epoch: [1][1800/3433] Elapsed 5m 22s (remain 4m 51s) Loss: 0.0424(0.0798) Grad: 8079.1890  LR: 0.00001462  \n","Epoch: [1][1900/3433] Elapsed 5m 40s (remain 4m 34s) Loss: 0.0354(0.0775) Grad: 1285.5808  LR: 0.00001457  \n","Epoch: [1][2000/3433] Elapsed 5m 58s (remain 4m 16s) Loss: 0.0479(0.0756) Grad: 3917.7227  LR: 0.00001452  \n","Epoch: [1][2100/3433] Elapsed 6m 16s (remain 3m 58s) Loss: 0.0172(0.0739) Grad: 7955.9512  LR: 0.00001447  \n","Epoch: [1][2200/3433] Elapsed 6m 34s (remain 3m 40s) Loss: 0.0213(0.0722) Grad: 6125.9507  LR: 0.00001442  \n","Epoch: [1][2300/3433] Elapsed 6m 52s (remain 3m 22s) Loss: 0.0370(0.0706) Grad: 17422.2090  LR: 0.00001437  \n","Epoch: [1][2400/3433] Elapsed 7m 10s (remain 3m 4s) Loss: 0.0714(0.0691) Grad: 12591.8984  LR: 0.00001431  \n","Epoch: [1][2500/3433] Elapsed 7m 28s (remain 2m 47s) Loss: 0.0179(0.0676) Grad: 10931.2539  LR: 0.00001425  \n","Epoch: [1][2600/3433] Elapsed 7m 46s (remain 2m 29s) Loss: 0.0941(0.0663) Grad: 12225.8760  LR: 0.00001419  \n","Epoch: [1][2700/3433] Elapsed 8m 4s (remain 2m 11s) Loss: 0.0171(0.0650) Grad: 3482.6580  LR: 0.00001413  \n","Epoch: [1][2800/3433] Elapsed 8m 22s (remain 1m 53s) Loss: 0.0316(0.0638) Grad: 3839.9905  LR: 0.00001406  \n","Epoch: [1][2900/3433] Elapsed 8m 39s (remain 1m 35s) Loss: 0.0195(0.0626) Grad: 2193.9033  LR: 0.00001400  \n","Epoch: [1][3000/3433] Elapsed 8m 57s (remain 1m 17s) Loss: 0.0321(0.0615) Grad: 3702.7969  LR: 0.00001393  \n","Epoch: [1][3100/3433] Elapsed 9m 15s (remain 0m 59s) Loss: 0.0359(0.0605) Grad: 3914.4182  LR: 0.00001385  \n","Epoch: [1][3200/3433] Elapsed 9m 33s (remain 0m 41s) Loss: 0.0125(0.0594) Grad: 2609.9612  LR: 0.00001378  \n","Epoch: [1][3300/3433] Elapsed 9m 50s (remain 0m 23s) Loss: 0.0148(0.0586) Grad: 3556.1245  LR: 0.00001370  \n","Epoch: [1][3400/3433] Elapsed 10m 8s (remain 0m 5s) Loss: 0.0149(0.0578) Grad: 7032.2559  LR: 0.00001363  \n","Epoch: [1][3432/3433] Elapsed 10m 14s (remain 0m 0s) Loss: 0.0809(0.0575) Grad: 29989.4688  LR: 0.00001360  \n","EVAL: [0/215] Elapsed 0m 0s (remain 1m 7s) Loss: 0.1147(0.1147) \n","EVAL: [100/215] Elapsed 0m 9s (remain 0m 11s) Loss: 0.1435(0.1007) \n","EVAL: [200/215] Elapsed 0m 19s (remain 0m 1s) Loss: 0.0873(0.1007) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0575  avg_val_loss: 0.1014  time: 635s\n","Epoch 1 - Score: 0.7402\n","Epoch 1 - Save Best Score: 0.7402 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [214/215] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0667(0.1014) \n","Epoch: [2][0/3433] Elapsed 0m 0s (remain 24m 3s) Loss: 0.0298(0.0298) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3433] Elapsed 0m 18s (remain 10m 1s) Loss: 0.0194(0.0252) Grad: 5962.8574  LR: 0.00001352  \n","Epoch: [2][200/3433] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0136(0.0248) Grad: 16068.8193  LR: 0.00001343  \n","Epoch: [2][300/3433] Elapsed 0m 54s (remain 9m 23s) Loss: 0.0497(0.0246) Grad: 8293.8516  LR: 0.00001335  \n","Epoch: [2][400/3433] Elapsed 1m 11s (remain 9m 3s) Loss: 0.0110(0.0251) Grad: 2419.3589  LR: 0.00001326  \n","Epoch: [2][500/3433] Elapsed 1m 29s (remain 8m 44s) Loss: 0.0163(0.0252) Grad: 5798.2710  LR: 0.00001317  \n","Epoch: [2][600/3433] Elapsed 1m 47s (remain 8m 25s) Loss: 0.0112(0.0246) Grad: 5321.7017  LR: 0.00001308  \n","Epoch: [2][700/3433] Elapsed 2m 4s (remain 8m 6s) Loss: 0.0230(0.0244) Grad: 7788.1694  LR: 0.00001299  \n","Epoch: [2][800/3433] Elapsed 2m 22s (remain 7m 48s) Loss: 0.0224(0.0240) Grad: 27124.5430  LR: 0.00001289  \n","Epoch: [2][900/3433] Elapsed 2m 40s (remain 7m 30s) Loss: 0.0066(0.0236) Grad: 9472.2148  LR: 0.00001280  \n","Epoch: [2][1000/3433] Elapsed 2m 57s (remain 7m 12s) Loss: 0.0214(0.0235) Grad: 15177.5225  LR: 0.00001270  \n","Epoch: [2][1100/3433] Elapsed 3m 15s (remain 6m 54s) Loss: 0.0247(0.0234) Grad: 5472.5513  LR: 0.00001260  \n","Epoch: [2][1200/3433] Elapsed 3m 33s (remain 6m 36s) Loss: 0.0205(0.0235) Grad: 13682.1641  LR: 0.00001250  \n","Epoch: [2][1300/3433] Elapsed 3m 51s (remain 6m 18s) Loss: 0.0039(0.0236) Grad: 6417.8145  LR: 0.00001239  \n","Epoch: [2][1400/3433] Elapsed 4m 9s (remain 6m 1s) Loss: 0.0147(0.0237) Grad: 14547.3086  LR: 0.00001229  \n","Epoch: [2][1500/3433] Elapsed 4m 27s (remain 5m 43s) Loss: 0.0372(0.0237) Grad: 10188.9912  LR: 0.00001218  \n","Epoch: [2][1600/3433] Elapsed 4m 45s (remain 5m 26s) Loss: 0.0254(0.0237) Grad: 8818.7891  LR: 0.00001207  \n","Epoch: [2][1700/3433] Elapsed 5m 3s (remain 5m 8s) Loss: 0.0258(0.0236) Grad: 27380.9531  LR: 0.00001196  \n","Epoch: [2][1800/3433] Elapsed 5m 21s (remain 4m 51s) Loss: 0.0099(0.0237) Grad: 18170.1777  LR: 0.00001185  \n","Epoch: [2][1900/3433] Elapsed 5m 39s (remain 4m 33s) Loss: 0.0123(0.0237) Grad: 8960.0537  LR: 0.00001174  \n","Epoch: [2][2000/3433] Elapsed 5m 57s (remain 4m 15s) Loss: 0.0100(0.0236) Grad: 6989.5020  LR: 0.00001163  \n","Epoch: [2][2100/3433] Elapsed 6m 15s (remain 3m 58s) Loss: 0.0110(0.0236) Grad: 35079.8438  LR: 0.00001151  \n","Epoch: [2][2200/3433] Elapsed 6m 33s (remain 3m 40s) Loss: 0.0308(0.0237) Grad: 21553.0273  LR: 0.00001139  \n","Epoch: [2][2300/3433] Elapsed 6m 51s (remain 3m 22s) Loss: 0.0104(0.0237) Grad: 4093.2004  LR: 0.00001128  \n","Epoch: [2][2400/3433] Elapsed 7m 9s (remain 3m 4s) Loss: 0.0276(0.0236) Grad: 6440.1797  LR: 0.00001116  \n","Epoch: [2][2500/3433] Elapsed 7m 26s (remain 2m 46s) Loss: 0.0069(0.0236) Grad: 7944.7705  LR: 0.00001103  \n","Epoch: [2][2600/3433] Elapsed 7m 44s (remain 2m 28s) Loss: 0.0220(0.0235) Grad: 16144.4062  LR: 0.00001091  \n","Epoch: [2][2700/3433] Elapsed 8m 2s (remain 2m 10s) Loss: 0.0201(0.0235) Grad: 16529.8008  LR: 0.00001079  \n","Epoch: [2][2800/3433] Elapsed 8m 19s (remain 1m 52s) Loss: 0.0289(0.0235) Grad: 21819.2656  LR: 0.00001067  \n","Epoch: [2][2900/3433] Elapsed 8m 37s (remain 1m 34s) Loss: 0.0044(0.0235) Grad: 1983.3743  LR: 0.00001054  \n","Epoch: [2][3000/3433] Elapsed 8m 54s (remain 1m 16s) Loss: 0.0129(0.0235) Grad: 2553.4109  LR: 0.00001041  \n","Epoch: [2][3100/3433] Elapsed 9m 12s (remain 0m 59s) Loss: 0.0673(0.0236) Grad: 20413.1035  LR: 0.00001029  \n","Epoch: [2][3200/3433] Elapsed 9m 29s (remain 0m 41s) Loss: 0.0463(0.0236) Grad: 12788.2188  LR: 0.00001016  \n","Epoch: [2][3300/3433] Elapsed 9m 47s (remain 0m 23s) Loss: 0.0083(0.0237) Grad: 4058.5312  LR: 0.00001003  \n","Epoch: [2][3400/3433] Elapsed 10m 4s (remain 0m 5s) Loss: 0.0367(0.0238) Grad: 11899.6201  LR: 0.00000990  \n","Epoch: [2][3432/3433] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0184(0.0238) Grad: 6065.9414  LR: 0.00000986  \n","EVAL: [0/215] Elapsed 0m 0s (remain 1m 0s) Loss: 0.1044(0.1044) \n","EVAL: [100/215] Elapsed 0m 9s (remain 0m 11s) Loss: 0.1324(0.0969) \n","EVAL: [200/215] Elapsed 0m 19s (remain 0m 1s) Loss: 0.0897(0.0969) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0238  avg_val_loss: 0.0976  time: 632s\n","Epoch 2 - Score: 0.7534\n","Epoch 2 - Save Best Score: 0.7534 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [214/215] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0518(0.0976) \n","Epoch: [3][0/3433] Elapsed 0m 0s (remain 23m 26s) Loss: 0.0158(0.0158) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3433] Elapsed 0m 18s (remain 10m 0s) Loss: 0.0092(0.0198) Grad: 10892.2061  LR: 0.00000972  \n","Epoch: [3][200/3433] Elapsed 0m 36s (remain 9m 39s) Loss: 0.0449(0.0204) Grad: 33299.1211  LR: 0.00000959  \n","Epoch: [3][300/3433] Elapsed 0m 53s (remain 9m 19s) Loss: 0.0153(0.0194) Grad: 6154.2153  LR: 0.00000946  \n","Epoch: [3][400/3433] Elapsed 1m 11s (remain 9m 0s) Loss: 0.0197(0.0194) Grad: 6042.3223  LR: 0.00000933  \n","Epoch: [3][500/3433] Elapsed 1m 29s (remain 8m 41s) Loss: 0.0210(0.0193) Grad: 17098.0078  LR: 0.00000919  \n","Epoch: [3][600/3433] Elapsed 1m 46s (remain 8m 23s) Loss: 0.0145(0.0191) Grad: 9122.3535  LR: 0.00000906  \n","Epoch: [3][700/3433] Elapsed 2m 4s (remain 8m 5s) Loss: 0.0084(0.0190) Grad: 6919.8013  LR: 0.00000892  \n","Epoch: [3][800/3433] Elapsed 2m 22s (remain 7m 47s) Loss: 0.0170(0.0188) Grad: 3982.9629  LR: 0.00000879  \n","Epoch: [3][900/3433] Elapsed 2m 39s (remain 7m 29s) Loss: 0.0095(0.0186) Grad: 7867.5542  LR: 0.00000865  \n","Epoch: [3][1000/3433] Elapsed 2m 57s (remain 7m 11s) Loss: 0.0364(0.0185) Grad: 10233.5469  LR: 0.00000852  \n","Epoch: [3][1100/3433] Elapsed 3m 15s (remain 6m 53s) Loss: 0.0158(0.0185) Grad: 5320.5405  LR: 0.00000838  \n","Epoch: [3][1200/3433] Elapsed 3m 32s (remain 6m 35s) Loss: 0.0181(0.0184) Grad: 6455.2148  LR: 0.00000824  \n","Epoch: [3][1300/3433] Elapsed 3m 50s (remain 6m 17s) Loss: 0.0137(0.0185) Grad: 8009.5366  LR: 0.00000811  \n","Epoch: [3][1400/3433] Elapsed 4m 8s (remain 6m 0s) Loss: 0.0053(0.0185) Grad: 8711.3789  LR: 0.00000797  \n","Epoch: [3][1500/3433] Elapsed 4m 26s (remain 5m 42s) Loss: 0.0170(0.0183) Grad: 4950.7017  LR: 0.00000783  \n","Epoch: [3][1600/3433] Elapsed 4m 44s (remain 5m 25s) Loss: 0.0096(0.0182) Grad: 5766.9565  LR: 0.00000769  \n","Epoch: [3][1700/3433] Elapsed 5m 2s (remain 5m 7s) Loss: 0.0243(0.0183) Grad: 20143.8027  LR: 0.00000756  \n","Epoch: [3][1800/3433] Elapsed 5m 20s (remain 4m 50s) Loss: 0.0145(0.0182) Grad: 21093.7012  LR: 0.00000742  \n","Epoch: [3][1900/3433] Elapsed 5m 38s (remain 4m 32s) Loss: 0.0195(0.0182) Grad: 4246.5547  LR: 0.00000728  \n","Epoch: [3][2000/3433] Elapsed 5m 56s (remain 4m 14s) Loss: 0.0401(0.0182) Grad: 21505.2246  LR: 0.00000714  \n","Epoch: [3][2100/3433] Elapsed 6m 14s (remain 3m 57s) Loss: 0.0312(0.0181) Grad: 37227.5000  LR: 0.00000701  \n","Epoch: [3][2200/3433] Elapsed 6m 31s (remain 3m 39s) Loss: 0.0275(0.0182) Grad: 5412.0684  LR: 0.00000687  \n","Epoch: [3][2300/3433] Elapsed 6m 49s (remain 3m 21s) Loss: 0.0048(0.0182) Grad: 6563.2393  LR: 0.00000673  \n","Epoch: [3][2400/3433] Elapsed 7m 7s (remain 3m 3s) Loss: 0.0168(0.0182) Grad: 18788.1602  LR: 0.00000659  \n","Epoch: [3][2500/3433] Elapsed 7m 25s (remain 2m 45s) Loss: 0.0059(0.0182) Grad: 8971.3076  LR: 0.00000646  \n","Epoch: [3][2600/3433] Elapsed 7m 42s (remain 2m 28s) Loss: 0.0054(0.0181) Grad: 1762.1593  LR: 0.00000632  \n","Epoch: [3][2700/3433] Elapsed 8m 0s (remain 2m 10s) Loss: 0.0111(0.0180) Grad: 4526.0332  LR: 0.00000619  \n","Epoch: [3][2800/3433] Elapsed 8m 18s (remain 1m 52s) Loss: 0.0343(0.0180) Grad: 25230.5508  LR: 0.00000605  \n","Epoch: [3][2900/3433] Elapsed 8m 35s (remain 1m 34s) Loss: 0.0144(0.0180) Grad: 4155.2866  LR: 0.00000592  \n","Epoch: [3][3000/3433] Elapsed 8m 53s (remain 1m 16s) Loss: 0.0107(0.0180) Grad: 18386.9316  LR: 0.00000578  \n","Epoch: [3][3100/3433] Elapsed 9m 11s (remain 0m 59s) Loss: 0.0315(0.0180) Grad: 35827.3359  LR: 0.00000565  \n","Epoch: [3][3200/3433] Elapsed 9m 28s (remain 0m 41s) Loss: 0.0215(0.0179) Grad: 28689.7246  LR: 0.00000551  \n","Epoch: [3][3300/3433] Elapsed 9m 46s (remain 0m 23s) Loss: 0.0165(0.0179) Grad: 11336.6553  LR: 0.00000538  \n","Epoch: [3][3400/3433] Elapsed 10m 4s (remain 0m 5s) Loss: 0.0332(0.0179) Grad: 14748.5469  LR: 0.00000525  \n","Epoch: [3][3432/3433] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0324(0.0179) Grad: 6704.7964  LR: 0.00000521  \n","EVAL: [0/215] Elapsed 0m 0s (remain 1m 1s) Loss: 0.1024(0.1024) \n","EVAL: [100/215] Elapsed 0m 9s (remain 0m 11s) Loss: 0.1370(0.0990) \n","EVAL: [200/215] Elapsed 0m 19s (remain 0m 1s) Loss: 0.0895(0.0991) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0179  avg_val_loss: 0.0999  time: 631s\n","Epoch 3 - Score: 0.7679\n","Epoch 3 - Save Best Score: 0.7679 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [214/215] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0638(0.0999) \n","Epoch: [4][0/3433] Elapsed 0m 0s (remain 23m 56s) Loss: 0.0106(0.0106) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3433] Elapsed 0m 18s (remain 10m 1s) Loss: 0.0077(0.0141) Grad: 25121.7227  LR: 0.00000508  \n","Epoch: [4][200/3433] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0065(0.0137) Grad: 12378.2510  LR: 0.00000495  \n","Epoch: [4][300/3433] Elapsed 0m 53s (remain 9m 20s) Loss: 0.0091(0.0136) Grad: 5606.1025  LR: 0.00000482  \n","Epoch: [4][400/3433] Elapsed 1m 11s (remain 9m 0s) Loss: 0.0073(0.0135) Grad: 4316.2925  LR: 0.00000469  \n","Epoch: [4][500/3433] Elapsed 1m 29s (remain 8m 41s) Loss: 0.0069(0.0135) Grad: 8950.2334  LR: 0.00000456  \n","Epoch: [4][600/3433] Elapsed 1m 46s (remain 8m 22s) Loss: 0.0074(0.0135) Grad: 4690.7427  LR: 0.00000444  \n","Epoch: [4][700/3433] Elapsed 2m 4s (remain 8m 4s) Loss: 0.0070(0.0134) Grad: 5508.4497  LR: 0.00000431  \n","Epoch: [4][800/3433] Elapsed 2m 21s (remain 7m 46s) Loss: 0.0046(0.0134) Grad: 6037.2754  LR: 0.00000419  \n","Epoch: [4][900/3433] Elapsed 2m 39s (remain 7m 28s) Loss: 0.0119(0.0134) Grad: 16805.0605  LR: 0.00000406  \n","Epoch: [4][1000/3433] Elapsed 2m 57s (remain 7m 10s) Loss: 0.0051(0.0135) Grad: 2185.9290  LR: 0.00000394  \n","Epoch: [4][1100/3433] Elapsed 3m 14s (remain 6m 52s) Loss: 0.0138(0.0135) Grad: 19226.1035  LR: 0.00000382  \n","Epoch: [4][1200/3433] Elapsed 3m 32s (remain 6m 35s) Loss: 0.0081(0.0136) Grad: 14035.8184  LR: 0.00000370  \n","Epoch: [4][1300/3433] Elapsed 3m 50s (remain 6m 17s) Loss: 0.0157(0.0136) Grad: 14924.0869  LR: 0.00000358  \n","Epoch: [4][1400/3433] Elapsed 4m 8s (remain 6m 0s) Loss: 0.0101(0.0135) Grad: 10732.5830  LR: 0.00000347  \n","Epoch: [4][1500/3433] Elapsed 4m 26s (remain 5m 43s) Loss: 0.0099(0.0138) Grad: 9524.9219  LR: 0.00000335  \n","Epoch: [4][1600/3433] Elapsed 4m 44s (remain 5m 26s) Loss: 0.0114(0.0137) Grad: 4008.4312  LR: 0.00000324  \n","Epoch: [4][1700/3433] Elapsed 5m 3s (remain 5m 8s) Loss: 0.0121(0.0136) Grad: 6903.0601  LR: 0.00000313  \n","Epoch: [4][1800/3433] Elapsed 5m 21s (remain 4m 51s) Loss: 0.0101(0.0137) Grad: 10829.9189  LR: 0.00000301  \n","Epoch: [4][1900/3433] Elapsed 5m 39s (remain 4m 33s) Loss: 0.0055(0.0136) Grad: 10770.0117  LR: 0.00000290  \n","Epoch: [4][2000/3433] Elapsed 5m 57s (remain 4m 15s) Loss: 0.0121(0.0136) Grad: 11849.3984  LR: 0.00000280  \n","Epoch: [4][2100/3433] Elapsed 6m 15s (remain 3m 57s) Loss: 0.0223(0.0135) Grad: 5575.1421  LR: 0.00000269  \n","Epoch: [4][2200/3433] Elapsed 6m 33s (remain 3m 40s) Loss: 0.0185(0.0135) Grad: 11458.3496  LR: 0.00000259  \n","Epoch: [4][2300/3433] Elapsed 6m 51s (remain 3m 22s) Loss: 0.0214(0.0134) Grad: 8049.5933  LR: 0.00000248  \n","Epoch: [4][2400/3433] Elapsed 7m 8s (remain 3m 4s) Loss: 0.0086(0.0134) Grad: 13778.7607  LR: 0.00000238  \n","Epoch: [4][2500/3433] Elapsed 7m 26s (remain 2m 46s) Loss: 0.0123(0.0133) Grad: 7315.8887  LR: 0.00000228  \n","Epoch: [4][2600/3433] Elapsed 7m 44s (remain 2m 28s) Loss: 0.0041(0.0133) Grad: 3956.6975  LR: 0.00000218  \n","Epoch: [4][2700/3433] Elapsed 8m 1s (remain 2m 10s) Loss: 0.0049(0.0133) Grad: 15038.5508  LR: 0.00000209  \n","Epoch: [4][2800/3433] Elapsed 8m 19s (remain 1m 52s) Loss: 0.0367(0.0132) Grad: 17796.1602  LR: 0.00000199  \n","Epoch: [4][2900/3433] Elapsed 8m 36s (remain 1m 34s) Loss: 0.0043(0.0132) Grad: 3574.3630  LR: 0.00000190  \n","Epoch: [4][3000/3433] Elapsed 8m 54s (remain 1m 16s) Loss: 0.0113(0.0132) Grad: 11036.5596  LR: 0.00000181  \n","Epoch: [4][3100/3433] Elapsed 9m 12s (remain 0m 59s) Loss: 0.0074(0.0131) Grad: 3612.4084  LR: 0.00000172  \n","Epoch: [4][3200/3433] Elapsed 9m 29s (remain 0m 41s) Loss: 0.0184(0.0132) Grad: 16322.3975  LR: 0.00000163  \n","Epoch: [4][3300/3433] Elapsed 9m 47s (remain 0m 23s) Loss: 0.0066(0.0132) Grad: 5140.3203  LR: 0.00000155  \n","Epoch: [4][3400/3433] Elapsed 10m 5s (remain 0m 5s) Loss: 0.0192(0.0132) Grad: 16721.6621  LR: 0.00000147  \n","Epoch: [4][3432/3433] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0072(0.0132) Grad: 4911.9688  LR: 0.00000144  \n","EVAL: [0/215] Elapsed 0m 0s (remain 1m 3s) Loss: 0.1002(0.1002) \n","EVAL: [100/215] Elapsed 0m 9s (remain 0m 11s) Loss: 0.1336(0.0990) \n","EVAL: [200/215] Elapsed 0m 19s (remain 0m 1s) Loss: 0.0834(0.0985) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0132  avg_val_loss: 0.0994  time: 632s\n","Epoch 4 - Score: 0.7709\n","Epoch 4 - Save Best Score: 0.7709 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [214/215] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0637(0.0994) \n","Epoch: [5][0/3433] Elapsed 0m 0s (remain 23m 42s) Loss: 0.0061(0.0061) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3433] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0039(0.0104) Grad: 6823.8018  LR: 0.00000136  \n","Epoch: [5][200/3433] Elapsed 0m 36s (remain 9m 47s) Loss: 0.0042(0.0103) Grad: 6803.6982  LR: 0.00000128  \n","Epoch: [5][300/3433] Elapsed 0m 54s (remain 9m 22s) Loss: 0.0012(0.0101) Grad: 1652.0654  LR: 0.00000121  \n","Epoch: [5][400/3433] Elapsed 1m 11s (remain 9m 2s) Loss: 0.0093(0.0102) Grad: 7020.4224  LR: 0.00000113  \n","Epoch: [5][500/3433] Elapsed 1m 29s (remain 8m 43s) Loss: 0.0055(0.0101) Grad: 2994.4436  LR: 0.00000106  \n","Epoch: [5][600/3433] Elapsed 1m 47s (remain 8m 25s) Loss: 0.0053(0.0103) Grad: 8315.7900  LR: 0.00000099  \n","Epoch: [5][700/3433] Elapsed 2m 5s (remain 8m 8s) Loss: 0.0369(0.0105) Grad: 8212.0312  LR: 0.00000092  \n","Epoch: [5][800/3433] Elapsed 2m 23s (remain 7m 50s) Loss: 0.0087(0.0104) Grad: 9357.1338  LR: 0.00000086  \n","Epoch: [5][900/3433] Elapsed 2m 41s (remain 7m 32s) Loss: 0.0170(0.0104) Grad: 18765.1758  LR: 0.00000080  \n","Epoch: [5][1000/3433] Elapsed 2m 58s (remain 7m 14s) Loss: 0.0088(0.0104) Grad: 2320.7244  LR: 0.00000073  \n","Epoch: [5][1100/3433] Elapsed 3m 16s (remain 6m 56s) Loss: 0.0094(0.0104) Grad: 4098.3794  LR: 0.00000068  \n","Epoch: [5][1200/3433] Elapsed 3m 34s (remain 6m 39s) Loss: 0.0054(0.0104) Grad: 5658.9902  LR: 0.00000062  \n","Epoch: [5][1300/3433] Elapsed 3m 52s (remain 6m 21s) Loss: 0.0596(0.0106) Grad: 24717.5820  LR: 0.00000057  \n","Epoch: [5][1400/3433] Elapsed 4m 10s (remain 6m 3s) Loss: 0.0067(0.0106) Grad: 4445.6519  LR: 0.00000052  \n","Epoch: [5][1500/3433] Elapsed 4m 28s (remain 5m 45s) Loss: 0.0084(0.0105) Grad: 12486.7266  LR: 0.00000047  \n","Epoch: [5][1600/3433] Elapsed 4m 46s (remain 5m 28s) Loss: 0.0142(0.0104) Grad: 17802.6074  LR: 0.00000042  \n","Epoch: [5][1700/3433] Elapsed 5m 4s (remain 5m 10s) Loss: 0.0097(0.0104) Grad: 8529.0371  LR: 0.00000038  \n","Epoch: [5][1800/3433] Elapsed 5m 22s (remain 4m 52s) Loss: 0.0078(0.0105) Grad: 13833.9502  LR: 0.00000033  \n","Epoch: [5][1900/3433] Elapsed 5m 40s (remain 4m 34s) Loss: 0.0054(0.0104) Grad: 8451.8066  LR: 0.00000029  \n","Epoch: [5][2000/3433] Elapsed 5m 58s (remain 4m 16s) Loss: 0.0019(0.0103) Grad: 4209.4302  LR: 0.00000026  \n","Epoch: [5][2100/3433] Elapsed 6m 16s (remain 3m 58s) Loss: 0.0063(0.0103) Grad: 6501.4839  LR: 0.00000022  \n","Epoch: [5][2200/3433] Elapsed 6m 34s (remain 3m 40s) Loss: 0.0194(0.0103) Grad: 36043.3477  LR: 0.00000019  \n","Epoch: [5][2300/3433] Elapsed 6m 51s (remain 3m 22s) Loss: 0.0056(0.0102) Grad: 4237.7886  LR: 0.00000016  \n","Epoch: [5][2400/3433] Elapsed 7m 9s (remain 3m 4s) Loss: 0.0020(0.0102) Grad: 6598.9194  LR: 0.00000013  \n","Epoch: [5][2500/3433] Elapsed 7m 27s (remain 2m 46s) Loss: 0.0063(0.0103) Grad: 2902.3032  LR: 0.00000011  \n","Epoch: [5][2600/3433] Elapsed 7m 44s (remain 2m 28s) Loss: 0.0092(0.0103) Grad: 6198.0127  LR: 0.00000009  \n","Epoch: [5][2700/3433] Elapsed 8m 2s (remain 2m 10s) Loss: 0.0100(0.0103) Grad: 14765.6855  LR: 0.00000007  \n","Epoch: [5][2800/3433] Elapsed 8m 20s (remain 1m 52s) Loss: 0.0091(0.0103) Grad: 6772.7612  LR: 0.00000005  \n","Epoch: [5][2900/3433] Elapsed 8m 37s (remain 1m 34s) Loss: 0.0018(0.0103) Grad: 6018.8228  LR: 0.00000004  \n","Epoch: [5][3000/3433] Elapsed 8m 55s (remain 1m 17s) Loss: 0.0109(0.0103) Grad: 4710.5483  LR: 0.00000002  \n","Epoch: [5][3100/3433] Elapsed 9m 13s (remain 0m 59s) Loss: 0.0220(0.0104) Grad: 10043.4561  LR: 0.00000001  \n","Epoch: [5][3200/3433] Elapsed 9m 30s (remain 0m 41s) Loss: 0.0011(0.0104) Grad: 3023.9915  LR: 0.00000001  \n","Epoch: [5][3300/3433] Elapsed 9m 48s (remain 0m 23s) Loss: 0.0100(0.0104) Grad: 17961.0723  LR: 0.00000000  \n","Epoch: [5][3400/3433] Elapsed 10m 5s (remain 0m 5s) Loss: 0.0153(0.0105) Grad: 10816.4941  LR: 0.00000000  \n","Epoch: [5][3432/3433] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0062(0.0105) Grad: 11241.7090  LR: 0.00000000  \n","EVAL: [0/215] Elapsed 0m 0s (remain 1m 2s) Loss: 0.1017(0.1017) \n","EVAL: [100/215] Elapsed 0m 9s (remain 0m 11s) Loss: 0.1322(0.1008) \n","EVAL: [200/215] Elapsed 0m 19s (remain 0m 1s) Loss: 0.0861(0.1001) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0105  avg_val_loss: 0.1009  time: 633s\n","Epoch 5 - Score: 0.7668\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [214/215] Elapsed 0m 20s (remain 0m 0s) Loss: 0.0628(0.1009) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.7709\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3385] Elapsed 0m 0s (remain 22m 42s) Loss: 1.0146(1.0146) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3385] Elapsed 0m 17s (remain 9m 42s) Loss: 0.1791(0.2289) Grad: 5913.0020  LR: 0.00001500  \n","Epoch: [1][200/3385] Elapsed 0m 35s (remain 9m 25s) Loss: 0.2107(0.1730) Grad: 19656.3066  LR: 0.00001500  \n","Epoch: [1][300/3385] Elapsed 0m 53s (remain 9m 8s) Loss: 0.0992(0.1484) Grad: 2880.1682  LR: 0.00001499  \n","Epoch: [1][400/3385] Elapsed 1m 11s (remain 8m 50s) Loss: 0.0371(0.1306) Grad: 1998.3474  LR: 0.00001498  \n","Epoch: [1][500/3385] Elapsed 1m 29s (remain 8m 33s) Loss: 0.0672(0.1178) Grad: 2147.2075  LR: 0.00001497  \n","Epoch: [1][600/3385] Elapsed 1m 46s (remain 8m 15s) Loss: 0.0984(0.1123) Grad: 15883.5332  LR: 0.00001496  \n","Epoch: [1][700/3385] Elapsed 2m 4s (remain 7m 57s) Loss: 0.0400(0.1058) Grad: 7867.4565  LR: 0.00001494  \n","Epoch: [1][800/3385] Elapsed 2m 22s (remain 7m 39s) Loss: 0.1689(0.1007) Grad: 6038.0757  LR: 0.00001493  \n","Epoch: [1][900/3385] Elapsed 2m 40s (remain 7m 22s) Loss: 0.0182(0.0965) Grad: 1882.9573  LR: 0.00001491  \n","Epoch: [1][1000/3385] Elapsed 2m 58s (remain 7m 5s) Loss: 0.1393(0.0927) Grad: 19184.3652  LR: 0.00001488  \n","Epoch: [1][1100/3385] Elapsed 3m 16s (remain 6m 48s) Loss: 0.0428(0.0893) Grad: 1939.2118  LR: 0.00001486  \n","Epoch: [1][1200/3385] Elapsed 3m 34s (remain 6m 30s) Loss: 0.0408(0.0859) Grad: 4545.7095  LR: 0.00001483  \n","Epoch: [1][1300/3385] Elapsed 3m 52s (remain 6m 13s) Loss: 0.0174(0.0828) Grad: 2927.7590  LR: 0.00001480  \n","Epoch: [1][1400/3385] Elapsed 4m 10s (remain 5m 55s) Loss: 0.0238(0.0805) Grad: 2824.1299  LR: 0.00001476  \n","Epoch: [1][1500/3385] Elapsed 4m 28s (remain 5m 37s) Loss: 0.0512(0.0780) Grad: 5803.9434  LR: 0.00001473  \n","Epoch: [1][1600/3385] Elapsed 4m 46s (remain 5m 19s) Loss: 0.0538(0.0756) Grad: 2722.9536  LR: 0.00001469  \n","Epoch: [1][1700/3385] Elapsed 5m 4s (remain 5m 1s) Loss: 0.0413(0.0733) Grad: 5422.4233  LR: 0.00001465  \n","Epoch: [1][1800/3385] Elapsed 5m 22s (remain 4m 43s) Loss: 0.0330(0.0717) Grad: 6500.1470  LR: 0.00001461  \n","Epoch: [1][1900/3385] Elapsed 5m 40s (remain 4m 26s) Loss: 0.0334(0.0698) Grad: 2194.5215  LR: 0.00001456  \n","Epoch: [1][2000/3385] Elapsed 5m 58s (remain 4m 7s) Loss: 0.0250(0.0681) Grad: 3060.4858  LR: 0.00001451  \n","Epoch: [1][2100/3385] Elapsed 6m 16s (remain 3m 49s) Loss: 0.0317(0.0666) Grad: 7010.9824  LR: 0.00001446  \n","Epoch: [1][2200/3385] Elapsed 6m 33s (remain 3m 31s) Loss: 0.0184(0.0650) Grad: 10510.7373  LR: 0.00001441  \n","Epoch: [1][2300/3385] Elapsed 6m 51s (remain 3m 13s) Loss: 0.0268(0.0635) Grad: 7704.4849  LR: 0.00001435  \n","Epoch: [1][2400/3385] Elapsed 7m 9s (remain 2m 55s) Loss: 0.0454(0.0622) Grad: 17712.7832  LR: 0.00001429  \n","Epoch: [1][2500/3385] Elapsed 7m 26s (remain 2m 37s) Loss: 0.0211(0.0610) Grad: 8833.4648  LR: 0.00001423  \n","Epoch: [1][2600/3385] Elapsed 7m 44s (remain 2m 20s) Loss: 0.0066(0.0599) Grad: 3055.3784  LR: 0.00001417  \n","Epoch: [1][2700/3385] Elapsed 8m 2s (remain 2m 2s) Loss: 0.0331(0.0589) Grad: 19327.6387  LR: 0.00001411  \n","Epoch: [1][2800/3385] Elapsed 8m 19s (remain 1m 44s) Loss: 0.0174(0.0579) Grad: 4325.6836  LR: 0.00001404  \n","Epoch: [1][2900/3385] Elapsed 8m 37s (remain 1m 26s) Loss: 0.0252(0.0570) Grad: 9556.7275  LR: 0.00001397  \n","Epoch: [1][3000/3385] Elapsed 8m 55s (remain 1m 8s) Loss: 0.0250(0.0562) Grad: 5186.2949  LR: 0.00001390  \n","Epoch: [1][3100/3385] Elapsed 9m 13s (remain 0m 50s) Loss: 0.0189(0.0553) Grad: 4638.3408  LR: 0.00001382  \n","Epoch: [1][3200/3385] Elapsed 9m 30s (remain 0m 32s) Loss: 0.0369(0.0545) Grad: 16285.3848  LR: 0.00001375  \n","Epoch: [1][3300/3385] Elapsed 9m 48s (remain 0m 14s) Loss: 0.0485(0.0538) Grad: 13890.4746  LR: 0.00001367  \n","Epoch: [1][3384/3385] Elapsed 10m 3s (remain 0m 0s) Loss: 0.0270(0.0532) Grad: 11241.5166  LR: 0.00001360  \n","EVAL: [0/262] Elapsed 0m 0s (remain 1m 23s) Loss: 0.1937(0.1937) \n","EVAL: [100/262] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0936(0.1068) \n","EVAL: [200/262] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0754(0.1028) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0532  avg_val_loss: 0.1018  time: 629s\n","Epoch 1 - Score: 0.7901\n","Epoch 1 - Save Best Score: 0.7901 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [261/262] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1964(0.1018) \n","Epoch: [2][0/3385] Elapsed 0m 0s (remain 25m 6s) Loss: 0.0303(0.0303) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3385] Elapsed 0m 18s (remain 10m 0s) Loss: 0.0180(0.0238) Grad: 7058.1494  LR: 0.00001352  \n","Epoch: [2][200/3385] Elapsed 0m 36s (remain 9m 39s) Loss: 0.0285(0.0237) Grad: 6669.6587  LR: 0.00001343  \n","Epoch: [2][300/3385] Elapsed 0m 54s (remain 9m 17s) Loss: 0.0235(0.0238) Grad: 26946.9180  LR: 0.00001335  \n","Epoch: [2][400/3385] Elapsed 1m 12s (remain 8m 56s) Loss: 0.0238(0.0244) Grad: 12049.7471  LR: 0.00001326  \n","Epoch: [2][500/3385] Elapsed 1m 29s (remain 8m 36s) Loss: 0.0099(0.0240) Grad: 6589.4912  LR: 0.00001317  \n","Epoch: [2][600/3385] Elapsed 1m 47s (remain 8m 17s) Loss: 0.0217(0.0240) Grad: 30572.6191  LR: 0.00001308  \n","Epoch: [2][700/3385] Elapsed 2m 5s (remain 7m 59s) Loss: 0.0325(0.0240) Grad: 9335.1562  LR: 0.00001298  \n","Epoch: [2][800/3385] Elapsed 2m 22s (remain 7m 41s) Loss: 0.0306(0.0239) Grad: 32545.2070  LR: 0.00001288  \n","Epoch: [2][900/3385] Elapsed 2m 40s (remain 7m 23s) Loss: 0.0332(0.0238) Grad: 15876.9268  LR: 0.00001279  \n","Epoch: [2][1000/3385] Elapsed 2m 58s (remain 7m 6s) Loss: 0.0124(0.0238) Grad: 7418.3530  LR: 0.00001269  \n","Epoch: [2][1100/3385] Elapsed 3m 16s (remain 6m 48s) Loss: 0.0367(0.0235) Grad: 13916.0391  LR: 0.00001259  \n","Epoch: [2][1200/3385] Elapsed 3m 35s (remain 6m 31s) Loss: 0.0105(0.0238) Grad: 14911.1953  LR: 0.00001248  \n","Epoch: [2][1300/3385] Elapsed 3m 53s (remain 6m 13s) Loss: 0.0111(0.0240) Grad: 12712.3555  LR: 0.00001238  \n","Epoch: [2][1400/3385] Elapsed 4m 11s (remain 5m 55s) Loss: 0.0190(0.0240) Grad: 19532.2773  LR: 0.00001227  \n","Epoch: [2][1500/3385] Elapsed 4m 29s (remain 5m 37s) Loss: 0.0292(0.0241) Grad: 9960.2275  LR: 0.00001216  \n","Epoch: [2][1600/3385] Elapsed 4m 47s (remain 5m 19s) Loss: 0.0175(0.0241) Grad: 10488.4170  LR: 0.00001205  \n","Epoch: [2][1700/3385] Elapsed 5m 5s (remain 5m 2s) Loss: 0.0285(0.0242) Grad: 11861.0215  LR: 0.00001194  \n","Epoch: [2][1800/3385] Elapsed 5m 23s (remain 4m 44s) Loss: 0.0095(0.0242) Grad: 15318.2832  LR: 0.00001183  \n","Epoch: [2][1900/3385] Elapsed 5m 41s (remain 4m 26s) Loss: 0.0181(0.0241) Grad: 8251.6650  LR: 0.00001171  \n","Epoch: [2][2000/3385] Elapsed 5m 58s (remain 4m 8s) Loss: 0.0209(0.0240) Grad: 8571.7354  LR: 0.00001159  \n","Epoch: [2][2100/3385] Elapsed 6m 16s (remain 3m 50s) Loss: 0.0102(0.0241) Grad: 7663.4922  LR: 0.00001148  \n","Epoch: [2][2200/3385] Elapsed 6m 34s (remain 3m 32s) Loss: 0.0267(0.0241) Grad: 5569.4683  LR: 0.00001136  \n","Epoch: [2][2300/3385] Elapsed 6m 52s (remain 3m 14s) Loss: 0.0160(0.0240) Grad: 10221.4346  LR: 0.00001124  \n","Epoch: [2][2400/3385] Elapsed 7m 9s (remain 2m 56s) Loss: 0.0076(0.0240) Grad: 18081.5586  LR: 0.00001112  \n","Epoch: [2][2500/3385] Elapsed 7m 27s (remain 2m 38s) Loss: 0.0384(0.0239) Grad: 12295.4922  LR: 0.00001099  \n","Epoch: [2][2600/3385] Elapsed 7m 45s (remain 2m 20s) Loss: 0.0599(0.0240) Grad: 29638.7910  LR: 0.00001087  \n","Epoch: [2][2700/3385] Elapsed 8m 2s (remain 2m 2s) Loss: 0.0269(0.0241) Grad: 8414.9688  LR: 0.00001074  \n","Epoch: [2][2800/3385] Elapsed 8m 20s (remain 1m 44s) Loss: 0.0126(0.0241) Grad: 6791.5708  LR: 0.00001062  \n","Epoch: [2][2900/3385] Elapsed 8m 38s (remain 1m 26s) Loss: 0.0075(0.0241) Grad: 6381.4082  LR: 0.00001049  \n","Epoch: [2][3000/3385] Elapsed 8m 56s (remain 1m 8s) Loss: 0.0039(0.0241) Grad: 4808.1440  LR: 0.00001036  \n","Epoch: [2][3100/3385] Elapsed 9m 13s (remain 0m 50s) Loss: 0.0392(0.0240) Grad: 31859.3711  LR: 0.00001023  \n","Epoch: [2][3200/3385] Elapsed 9m 31s (remain 0m 32s) Loss: 0.0142(0.0240) Grad: 13632.6797  LR: 0.00001010  \n","Epoch: [2][3300/3385] Elapsed 9m 49s (remain 0m 14s) Loss: 0.0293(0.0239) Grad: 24330.3945  LR: 0.00000997  \n","Epoch: [2][3384/3385] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0224(0.0239) Grad: 7549.3550  LR: 0.00000986  \n","EVAL: [0/262] Elapsed 0m 0s (remain 1m 24s) Loss: 0.1970(0.1970) \n","EVAL: [100/262] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1072(0.1064) \n","EVAL: [200/262] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0760(0.1028) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0239  avg_val_loss: 0.1021  time: 630s\n","Epoch 2 - Score: 0.7886\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [261/262] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1974(0.1021) \n","Epoch: [3][0/3385] Elapsed 0m 0s (remain 25m 8s) Loss: 0.0215(0.0215) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3385] Elapsed 0m 18s (remain 9m 47s) Loss: 0.0137(0.0176) Grad: 22388.2598  LR: 0.00000972  \n","Epoch: [3][200/3385] Elapsed 0m 35s (remain 9m 27s) Loss: 0.0485(0.0179) Grad: 48329.6953  LR: 0.00000959  \n","Epoch: [3][300/3385] Elapsed 0m 53s (remain 9m 8s) Loss: 0.0141(0.0180) Grad: 8485.2305  LR: 0.00000946  \n","Epoch: [3][400/3385] Elapsed 1m 11s (remain 8m 50s) Loss: 0.0088(0.0181) Grad: 5705.5923  LR: 0.00000932  \n","Epoch: [3][500/3385] Elapsed 1m 28s (remain 8m 32s) Loss: 0.0109(0.0181) Grad: 15778.8916  LR: 0.00000919  \n","Epoch: [3][600/3385] Elapsed 1m 46s (remain 8m 14s) Loss: 0.0106(0.0183) Grad: 2967.3740  LR: 0.00000905  \n","Epoch: [3][700/3385] Elapsed 2m 4s (remain 7m 56s) Loss: 0.0155(0.0184) Grad: 8304.9707  LR: 0.00000891  \n","Epoch: [3][800/3385] Elapsed 2m 22s (remain 7m 39s) Loss: 0.0443(0.0184) Grad: 19286.1270  LR: 0.00000877  \n","Epoch: [3][900/3385] Elapsed 2m 40s (remain 7m 21s) Loss: 0.0353(0.0186) Grad: 92544.1719  LR: 0.00000864  \n","Epoch: [3][1000/3385] Elapsed 2m 58s (remain 7m 5s) Loss: 0.0195(0.0184) Grad: 22264.8906  LR: 0.00000850  \n","Epoch: [3][1100/3385] Elapsed 3m 16s (remain 6m 47s) Loss: 0.0395(0.0184) Grad: 17511.2363  LR: 0.00000836  \n","Epoch: [3][1200/3385] Elapsed 3m 34s (remain 6m 30s) Loss: 0.0170(0.0187) Grad: 8208.6016  LR: 0.00000822  \n","Epoch: [3][1300/3385] Elapsed 3m 52s (remain 6m 12s) Loss: 0.0181(0.0188) Grad: 13093.3760  LR: 0.00000808  \n","Epoch: [3][1400/3385] Elapsed 4m 10s (remain 5m 55s) Loss: 0.0355(0.0188) Grad: 8466.9375  LR: 0.00000794  \n","Epoch: [3][1500/3385] Elapsed 4m 28s (remain 5m 37s) Loss: 0.0232(0.0187) Grad: 9681.6621  LR: 0.00000780  \n","Epoch: [3][1600/3385] Elapsed 4m 46s (remain 5m 19s) Loss: 0.0163(0.0187) Grad: 5336.7861  LR: 0.00000766  \n","Epoch: [3][1700/3385] Elapsed 5m 4s (remain 5m 1s) Loss: 0.0054(0.0186) Grad: 19982.6914  LR: 0.00000752  \n","Epoch: [3][1800/3385] Elapsed 5m 22s (remain 4m 44s) Loss: 0.0083(0.0187) Grad: 8184.4526  LR: 0.00000738  \n","Epoch: [3][1900/3385] Elapsed 5m 40s (remain 4m 26s) Loss: 0.0090(0.0186) Grad: 6422.1279  LR: 0.00000725  \n","Epoch: [3][2000/3385] Elapsed 5m 58s (remain 4m 8s) Loss: 0.0098(0.0187) Grad: 7459.3516  LR: 0.00000711  \n","Epoch: [3][2100/3385] Elapsed 6m 16s (remain 3m 50s) Loss: 0.0169(0.0187) Grad: 14875.4502  LR: 0.00000697  \n","Epoch: [3][2200/3385] Elapsed 6m 34s (remain 3m 31s) Loss: 0.0341(0.0188) Grad: 29405.5176  LR: 0.00000683  \n","Epoch: [3][2300/3385] Elapsed 6m 51s (remain 3m 13s) Loss: 0.0133(0.0187) Grad: 12299.3662  LR: 0.00000669  \n","Epoch: [3][2400/3385] Elapsed 7m 9s (remain 2m 55s) Loss: 0.0068(0.0187) Grad: 9511.6318  LR: 0.00000655  \n","Epoch: [3][2500/3385] Elapsed 7m 26s (remain 2m 37s) Loss: 0.0355(0.0186) Grad: 26462.5312  LR: 0.00000641  \n","Epoch: [3][2600/3385] Elapsed 7m 44s (remain 2m 20s) Loss: 0.0501(0.0186) Grad: 25682.0195  LR: 0.00000627  \n","Epoch: [3][2700/3385] Elapsed 8m 2s (remain 2m 2s) Loss: 0.0081(0.0185) Grad: 2628.2278  LR: 0.00000614  \n","Epoch: [3][2800/3385] Elapsed 8m 20s (remain 1m 44s) Loss: 0.0115(0.0185) Grad: 7607.6802  LR: 0.00000600  \n","Epoch: [3][2900/3385] Elapsed 8m 37s (remain 1m 26s) Loss: 0.0234(0.0185) Grad: 18064.4609  LR: 0.00000586  \n","Epoch: [3][3000/3385] Elapsed 8m 55s (remain 1m 8s) Loss: 0.0123(0.0185) Grad: 11690.4756  LR: 0.00000573  \n","Epoch: [3][3100/3385] Elapsed 9m 13s (remain 0m 50s) Loss: 0.0194(0.0184) Grad: 9255.5615  LR: 0.00000559  \n","Epoch: [3][3200/3385] Elapsed 9m 30s (remain 0m 32s) Loss: 0.0088(0.0184) Grad: 10113.7822  LR: 0.00000546  \n","Epoch: [3][3300/3385] Elapsed 9m 48s (remain 0m 14s) Loss: 0.0157(0.0184) Grad: 13304.1074  LR: 0.00000532  \n","Epoch: [3][3384/3385] Elapsed 10m 3s (remain 0m 0s) Loss: 0.0216(0.0184) Grad: 9180.4092  LR: 0.00000521  \n","EVAL: [0/262] Elapsed 0m 0s (remain 1m 24s) Loss: 0.1741(0.1741) \n","EVAL: [100/262] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0853(0.0989) \n","EVAL: [200/262] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0710(0.0960) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0184  avg_val_loss: 0.0956  time: 629s\n","Epoch 3 - Score: 0.7954\n","Epoch 3 - Save Best Score: 0.7954 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [261/262] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1789(0.0956) \n","Epoch: [4][0/3385] Elapsed 0m 0s (remain 25m 22s) Loss: 0.0269(0.0269) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3385] Elapsed 0m 18s (remain 10m 1s) Loss: 0.0089(0.0125) Grad: 10282.4102  LR: 0.00000508  \n","Epoch: [4][200/3385] Elapsed 0m 36s (remain 9m 40s) Loss: 0.0086(0.0134) Grad: 9791.0469  LR: 0.00000494  \n","Epoch: [4][300/3385] Elapsed 0m 54s (remain 9m 16s) Loss: 0.0036(0.0131) Grad: 6016.1963  LR: 0.00000481  \n","Epoch: [4][400/3385] Elapsed 1m 12s (remain 8m 56s) Loss: 0.0172(0.0135) Grad: 15439.0273  LR: 0.00000468  \n","Epoch: [4][500/3385] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0241(0.0136) Grad: 6203.5347  LR: 0.00000456  \n","Epoch: [4][600/3385] Elapsed 1m 47s (remain 8m 17s) Loss: 0.0168(0.0136) Grad: 13182.0684  LR: 0.00000443  \n","Epoch: [4][700/3385] Elapsed 2m 5s (remain 8m 0s) Loss: 0.0148(0.0139) Grad: 11947.9941  LR: 0.00000430  \n","Epoch: [4][800/3385] Elapsed 2m 23s (remain 7m 43s) Loss: 0.0203(0.0137) Grad: 19537.3848  LR: 0.00000417  \n","Epoch: [4][900/3385] Elapsed 2m 41s (remain 7m 25s) Loss: 0.0087(0.0136) Grad: 8900.8633  LR: 0.00000405  \n","Epoch: [4][1000/3385] Elapsed 2m 59s (remain 7m 8s) Loss: 0.0070(0.0138) Grad: 6607.1523  LR: 0.00000393  \n","Epoch: [4][1100/3385] Elapsed 3m 17s (remain 6m 50s) Loss: 0.0092(0.0138) Grad: 11858.9648  LR: 0.00000380  \n","Epoch: [4][1200/3385] Elapsed 3m 35s (remain 6m 32s) Loss: 0.0703(0.0138) Grad: 15927.6279  LR: 0.00000368  \n","Epoch: [4][1300/3385] Elapsed 3m 53s (remain 6m 14s) Loss: 0.0174(0.0138) Grad: 6063.3955  LR: 0.00000356  \n","Epoch: [4][1400/3385] Elapsed 4m 12s (remain 5m 56s) Loss: 0.0178(0.0138) Grad: 10725.5488  LR: 0.00000345  \n","Epoch: [4][1500/3385] Elapsed 4m 30s (remain 5m 39s) Loss: 0.0047(0.0137) Grad: 2126.4568  LR: 0.00000333  \n","Epoch: [4][1600/3385] Elapsed 4m 48s (remain 5m 21s) Loss: 0.0059(0.0137) Grad: 3450.8472  LR: 0.00000321  \n","Epoch: [4][1700/3385] Elapsed 5m 6s (remain 5m 3s) Loss: 0.0095(0.0137) Grad: 3463.2268  LR: 0.00000310  \n","Epoch: [4][1800/3385] Elapsed 5m 23s (remain 4m 44s) Loss: 0.0090(0.0137) Grad: 10143.5469  LR: 0.00000299  \n","Epoch: [4][1900/3385] Elapsed 5m 41s (remain 4m 26s) Loss: 0.0050(0.0136) Grad: 4533.7495  LR: 0.00000288  \n","Epoch: [4][2000/3385] Elapsed 5m 59s (remain 4m 8s) Loss: 0.0067(0.0137) Grad: 7190.9019  LR: 0.00000277  \n","Epoch: [4][2100/3385] Elapsed 6m 17s (remain 3m 50s) Loss: 0.0137(0.0137) Grad: 22444.9902  LR: 0.00000266  \n","Epoch: [4][2200/3385] Elapsed 6m 34s (remain 3m 32s) Loss: 0.0040(0.0137) Grad: 6362.9561  LR: 0.00000256  \n","Epoch: [4][2300/3385] Elapsed 6m 52s (remain 3m 14s) Loss: 0.0055(0.0136) Grad: 11417.1035  LR: 0.00000245  \n","Epoch: [4][2400/3385] Elapsed 7m 10s (remain 2m 56s) Loss: 0.0042(0.0136) Grad: 7687.1040  LR: 0.00000235  \n","Epoch: [4][2500/3385] Elapsed 7m 28s (remain 2m 38s) Loss: 0.0075(0.0135) Grad: 8763.9219  LR: 0.00000225  \n","Epoch: [4][2600/3385] Elapsed 7m 45s (remain 2m 20s) Loss: 0.0070(0.0135) Grad: 5016.5698  LR: 0.00000215  \n","Epoch: [4][2700/3385] Elapsed 8m 3s (remain 2m 2s) Loss: 0.0022(0.0134) Grad: 3373.1763  LR: 0.00000205  \n","Epoch: [4][2800/3385] Elapsed 8m 21s (remain 1m 44s) Loss: 0.0050(0.0134) Grad: 6400.3892  LR: 0.00000196  \n","Epoch: [4][2900/3385] Elapsed 8m 39s (remain 1m 26s) Loss: 0.0119(0.0135) Grad: 8015.8701  LR: 0.00000186  \n","Epoch: [4][3000/3385] Elapsed 8m 57s (remain 1m 8s) Loss: 0.0061(0.0134) Grad: 6723.0415  LR: 0.00000177  \n","Epoch: [4][3100/3385] Elapsed 9m 14s (remain 0m 50s) Loss: 0.0291(0.0134) Grad: 22169.9668  LR: 0.00000168  \n","Epoch: [4][3200/3385] Elapsed 9m 32s (remain 0m 32s) Loss: 0.0169(0.0134) Grad: 25092.9434  LR: 0.00000160  \n","Epoch: [4][3300/3385] Elapsed 9m 50s (remain 0m 15s) Loss: 0.0028(0.0134) Grad: 3187.1428  LR: 0.00000151  \n","Epoch: [4][3384/3385] Elapsed 10m 5s (remain 0m 0s) Loss: 0.0056(0.0134) Grad: 9227.5820  LR: 0.00000144  \n","EVAL: [0/262] Elapsed 0m 0s (remain 1m 25s) Loss: 0.1749(0.1749) \n","EVAL: [100/262] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0873(0.1010) \n","EVAL: [200/262] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0742(0.0979) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0134  avg_val_loss: 0.0977  time: 631s\n","Epoch 4 - Score: 0.7998\n","Epoch 4 - Save Best Score: 0.7998 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [261/262] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1886(0.0977) \n","Epoch: [5][0/3385] Elapsed 0m 0s (remain 26m 41s) Loss: 0.0086(0.0086) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3385] Elapsed 0m 18s (remain 9m 59s) Loss: 0.0131(0.0110) Grad: 12770.1123  LR: 0.00000136  \n","Epoch: [5][200/3385] Elapsed 0m 36s (remain 9m 38s) Loss: 0.0180(0.0109) Grad: 20011.0293  LR: 0.00000128  \n","Epoch: [5][300/3385] Elapsed 0m 54s (remain 9m 15s) Loss: 0.0139(0.0107) Grad: 25752.6230  LR: 0.00000120  \n","Epoch: [5][400/3385] Elapsed 1m 11s (remain 8m 54s) Loss: 0.0016(0.0105) Grad: 2962.9878  LR: 0.00000113  \n","Epoch: [5][500/3385] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0282(0.0105) Grad: 17100.7441  LR: 0.00000106  \n","Epoch: [5][600/3385] Elapsed 1m 47s (remain 8m 19s) Loss: 0.0291(0.0107) Grad: 19176.7812  LR: 0.00000099  \n","Epoch: [5][700/3385] Elapsed 2m 5s (remain 8m 2s) Loss: 0.0100(0.0106) Grad: 31261.5645  LR: 0.00000092  \n","Epoch: [5][800/3385] Elapsed 2m 24s (remain 7m 44s) Loss: 0.0044(0.0108) Grad: 8313.3438  LR: 0.00000085  \n","Epoch: [5][900/3385] Elapsed 2m 42s (remain 7m 26s) Loss: 0.0170(0.0107) Grad: 26459.4512  LR: 0.00000079  \n","Epoch: [5][1000/3385] Elapsed 3m 0s (remain 7m 8s) Loss: 0.0137(0.0107) Grad: 34368.2148  LR: 0.00000073  \n","Epoch: [5][1100/3385] Elapsed 3m 18s (remain 6m 51s) Loss: 0.0114(0.0107) Grad: 5664.6216  LR: 0.00000067  \n","Epoch: [5][1200/3385] Elapsed 3m 36s (remain 6m 33s) Loss: 0.0174(0.0107) Grad: 7304.8491  LR: 0.00000061  \n","Epoch: [5][1300/3385] Elapsed 3m 54s (remain 6m 15s) Loss: 0.0115(0.0107) Grad: 2684.6338  LR: 0.00000056  \n","Epoch: [5][1400/3385] Elapsed 4m 12s (remain 5m 57s) Loss: 0.0132(0.0108) Grad: 22978.7832  LR: 0.00000051  \n","Epoch: [5][1500/3385] Elapsed 4m 30s (remain 5m 39s) Loss: 0.0128(0.0107) Grad: 18855.2617  LR: 0.00000046  \n","Epoch: [5][1600/3385] Elapsed 4m 47s (remain 5m 20s) Loss: 0.0170(0.0107) Grad: 10696.2061  LR: 0.00000041  \n","Epoch: [5][1700/3385] Elapsed 5m 5s (remain 5m 2s) Loss: 0.0114(0.0107) Grad: 13616.1367  LR: 0.00000037  \n","Epoch: [5][1800/3385] Elapsed 5m 23s (remain 4m 44s) Loss: 0.0330(0.0107) Grad: 23795.0234  LR: 0.00000032  \n","Epoch: [5][1900/3385] Elapsed 5m 41s (remain 4m 26s) Loss: 0.0162(0.0107) Grad: 25297.7246  LR: 0.00000029  \n","Epoch: [5][2000/3385] Elapsed 5m 58s (remain 4m 8s) Loss: 0.0011(0.0107) Grad: 1735.0625  LR: 0.00000025  \n","Epoch: [5][2100/3385] Elapsed 6m 16s (remain 3m 50s) Loss: 0.0108(0.0107) Grad: 4331.2812  LR: 0.00000021  \n","Epoch: [5][2200/3385] Elapsed 6m 34s (remain 3m 32s) Loss: 0.0227(0.0106) Grad: 9852.4727  LR: 0.00000018  \n","Epoch: [5][2300/3385] Elapsed 6m 51s (remain 3m 14s) Loss: 0.0100(0.0107) Grad: 4005.7312  LR: 0.00000015  \n","Epoch: [5][2400/3385] Elapsed 7m 9s (remain 2m 56s) Loss: 0.0031(0.0107) Grad: 6041.9385  LR: 0.00000013  \n","Epoch: [5][2500/3385] Elapsed 7m 27s (remain 2m 38s) Loss: 0.0124(0.0107) Grad: 21080.8926  LR: 0.00000010  \n","Epoch: [5][2600/3385] Elapsed 7m 45s (remain 2m 20s) Loss: 0.0109(0.0107) Grad: 8385.0166  LR: 0.00000008  \n","Epoch: [5][2700/3385] Elapsed 8m 2s (remain 2m 2s) Loss: 0.0026(0.0107) Grad: 5602.4761  LR: 0.00000006  \n","Epoch: [5][2800/3385] Elapsed 8m 20s (remain 1m 44s) Loss: 0.0046(0.0107) Grad: 2474.1394  LR: 0.00000004  \n","Epoch: [5][2900/3385] Elapsed 8m 38s (remain 1m 26s) Loss: 0.0105(0.0107) Grad: 11490.3691  LR: 0.00000003  \n","Epoch: [5][3000/3385] Elapsed 8m 55s (remain 1m 8s) Loss: 0.0080(0.0107) Grad: 8205.9961  LR: 0.00000002  \n","Epoch: [5][3100/3385] Elapsed 9m 13s (remain 0m 50s) Loss: 0.0078(0.0107) Grad: 23032.1445  LR: 0.00000001  \n","Epoch: [5][3200/3385] Elapsed 9m 31s (remain 0m 32s) Loss: 0.0125(0.0107) Grad: 12032.5215  LR: 0.00000000  \n","Epoch: [5][3300/3385] Elapsed 9m 49s (remain 0m 14s) Loss: 0.0056(0.0107) Grad: 11862.5908  LR: 0.00000000  \n","Epoch: [5][3384/3385] Elapsed 10m 3s (remain 0m 0s) Loss: 0.0011(0.0106) Grad: 2886.7903  LR: 0.00000000  \n","EVAL: [0/262] Elapsed 0m 0s (remain 1m 25s) Loss: 0.1753(0.1753) \n","EVAL: [100/262] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0865(0.1011) \n","EVAL: [200/262] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0732(0.0981) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0106  avg_val_loss: 0.0979  time: 630s\n","Epoch 5 - Score: 0.8010\n","Epoch 5 - Save Best Score: 0.8010 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [261/262] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1865(0.0979) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Score: 0.8010\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3405] Elapsed 0m 0s (remain 22m 38s) Loss: 0.7285(0.7285) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3405] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0472(0.2157) Grad: 2769.5022  LR: 0.00001500  \n","Epoch: [1][200/3405] Elapsed 0m 36s (remain 9m 39s) Loss: 0.1238(0.1704) Grad: 7800.5820  LR: 0.00001500  \n","Epoch: [1][300/3405] Elapsed 0m 54s (remain 9m 17s) Loss: 0.0536(0.1539) Grad: 7507.5879  LR: 0.00001499  \n","Epoch: [1][400/3405] Elapsed 1m 11s (remain 8m 58s) Loss: 0.0536(0.1361) Grad: 940.4523  LR: 0.00001498  \n","Epoch: [1][500/3405] Elapsed 1m 29s (remain 8m 41s) Loss: 0.0694(0.1242) Grad: 2580.0527  LR: 0.00001497  \n","Epoch: [1][600/3405] Elapsed 1m 48s (remain 8m 23s) Loss: 0.1453(0.1174) Grad: 5702.1475  LR: 0.00001496  \n","Epoch: [1][700/3405] Elapsed 2m 5s (remain 8m 5s) Loss: 0.0772(0.1113) Grad: 7797.4502  LR: 0.00001495  \n","Epoch: [1][800/3405] Elapsed 2m 23s (remain 7m 48s) Loss: 0.0199(0.1066) Grad: 3605.2817  LR: 0.00001493  \n","Epoch: [1][900/3405] Elapsed 2m 41s (remain 7m 30s) Loss: 0.0302(0.1013) Grad: 2404.3000  LR: 0.00001491  \n","Epoch: [1][1000/3405] Elapsed 2m 59s (remain 7m 12s) Loss: 0.0408(0.0965) Grad: 1015.9905  LR: 0.00001488  \n","Epoch: [1][1100/3405] Elapsed 3m 17s (remain 6m 54s) Loss: 0.0712(0.0928) Grad: 5557.7231  LR: 0.00001486  \n","Epoch: [1][1200/3405] Elapsed 3m 35s (remain 6m 36s) Loss: 0.0500(0.0890) Grad: 2521.0576  LR: 0.00001483  \n","Epoch: [1][1300/3405] Elapsed 3m 53s (remain 6m 18s) Loss: 0.0338(0.0858) Grad: 3182.7358  LR: 0.00001480  \n","Epoch: [1][1400/3405] Elapsed 4m 11s (remain 6m 0s) Loss: 0.0301(0.0825) Grad: 901.3515  LR: 0.00001477  \n","Epoch: [1][1500/3405] Elapsed 4m 29s (remain 5m 42s) Loss: 0.0465(0.0798) Grad: 3856.2832  LR: 0.00001473  \n","Epoch: [1][1600/3405] Elapsed 4m 47s (remain 5m 24s) Loss: 0.0202(0.0774) Grad: 4057.4695  LR: 0.00001469  \n","Epoch: [1][1700/3405] Elapsed 5m 5s (remain 5m 5s) Loss: 0.0691(0.0751) Grad: 5341.0317  LR: 0.00001465  \n","Epoch: [1][1800/3405] Elapsed 5m 22s (remain 4m 47s) Loss: 0.0188(0.0730) Grad: 3783.6848  LR: 0.00001461  \n","Epoch: [1][1900/3405] Elapsed 5m 40s (remain 4m 29s) Loss: 0.0459(0.0710) Grad: 3844.2981  LR: 0.00001456  \n","Epoch: [1][2000/3405] Elapsed 5m 58s (remain 4m 11s) Loss: 0.0127(0.0692) Grad: 1696.4313  LR: 0.00001452  \n","Epoch: [1][2100/3405] Elapsed 6m 15s (remain 3m 53s) Loss: 0.0310(0.0674) Grad: 2067.6514  LR: 0.00001447  \n","Epoch: [1][2200/3405] Elapsed 6m 33s (remain 3m 35s) Loss: 0.0282(0.0658) Grad: 1189.5031  LR: 0.00001441  \n","Epoch: [1][2300/3405] Elapsed 6m 51s (remain 3m 17s) Loss: 0.0271(0.0643) Grad: 5316.8940  LR: 0.00001436  \n","Epoch: [1][2400/3405] Elapsed 7m 8s (remain 2m 59s) Loss: 0.0634(0.0630) Grad: 2842.6934  LR: 0.00001430  \n","Epoch: [1][2500/3405] Elapsed 7m 26s (remain 2m 41s) Loss: 0.0401(0.0617) Grad: 6245.5361  LR: 0.00001424  \n","Epoch: [1][2600/3405] Elapsed 7m 44s (remain 2m 23s) Loss: 0.0568(0.0606) Grad: 6479.6211  LR: 0.00001418  \n","Epoch: [1][2700/3405] Elapsed 8m 1s (remain 2m 5s) Loss: 0.0163(0.0595) Grad: 1102.0853  LR: 0.00001412  \n","Epoch: [1][2800/3405] Elapsed 8m 19s (remain 1m 47s) Loss: 0.0277(0.0585) Grad: 3416.9265  LR: 0.00001405  \n","Epoch: [1][2900/3405] Elapsed 8m 37s (remain 1m 29s) Loss: 0.0189(0.0576) Grad: 2136.1655  LR: 0.00001398  \n","Epoch: [1][3000/3405] Elapsed 8m 55s (remain 1m 12s) Loss: 0.0211(0.0565) Grad: 4680.4932  LR: 0.00001391  \n","Epoch: [1][3100/3405] Elapsed 9m 13s (remain 0m 54s) Loss: 0.0210(0.0557) Grad: 3554.5642  LR: 0.00001384  \n","Epoch: [1][3200/3405] Elapsed 9m 30s (remain 0m 36s) Loss: 0.0214(0.0549) Grad: 2097.6130  LR: 0.00001376  \n","Epoch: [1][3300/3405] Elapsed 9m 48s (remain 0m 18s) Loss: 0.0270(0.0540) Grad: 3861.6257  LR: 0.00001368  \n","Epoch: [1][3400/3405] Elapsed 10m 6s (remain 0m 0s) Loss: 0.0843(0.0532) Grad: 6967.9507  LR: 0.00001360  \n","Epoch: [1][3404/3405] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0316(0.0532) Grad: 2807.4724  LR: 0.00001360  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0433(0.0433) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 13s) Loss: 0.0635(0.1013) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.1018(0.1061) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0532  avg_val_loss: 0.1056  time: 631s\n","Epoch 1 - Score: 0.7914\n","Epoch 1 - Save Best Score: 0.7914 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0160(0.1056) \n","Epoch: [2][0/3405] Elapsed 0m 0s (remain 26m 1s) Loss: 0.0260(0.0260) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3405] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0113(0.0232) Grad: 3161.4224  LR: 0.00001352  \n","Epoch: [2][200/3405] Elapsed 0m 36s (remain 9m 44s) Loss: 0.0227(0.0226) Grad: 18662.1035  LR: 0.00001343  \n","Epoch: [2][300/3405] Elapsed 0m 54s (remain 9m 23s) Loss: 0.0371(0.0224) Grad: 23192.0039  LR: 0.00001335  \n","Epoch: [2][400/3405] Elapsed 1m 12s (remain 9m 5s) Loss: 0.0415(0.0223) Grad: 10743.2227  LR: 0.00001326  \n","Epoch: [2][500/3405] Elapsed 1m 30s (remain 8m 46s) Loss: 0.0185(0.0225) Grad: 4549.8545  LR: 0.00001317  \n","Epoch: [2][600/3405] Elapsed 1m 49s (remain 8m 28s) Loss: 0.0526(0.0226) Grad: 23107.9121  LR: 0.00001308  \n","Epoch: [2][700/3405] Elapsed 2m 7s (remain 8m 10s) Loss: 0.0210(0.0224) Grad: 5645.5249  LR: 0.00001298  \n","Epoch: [2][800/3405] Elapsed 2m 25s (remain 7m 52s) Loss: 0.0111(0.0218) Grad: 5015.7520  LR: 0.00001289  \n","Epoch: [2][900/3405] Elapsed 2m 43s (remain 7m 34s) Loss: 0.0258(0.0216) Grad: 4965.2354  LR: 0.00001279  \n","Epoch: [2][1000/3405] Elapsed 3m 1s (remain 7m 16s) Loss: 0.0384(0.0215) Grad: 15879.2295  LR: 0.00001269  \n","Epoch: [2][1100/3405] Elapsed 3m 19s (remain 6m 58s) Loss: 0.0076(0.0215) Grad: 7548.5073  LR: 0.00001259  \n","Epoch: [2][1200/3405] Elapsed 3m 37s (remain 6m 39s) Loss: 0.0320(0.0215) Grad: 6107.4390  LR: 0.00001249  \n","Epoch: [2][1300/3405] Elapsed 3m 56s (remain 6m 21s) Loss: 0.0079(0.0213) Grad: 4677.0679  LR: 0.00001238  \n","Epoch: [2][1400/3405] Elapsed 4m 13s (remain 6m 3s) Loss: 0.0183(0.0212) Grad: 15802.6191  LR: 0.00001228  \n","Epoch: [2][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0171(0.0211) Grad: 4317.7925  LR: 0.00001217  \n","Epoch: [2][1600/3405] Elapsed 4m 49s (remain 5m 26s) Loss: 0.0303(0.0211) Grad: 5183.4297  LR: 0.00001206  \n","Epoch: [2][1700/3405] Elapsed 5m 7s (remain 5m 7s) Loss: 0.0098(0.0211) Grad: 6263.6479  LR: 0.00001195  \n","Epoch: [2][1800/3405] Elapsed 5m 25s (remain 4m 49s) Loss: 0.0083(0.0211) Grad: 5949.0913  LR: 0.00001184  \n","Epoch: [2][1900/3405] Elapsed 5m 42s (remain 4m 31s) Loss: 0.0179(0.0212) Grad: 5107.9673  LR: 0.00001172  \n","Epoch: [2][2000/3405] Elapsed 6m 0s (remain 4m 12s) Loss: 0.0253(0.0213) Grad: 5985.4888  LR: 0.00001161  \n","Epoch: [2][2100/3405] Elapsed 6m 18s (remain 3m 54s) Loss: 0.0259(0.0213) Grad: 13661.8770  LR: 0.00001149  \n","Epoch: [2][2200/3405] Elapsed 6m 36s (remain 3m 36s) Loss: 0.0261(0.0213) Grad: 36972.4453  LR: 0.00001137  \n","Epoch: [2][2300/3405] Elapsed 6m 53s (remain 3m 18s) Loss: 0.0213(0.0213) Grad: 3223.2363  LR: 0.00001125  \n","Epoch: [2][2400/3405] Elapsed 7m 11s (remain 3m 0s) Loss: 0.0125(0.0213) Grad: 23612.5508  LR: 0.00001113  \n","Epoch: [2][2500/3405] Elapsed 7m 29s (remain 2m 42s) Loss: 0.0325(0.0213) Grad: 7472.0005  LR: 0.00001101  \n","Epoch: [2][2600/3405] Elapsed 7m 47s (remain 2m 24s) Loss: 0.0210(0.0212) Grad: 5048.8862  LR: 0.00001089  \n","Epoch: [2][2700/3405] Elapsed 8m 5s (remain 2m 6s) Loss: 0.0186(0.0212) Grad: 12624.6240  LR: 0.00001076  \n","Epoch: [2][2800/3405] Elapsed 8m 22s (remain 1m 48s) Loss: 0.0134(0.0212) Grad: 6626.1855  LR: 0.00001064  \n","Epoch: [2][2900/3405] Elapsed 8m 40s (remain 1m 30s) Loss: 0.0082(0.0211) Grad: 2833.4600  LR: 0.00001051  \n","Epoch: [2][3000/3405] Elapsed 8m 58s (remain 1m 12s) Loss: 0.0225(0.0211) Grad: 14885.7588  LR: 0.00001038  \n","Epoch: [2][3100/3405] Elapsed 9m 16s (remain 0m 54s) Loss: 0.0174(0.0211) Grad: 8504.0332  LR: 0.00001025  \n","Epoch: [2][3200/3405] Elapsed 9m 34s (remain 0m 36s) Loss: 0.0236(0.0211) Grad: 12175.6895  LR: 0.00001012  \n","Epoch: [2][3300/3405] Elapsed 9m 51s (remain 0m 18s) Loss: 0.0222(0.0210) Grad: 12767.5078  LR: 0.00000999  \n","Epoch: [2][3400/3405] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0297(0.0211) Grad: 19774.0234  LR: 0.00000986  \n","Epoch: [2][3404/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0200(0.0211) Grad: 5487.8916  LR: 0.00000986  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 20s) Loss: 0.0453(0.0453) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0610(0.0933) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0936(0.0984) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0211  avg_val_loss: 0.0980  time: 634s\n","Epoch 2 - Score: 0.8027\n","Epoch 2 - Save Best Score: 0.8027 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0167(0.0980) \n","Epoch: [3][0/3405] Elapsed 0m 0s (remain 26m 6s) Loss: 0.0354(0.0354) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3405] Elapsed 0m 18s (remain 10m 9s) Loss: 0.0076(0.0164) Grad: 6589.9004  LR: 0.00000972  \n","Epoch: [3][200/3405] Elapsed 0m 37s (remain 9m 53s) Loss: 0.0062(0.0176) Grad: 5631.1279  LR: 0.00000959  \n","Epoch: [3][300/3405] Elapsed 0m 55s (remain 9m 30s) Loss: 0.0347(0.0175) Grad: 8145.2139  LR: 0.00000946  \n","Epoch: [3][400/3405] Elapsed 1m 13s (remain 9m 9s) Loss: 0.0289(0.0182) Grad: 8313.5664  LR: 0.00000932  \n","Epoch: [3][500/3405] Elapsed 1m 31s (remain 8m 50s) Loss: 0.0102(0.0180) Grad: 17107.2930  LR: 0.00000919  \n","Epoch: [3][600/3405] Elapsed 1m 49s (remain 8m 31s) Loss: 0.0422(0.0178) Grad: 16934.5938  LR: 0.00000905  \n","Epoch: [3][700/3405] Elapsed 2m 7s (remain 8m 12s) Loss: 0.0094(0.0181) Grad: 20064.4766  LR: 0.00000892  \n","Epoch: [3][800/3405] Elapsed 2m 25s (remain 7m 53s) Loss: 0.0186(0.0181) Grad: 17477.6543  LR: 0.00000878  \n","Epoch: [3][900/3405] Elapsed 2m 43s (remain 7m 35s) Loss: 0.0180(0.0180) Grad: 13205.3574  LR: 0.00000864  \n","Epoch: [3][1000/3405] Elapsed 3m 1s (remain 7m 17s) Loss: 0.0126(0.0181) Grad: 12219.3896  LR: 0.00000851  \n","Epoch: [3][1100/3405] Elapsed 3m 20s (remain 6m 58s) Loss: 0.0120(0.0181) Grad: 13683.4004  LR: 0.00000837  \n","Epoch: [3][1200/3405] Elapsed 3m 38s (remain 6m 40s) Loss: 0.0180(0.0181) Grad: 15300.3545  LR: 0.00000823  \n","Epoch: [3][1300/3405] Elapsed 3m 55s (remain 6m 21s) Loss: 0.0168(0.0181) Grad: 27203.8145  LR: 0.00000809  \n","Epoch: [3][1400/3405] Elapsed 4m 13s (remain 6m 2s) Loss: 0.0090(0.0181) Grad: 12838.5527  LR: 0.00000795  \n","Epoch: [3][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0236(0.0182) Grad: 17011.9219  LR: 0.00000781  \n","Epoch: [3][1600/3405] Elapsed 4m 49s (remain 5m 26s) Loss: 0.0085(0.0181) Grad: 7205.6787  LR: 0.00000768  \n","Epoch: [3][1700/3405] Elapsed 5m 7s (remain 5m 7s) Loss: 0.0079(0.0183) Grad: 15164.6279  LR: 0.00000754  \n","Epoch: [3][1800/3405] Elapsed 5m 25s (remain 4m 49s) Loss: 0.0100(0.0182) Grad: 15370.3740  LR: 0.00000740  \n","Epoch: [3][1900/3405] Elapsed 5m 42s (remain 4m 31s) Loss: 0.0499(0.0182) Grad: 43196.4336  LR: 0.00000726  \n","Epoch: [3][2000/3405] Elapsed 6m 0s (remain 4m 13s) Loss: 0.0069(0.0182) Grad: 16269.3096  LR: 0.00000712  \n","Epoch: [3][2100/3405] Elapsed 6m 18s (remain 3m 54s) Loss: 0.0077(0.0181) Grad: 6872.2661  LR: 0.00000698  \n","Epoch: [3][2200/3405] Elapsed 6m 36s (remain 3m 36s) Loss: 0.0242(0.0181) Grad: 9793.6963  LR: 0.00000684  \n","Epoch: [3][2300/3405] Elapsed 6m 54s (remain 3m 18s) Loss: 0.0113(0.0181) Grad: 9303.1289  LR: 0.00000671  \n","Epoch: [3][2400/3405] Elapsed 7m 11s (remain 3m 0s) Loss: 0.0221(0.0181) Grad: 3766.5830  LR: 0.00000657  \n","Epoch: [3][2500/3405] Elapsed 7m 29s (remain 2m 42s) Loss: 0.0136(0.0180) Grad: 7618.7744  LR: 0.00000643  \n","Epoch: [3][2600/3405] Elapsed 7m 47s (remain 2m 24s) Loss: 0.0146(0.0180) Grad: 9400.0693  LR: 0.00000629  \n","Epoch: [3][2700/3405] Elapsed 8m 5s (remain 2m 6s) Loss: 0.0062(0.0180) Grad: 1752.8915  LR: 0.00000616  \n","Epoch: [3][2800/3405] Elapsed 8m 23s (remain 1m 48s) Loss: 0.0221(0.0179) Grad: 20245.2598  LR: 0.00000602  \n","Epoch: [3][2900/3405] Elapsed 8m 41s (remain 1m 30s) Loss: 0.0135(0.0179) Grad: 11766.1865  LR: 0.00000588  \n","Epoch: [3][3000/3405] Elapsed 8m 58s (remain 1m 12s) Loss: 0.0159(0.0178) Grad: 5945.5215  LR: 0.00000575  \n","Epoch: [3][3100/3405] Elapsed 9m 16s (remain 0m 54s) Loss: 0.0094(0.0178) Grad: 2082.6658  LR: 0.00000561  \n","Epoch: [3][3200/3405] Elapsed 9m 34s (remain 0m 36s) Loss: 0.0116(0.0178) Grad: 15238.1768  LR: 0.00000548  \n","Epoch: [3][3300/3405] Elapsed 9m 52s (remain 0m 18s) Loss: 0.0205(0.0178) Grad: 7833.2598  LR: 0.00000535  \n","Epoch: [3][3400/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0134(0.0177) Grad: 9096.9404  LR: 0.00000521  \n","Epoch: [3][3404/3405] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0155(0.0177) Grad: 20520.0469  LR: 0.00000521  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 20s) Loss: 0.0422(0.0422) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0666(0.0958) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0884(0.1008) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0177  avg_val_loss: 0.1005  time: 635s\n","Epoch 3 - Score: 0.8034\n","Epoch 3 - Save Best Score: 0.8034 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0157(0.1005) \n","Epoch: [4][0/3405] Elapsed 0m 0s (remain 26m 10s) Loss: 0.0267(0.0267) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3405] Elapsed 0m 18s (remain 10m 14s) Loss: 0.0017(0.0135) Grad: 16673.0000  LR: 0.00000508  \n","Epoch: [4][200/3405] Elapsed 0m 37s (remain 9m 52s) Loss: 0.0155(0.0132) Grad: 6597.8638  LR: 0.00000494  \n","Epoch: [4][300/3405] Elapsed 0m 55s (remain 9m 30s) Loss: 0.0092(0.0130) Grad: 2747.9778  LR: 0.00000481  \n","Epoch: [4][400/3405] Elapsed 1m 13s (remain 9m 10s) Loss: 0.0107(0.0135) Grad: 14823.3916  LR: 0.00000469  \n","Epoch: [4][500/3405] Elapsed 1m 31s (remain 8m 50s) Loss: 0.0161(0.0135) Grad: 7160.7725  LR: 0.00000456  \n","Epoch: [4][600/3405] Elapsed 1m 49s (remain 8m 31s) Loss: 0.0161(0.0135) Grad: 4238.4307  LR: 0.00000443  \n","Epoch: [4][700/3405] Elapsed 2m 7s (remain 8m 12s) Loss: 0.0015(0.0134) Grad: 3127.7864  LR: 0.00000430  \n","Epoch: [4][800/3405] Elapsed 2m 25s (remain 7m 54s) Loss: 0.0135(0.0136) Grad: 5929.3965  LR: 0.00000418  \n","Epoch: [4][900/3405] Elapsed 2m 44s (remain 7m 35s) Loss: 0.0070(0.0135) Grad: 13733.3887  LR: 0.00000406  \n","Epoch: [4][1000/3405] Elapsed 3m 2s (remain 7m 17s) Loss: 0.0085(0.0133) Grad: 8547.6035  LR: 0.00000393  \n","Epoch: [4][1100/3405] Elapsed 3m 20s (remain 6m 59s) Loss: 0.0060(0.0132) Grad: 9571.2988  LR: 0.00000381  \n","Epoch: [4][1200/3405] Elapsed 3m 38s (remain 6m 40s) Loss: 0.0039(0.0132) Grad: 5225.0220  LR: 0.00000369  \n","Epoch: [4][1300/3405] Elapsed 3m 56s (remain 6m 22s) Loss: 0.0107(0.0131) Grad: 4167.4365  LR: 0.00000357  \n","Epoch: [4][1400/3405] Elapsed 4m 14s (remain 6m 3s) Loss: 0.0079(0.0130) Grad: 8851.9736  LR: 0.00000345  \n","Epoch: [4][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0117(0.0130) Grad: 10589.0420  LR: 0.00000334  \n","Epoch: [4][1600/3405] Elapsed 4m 49s (remain 5m 26s) Loss: 0.0085(0.0130) Grad: 3919.9668  LR: 0.00000322  \n","Epoch: [4][1700/3405] Elapsed 5m 7s (remain 5m 7s) Loss: 0.0147(0.0130) Grad: 26454.9648  LR: 0.00000311  \n","Epoch: [4][1800/3405] Elapsed 5m 25s (remain 4m 49s) Loss: 0.0132(0.0130) Grad: 4250.0254  LR: 0.00000300  \n","Epoch: [4][1900/3405] Elapsed 5m 42s (remain 4m 31s) Loss: 0.0416(0.0131) Grad: 21914.4219  LR: 0.00000289  \n","Epoch: [4][2000/3405] Elapsed 6m 0s (remain 4m 12s) Loss: 0.0205(0.0131) Grad: 7756.8765  LR: 0.00000278  \n","Epoch: [4][2100/3405] Elapsed 6m 18s (remain 3m 54s) Loss: 0.0282(0.0131) Grad: 19611.5078  LR: 0.00000267  \n","Epoch: [4][2200/3405] Elapsed 6m 36s (remain 3m 36s) Loss: 0.0126(0.0131) Grad: 11404.7832  LR: 0.00000257  \n","Epoch: [4][2300/3405] Elapsed 6m 53s (remain 3m 18s) Loss: 0.0103(0.0131) Grad: 11637.4395  LR: 0.00000246  \n","Epoch: [4][2400/3405] Elapsed 7m 11s (remain 3m 0s) Loss: 0.0288(0.0130) Grad: 18863.5000  LR: 0.00000236  \n","Epoch: [4][2500/3405] Elapsed 7m 29s (remain 2m 42s) Loss: 0.0198(0.0130) Grad: 31313.7070  LR: 0.00000226  \n","Epoch: [4][2600/3405] Elapsed 7m 47s (remain 2m 24s) Loss: 0.0052(0.0130) Grad: 3956.3938  LR: 0.00000216  \n","Epoch: [4][2700/3405] Elapsed 8m 5s (remain 2m 6s) Loss: 0.0132(0.0130) Grad: 6994.9736  LR: 0.00000207  \n","Epoch: [4][2800/3405] Elapsed 8m 22s (remain 1m 48s) Loss: 0.0173(0.0129) Grad: 18130.1523  LR: 0.00000197  \n","Epoch: [4][2900/3405] Elapsed 8m 40s (remain 1m 30s) Loss: 0.0175(0.0129) Grad: 7831.5859  LR: 0.00000188  \n","Epoch: [4][3000/3405] Elapsed 8m 58s (remain 1m 12s) Loss: 0.0058(0.0129) Grad: 10477.9512  LR: 0.00000179  \n","Epoch: [4][3100/3405] Elapsed 9m 16s (remain 0m 54s) Loss: 0.0010(0.0128) Grad: 3827.3584  LR: 0.00000170  \n","Epoch: [4][3200/3405] Elapsed 9m 34s (remain 0m 36s) Loss: 0.0660(0.0128) Grad: 18528.9629  LR: 0.00000161  \n","Epoch: [4][3300/3405] Elapsed 9m 52s (remain 0m 18s) Loss: 0.0188(0.0128) Grad: 17557.7910  LR: 0.00000153  \n","Epoch: [4][3400/3405] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0026(0.0128) Grad: 3796.9709  LR: 0.00000144  \n","Epoch: [4][3404/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0149(0.0128) Grad: 4120.3213  LR: 0.00000144  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0435(0.0435) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 13s) Loss: 0.0661(0.0962) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0924(0.1008) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0128  avg_val_loss: 0.1005  time: 634s\n","Epoch 4 - Score: 0.8018\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0154(0.1005) \n","Epoch: [5][0/3405] Elapsed 0m 0s (remain 26m 9s) Loss: 0.0116(0.0116) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3405] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0122(0.0092) Grad: 13083.5742  LR: 0.00000136  \n","Epoch: [5][200/3405] Elapsed 0m 36s (remain 9m 44s) Loss: 0.0060(0.0100) Grad: 9248.5547  LR: 0.00000128  \n","Epoch: [5][300/3405] Elapsed 0m 54s (remain 9m 25s) Loss: 0.0170(0.0101) Grad: 13189.6357  LR: 0.00000120  \n","Epoch: [5][400/3405] Elapsed 1m 13s (remain 9m 7s) Loss: 0.0303(0.0101) Grad: 12147.0312  LR: 0.00000113  \n","Epoch: [5][500/3405] Elapsed 1m 31s (remain 8m 48s) Loss: 0.0045(0.0103) Grad: 10054.9727  LR: 0.00000106  \n","Epoch: [5][600/3405] Elapsed 1m 49s (remain 8m 30s) Loss: 0.0312(0.0101) Grad: 3769.3271  LR: 0.00000099  \n","Epoch: [5][700/3405] Elapsed 2m 7s (remain 8m 12s) Loss: 0.0013(0.0103) Grad: 901.5984  LR: 0.00000092  \n","Epoch: [5][800/3405] Elapsed 2m 25s (remain 7m 54s) Loss: 0.0190(0.0101) Grad: 25367.7070  LR: 0.00000085  \n","Epoch: [5][900/3405] Elapsed 2m 44s (remain 7m 36s) Loss: 0.0060(0.0101) Grad: 3812.4675  LR: 0.00000079  \n","Epoch: [5][1000/3405] Elapsed 3m 2s (remain 7m 17s) Loss: 0.0157(0.0101) Grad: 23591.3691  LR: 0.00000073  \n","Epoch: [5][1100/3405] Elapsed 3m 20s (remain 6m 58s) Loss: 0.0128(0.0102) Grad: 16981.1055  LR: 0.00000067  \n","Epoch: [5][1200/3405] Elapsed 3m 37s (remain 6m 39s) Loss: 0.0073(0.0103) Grad: 2539.0847  LR: 0.00000062  \n","Epoch: [5][1300/3405] Elapsed 3m 55s (remain 6m 21s) Loss: 0.0064(0.0103) Grad: 12835.0684  LR: 0.00000056  \n","Epoch: [5][1400/3405] Elapsed 4m 13s (remain 6m 2s) Loss: 0.0133(0.0102) Grad: 10209.1709  LR: 0.00000051  \n","Epoch: [5][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0042(0.0101) Grad: 4774.7583  LR: 0.00000046  \n","Epoch: [5][1600/3405] Elapsed 4m 49s (remain 5m 25s) Loss: 0.0171(0.0101) Grad: 6029.1206  LR: 0.00000041  \n","Epoch: [5][1700/3405] Elapsed 5m 7s (remain 5m 7s) Loss: 0.0088(0.0101) Grad: 6955.5830  LR: 0.00000037  \n","Epoch: [5][1800/3405] Elapsed 5m 25s (remain 4m 49s) Loss: 0.0037(0.0101) Grad: 2263.6965  LR: 0.00000033  \n","Epoch: [5][1900/3405] Elapsed 5m 42s (remain 4m 31s) Loss: 0.0046(0.0101) Grad: 6169.4038  LR: 0.00000029  \n","Epoch: [5][2000/3405] Elapsed 6m 0s (remain 4m 13s) Loss: 0.0111(0.0101) Grad: 2904.8374  LR: 0.00000025  \n","Epoch: [5][2100/3405] Elapsed 6m 18s (remain 3m 54s) Loss: 0.0069(0.0101) Grad: 19567.3223  LR: 0.00000022  \n","Epoch: [5][2200/3405] Elapsed 6m 36s (remain 3m 36s) Loss: 0.0104(0.0100) Grad: 13938.1260  LR: 0.00000019  \n","Epoch: [5][2300/3405] Elapsed 6m 54s (remain 3m 18s) Loss: 0.0076(0.0101) Grad: 13033.0342  LR: 0.00000016  \n","Epoch: [5][2400/3405] Elapsed 7m 12s (remain 3m 0s) Loss: 0.0028(0.0100) Grad: 9738.3682  LR: 0.00000013  \n","Epoch: [5][2500/3405] Elapsed 7m 30s (remain 2m 42s) Loss: 0.0117(0.0100) Grad: 12366.7969  LR: 0.00000010  \n","Epoch: [5][2600/3405] Elapsed 7m 47s (remain 2m 24s) Loss: 0.0013(0.0100) Grad: 5299.7856  LR: 0.00000008  \n","Epoch: [5][2700/3405] Elapsed 8m 5s (remain 2m 6s) Loss: 0.0078(0.0100) Grad: 5481.2725  LR: 0.00000006  \n","Epoch: [5][2800/3405] Elapsed 8m 23s (remain 1m 48s) Loss: 0.0085(0.0100) Grad: 3717.5901  LR: 0.00000005  \n","Epoch: [5][2900/3405] Elapsed 8m 41s (remain 1m 30s) Loss: 0.0035(0.0100) Grad: 3376.0190  LR: 0.00000003  \n","Epoch: [5][3000/3405] Elapsed 8m 59s (remain 1m 12s) Loss: 0.0011(0.0101) Grad: 866.3789  LR: 0.00000002  \n","Epoch: [5][3100/3405] Elapsed 9m 17s (remain 0m 54s) Loss: 0.0136(0.0101) Grad: 5798.0913  LR: 0.00000001  \n","Epoch: [5][3200/3405] Elapsed 9m 35s (remain 0m 36s) Loss: 0.0075(0.0101) Grad: 3270.0149  LR: 0.00000001  \n","Epoch: [5][3300/3405] Elapsed 9m 52s (remain 0m 18s) Loss: 0.0038(0.0100) Grad: 4271.2378  LR: 0.00000000  \n","Epoch: [5][3400/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0051(0.0101) Grad: 4497.9292  LR: 0.00000000  \n","Epoch: [5][3404/3405] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0048(0.0100) Grad: 7616.6226  LR: 0.00000000  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 19s) Loss: 0.0421(0.0421) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0655(0.0946) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0902(0.0993) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0100  avg_val_loss: 0.0989  time: 635s\n","Epoch 5 - Score: 0.8042\n","Epoch 5 - Save Best Score: 0.8042 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0152(0.0989) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","Score: 0.8042\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3395] Elapsed 0m 0s (remain 24m 48s) Loss: 0.1192(0.1192) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3395] Elapsed 0m 18s (remain 10m 19s) Loss: 0.0837(0.0853) Grad: 10872.2754  LR: 0.00001500  \n","Epoch: [1][200/3395] Elapsed 0m 37s (remain 9m 52s) Loss: 0.0379(0.0763) Grad: 17137.8672  LR: 0.00001500  \n","Epoch: [1][300/3395] Elapsed 0m 55s (remain 9m 29s) Loss: 0.0592(0.0715) Grad: 3414.8203  LR: 0.00001499  \n","Epoch: [1][400/3395] Elapsed 1m 13s (remain 9m 9s) Loss: 0.1366(0.0657) Grad: 26848.9531  LR: 0.00001498  \n","Epoch: [1][500/3395] Elapsed 1m 31s (remain 8m 49s) Loss: 0.0347(0.0618) Grad: 8837.1221  LR: 0.00001497  \n","Epoch: [1][600/3395] Elapsed 1m 49s (remain 8m 29s) Loss: 0.0354(0.0594) Grad: 17937.9883  LR: 0.00001496  \n","Epoch: [1][700/3395] Elapsed 2m 7s (remain 8m 10s) Loss: 0.0164(0.0571) Grad: 3301.4155  LR: 0.00001495  \n","Epoch: [1][800/3395] Elapsed 2m 25s (remain 7m 51s) Loss: 0.0374(0.0555) Grad: 10304.1748  LR: 0.00001493  \n","Epoch: [1][900/3395] Elapsed 2m 43s (remain 7m 32s) Loss: 0.0084(0.0537) Grad: 9087.2969  LR: 0.00001491  \n","Epoch: [1][1000/3395] Elapsed 3m 1s (remain 7m 13s) Loss: 0.0645(0.0525) Grad: 22474.1270  LR: 0.00001488  \n","Epoch: [1][1100/3395] Elapsed 3m 18s (remain 6m 54s) Loss: 0.0329(0.0512) Grad: 4617.3838  LR: 0.00001486  \n","Epoch: [1][1200/3395] Elapsed 3m 36s (remain 6m 35s) Loss: 0.0391(0.0502) Grad: 19951.3086  LR: 0.00001483  \n","Epoch: [1][1300/3395] Elapsed 3m 54s (remain 6m 16s) Loss: 0.0169(0.0490) Grad: 6561.6323  LR: 0.00001480  \n","Epoch: [1][1400/3395] Elapsed 4m 11s (remain 5m 58s) Loss: 0.0163(0.0484) Grad: 9334.5068  LR: 0.00001477  \n","Epoch: [1][1500/3395] Elapsed 4m 29s (remain 5m 40s) Loss: 0.0408(0.0475) Grad: 7607.7935  LR: 0.00001473  \n","Epoch: [1][1600/3395] Elapsed 4m 47s (remain 5m 21s) Loss: 0.0122(0.0467) Grad: 8101.4839  LR: 0.00001469  \n","Epoch: [1][1700/3395] Elapsed 5m 4s (remain 5m 3s) Loss: 0.0154(0.0459) Grad: 4769.5273  LR: 0.00001465  \n","Epoch: [1][1800/3395] Elapsed 5m 22s (remain 4m 45s) Loss: 0.0163(0.0452) Grad: 1690.4993  LR: 0.00001461  \n","Epoch: [1][1900/3395] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0363(0.0447) Grad: 13791.1396  LR: 0.00001456  \n","Epoch: [1][2000/3395] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0238(0.0443) Grad: 9382.0576  LR: 0.00001451  \n","Epoch: [1][2100/3395] Elapsed 6m 15s (remain 3m 51s) Loss: 0.0371(0.0438) Grad: 19912.5488  LR: 0.00001446  \n","Epoch: [1][2200/3395] Elapsed 6m 33s (remain 3m 33s) Loss: 0.0282(0.0432) Grad: 17701.9238  LR: 0.00001441  \n","Epoch: [1][2300/3395] Elapsed 6m 51s (remain 3m 15s) Loss: 0.0053(0.0426) Grad: 3728.7827  LR: 0.00001435  \n","Epoch: [1][2400/3395] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0582(0.0420) Grad: 14358.2432  LR: 0.00001430  \n","Epoch: [1][2500/3395] Elapsed 7m 26s (remain 2m 39s) Loss: 0.0291(0.0415) Grad: 8943.1191  LR: 0.00001424  \n","Epoch: [1][2600/3395] Elapsed 7m 44s (remain 2m 21s) Loss: 0.0544(0.0410) Grad: 18348.0488  LR: 0.00001417  \n","Epoch: [1][2700/3395] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0320(0.0404) Grad: 26983.7559  LR: 0.00001411  \n","Epoch: [1][2800/3395] Elapsed 8m 20s (remain 1m 46s) Loss: 0.0248(0.0400) Grad: 12715.8174  LR: 0.00001404  \n","Epoch: [1][2900/3395] Elapsed 8m 37s (remain 1m 28s) Loss: 0.0152(0.0396) Grad: 13533.6855  LR: 0.00001397  \n","Epoch: [1][3000/3395] Elapsed 8m 55s (remain 1m 10s) Loss: 0.0301(0.0392) Grad: 30504.8438  LR: 0.00001390  \n","Epoch: [1][3100/3395] Elapsed 9m 13s (remain 0m 52s) Loss: 0.0227(0.0388) Grad: 37949.3945  LR: 0.00001383  \n","Epoch: [1][3200/3395] Elapsed 9m 31s (remain 0m 34s) Loss: 0.0440(0.0385) Grad: 39025.6758  LR: 0.00001375  \n","Epoch: [1][3300/3395] Elapsed 9m 50s (remain 0m 16s) Loss: 0.0426(0.0382) Grad: 39717.0625  LR: 0.00001368  \n","Epoch: [1][3394/3395] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0382(0.0379) Grad: 11014.3672  LR: 0.00001360  \n","EVAL: [0/253] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0377(0.0377) \n","EVAL: [100/253] Elapsed 0m 10s (remain 0m 15s) Loss: 0.1168(0.1006) \n","EVAL: [200/253] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0486(0.0976) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0379  avg_val_loss: 0.0965  time: 632s\n","Epoch 1 - Score: 0.7634\n","Epoch 1 - Save Best Score: 0.7634 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [252/253] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0148(0.0965) \n","Epoch: [2][0/3395] Elapsed 0m 0s (remain 24m 56s) Loss: 0.0395(0.0395) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3395] Elapsed 0m 18s (remain 10m 9s) Loss: 0.0125(0.0241) Grad: 7603.5391  LR: 0.00001352  \n","Epoch: [2][200/3395] Elapsed 0m 37s (remain 9m 53s) Loss: 0.0103(0.0236) Grad: 16945.5215  LR: 0.00001343  \n","Epoch: [2][300/3395] Elapsed 0m 55s (remain 9m 29s) Loss: 0.0094(0.0229) Grad: 6331.6724  LR: 0.00001335  \n","Epoch: [2][400/3395] Elapsed 1m 13s (remain 9m 8s) Loss: 0.0095(0.0230) Grad: 5048.5938  LR: 0.00001326  \n","Epoch: [2][500/3395] Elapsed 1m 31s (remain 8m 48s) Loss: 0.0213(0.0228) Grad: 58587.5508  LR: 0.00001317  \n","Epoch: [2][600/3395] Elapsed 1m 49s (remain 8m 27s) Loss: 0.0164(0.0230) Grad: 25746.8379  LR: 0.00001308  \n","Epoch: [2][700/3395] Elapsed 2m 7s (remain 8m 8s) Loss: 0.0344(0.0230) Grad: 21741.5723  LR: 0.00001298  \n","Epoch: [2][800/3395] Elapsed 2m 24s (remain 7m 48s) Loss: 0.0210(0.0232) Grad: 9177.5234  LR: 0.00001289  \n","Epoch: [2][900/3395] Elapsed 2m 42s (remain 7m 29s) Loss: 0.0106(0.0234) Grad: 3766.8523  LR: 0.00001279  \n","Epoch: [2][1000/3395] Elapsed 3m 0s (remain 7m 11s) Loss: 0.0170(0.0235) Grad: 9824.8398  LR: 0.00001269  \n","Epoch: [2][1100/3395] Elapsed 3m 18s (remain 6m 52s) Loss: 0.0422(0.0235) Grad: 8416.8555  LR: 0.00001259  \n","Epoch: [2][1200/3395] Elapsed 3m 35s (remain 6m 34s) Loss: 0.0162(0.0235) Grad: 9284.6309  LR: 0.00001248  \n","Epoch: [2][1300/3395] Elapsed 3m 53s (remain 6m 15s) Loss: 0.0225(0.0236) Grad: 9123.4541  LR: 0.00001238  \n","Epoch: [2][1400/3395] Elapsed 4m 11s (remain 5m 57s) Loss: 0.0147(0.0235) Grad: 17122.2246  LR: 0.00001227  \n","Epoch: [2][1500/3395] Elapsed 4m 29s (remain 5m 39s) Loss: 0.0336(0.0235) Grad: 14654.5625  LR: 0.00001216  \n","Epoch: [2][1600/3395] Elapsed 4m 46s (remain 5m 21s) Loss: 0.0484(0.0236) Grad: 8483.1670  LR: 0.00001206  \n","Epoch: [2][1700/3395] Elapsed 5m 4s (remain 5m 3s) Loss: 0.0293(0.0235) Grad: 17420.2988  LR: 0.00001194  \n","Epoch: [2][1800/3395] Elapsed 5m 22s (remain 4m 45s) Loss: 0.0046(0.0235) Grad: 10778.0947  LR: 0.00001183  \n","Epoch: [2][1900/3395] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0180(0.0235) Grad: 9211.8623  LR: 0.00001172  \n","Epoch: [2][2000/3395] Elapsed 5m 57s (remain 4m 9s) Loss: 0.0166(0.0235) Grad: 3286.2244  LR: 0.00001160  \n","Epoch: [2][2100/3395] Elapsed 6m 15s (remain 3m 51s) Loss: 0.0224(0.0234) Grad: 32476.8770  LR: 0.00001148  \n","Epoch: [2][2200/3395] Elapsed 6m 33s (remain 3m 33s) Loss: 0.0258(0.0232) Grad: 4374.3340  LR: 0.00001136  \n","Epoch: [2][2300/3395] Elapsed 6m 51s (remain 3m 15s) Loss: 0.0246(0.0233) Grad: 5543.5840  LR: 0.00001124  \n","Epoch: [2][2400/3395] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0177(0.0232) Grad: 16697.8652  LR: 0.00001112  \n","Epoch: [2][2500/3395] Elapsed 7m 26s (remain 2m 39s) Loss: 0.0146(0.0233) Grad: 10050.2852  LR: 0.00001100  \n","Epoch: [2][2600/3395] Elapsed 7m 44s (remain 2m 21s) Loss: 0.0319(0.0233) Grad: 33545.1445  LR: 0.00001088  \n","Epoch: [2][2700/3395] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0123(0.0233) Grad: 4805.6685  LR: 0.00001075  \n","Epoch: [2][2800/3395] Elapsed 8m 19s (remain 1m 46s) Loss: 0.0158(0.0233) Grad: 16971.3867  LR: 0.00001063  \n","Epoch: [2][2900/3395] Elapsed 8m 38s (remain 1m 28s) Loss: 0.0140(0.0232) Grad: 9468.2695  LR: 0.00001050  \n","Epoch: [2][3000/3395] Elapsed 8m 56s (remain 1m 10s) Loss: 0.0262(0.0231) Grad: 7978.8057  LR: 0.00001037  \n","Epoch: [2][3100/3395] Elapsed 9m 14s (remain 0m 52s) Loss: 0.0248(0.0231) Grad: 8513.1807  LR: 0.00001024  \n","Epoch: [2][3200/3395] Elapsed 9m 32s (remain 0m 34s) Loss: 0.0304(0.0230) Grad: 20221.0117  LR: 0.00001011  \n","Epoch: [2][3300/3395] Elapsed 9m 50s (remain 0m 16s) Loss: 0.0096(0.0230) Grad: 13044.9756  LR: 0.00000998  \n","Epoch: [2][3394/3395] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0128(0.0230) Grad: 20130.4785  LR: 0.00000986  \n","EVAL: [0/253] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0460(0.0460) \n","EVAL: [100/253] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1220(0.1071) \n","EVAL: [200/253] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0508(0.1036) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0230  avg_val_loss: 0.1022  time: 632s\n","Epoch 2 - Score: 0.7839\n","Epoch 2 - Save Best Score: 0.7839 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [252/253] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0158(0.1022) \n","Epoch: [3][0/3395] Elapsed 0m 0s (remain 26m 59s) Loss: 0.0089(0.0089) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3395] Elapsed 0m 18s (remain 10m 17s) Loss: 0.0403(0.0154) Grad: 25872.4082  LR: 0.00000972  \n","Epoch: [3][200/3395] Elapsed 0m 37s (remain 10m 1s) Loss: 0.0043(0.0158) Grad: 12875.2627  LR: 0.00000959  \n","Epoch: [3][300/3395] Elapsed 0m 55s (remain 9m 35s) Loss: 0.0112(0.0161) Grad: 7146.2524  LR: 0.00000946  \n","Epoch: [3][400/3395] Elapsed 1m 13s (remain 9m 11s) Loss: 0.0224(0.0164) Grad: 16599.3340  LR: 0.00000932  \n","Epoch: [3][500/3395] Elapsed 1m 31s (remain 8m 49s) Loss: 0.0217(0.0168) Grad: 7099.8770  LR: 0.00000919  \n","Epoch: [3][600/3395] Elapsed 1m 49s (remain 8m 28s) Loss: 0.0222(0.0170) Grad: 23851.5781  LR: 0.00000905  \n","Epoch: [3][700/3395] Elapsed 2m 7s (remain 8m 8s) Loss: 0.0264(0.0169) Grad: 21292.2344  LR: 0.00000891  \n","Epoch: [3][800/3395] Elapsed 2m 25s (remain 7m 49s) Loss: 0.0037(0.0169) Grad: 2324.8196  LR: 0.00000878  \n","Epoch: [3][900/3395] Elapsed 2m 43s (remain 7m 31s) Loss: 0.0253(0.0168) Grad: 7872.1362  LR: 0.00000864  \n","Epoch: [3][1000/3395] Elapsed 3m 0s (remain 7m 12s) Loss: 0.0057(0.0168) Grad: 5614.8281  LR: 0.00000850  \n","Epoch: [3][1100/3395] Elapsed 3m 18s (remain 6m 53s) Loss: 0.0361(0.0167) Grad: 12860.2979  LR: 0.00000836  \n","Epoch: [3][1200/3395] Elapsed 3m 36s (remain 6m 35s) Loss: 0.0171(0.0167) Grad: 14932.6426  LR: 0.00000822  \n","Epoch: [3][1300/3395] Elapsed 3m 54s (remain 6m 16s) Loss: 0.0193(0.0168) Grad: 23886.7773  LR: 0.00000809  \n","Epoch: [3][1400/3395] Elapsed 4m 11s (remain 5m 58s) Loss: 0.0074(0.0168) Grad: 4504.6660  LR: 0.00000795  \n","Epoch: [3][1500/3395] Elapsed 4m 29s (remain 5m 40s) Loss: 0.0339(0.0168) Grad: 21626.4160  LR: 0.00000781  \n","Epoch: [3][1600/3395] Elapsed 4m 47s (remain 5m 22s) Loss: 0.0213(0.0167) Grad: 3214.9065  LR: 0.00000767  \n","Epoch: [3][1700/3395] Elapsed 5m 5s (remain 5m 4s) Loss: 0.0065(0.0168) Grad: 3754.8203  LR: 0.00000753  \n","Epoch: [3][1800/3395] Elapsed 5m 23s (remain 4m 46s) Loss: 0.0189(0.0168) Grad: 11355.4785  LR: 0.00000739  \n","Epoch: [3][1900/3395] Elapsed 5m 41s (remain 4m 28s) Loss: 0.0183(0.0168) Grad: 10526.8701  LR: 0.00000725  \n","Epoch: [3][2000/3395] Elapsed 5m 59s (remain 4m 10s) Loss: 0.0143(0.0167) Grad: 3831.5757  LR: 0.00000711  \n","Epoch: [3][2100/3395] Elapsed 6m 16s (remain 3m 52s) Loss: 0.0056(0.0167) Grad: 9117.6094  LR: 0.00000697  \n","Epoch: [3][2200/3395] Elapsed 6m 34s (remain 3m 34s) Loss: 0.0108(0.0168) Grad: 2339.6404  LR: 0.00000683  \n","Epoch: [3][2300/3395] Elapsed 6m 52s (remain 3m 16s) Loss: 0.0080(0.0168) Grad: 18273.4707  LR: 0.00000670  \n","Epoch: [3][2400/3395] Elapsed 7m 10s (remain 2m 58s) Loss: 0.0079(0.0168) Grad: 8823.6426  LR: 0.00000656  \n","Epoch: [3][2500/3395] Elapsed 7m 27s (remain 2m 40s) Loss: 0.0071(0.0168) Grad: 12978.2793  LR: 0.00000642  \n","Epoch: [3][2600/3395] Elapsed 7m 45s (remain 2m 22s) Loss: 0.0146(0.0169) Grad: 2035.1404  LR: 0.00000628  \n","Epoch: [3][2700/3395] Elapsed 8m 3s (remain 2m 4s) Loss: 0.0121(0.0169) Grad: 3301.5388  LR: 0.00000615  \n","Epoch: [3][2800/3395] Elapsed 8m 21s (remain 1m 46s) Loss: 0.0213(0.0168) Grad: 4549.3882  LR: 0.00000601  \n","Epoch: [3][2900/3395] Elapsed 8m 39s (remain 1m 28s) Loss: 0.0099(0.0168) Grad: 8599.6162  LR: 0.00000587  \n","Epoch: [3][3000/3395] Elapsed 8m 57s (remain 1m 10s) Loss: 0.0144(0.0168) Grad: 7457.1343  LR: 0.00000574  \n","Epoch: [3][3100/3395] Elapsed 9m 16s (remain 0m 52s) Loss: 0.0255(0.0167) Grad: 20852.1309  LR: 0.00000560  \n","Epoch: [3][3200/3395] Elapsed 9m 34s (remain 0m 34s) Loss: 0.0270(0.0168) Grad: 8265.2334  LR: 0.00000547  \n","Epoch: [3][3300/3395] Elapsed 9m 52s (remain 0m 16s) Loss: 0.0172(0.0167) Grad: 14207.5566  LR: 0.00000533  \n","Epoch: [3][3394/3395] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0370(0.0167) Grad: 10473.8896  LR: 0.00000521  \n","EVAL: [0/253] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0483(0.0483) \n","EVAL: [100/253] Elapsed 0m 10s (remain 0m 15s) Loss: 0.1225(0.1115) \n","EVAL: [200/253] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0577(0.1080) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0167  avg_val_loss: 0.1066  time: 634s\n","Epoch 3 - Score: 0.8031\n","Epoch 3 - Save Best Score: 0.8031 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [252/253] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0184(0.1066) \n","Epoch: [4][0/3395] Elapsed 0m 0s (remain 29m 13s) Loss: 0.0093(0.0093) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3395] Elapsed 0m 18s (remain 10m 12s) Loss: 0.0241(0.0124) Grad: 35459.8633  LR: 0.00000508  \n","Epoch: [4][200/3395] Elapsed 0m 37s (remain 9m 54s) Loss: 0.0107(0.0123) Grad: 22477.5801  LR: 0.00000494  \n","Epoch: [4][300/3395] Elapsed 0m 55s (remain 9m 28s) Loss: 0.0100(0.0118) Grad: 22053.3828  LR: 0.00000481  \n","Epoch: [4][400/3395] Elapsed 1m 13s (remain 9m 6s) Loss: 0.0066(0.0120) Grad: 9930.0996  LR: 0.00000468  \n","Epoch: [4][500/3395] Elapsed 1m 30s (remain 8m 45s) Loss: 0.0033(0.0123) Grad: 16763.5527  LR: 0.00000456  \n","Epoch: [4][600/3395] Elapsed 1m 48s (remain 8m 25s) Loss: 0.0204(0.0123) Grad: 11032.6826  LR: 0.00000443  \n","Epoch: [4][700/3395] Elapsed 2m 6s (remain 8m 6s) Loss: 0.0139(0.0126) Grad: 10907.1533  LR: 0.00000430  \n","Epoch: [4][800/3395] Elapsed 2m 24s (remain 7m 47s) Loss: 0.0087(0.0126) Grad: 11150.0742  LR: 0.00000418  \n","Epoch: [4][900/3395] Elapsed 2m 42s (remain 7m 28s) Loss: 0.0255(0.0125) Grad: 29766.4199  LR: 0.00000405  \n","Epoch: [4][1000/3395] Elapsed 3m 0s (remain 7m 10s) Loss: 0.0097(0.0124) Grad: 17683.0586  LR: 0.00000393  \n","Epoch: [4][1100/3395] Elapsed 3m 17s (remain 6m 52s) Loss: 0.0096(0.0126) Grad: 10737.3691  LR: 0.00000381  \n","Epoch: [4][1200/3395] Elapsed 3m 35s (remain 6m 33s) Loss: 0.0139(0.0125) Grad: 11969.1895  LR: 0.00000369  \n","Epoch: [4][1300/3395] Elapsed 3m 53s (remain 6m 15s) Loss: 0.0094(0.0125) Grad: 8168.8120  LR: 0.00000357  \n","Epoch: [4][1400/3395] Elapsed 4m 11s (remain 5m 57s) Loss: 0.0145(0.0124) Grad: 9558.3223  LR: 0.00000345  \n","Epoch: [4][1500/3395] Elapsed 4m 29s (remain 5m 39s) Loss: 0.0221(0.0124) Grad: 9457.6328  LR: 0.00000333  \n","Epoch: [4][1600/3395] Elapsed 4m 46s (remain 5m 21s) Loss: 0.0023(0.0124) Grad: 5014.7915  LR: 0.00000322  \n","Epoch: [4][1700/3395] Elapsed 5m 4s (remain 5m 3s) Loss: 0.0093(0.0123) Grad: 16267.1660  LR: 0.00000310  \n","Epoch: [4][1800/3395] Elapsed 5m 22s (remain 4m 45s) Loss: 0.0049(0.0123) Grad: 2189.2429  LR: 0.00000299  \n","Epoch: [4][1900/3395] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0098(0.0123) Grad: 6064.7261  LR: 0.00000288  \n","Epoch: [4][2000/3395] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0121(0.0123) Grad: 6845.2954  LR: 0.00000277  \n","Epoch: [4][2100/3395] Elapsed 6m 16s (remain 3m 51s) Loss: 0.0064(0.0122) Grad: 11208.8887  LR: 0.00000267  \n","Epoch: [4][2200/3395] Elapsed 6m 34s (remain 3m 33s) Loss: 0.0244(0.0121) Grad: 16205.7500  LR: 0.00000256  \n","Epoch: [4][2300/3395] Elapsed 6m 52s (remain 3m 15s) Loss: 0.0099(0.0122) Grad: 19417.1855  LR: 0.00000246  \n","Epoch: [4][2400/3395] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0315(0.0122) Grad: 23632.1777  LR: 0.00000235  \n","Epoch: [4][2500/3395] Elapsed 7m 27s (remain 2m 40s) Loss: 0.0051(0.0121) Grad: 6896.9336  LR: 0.00000225  \n","Epoch: [4][2600/3395] Elapsed 7m 45s (remain 2m 22s) Loss: 0.0015(0.0121) Grad: 5421.4810  LR: 0.00000216  \n","Epoch: [4][2700/3395] Elapsed 8m 3s (remain 2m 4s) Loss: 0.0119(0.0121) Grad: 8481.9834  LR: 0.00000206  \n","Epoch: [4][2800/3395] Elapsed 8m 21s (remain 1m 46s) Loss: 0.0049(0.0120) Grad: 8560.6924  LR: 0.00000196  \n","Epoch: [4][2900/3395] Elapsed 8m 40s (remain 1m 28s) Loss: 0.0274(0.0120) Grad: 46531.3594  LR: 0.00000187  \n","Epoch: [4][3000/3395] Elapsed 8m 58s (remain 1m 10s) Loss: 0.0098(0.0119) Grad: 15175.4688  LR: 0.00000178  \n","Epoch: [4][3100/3395] Elapsed 9m 16s (remain 0m 52s) Loss: 0.0035(0.0119) Grad: 11163.6943  LR: 0.00000169  \n","Epoch: [4][3200/3395] Elapsed 9m 34s (remain 0m 34s) Loss: 0.0062(0.0119) Grad: 10077.0996  LR: 0.00000160  \n","Epoch: [4][3300/3395] Elapsed 9m 52s (remain 0m 16s) Loss: 0.0335(0.0119) Grad: 26907.1191  LR: 0.00000152  \n","Epoch: [4][3394/3395] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0167(0.0119) Grad: 11208.7969  LR: 0.00000144  \n","EVAL: [0/253] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0412(0.0412) \n","EVAL: [100/253] Elapsed 0m 10s (remain 0m 15s) Loss: 0.1088(0.1016) \n","EVAL: [200/253] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0496(0.0986) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0119  avg_val_loss: 0.0975  time: 634s\n","Epoch 4 - Score: 0.8005\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [252/253] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0170(0.0975) \n","Epoch: [5][0/3395] Elapsed 0m 0s (remain 26m 12s) Loss: 0.0037(0.0037) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3395] Elapsed 0m 18s (remain 10m 4s) Loss: 0.0140(0.0091) Grad: 16363.9336  LR: 0.00000136  \n","Epoch: [5][200/3395] Elapsed 0m 36s (remain 9m 38s) Loss: 0.0029(0.0097) Grad: 14838.1465  LR: 0.00000128  \n","Epoch: [5][300/3395] Elapsed 0m 54s (remain 9m 17s) Loss: 0.0072(0.0092) Grad: 32551.6094  LR: 0.00000120  \n","Epoch: [5][400/3395] Elapsed 1m 12s (remain 8m 57s) Loss: 0.0052(0.0097) Grad: 16293.2568  LR: 0.00000113  \n","Epoch: [5][500/3395] Elapsed 1m 29s (remain 8m 38s) Loss: 0.0092(0.0096) Grad: 14614.1113  LR: 0.00000106  \n","Epoch: [5][600/3395] Elapsed 1m 47s (remain 8m 20s) Loss: 0.0058(0.0095) Grad: 10705.6211  LR: 0.00000099  \n","Epoch: [5][700/3395] Elapsed 2m 5s (remain 8m 1s) Loss: 0.0030(0.0095) Grad: 8838.7266  LR: 0.00000092  \n","Epoch: [5][800/3395] Elapsed 2m 23s (remain 7m 43s) Loss: 0.0134(0.0094) Grad: 41155.8164  LR: 0.00000085  \n","Epoch: [5][900/3395] Elapsed 2m 40s (remain 7m 25s) Loss: 0.0158(0.0094) Grad: 10979.5508  LR: 0.00000079  \n","Epoch: [5][1000/3395] Elapsed 2m 58s (remain 7m 7s) Loss: 0.0105(0.0094) Grad: 12139.2441  LR: 0.00000073  \n","Epoch: [5][1100/3395] Elapsed 3m 16s (remain 6m 49s) Loss: 0.0024(0.0094) Grad: 8091.6602  LR: 0.00000067  \n","Epoch: [5][1200/3395] Elapsed 3m 34s (remain 6m 31s) Loss: 0.0115(0.0094) Grad: 7477.0918  LR: 0.00000061  \n","Epoch: [5][1300/3395] Elapsed 3m 52s (remain 6m 13s) Loss: 0.0122(0.0095) Grad: 23920.7500  LR: 0.00000056  \n","Epoch: [5][1400/3395] Elapsed 4m 10s (remain 5m 55s) Loss: 0.0106(0.0096) Grad: 5499.7690  LR: 0.00000051  \n","Epoch: [5][1500/3395] Elapsed 4m 27s (remain 5m 37s) Loss: 0.0159(0.0096) Grad: 14069.2480  LR: 0.00000046  \n","Epoch: [5][1600/3395] Elapsed 4m 45s (remain 5m 20s) Loss: 0.0087(0.0096) Grad: 22626.4824  LR: 0.00000041  \n","Epoch: [5][1700/3395] Elapsed 5m 3s (remain 5m 2s) Loss: 0.0073(0.0095) Grad: 6440.1431  LR: 0.00000037  \n","Epoch: [5][1800/3395] Elapsed 5m 21s (remain 4m 44s) Loss: 0.0026(0.0095) Grad: 10199.8438  LR: 0.00000033  \n","Epoch: [5][1900/3395] Elapsed 5m 39s (remain 4m 26s) Loss: 0.0168(0.0095) Grad: 8045.0854  LR: 0.00000029  \n","Epoch: [5][2000/3395] Elapsed 5m 56s (remain 4m 8s) Loss: 0.0097(0.0094) Grad: 9516.3418  LR: 0.00000025  \n","Epoch: [5][2100/3395] Elapsed 6m 14s (remain 3m 50s) Loss: 0.0027(0.0094) Grad: 12212.1836  LR: 0.00000022  \n","Epoch: [5][2200/3395] Elapsed 6m 32s (remain 3m 32s) Loss: 0.0048(0.0094) Grad: 5827.5088  LR: 0.00000018  \n","Epoch: [5][2300/3395] Elapsed 6m 50s (remain 3m 15s) Loss: 0.0153(0.0094) Grad: 50180.1133  LR: 0.00000015  \n","Epoch: [5][2400/3395] Elapsed 7m 8s (remain 2m 57s) Loss: 0.0067(0.0094) Grad: 17506.8945  LR: 0.00000013  \n","Epoch: [5][2500/3395] Elapsed 7m 25s (remain 2m 39s) Loss: 0.0117(0.0094) Grad: 16920.7598  LR: 0.00000010  \n","Epoch: [5][2600/3395] Elapsed 7m 43s (remain 2m 21s) Loss: 0.0129(0.0094) Grad: 7400.2412  LR: 0.00000008  \n","Epoch: [5][2700/3395] Elapsed 8m 1s (remain 2m 3s) Loss: 0.0085(0.0094) Grad: 7378.7524  LR: 0.00000006  \n","Epoch: [5][2800/3395] Elapsed 8m 20s (remain 1m 46s) Loss: 0.0035(0.0094) Grad: 8178.6523  LR: 0.00000005  \n","Epoch: [5][2900/3395] Elapsed 8m 38s (remain 1m 28s) Loss: 0.0060(0.0094) Grad: 27808.2812  LR: 0.00000003  \n","Epoch: [5][3000/3395] Elapsed 8m 56s (remain 1m 10s) Loss: 0.0150(0.0094) Grad: 36113.4336  LR: 0.00000002  \n","Epoch: [5][3100/3395] Elapsed 9m 14s (remain 0m 52s) Loss: 0.0106(0.0094) Grad: 11908.8789  LR: 0.00000001  \n","Epoch: [5][3200/3395] Elapsed 9m 32s (remain 0m 34s) Loss: 0.0099(0.0094) Grad: 11466.7451  LR: 0.00000000  \n","Epoch: [5][3300/3395] Elapsed 9m 50s (remain 0m 16s) Loss: 0.0019(0.0094) Grad: 1048.3201  LR: 0.00000000  \n","Epoch: [5][3394/3395] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0066(0.0094) Grad: 5854.0894  LR: 0.00000000  \n","EVAL: [0/253] Elapsed 0m 0s (remain 1m 28s) Loss: 0.0428(0.0428) \n","EVAL: [100/253] Elapsed 0m 10s (remain 0m 15s) Loss: 0.1086(0.1030) \n","EVAL: [200/253] Elapsed 0m 19s (remain 0m 5s) Loss: 0.0497(0.1000) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0094  avg_val_loss: 0.0990  time: 633s\n","Epoch 5 - Score: 0.7998\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [252/253] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0170(0.0990) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 3 result ==========\n","Score: 0.8031\n","========== fold: 4 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3406] Elapsed 0m 0s (remain 23m 43s) Loss: 0.2207(0.2207) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3406] Elapsed 0m 18s (remain 9m 51s) Loss: 0.1238(0.1033) Grad: 15864.6689  LR: 0.00001500  \n","Epoch: [1][200/3406] Elapsed 0m 35s (remain 9m 32s) Loss: 0.0777(0.0839) Grad: 9795.7363  LR: 0.00001500  \n","Epoch: [1][300/3406] Elapsed 0m 53s (remain 9m 12s) Loss: 0.0446(0.0742) Grad: 5558.3457  LR: 0.00001499  \n","Epoch: [1][400/3406] Elapsed 1m 11s (remain 8m 55s) Loss: 0.0278(0.0681) Grad: 8549.4561  LR: 0.00001498  \n","Epoch: [1][500/3406] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0262(0.0644) Grad: 8702.5654  LR: 0.00001497  \n","Epoch: [1][600/3406] Elapsed 1m 46s (remain 8m 18s) Loss: 0.0320(0.0616) Grad: 1191.8500  LR: 0.00001496  \n","Epoch: [1][700/3406] Elapsed 2m 4s (remain 8m 0s) Loss: 0.0698(0.0587) Grad: 2782.1021  LR: 0.00001495  \n","Epoch: [1][800/3406] Elapsed 2m 22s (remain 7m 42s) Loss: 0.0470(0.0567) Grad: 3552.4363  LR: 0.00001493  \n","Epoch: [1][900/3406] Elapsed 2m 40s (remain 7m 25s) Loss: 0.0268(0.0546) Grad: 2696.3091  LR: 0.00001491  \n","Epoch: [1][1000/3406] Elapsed 2m 57s (remain 7m 6s) Loss: 0.0473(0.0529) Grad: 4787.4648  LR: 0.00001488  \n","Epoch: [1][1100/3406] Elapsed 3m 15s (remain 6m 49s) Loss: 0.0779(0.0516) Grad: 5544.6465  LR: 0.00001486  \n","Epoch: [1][1200/3406] Elapsed 3m 33s (remain 6m 31s) Loss: 0.0186(0.0504) Grad: 2120.5864  LR: 0.00001483  \n","Epoch: [1][1300/3406] Elapsed 3m 51s (remain 6m 13s) Loss: 0.0406(0.0491) Grad: 6138.7207  LR: 0.00001480  \n","Epoch: [1][1400/3406] Elapsed 4m 8s (remain 5m 56s) Loss: 0.0276(0.0484) Grad: 2861.6301  LR: 0.00001477  \n","Epoch: [1][1500/3406] Elapsed 4m 26s (remain 5m 38s) Loss: 0.0146(0.0477) Grad: 1751.5857  LR: 0.00001473  \n","Epoch: [1][1600/3406] Elapsed 4m 44s (remain 5m 20s) Loss: 0.0381(0.0468) Grad: 2005.3230  LR: 0.00001469  \n","Epoch: [1][1700/3406] Elapsed 5m 2s (remain 5m 2s) Loss: 0.0470(0.0458) Grad: 4749.5029  LR: 0.00001465  \n","Epoch: [1][1800/3406] Elapsed 5m 19s (remain 4m 44s) Loss: 0.0130(0.0452) Grad: 1462.4457  LR: 0.00001461  \n","Epoch: [1][1900/3406] Elapsed 5m 37s (remain 4m 27s) Loss: 0.0436(0.0446) Grad: 1822.3250  LR: 0.00001456  \n","Epoch: [1][2000/3406] Elapsed 5m 55s (remain 4m 9s) Loss: 0.0567(0.0440) Grad: 3757.6560  LR: 0.00001452  \n","Epoch: [1][2100/3406] Elapsed 6m 12s (remain 3m 51s) Loss: 0.0132(0.0434) Grad: 3274.3191  LR: 0.00001447  \n","Epoch: [1][2200/3406] Elapsed 6m 30s (remain 3m 33s) Loss: 0.0271(0.0428) Grad: 3787.7844  LR: 0.00001441  \n","Epoch: [1][2300/3406] Elapsed 6m 48s (remain 3m 16s) Loss: 0.0344(0.0421) Grad: 8825.2158  LR: 0.00001436  \n","Epoch: [1][2400/3406] Elapsed 7m 5s (remain 2m 58s) Loss: 0.0254(0.0416) Grad: 8297.5635  LR: 0.00001430  \n","Epoch: [1][2500/3406] Elapsed 7m 23s (remain 2m 40s) Loss: 0.0259(0.0411) Grad: 14815.9893  LR: 0.00001424  \n","Epoch: [1][2600/3406] Elapsed 7m 42s (remain 2m 23s) Loss: 0.0755(0.0406) Grad: 7952.1997  LR: 0.00001418  \n","Epoch: [1][2700/3406] Elapsed 8m 0s (remain 2m 5s) Loss: 0.0222(0.0403) Grad: 2896.0217  LR: 0.00001412  \n","Epoch: [1][2800/3406] Elapsed 8m 18s (remain 1m 47s) Loss: 0.0450(0.0399) Grad: 11283.6553  LR: 0.00001405  \n","Epoch: [1][2900/3406] Elapsed 8m 36s (remain 1m 29s) Loss: 0.0287(0.0396) Grad: 9702.8340  LR: 0.00001398  \n","Epoch: [1][3000/3406] Elapsed 8m 54s (remain 1m 12s) Loss: 0.0185(0.0392) Grad: 7124.0474  LR: 0.00001391  \n","Epoch: [1][3100/3406] Elapsed 9m 12s (remain 0m 54s) Loss: 0.0318(0.0388) Grad: 5436.1538  LR: 0.00001384  \n","Epoch: [1][3200/3406] Elapsed 9m 31s (remain 0m 36s) Loss: 0.0099(0.0386) Grad: 2205.8035  LR: 0.00001376  \n","Epoch: [1][3300/3406] Elapsed 9m 49s (remain 0m 18s) Loss: 0.0181(0.0383) Grad: 5808.1226  LR: 0.00001368  \n","Epoch: [1][3400/3406] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0261(0.0380) Grad: 4523.1011  LR: 0.00001360  \n","Epoch: [1][3405/3406] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0243(0.0380) Grad: 5660.8799  LR: 0.00001360  \n","EVAL: [0/241] Elapsed 0m 0s (remain 1m 22s) Loss: 0.0712(0.0712) \n","EVAL: [100/241] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1981(0.1112) \n","EVAL: [200/241] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0948(0.1084) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0380  avg_val_loss: 0.1096  time: 632s\n","Epoch 1 - Score: 0.7624\n","Epoch 1 - Save Best Score: 0.7624 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [240/241] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0142(0.1096) \n","Epoch: [2][0/3406] Elapsed 0m 0s (remain 25m 50s) Loss: 0.0298(0.0298) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3406] Elapsed 0m 18s (remain 10m 0s) Loss: 0.0181(0.0260) Grad: 16826.3047  LR: 0.00001352  \n","Epoch: [2][200/3406] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0233(0.0235) Grad: 32018.9805  LR: 0.00001343  \n","Epoch: [2][300/3406] Elapsed 0m 54s (remain 9m 21s) Loss: 0.0479(0.0223) Grad: 8617.0469  LR: 0.00001335  \n","Epoch: [2][400/3406] Elapsed 1m 12s (remain 9m 2s) Loss: 0.0154(0.0219) Grad: 10549.4307  LR: 0.00001326  \n","Epoch: [2][500/3406] Elapsed 1m 30s (remain 8m 42s) Loss: 0.0410(0.0220) Grad: 31874.2656  LR: 0.00001317  \n","Epoch: [2][600/3406] Elapsed 1m 48s (remain 8m 24s) Loss: 0.0072(0.0220) Grad: 5573.4810  LR: 0.00001308  \n","Epoch: [2][700/3406] Elapsed 2m 5s (remain 8m 5s) Loss: 0.0143(0.0222) Grad: 7676.8735  LR: 0.00001299  \n","Epoch: [2][800/3406] Elapsed 2m 23s (remain 7m 47s) Loss: 0.0453(0.0222) Grad: 27077.4883  LR: 0.00001289  \n","Epoch: [2][900/3406] Elapsed 2m 41s (remain 7m 28s) Loss: 0.0163(0.0224) Grad: 13856.4160  LR: 0.00001279  \n","Epoch: [2][1000/3406] Elapsed 2m 59s (remain 7m 10s) Loss: 0.0124(0.0223) Grad: 4875.6157  LR: 0.00001269  \n","Epoch: [2][1100/3406] Elapsed 3m 17s (remain 6m 52s) Loss: 0.0090(0.0225) Grad: 11577.0010  LR: 0.00001259  \n","Epoch: [2][1200/3406] Elapsed 3m 34s (remain 6m 34s) Loss: 0.0158(0.0224) Grad: 7310.6245  LR: 0.00001249  \n","Epoch: [2][1300/3406] Elapsed 3m 52s (remain 6m 16s) Loss: 0.0362(0.0224) Grad: 11849.7158  LR: 0.00001239  \n","Epoch: [2][1400/3406] Elapsed 4m 10s (remain 5m 58s) Loss: 0.0062(0.0224) Grad: 6155.8638  LR: 0.00001228  \n","Epoch: [2][1500/3406] Elapsed 4m 28s (remain 5m 40s) Loss: 0.0202(0.0224) Grad: 6868.7432  LR: 0.00001217  \n","Epoch: [2][1600/3406] Elapsed 4m 46s (remain 5m 22s) Loss: 0.0361(0.0223) Grad: 17217.2715  LR: 0.00001206  \n","Epoch: [2][1700/3406] Elapsed 5m 3s (remain 5m 4s) Loss: 0.0142(0.0223) Grad: 4709.8105  LR: 0.00001195  \n","Epoch: [2][1800/3406] Elapsed 5m 21s (remain 4m 46s) Loss: 0.0161(0.0223) Grad: 6453.7866  LR: 0.00001184  \n","Epoch: [2][1900/3406] Elapsed 5m 39s (remain 4m 28s) Loss: 0.0339(0.0222) Grad: 31106.4570  LR: 0.00001172  \n","Epoch: [2][2000/3406] Elapsed 5m 57s (remain 4m 10s) Loss: 0.0430(0.0223) Grad: 17388.8340  LR: 0.00001161  \n","Epoch: [2][2100/3406] Elapsed 6m 14s (remain 3m 52s) Loss: 0.0311(0.0223) Grad: 11845.8584  LR: 0.00001149  \n","Epoch: [2][2200/3406] Elapsed 6m 32s (remain 3m 34s) Loss: 0.0267(0.0224) Grad: 31256.3555  LR: 0.00001137  \n","Epoch: [2][2300/3406] Elapsed 6m 50s (remain 3m 17s) Loss: 0.0200(0.0223) Grad: 15435.5605  LR: 0.00001126  \n","Epoch: [2][2400/3406] Elapsed 7m 8s (remain 2m 59s) Loss: 0.0273(0.0222) Grad: 21595.7715  LR: 0.00001113  \n","Epoch: [2][2500/3406] Elapsed 7m 26s (remain 2m 41s) Loss: 0.0190(0.0221) Grad: 11802.6191  LR: 0.00001101  \n","Epoch: [2][2600/3406] Elapsed 7m 44s (remain 2m 23s) Loss: 0.0160(0.0220) Grad: 4754.8916  LR: 0.00001089  \n","Epoch: [2][2700/3406] Elapsed 8m 2s (remain 2m 6s) Loss: 0.0355(0.0220) Grad: 9397.2754  LR: 0.00001077  \n","Epoch: [2][2800/3406] Elapsed 8m 20s (remain 1m 48s) Loss: 0.0050(0.0220) Grad: 2652.7434  LR: 0.00001064  \n","Epoch: [2][2900/3406] Elapsed 8m 39s (remain 1m 30s) Loss: 0.0278(0.0220) Grad: 7412.3613  LR: 0.00001051  \n","Epoch: [2][3000/3406] Elapsed 8m 57s (remain 1m 12s) Loss: 0.0117(0.0220) Grad: 15587.3428  LR: 0.00001039  \n","Epoch: [2][3100/3406] Elapsed 9m 15s (remain 0m 54s) Loss: 0.0117(0.0220) Grad: 6390.3701  LR: 0.00001026  \n","Epoch: [2][3200/3406] Elapsed 9m 33s (remain 0m 36s) Loss: 0.0163(0.0219) Grad: 21777.2520  LR: 0.00001013  \n","Epoch: [2][3300/3406] Elapsed 9m 51s (remain 0m 18s) Loss: 0.0371(0.0219) Grad: 32760.4824  LR: 0.00001000  \n","Epoch: [2][3400/3406] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0155(0.0219) Grad: 7058.5659  LR: 0.00000987  \n","Epoch: [2][3405/3406] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0150(0.0219) Grad: 7495.1025  LR: 0.00000986  \n","EVAL: [0/241] Elapsed 0m 0s (remain 1m 20s) Loss: 0.0738(0.0738) \n","EVAL: [100/241] Elapsed 0m 10s (remain 0m 13s) Loss: 0.2013(0.1080) \n","EVAL: [200/241] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0998(0.1049) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0219  avg_val_loss: 0.1062  time: 634s\n","Epoch 2 - Score: 0.7628\n","Epoch 2 - Save Best Score: 0.7628 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [240/241] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0141(0.1062) \n","Epoch: [3][0/3406] Elapsed 0m 0s (remain 25m 26s) Loss: 0.0038(0.0038) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3406] Elapsed 0m 18s (remain 10m 1s) Loss: 0.0071(0.0164) Grad: 24798.6094  LR: 0.00000973  \n","Epoch: [3][200/3406] Elapsed 0m 36s (remain 9m 41s) Loss: 0.0053(0.0155) Grad: 2860.7061  LR: 0.00000959  \n","Epoch: [3][300/3406] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0096(0.0160) Grad: 18540.1387  LR: 0.00000946  \n","Epoch: [3][400/3406] Elapsed 1m 11s (remain 8m 59s) Loss: 0.0121(0.0162) Grad: 5719.8149  LR: 0.00000933  \n","Epoch: [3][500/3406] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0150(0.0165) Grad: 4887.6943  LR: 0.00000919  \n","Epoch: [3][600/3406] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0526(0.0166) Grad: 13869.8018  LR: 0.00000905  \n","Epoch: [3][700/3406] Elapsed 2m 5s (remain 8m 3s) Loss: 0.0050(0.0168) Grad: 10571.9287  LR: 0.00000892  \n","Epoch: [3][800/3406] Elapsed 2m 22s (remain 7m 44s) Loss: 0.0312(0.0169) Grad: 12740.1748  LR: 0.00000878  \n","Epoch: [3][900/3406] Elapsed 2m 40s (remain 7m 26s) Loss: 0.0105(0.0167) Grad: 4190.8228  LR: 0.00000865  \n","Epoch: [3][1000/3406] Elapsed 2m 58s (remain 7m 8s) Loss: 0.0066(0.0166) Grad: 5825.6631  LR: 0.00000851  \n","Epoch: [3][1100/3406] Elapsed 3m 16s (remain 6m 51s) Loss: 0.0184(0.0165) Grad: 5270.7271  LR: 0.00000837  \n","Epoch: [3][1200/3406] Elapsed 3m 34s (remain 6m 32s) Loss: 0.0078(0.0164) Grad: 10094.7295  LR: 0.00000823  \n","Epoch: [3][1300/3406] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0184(0.0164) Grad: 7953.2520  LR: 0.00000809  \n","Epoch: [3][1400/3406] Elapsed 4m 9s (remain 5m 57s) Loss: 0.0269(0.0164) Grad: 7104.7695  LR: 0.00000796  \n","Epoch: [3][1500/3406] Elapsed 4m 27s (remain 5m 39s) Loss: 0.0055(0.0165) Grad: 1715.3071  LR: 0.00000782  \n","Epoch: [3][1600/3406] Elapsed 4m 45s (remain 5m 21s) Loss: 0.0253(0.0166) Grad: 12171.1123  LR: 0.00000768  \n","Epoch: [3][1700/3406] Elapsed 5m 2s (remain 5m 3s) Loss: 0.0130(0.0166) Grad: 7767.5820  LR: 0.00000754  \n","Epoch: [3][1800/3406] Elapsed 5m 20s (remain 4m 45s) Loss: 0.0049(0.0166) Grad: 2154.6960  LR: 0.00000740  \n","Epoch: [3][1900/3406] Elapsed 5m 38s (remain 4m 27s) Loss: 0.0113(0.0166) Grad: 9136.2100  LR: 0.00000726  \n","Epoch: [3][2000/3406] Elapsed 5m 56s (remain 4m 10s) Loss: 0.0252(0.0165) Grad: 22583.8223  LR: 0.00000712  \n","Epoch: [3][2100/3406] Elapsed 6m 14s (remain 3m 52s) Loss: 0.0258(0.0165) Grad: 19237.4707  LR: 0.00000699  \n","Epoch: [3][2200/3406] Elapsed 6m 32s (remain 3m 34s) Loss: 0.0110(0.0165) Grad: 18352.3086  LR: 0.00000685  \n","Epoch: [3][2300/3406] Elapsed 6m 50s (remain 3m 17s) Loss: 0.0274(0.0165) Grad: 12672.8301  LR: 0.00000671  \n","Epoch: [3][2400/3406] Elapsed 7m 8s (remain 2m 59s) Loss: 0.0101(0.0165) Grad: 5099.8296  LR: 0.00000657  \n","Epoch: [3][2500/3406] Elapsed 7m 26s (remain 2m 41s) Loss: 0.0117(0.0166) Grad: 11628.3662  LR: 0.00000643  \n","Epoch: [3][2600/3406] Elapsed 7m 44s (remain 2m 23s) Loss: 0.0118(0.0167) Grad: 9447.3545  LR: 0.00000630  \n","Epoch: [3][2700/3406] Elapsed 8m 2s (remain 2m 5s) Loss: 0.0272(0.0167) Grad: 33674.4336  LR: 0.00000616  \n","Epoch: [3][2800/3406] Elapsed 8m 20s (remain 1m 48s) Loss: 0.0258(0.0167) Grad: 10641.7871  LR: 0.00000602  \n","Epoch: [3][2900/3406] Elapsed 8m 38s (remain 1m 30s) Loss: 0.0259(0.0167) Grad: 6071.5913  LR: 0.00000589  \n","Epoch: [3][3000/3406] Elapsed 8m 56s (remain 1m 12s) Loss: 0.0167(0.0167) Grad: 5215.0220  LR: 0.00000575  \n","Epoch: [3][3100/3406] Elapsed 9m 14s (remain 0m 54s) Loss: 0.0136(0.0166) Grad: 15619.7744  LR: 0.00000562  \n","Epoch: [3][3200/3406] Elapsed 9m 32s (remain 0m 36s) Loss: 0.0377(0.0166) Grad: 32145.1113  LR: 0.00000548  \n","Epoch: [3][3300/3406] Elapsed 9m 50s (remain 0m 18s) Loss: 0.0055(0.0165) Grad: 8807.0742  LR: 0.00000535  \n","Epoch: [3][3400/3406] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0225(0.0166) Grad: 20014.1133  LR: 0.00000522  \n","Epoch: [3][3405/3406] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0127(0.0165) Grad: 12273.2598  LR: 0.00000521  \n","EVAL: [0/241] Elapsed 0m 0s (remain 1m 19s) Loss: 0.0676(0.0676) \n","EVAL: [100/241] Elapsed 0m 9s (remain 0m 13s) Loss: 0.1861(0.1020) \n","EVAL: [200/241] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0872(0.0997) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0165  avg_val_loss: 0.1010  time: 633s\n","Epoch 3 - Score: 0.7681\n","Epoch 3 - Save Best Score: 0.7681 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [240/241] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0142(0.1010) \n","Epoch: [4][0/3406] Elapsed 0m 0s (remain 25m 39s) Loss: 0.0208(0.0208) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3406] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0151(0.0123) Grad: 34125.4844  LR: 0.00000508  \n","Epoch: [4][200/3406] Elapsed 0m 36s (remain 9m 42s) Loss: 0.0050(0.0125) Grad: 11751.4385  LR: 0.00000495  \n","Epoch: [4][300/3406] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0261(0.0123) Grad: 13718.1875  LR: 0.00000482  \n","Epoch: [4][400/3406] Elapsed 1m 12s (remain 9m 0s) Loss: 0.0106(0.0123) Grad: 12747.0732  LR: 0.00000469  \n","Epoch: [4][500/3406] Elapsed 1m 29s (remain 8m 40s) Loss: 0.0040(0.0124) Grad: 6945.5215  LR: 0.00000456  \n","Epoch: [4][600/3406] Elapsed 1m 47s (remain 8m 22s) Loss: 0.0142(0.0124) Grad: 14284.4326  LR: 0.00000443  \n","Epoch: [4][700/3406] Elapsed 2m 5s (remain 8m 3s) Loss: 0.0105(0.0123) Grad: 16228.1504  LR: 0.00000431  \n","Epoch: [4][800/3406] Elapsed 2m 23s (remain 7m 45s) Loss: 0.0015(0.0124) Grad: 13956.5674  LR: 0.00000418  \n","Epoch: [4][900/3406] Elapsed 2m 40s (remain 7m 27s) Loss: 0.0072(0.0125) Grad: 11972.3564  LR: 0.00000406  \n","Epoch: [4][1000/3406] Elapsed 2m 58s (remain 7m 8s) Loss: 0.0175(0.0123) Grad: 11556.0908  LR: 0.00000394  \n","Epoch: [4][1100/3406] Elapsed 3m 16s (remain 6m 50s) Loss: 0.0166(0.0123) Grad: 8559.3271  LR: 0.00000381  \n","Epoch: [4][1200/3406] Elapsed 3m 33s (remain 6m 32s) Loss: 0.0118(0.0123) Grad: 19755.0703  LR: 0.00000369  \n","Epoch: [4][1300/3406] Elapsed 3m 51s (remain 6m 14s) Loss: 0.0058(0.0123) Grad: 16101.4141  LR: 0.00000358  \n","Epoch: [4][1400/3406] Elapsed 4m 9s (remain 5m 56s) Loss: 0.0068(0.0123) Grad: 4060.1570  LR: 0.00000346  \n","Epoch: [4][1500/3406] Elapsed 4m 27s (remain 5m 38s) Loss: 0.0043(0.0122) Grad: 11543.4238  LR: 0.00000334  \n","Epoch: [4][1600/3406] Elapsed 4m 44s (remain 5m 20s) Loss: 0.0138(0.0121) Grad: 2663.9661  LR: 0.00000323  \n","Epoch: [4][1700/3406] Elapsed 5m 2s (remain 5m 3s) Loss: 0.0039(0.0121) Grad: 1890.8134  LR: 0.00000311  \n","Epoch: [4][1800/3406] Elapsed 5m 20s (remain 4m 45s) Loss: 0.0072(0.0121) Grad: 5865.2251  LR: 0.00000300  \n","Epoch: [4][1900/3406] Elapsed 5m 37s (remain 4m 27s) Loss: 0.0057(0.0121) Grad: 6329.6504  LR: 0.00000289  \n","Epoch: [4][2000/3406] Elapsed 5m 55s (remain 4m 9s) Loss: 0.0128(0.0122) Grad: 14828.9961  LR: 0.00000278  \n","Epoch: [4][2100/3406] Elapsed 6m 13s (remain 3m 52s) Loss: 0.0036(0.0121) Grad: 5978.7549  LR: 0.00000268  \n","Epoch: [4][2200/3406] Elapsed 6m 31s (remain 3m 34s) Loss: 0.0181(0.0122) Grad: 7329.0435  LR: 0.00000257  \n","Epoch: [4][2300/3406] Elapsed 6m 50s (remain 3m 16s) Loss: 0.0427(0.0122) Grad: 6128.2739  LR: 0.00000247  \n","Epoch: [4][2400/3406] Elapsed 7m 8s (remain 2m 59s) Loss: 0.0093(0.0121) Grad: 12943.8701  LR: 0.00000237  \n","Epoch: [4][2500/3406] Elapsed 7m 26s (remain 2m 41s) Loss: 0.0027(0.0121) Grad: 5019.5425  LR: 0.00000226  \n","Epoch: [4][2600/3406] Elapsed 7m 44s (remain 2m 23s) Loss: 0.0141(0.0120) Grad: 11897.3350  LR: 0.00000217  \n","Epoch: [4][2700/3406] Elapsed 8m 2s (remain 2m 5s) Loss: 0.0106(0.0120) Grad: 4122.4844  LR: 0.00000207  \n","Epoch: [4][2800/3406] Elapsed 8m 20s (remain 1m 48s) Loss: 0.0131(0.0120) Grad: 4912.0425  LR: 0.00000198  \n","Epoch: [4][2900/3406] Elapsed 8m 38s (remain 1m 30s) Loss: 0.0119(0.0119) Grad: 4033.7275  LR: 0.00000188  \n","Epoch: [4][3000/3406] Elapsed 8m 56s (remain 1m 12s) Loss: 0.0148(0.0119) Grad: 4210.8530  LR: 0.00000179  \n","Epoch: [4][3100/3406] Elapsed 9m 14s (remain 0m 54s) Loss: 0.0154(0.0118) Grad: 9648.3975  LR: 0.00000170  \n","Epoch: [4][3200/3406] Elapsed 9m 31s (remain 0m 36s) Loss: 0.0259(0.0118) Grad: 6351.4106  LR: 0.00000162  \n","Epoch: [4][3300/3406] Elapsed 9m 49s (remain 0m 18s) Loss: 0.0041(0.0118) Grad: 7624.6890  LR: 0.00000153  \n","Epoch: [4][3400/3406] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0016(0.0118) Grad: 3989.3127  LR: 0.00000145  \n","Epoch: [4][3405/3406] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0040(0.0118) Grad: 2523.7847  LR: 0.00000144  \n","EVAL: [0/241] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0741(0.0741) \n","EVAL: [100/241] Elapsed 0m 9s (remain 0m 13s) Loss: 0.1920(0.1040) \n","EVAL: [200/241] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0913(0.1013) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0118  avg_val_loss: 0.1024  time: 632s\n","Epoch 4 - Score: 0.7782\n","Epoch 4 - Save Best Score: 0.7782 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [240/241] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0134(0.1024) \n","Epoch: [5][0/3406] Elapsed 0m 0s (remain 25m 18s) Loss: 0.0045(0.0045) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3406] Elapsed 0m 18s (remain 10m 1s) Loss: 0.0030(0.0086) Grad: 13945.8027  LR: 0.00000136  \n","Epoch: [5][200/3406] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0093(0.0094) Grad: 9385.9463  LR: 0.00000128  \n","Epoch: [5][300/3406] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0012(0.0094) Grad: 4883.8691  LR: 0.00000121  \n","Epoch: [5][400/3406] Elapsed 1m 11s (remain 8m 58s) Loss: 0.0018(0.0091) Grad: 6093.9136  LR: 0.00000113  \n","Epoch: [5][500/3406] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0069(0.0092) Grad: 8574.5547  LR: 0.00000106  \n","Epoch: [5][600/3406] Elapsed 1m 47s (remain 8m 20s) Loss: 0.0060(0.0092) Grad: 17851.7051  LR: 0.00000099  \n","Epoch: [5][700/3406] Elapsed 2m 5s (remain 8m 2s) Loss: 0.0068(0.0092) Grad: 6994.2148  LR: 0.00000092  \n","Epoch: [5][800/3406] Elapsed 2m 22s (remain 7m 43s) Loss: 0.0093(0.0092) Grad: 14111.2764  LR: 0.00000086  \n","Epoch: [5][900/3406] Elapsed 2m 40s (remain 7m 26s) Loss: 0.0033(0.0093) Grad: 12106.7539  LR: 0.00000079  \n","Epoch: [5][1000/3406] Elapsed 2m 58s (remain 7m 8s) Loss: 0.0098(0.0094) Grad: 8855.5361  LR: 0.00000073  \n","Epoch: [5][1100/3406] Elapsed 3m 16s (remain 6m 50s) Loss: 0.0149(0.0094) Grad: 24387.6562  LR: 0.00000067  \n","Epoch: [5][1200/3406] Elapsed 3m 33s (remain 6m 32s) Loss: 0.0080(0.0094) Grad: 12090.0088  LR: 0.00000062  \n","Epoch: [5][1300/3406] Elapsed 3m 51s (remain 6m 14s) Loss: 0.0107(0.0095) Grad: 25224.6777  LR: 0.00000056  \n","Epoch: [5][1400/3406] Elapsed 4m 9s (remain 5m 56s) Loss: 0.0005(0.0095) Grad: 2093.4744  LR: 0.00000051  \n","Epoch: [5][1500/3406] Elapsed 4m 27s (remain 5m 38s) Loss: 0.0215(0.0096) Grad: 19768.7109  LR: 0.00000046  \n","Epoch: [5][1600/3406] Elapsed 4m 44s (remain 5m 20s) Loss: 0.0119(0.0097) Grad: 6102.1694  LR: 0.00000042  \n","Epoch: [5][1700/3406] Elapsed 5m 2s (remain 5m 2s) Loss: 0.0112(0.0097) Grad: 9065.6670  LR: 0.00000037  \n","Epoch: [5][1800/3406] Elapsed 5m 20s (remain 4m 45s) Loss: 0.0045(0.0098) Grad: 3223.2109  LR: 0.00000033  \n","Epoch: [5][1900/3406] Elapsed 5m 38s (remain 4m 27s) Loss: 0.0085(0.0097) Grad: 2469.7915  LR: 0.00000029  \n","Epoch: [5][2000/3406] Elapsed 5m 56s (remain 4m 10s) Loss: 0.0090(0.0096) Grad: 14457.4072  LR: 0.00000025  \n","Epoch: [5][2100/3406] Elapsed 6m 14s (remain 3m 52s) Loss: 0.0051(0.0096) Grad: 2787.6072  LR: 0.00000022  \n","Epoch: [5][2200/3406] Elapsed 6m 32s (remain 3m 34s) Loss: 0.0009(0.0097) Grad: 1906.0074  LR: 0.00000019  \n","Epoch: [5][2300/3406] Elapsed 6m 50s (remain 3m 16s) Loss: 0.0010(0.0097) Grad: 1450.5219  LR: 0.00000016  \n","Epoch: [5][2400/3406] Elapsed 7m 8s (remain 2m 59s) Loss: 0.0140(0.0096) Grad: 16170.8301  LR: 0.00000013  \n","Epoch: [5][2500/3406] Elapsed 7m 26s (remain 2m 41s) Loss: 0.0140(0.0096) Grad: 6677.0801  LR: 0.00000011  \n","Epoch: [5][2600/3406] Elapsed 7m 44s (remain 2m 23s) Loss: 0.0060(0.0096) Grad: 3596.4585  LR: 0.00000008  \n","Epoch: [5][2700/3406] Elapsed 8m 2s (remain 2m 5s) Loss: 0.0041(0.0096) Grad: 2289.6182  LR: 0.00000006  \n","Epoch: [5][2800/3406] Elapsed 8m 20s (remain 1m 48s) Loss: 0.0074(0.0096) Grad: 3542.5854  LR: 0.00000005  \n","Epoch: [5][2900/3406] Elapsed 8m 38s (remain 1m 30s) Loss: 0.0048(0.0096) Grad: 11515.9482  LR: 0.00000003  \n","Epoch: [5][3000/3406] Elapsed 8m 55s (remain 1m 12s) Loss: 0.0383(0.0096) Grad: 24024.4570  LR: 0.00000002  \n","Epoch: [5][3100/3406] Elapsed 9m 13s (remain 0m 54s) Loss: 0.0073(0.0096) Grad: 13221.9746  LR: 0.00000001  \n","Epoch: [5][3200/3406] Elapsed 9m 31s (remain 0m 36s) Loss: 0.0157(0.0096) Grad: 11334.5195  LR: 0.00000001  \n","Epoch: [5][3300/3406] Elapsed 9m 49s (remain 0m 18s) Loss: 0.0020(0.0096) Grad: 8851.3994  LR: 0.00000000  \n","Epoch: [5][3400/3406] Elapsed 10m 6s (remain 0m 0s) Loss: 0.0003(0.0096) Grad: 804.8869  LR: 0.00000000  \n","Epoch: [5][3405/3406] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0035(0.0096) Grad: 4149.2954  LR: 0.00000000  \n","EVAL: [0/241] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0767(0.0767) \n","EVAL: [100/241] Elapsed 0m 9s (remain 0m 13s) Loss: 0.1922(0.1045) \n","EVAL: [200/241] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0919(0.1017) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0096  avg_val_loss: 0.1029  time: 631s\n","Epoch 5 - Score: 0.7770\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [240/241] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0135(0.1029) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 4 result ==========\n","Score: 0.7782\n","========== fold: 5 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3393] Elapsed 0m 0s (remain 22m 32s) Loss: 0.0936(0.0936) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3393] Elapsed 0m 17s (remain 9m 46s) Loss: 0.0580(0.0846) Grad: 5764.8027  LR: 0.00001500  \n","Epoch: [1][200/3393] Elapsed 0m 35s (remain 9m 27s) Loss: 0.1599(0.0877) Grad: 6185.4961  LR: 0.00001500  \n","Epoch: [1][300/3393] Elapsed 0m 53s (remain 9m 10s) Loss: 0.0916(0.0859) Grad: 13976.9824  LR: 0.00001499  \n","Epoch: [1][400/3393] Elapsed 1m 11s (remain 8m 51s) Loss: 0.1205(0.0845) Grad: 5561.1787  LR: 0.00001498  \n","Epoch: [1][500/3393] Elapsed 1m 29s (remain 8m 34s) Loss: 0.0945(0.0801) Grad: 25914.4863  LR: 0.00001497  \n","Epoch: [1][600/3393] Elapsed 1m 46s (remain 8m 16s) Loss: 0.0361(0.0764) Grad: 13817.3936  LR: 0.00001496  \n","Epoch: [1][700/3393] Elapsed 2m 4s (remain 7m 58s) Loss: 0.0738(0.0736) Grad: 6337.7510  LR: 0.00001495  \n","Epoch: [1][800/3393] Elapsed 2m 22s (remain 7m 40s) Loss: 0.0391(0.0707) Grad: 15953.6279  LR: 0.00001493  \n","Epoch: [1][900/3393] Elapsed 2m 40s (remain 7m 23s) Loss: 0.0987(0.0681) Grad: 4551.6367  LR: 0.00001491  \n","Epoch: [1][1000/3393] Elapsed 2m 57s (remain 7m 5s) Loss: 0.1235(0.0656) Grad: 31124.5605  LR: 0.00001488  \n","Epoch: [1][1100/3393] Elapsed 3m 15s (remain 6m 47s) Loss: 0.0112(0.0639) Grad: 3118.2656  LR: 0.00001486  \n","Epoch: [1][1200/3393] Elapsed 3m 33s (remain 6m 29s) Loss: 0.0378(0.0619) Grad: 12831.9893  LR: 0.00001483  \n","Epoch: [1][1300/3393] Elapsed 3m 51s (remain 6m 11s) Loss: 0.0494(0.0600) Grad: 3945.8096  LR: 0.00001480  \n","Epoch: [1][1400/3393] Elapsed 4m 8s (remain 5m 53s) Loss: 0.0509(0.0587) Grad: 25220.8203  LR: 0.00001477  \n","Epoch: [1][1500/3393] Elapsed 4m 26s (remain 5m 35s) Loss: 0.0367(0.0574) Grad: 15745.0645  LR: 0.00001473  \n","Epoch: [1][1600/3393] Elapsed 4m 44s (remain 5m 17s) Loss: 0.0341(0.0561) Grad: 16482.4727  LR: 0.00001469  \n","Epoch: [1][1700/3393] Elapsed 5m 2s (remain 5m 0s) Loss: 0.1046(0.0548) Grad: 21726.1641  LR: 0.00001465  \n","Epoch: [1][1800/3393] Elapsed 5m 20s (remain 4m 42s) Loss: 0.0226(0.0536) Grad: 6623.0864  LR: 0.00001461  \n","Epoch: [1][1900/3393] Elapsed 5m 38s (remain 4m 25s) Loss: 0.0201(0.0526) Grad: 4589.2485  LR: 0.00001456  \n","Epoch: [1][2000/3393] Elapsed 5m 56s (remain 4m 7s) Loss: 0.0617(0.0519) Grad: 6564.9229  LR: 0.00001451  \n","Epoch: [1][2100/3393] Elapsed 6m 14s (remain 3m 50s) Loss: 0.0328(0.0510) Grad: 9471.8691  LR: 0.00001446  \n","Epoch: [1][2200/3393] Elapsed 6m 32s (remain 3m 32s) Loss: 0.0496(0.0502) Grad: 29342.6367  LR: 0.00001441  \n","Epoch: [1][2300/3393] Elapsed 6m 50s (remain 3m 14s) Loss: 0.0333(0.0493) Grad: 16873.5195  LR: 0.00001435  \n","Epoch: [1][2400/3393] Elapsed 7m 8s (remain 2m 57s) Loss: 0.0280(0.0485) Grad: 23318.6328  LR: 0.00001430  \n","Epoch: [1][2500/3393] Elapsed 7m 26s (remain 2m 39s) Loss: 0.0356(0.0478) Grad: 16924.4648  LR: 0.00001424  \n","Epoch: [1][2600/3393] Elapsed 7m 44s (remain 2m 21s) Loss: 0.0107(0.0470) Grad: 6792.7402  LR: 0.00001417  \n","Epoch: [1][2700/3393] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0772(0.0464) Grad: 24168.6094  LR: 0.00001411  \n","Epoch: [1][2800/3393] Elapsed 8m 20s (remain 1m 45s) Loss: 0.0252(0.0458) Grad: 22142.8203  LR: 0.00001404  \n","Epoch: [1][2900/3393] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0180(0.0452) Grad: 8332.6797  LR: 0.00001397  \n","Epoch: [1][3000/3393] Elapsed 8m 56s (remain 1m 10s) Loss: 0.0304(0.0447) Grad: 4220.8960  LR: 0.00001390  \n","Epoch: [1][3100/3393] Elapsed 9m 14s (remain 0m 52s) Loss: 0.0468(0.0442) Grad: 8193.4561  LR: 0.00001383  \n","Epoch: [1][3200/3393] Elapsed 9m 31s (remain 0m 34s) Loss: 0.0323(0.0437) Grad: 12538.3506  LR: 0.00001375  \n","Epoch: [1][3300/3393] Elapsed 9m 49s (remain 0m 16s) Loss: 0.0614(0.0433) Grad: 24026.2637  LR: 0.00001367  \n","Epoch: [1][3392/3393] Elapsed 10m 6s (remain 0m 0s) Loss: 0.0452(0.0429) Grad: 35635.9531  LR: 0.00001360  \n","EVAL: [0/255] Elapsed 0m 0s (remain 1m 24s) Loss: 0.2018(0.2018) \n","EVAL: [100/255] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1129(0.1166) \n","EVAL: [200/255] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1582(0.1150) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0429  avg_val_loss: 0.1149  time: 631s\n","Epoch 1 - Score: 0.7783\n","Epoch 1 - Save Best Score: 0.7783 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [254/255] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0045(0.1149) \n","Epoch: [2][0/3393] Elapsed 0m 0s (remain 25m 44s) Loss: 0.0274(0.0274) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3393] Elapsed 0m 18s (remain 10m 2s) Loss: 0.0427(0.0239) Grad: 18355.8613  LR: 0.00001352  \n","Epoch: [2][200/3393] Elapsed 0m 36s (remain 9m 41s) Loss: 0.0232(0.0233) Grad: 28703.6641  LR: 0.00001343  \n","Epoch: [2][300/3393] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0208(0.0240) Grad: 7427.1587  LR: 0.00001335  \n","Epoch: [2][400/3393] Elapsed 1m 12s (remain 8m 59s) Loss: 0.0335(0.0246) Grad: 23236.1465  LR: 0.00001326  \n","Epoch: [2][500/3393] Elapsed 1m 30s (remain 8m 40s) Loss: 0.0089(0.0239) Grad: 3596.9346  LR: 0.00001317  \n","Epoch: [2][600/3393] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0082(0.0239) Grad: 5746.2085  LR: 0.00001308  \n","Epoch: [2][700/3393] Elapsed 2m 5s (remain 8m 2s) Loss: 0.0410(0.0240) Grad: 9069.2168  LR: 0.00001298  \n","Epoch: [2][800/3393] Elapsed 2m 23s (remain 7m 44s) Loss: 0.0456(0.0241) Grad: 21158.5664  LR: 0.00001289  \n","Epoch: [2][900/3393] Elapsed 2m 41s (remain 7m 26s) Loss: 0.0317(0.0240) Grad: 10348.3027  LR: 0.00001279  \n","Epoch: [2][1000/3393] Elapsed 2m 59s (remain 7m 8s) Loss: 0.0302(0.0240) Grad: 19130.3203  LR: 0.00001269  \n","Epoch: [2][1100/3393] Elapsed 3m 17s (remain 6m 50s) Loss: 0.0092(0.0242) Grad: 2705.3276  LR: 0.00001259  \n","Epoch: [2][1200/3393] Elapsed 3m 34s (remain 6m 31s) Loss: 0.0468(0.0244) Grad: 7377.6367  LR: 0.00001248  \n","Epoch: [2][1300/3393] Elapsed 3m 52s (remain 6m 13s) Loss: 0.0158(0.0246) Grad: 5685.6123  LR: 0.00001238  \n","Epoch: [2][1400/3393] Elapsed 4m 10s (remain 5m 55s) Loss: 0.0125(0.0248) Grad: 3226.3538  LR: 0.00001227  \n","Epoch: [2][1500/3393] Elapsed 4m 28s (remain 5m 37s) Loss: 0.0479(0.0251) Grad: 21953.4297  LR: 0.00001216  \n","Epoch: [2][1600/3393] Elapsed 4m 45s (remain 5m 19s) Loss: 0.0086(0.0252) Grad: 1892.2031  LR: 0.00001205  \n","Epoch: [2][1700/3393] Elapsed 5m 3s (remain 5m 2s) Loss: 0.0625(0.0252) Grad: 15513.2900  LR: 0.00001194  \n","Epoch: [2][1800/3393] Elapsed 5m 21s (remain 4m 44s) Loss: 0.0097(0.0251) Grad: 1295.8206  LR: 0.00001183  \n","Epoch: [2][1900/3393] Elapsed 5m 39s (remain 4m 26s) Loss: 0.0333(0.0250) Grad: 24128.8535  LR: 0.00001172  \n","Epoch: [2][2000/3393] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0274(0.0251) Grad: 5337.7222  LR: 0.00001160  \n","Epoch: [2][2100/3393] Elapsed 6m 16s (remain 3m 51s) Loss: 0.0414(0.0252) Grad: 6509.5747  LR: 0.00001148  \n","Epoch: [2][2200/3393] Elapsed 6m 34s (remain 3m 33s) Loss: 0.0457(0.0252) Grad: 11942.8076  LR: 0.00001136  \n","Epoch: [2][2300/3393] Elapsed 6m 52s (remain 3m 15s) Loss: 0.0310(0.0252) Grad: 9941.7344  LR: 0.00001124  \n","Epoch: [2][2400/3393] Elapsed 7m 10s (remain 2m 57s) Loss: 0.0201(0.0252) Grad: 15073.7539  LR: 0.00001112  \n","Epoch: [2][2500/3393] Elapsed 7m 28s (remain 2m 39s) Loss: 0.0046(0.0251) Grad: 1492.4218  LR: 0.00001100  \n","Epoch: [2][2600/3393] Elapsed 7m 46s (remain 2m 22s) Loss: 0.0042(0.0250) Grad: 5939.3555  LR: 0.00001088  \n","Epoch: [2][2700/3393] Elapsed 8m 4s (remain 2m 4s) Loss: 0.0513(0.0250) Grad: 19857.7363  LR: 0.00001075  \n","Epoch: [2][2800/3393] Elapsed 8m 22s (remain 1m 46s) Loss: 0.0114(0.0250) Grad: 1750.9148  LR: 0.00001062  \n","Epoch: [2][2900/3393] Elapsed 8m 39s (remain 1m 28s) Loss: 0.0417(0.0249) Grad: 20681.8926  LR: 0.00001050  \n","Epoch: [2][3000/3393] Elapsed 8m 57s (remain 1m 10s) Loss: 0.0116(0.0249) Grad: 4873.9219  LR: 0.00001037  \n","Epoch: [2][3100/3393] Elapsed 9m 15s (remain 0m 52s) Loss: 0.0047(0.0248) Grad: 2084.4956  LR: 0.00001024  \n","Epoch: [2][3200/3393] Elapsed 9m 33s (remain 0m 34s) Loss: 0.0493(0.0248) Grad: 42053.1992  LR: 0.00001011  \n","Epoch: [2][3300/3393] Elapsed 9m 50s (remain 0m 16s) Loss: 0.0111(0.0248) Grad: 4650.9673  LR: 0.00000998  \n","Epoch: [2][3392/3393] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0335(0.0247) Grad: 21089.3809  LR: 0.00000986  \n","EVAL: [0/255] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1677(0.1677) \n","EVAL: [100/255] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1048(0.1025) \n","EVAL: [200/255] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1428(0.1012) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0247  avg_val_loss: 0.1016  time: 632s\n","Epoch 2 - Score: 0.7895\n","Epoch 2 - Save Best Score: 0.7895 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [254/255] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0079(0.1016) \n","Epoch: [3][0/3393] Elapsed 0m 0s (remain 25m 30s) Loss: 0.0116(0.0116) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3393] Elapsed 0m 18s (remain 9m 55s) Loss: 0.0043(0.0187) Grad: 5904.1953  LR: 0.00000972  \n","Epoch: [3][200/3393] Elapsed 0m 36s (remain 9m 40s) Loss: 0.0119(0.0173) Grad: 24306.2207  LR: 0.00000959  \n","Epoch: [3][300/3393] Elapsed 0m 54s (remain 9m 17s) Loss: 0.0219(0.0176) Grad: 13646.4141  LR: 0.00000946  \n","Epoch: [3][400/3393] Elapsed 1m 11s (remain 8m 57s) Loss: 0.0282(0.0175) Grad: 24143.0859  LR: 0.00000932  \n","Epoch: [3][500/3393] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0170(0.0172) Grad: 8956.8672  LR: 0.00000919  \n","Epoch: [3][600/3393] Elapsed 1m 47s (remain 8m 18s) Loss: 0.0580(0.0169) Grad: 41389.4922  LR: 0.00000905  \n","Epoch: [3][700/3393] Elapsed 2m 5s (remain 8m 0s) Loss: 0.0274(0.0167) Grad: 15002.6123  LR: 0.00000891  \n","Epoch: [3][800/3393] Elapsed 2m 22s (remain 7m 42s) Loss: 0.0089(0.0167) Grad: 20194.3867  LR: 0.00000878  \n","Epoch: [3][900/3393] Elapsed 2m 40s (remain 7m 24s) Loss: 0.0103(0.0168) Grad: 8283.7539  LR: 0.00000864  \n","Epoch: [3][1000/3393] Elapsed 2m 58s (remain 7m 6s) Loss: 0.0338(0.0168) Grad: 12125.2383  LR: 0.00000850  \n","Epoch: [3][1100/3393] Elapsed 3m 16s (remain 6m 48s) Loss: 0.0224(0.0168) Grad: 11021.0664  LR: 0.00000836  \n","Epoch: [3][1200/3393] Elapsed 3m 34s (remain 6m 30s) Loss: 0.0063(0.0168) Grad: 9264.6221  LR: 0.00000822  \n","Epoch: [3][1300/3393] Elapsed 3m 51s (remain 6m 12s) Loss: 0.0228(0.0168) Grad: 10856.2520  LR: 0.00000809  \n","Epoch: [3][1400/3393] Elapsed 4m 9s (remain 5m 54s) Loss: 0.0074(0.0168) Grad: 6813.5259  LR: 0.00000795  \n","Epoch: [3][1500/3393] Elapsed 4m 27s (remain 5m 36s) Loss: 0.0080(0.0167) Grad: 3826.0398  LR: 0.00000781  \n","Epoch: [3][1600/3393] Elapsed 4m 45s (remain 5m 19s) Loss: 0.0162(0.0167) Grad: 4512.2861  LR: 0.00000767  \n","Epoch: [3][1700/3393] Elapsed 5m 3s (remain 5m 1s) Loss: 0.0262(0.0166) Grad: 18663.5391  LR: 0.00000753  \n","Epoch: [3][1800/3393] Elapsed 5m 21s (remain 4m 44s) Loss: 0.0163(0.0166) Grad: 6632.9736  LR: 0.00000739  \n","Epoch: [3][1900/3393] Elapsed 5m 39s (remain 4m 26s) Loss: 0.0078(0.0166) Grad: 8409.6475  LR: 0.00000725  \n","Epoch: [3][2000/3393] Elapsed 5m 57s (remain 4m 8s) Loss: 0.0324(0.0165) Grad: 8117.6646  LR: 0.00000711  \n","Epoch: [3][2100/3393] Elapsed 6m 15s (remain 3m 50s) Loss: 0.0103(0.0165) Grad: 12237.1162  LR: 0.00000697  \n","Epoch: [3][2200/3393] Elapsed 6m 33s (remain 3m 33s) Loss: 0.0252(0.0166) Grad: 7788.6567  LR: 0.00000683  \n","Epoch: [3][2300/3393] Elapsed 6m 51s (remain 3m 15s) Loss: 0.0107(0.0165) Grad: 14738.4541  LR: 0.00000670  \n","Epoch: [3][2400/3393] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0130(0.0165) Grad: 1914.0590  LR: 0.00000656  \n","Epoch: [3][2500/3393] Elapsed 7m 27s (remain 2m 39s) Loss: 0.0295(0.0164) Grad: 10794.9756  LR: 0.00000642  \n","Epoch: [3][2600/3393] Elapsed 7m 45s (remain 2m 21s) Loss: 0.0057(0.0164) Grad: 10709.1895  LR: 0.00000628  \n","Epoch: [3][2700/3393] Elapsed 8m 3s (remain 2m 3s) Loss: 0.0074(0.0163) Grad: 7514.0190  LR: 0.00000614  \n","Epoch: [3][2800/3393] Elapsed 8m 21s (remain 1m 45s) Loss: 0.0140(0.0164) Grad: 8445.6621  LR: 0.00000601  \n","Epoch: [3][2900/3393] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0231(0.0164) Grad: 11051.2510  LR: 0.00000587  \n","Epoch: [3][3000/3393] Elapsed 8m 56s (remain 1m 10s) Loss: 0.0190(0.0163) Grad: 13629.7686  LR: 0.00000574  \n","Epoch: [3][3100/3393] Elapsed 9m 14s (remain 0m 52s) Loss: 0.0195(0.0164) Grad: 20175.5664  LR: 0.00000560  \n","Epoch: [3][3200/3393] Elapsed 9m 31s (remain 0m 34s) Loss: 0.0128(0.0163) Grad: 11394.2305  LR: 0.00000547  \n","Epoch: [3][3300/3393] Elapsed 9m 49s (remain 0m 16s) Loss: 0.0059(0.0163) Grad: 2836.0820  LR: 0.00000533  \n","Epoch: [3][3392/3393] Elapsed 10m 5s (remain 0m 0s) Loss: 0.0047(0.0162) Grad: 1598.6353  LR: 0.00000521  \n","EVAL: [0/255] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1713(0.1713) \n","EVAL: [100/255] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1055(0.1058) \n","EVAL: [200/255] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1469(0.1045) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0162  avg_val_loss: 0.1045  time: 631s\n","Epoch 3 - Score: 0.8057\n","Epoch 3 - Save Best Score: 0.8057 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [254/255] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0091(0.1045) \n","Epoch: [4][0/3393] Elapsed 0m 0s (remain 25m 20s) Loss: 0.0086(0.0086) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3393] Elapsed 0m 18s (remain 9m 54s) Loss: 0.0199(0.0125) Grad: 5373.9648  LR: 0.00000508  \n","Epoch: [4][200/3393] Elapsed 0m 36s (remain 9m 39s) Loss: 0.0108(0.0127) Grad: 21271.7676  LR: 0.00000494  \n","Epoch: [4][300/3393] Elapsed 0m 54s (remain 9m 16s) Loss: 0.0443(0.0126) Grad: 19374.9531  LR: 0.00000481  \n","Epoch: [4][400/3393] Elapsed 1m 11s (remain 8m 55s) Loss: 0.0203(0.0126) Grad: 6976.6885  LR: 0.00000468  \n","Epoch: [4][500/3393] Elapsed 1m 29s (remain 8m 36s) Loss: 0.0100(0.0125) Grad: 14984.9492  LR: 0.00000456  \n","Epoch: [4][600/3393] Elapsed 1m 47s (remain 8m 17s) Loss: 0.0122(0.0126) Grad: 12829.3262  LR: 0.00000443  \n","Epoch: [4][700/3393] Elapsed 2m 4s (remain 7m 59s) Loss: 0.0057(0.0125) Grad: 3096.3032  LR: 0.00000430  \n","Epoch: [4][800/3393] Elapsed 2m 23s (remain 7m 43s) Loss: 0.0178(0.0124) Grad: 12205.5059  LR: 0.00000418  \n","Epoch: [4][900/3393] Elapsed 2m 41s (remain 7m 25s) Loss: 0.0127(0.0126) Grad: 7254.4600  LR: 0.00000405  \n","Epoch: [4][1000/3393] Elapsed 2m 58s (remain 7m 7s) Loss: 0.0128(0.0125) Grad: 5519.2231  LR: 0.00000393  \n","Epoch: [4][1100/3393] Elapsed 3m 16s (remain 6m 49s) Loss: 0.0086(0.0125) Grad: 6406.9146  LR: 0.00000381  \n","Epoch: [4][1200/3393] Elapsed 3m 34s (remain 6m 31s) Loss: 0.0079(0.0126) Grad: 9028.7285  LR: 0.00000369  \n","Epoch: [4][1300/3393] Elapsed 3m 51s (remain 6m 12s) Loss: 0.0109(0.0125) Grad: 6696.7896  LR: 0.00000357  \n","Epoch: [4][1400/3393] Elapsed 4m 9s (remain 5m 55s) Loss: 0.0373(0.0126) Grad: 18188.0469  LR: 0.00000345  \n","Epoch: [4][1500/3393] Elapsed 4m 27s (remain 5m 37s) Loss: 0.0042(0.0125) Grad: 8275.0928  LR: 0.00000333  \n","Epoch: [4][1600/3393] Elapsed 4m 45s (remain 5m 20s) Loss: 0.0318(0.0126) Grad: 3901.8242  LR: 0.00000322  \n","Epoch: [4][1700/3393] Elapsed 5m 3s (remain 5m 2s) Loss: 0.0069(0.0126) Grad: 2772.8872  LR: 0.00000310  \n","Epoch: [4][1800/3393] Elapsed 5m 21s (remain 4m 44s) Loss: 0.0305(0.0126) Grad: 20894.2871  LR: 0.00000299  \n","Epoch: [4][1900/3393] Elapsed 5m 40s (remain 4m 26s) Loss: 0.0111(0.0126) Grad: 9132.1162  LR: 0.00000288  \n","Epoch: [4][2000/3393] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0065(0.0125) Grad: 7149.2222  LR: 0.00000277  \n","Epoch: [4][2100/3393] Elapsed 6m 16s (remain 3m 51s) Loss: 0.0011(0.0125) Grad: 4339.5635  LR: 0.00000267  \n","Epoch: [4][2200/3393] Elapsed 6m 34s (remain 3m 33s) Loss: 0.0063(0.0125) Grad: 24055.4336  LR: 0.00000256  \n","Epoch: [4][2300/3393] Elapsed 6m 52s (remain 3m 15s) Loss: 0.0091(0.0124) Grad: 3530.0703  LR: 0.00000246  \n","Epoch: [4][2400/3393] Elapsed 7m 10s (remain 2m 57s) Loss: 0.0105(0.0124) Grad: 6260.2549  LR: 0.00000235  \n","Epoch: [4][2500/3393] Elapsed 7m 28s (remain 2m 39s) Loss: 0.0193(0.0123) Grad: 7152.0396  LR: 0.00000225  \n","Epoch: [4][2600/3393] Elapsed 7m 45s (remain 2m 21s) Loss: 0.0060(0.0123) Grad: 3105.0803  LR: 0.00000215  \n","Epoch: [4][2700/3393] Elapsed 8m 3s (remain 2m 3s) Loss: 0.0142(0.0123) Grad: 16102.1748  LR: 0.00000206  \n","Epoch: [4][2800/3393] Elapsed 8m 21s (remain 1m 45s) Loss: 0.0063(0.0122) Grad: 11627.6875  LR: 0.00000196  \n","Epoch: [4][2900/3393] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0033(0.0122) Grad: 2148.7920  LR: 0.00000187  \n","Epoch: [4][3000/3393] Elapsed 8m 56s (remain 1m 10s) Loss: 0.0314(0.0123) Grad: 20890.6973  LR: 0.00000178  \n","Epoch: [4][3100/3393] Elapsed 9m 14s (remain 0m 52s) Loss: 0.0109(0.0123) Grad: 18961.4492  LR: 0.00000169  \n","Epoch: [4][3200/3393] Elapsed 9m 31s (remain 0m 34s) Loss: 0.0209(0.0123) Grad: 5932.6538  LR: 0.00000160  \n","Epoch: [4][3300/3393] Elapsed 9m 49s (remain 0m 16s) Loss: 0.0111(0.0122) Grad: 3530.0818  LR: 0.00000152  \n","Epoch: [4][3392/3393] Elapsed 10m 5s (remain 0m 0s) Loss: 0.0114(0.0122) Grad: 5667.7202  LR: 0.00000144  \n","EVAL: [0/255] Elapsed 0m 0s (remain 1m 24s) Loss: 0.1689(0.1689) \n","EVAL: [100/255] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1065(0.1044) \n","EVAL: [200/255] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1429(0.1031) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0122  avg_val_loss: 0.1030  time: 631s\n","Epoch 4 - Score: 0.8159\n","Epoch 4 - Save Best Score: 0.8159 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [254/255] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0055(0.1030) \n","Epoch: [5][0/3393] Elapsed 0m 0s (remain 27m 5s) Loss: 0.0051(0.0051) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3393] Elapsed 0m 18s (remain 10m 8s) Loss: 0.0021(0.0090) Grad: 18692.3379  LR: 0.00000136  \n","Epoch: [5][200/3393] Elapsed 0m 36s (remain 9m 46s) Loss: 0.0129(0.0100) Grad: 21096.6797  LR: 0.00000128  \n","Epoch: [5][300/3393] Elapsed 0m 54s (remain 9m 21s) Loss: 0.0083(0.0099) Grad: 23082.8379  LR: 0.00000120  \n","Epoch: [5][400/3393] Elapsed 1m 12s (remain 9m 1s) Loss: 0.0053(0.0103) Grad: 7773.5020  LR: 0.00000113  \n","Epoch: [5][500/3393] Elapsed 1m 30s (remain 8m 41s) Loss: 0.0233(0.0102) Grad: 9192.1611  LR: 0.00000106  \n","Epoch: [5][600/3393] Elapsed 1m 48s (remain 8m 22s) Loss: 0.0047(0.0099) Grad: 8302.1553  LR: 0.00000099  \n","Epoch: [5][700/3393] Elapsed 2m 5s (remain 8m 3s) Loss: 0.0067(0.0099) Grad: 4669.9976  LR: 0.00000092  \n","Epoch: [5][800/3393] Elapsed 2m 23s (remain 7m 44s) Loss: 0.0020(0.0098) Grad: 3997.0144  LR: 0.00000085  \n","Epoch: [5][900/3393] Elapsed 2m 41s (remain 7m 26s) Loss: 0.0012(0.0096) Grad: 3680.1260  LR: 0.00000079  \n","Epoch: [5][1000/3393] Elapsed 2m 59s (remain 7m 8s) Loss: 0.0064(0.0096) Grad: 3730.8660  LR: 0.00000073  \n","Epoch: [5][1100/3393] Elapsed 3m 16s (remain 6m 49s) Loss: 0.0109(0.0095) Grad: 10358.1953  LR: 0.00000067  \n","Epoch: [5][1200/3393] Elapsed 3m 34s (remain 6m 32s) Loss: 0.0121(0.0095) Grad: 11190.2119  LR: 0.00000061  \n","Epoch: [5][1300/3393] Elapsed 3m 52s (remain 6m 14s) Loss: 0.0076(0.0095) Grad: 9470.8105  LR: 0.00000056  \n","Epoch: [5][1400/3393] Elapsed 4m 11s (remain 5m 56s) Loss: 0.0111(0.0095) Grad: 3139.9800  LR: 0.00000051  \n","Epoch: [5][1500/3393] Elapsed 4m 29s (remain 5m 39s) Loss: 0.0059(0.0095) Grad: 3178.3440  LR: 0.00000046  \n","Epoch: [5][1600/3393] Elapsed 4m 47s (remain 5m 21s) Loss: 0.0103(0.0095) Grad: 10840.8262  LR: 0.00000041  \n","Epoch: [5][1700/3393] Elapsed 5m 5s (remain 5m 3s) Loss: 0.0071(0.0095) Grad: 6835.5908  LR: 0.00000037  \n","Epoch: [5][1800/3393] Elapsed 5m 23s (remain 4m 45s) Loss: 0.0016(0.0095) Grad: 1345.3320  LR: 0.00000033  \n","Epoch: [5][1900/3393] Elapsed 5m 41s (remain 4m 28s) Loss: 0.0117(0.0095) Grad: 13712.8760  LR: 0.00000029  \n","Epoch: [5][2000/3393] Elapsed 5m 59s (remain 4m 10s) Loss: 0.0099(0.0095) Grad: 3405.5503  LR: 0.00000025  \n","Epoch: [5][2100/3393] Elapsed 6m 17s (remain 3m 52s) Loss: 0.0110(0.0095) Grad: 3705.5742  LR: 0.00000022  \n","Epoch: [5][2200/3393] Elapsed 6m 36s (remain 3m 34s) Loss: 0.0069(0.0096) Grad: 2471.1584  LR: 0.00000018  \n","Epoch: [5][2300/3393] Elapsed 6m 53s (remain 3m 16s) Loss: 0.0158(0.0096) Grad: 10889.1035  LR: 0.00000015  \n","Epoch: [5][2400/3393] Elapsed 7m 11s (remain 2m 58s) Loss: 0.0112(0.0096) Grad: 5295.4355  LR: 0.00000013  \n","Epoch: [5][2500/3393] Elapsed 7m 29s (remain 2m 40s) Loss: 0.0090(0.0096) Grad: 10474.0361  LR: 0.00000010  \n","Epoch: [5][2600/3393] Elapsed 7m 47s (remain 2m 22s) Loss: 0.0084(0.0096) Grad: 18459.2363  LR: 0.00000008  \n","Epoch: [5][2700/3393] Elapsed 8m 5s (remain 2m 4s) Loss: 0.0104(0.0096) Grad: 8431.8086  LR: 0.00000006  \n","Epoch: [5][2800/3393] Elapsed 8m 22s (remain 1m 46s) Loss: 0.0171(0.0097) Grad: 6617.2114  LR: 0.00000005  \n","Epoch: [5][2900/3393] Elapsed 8m 40s (remain 1m 28s) Loss: 0.0313(0.0097) Grad: 12884.1787  LR: 0.00000003  \n","Epoch: [5][3000/3393] Elapsed 8m 58s (remain 1m 10s) Loss: 0.0088(0.0097) Grad: 14498.3779  LR: 0.00000002  \n","Epoch: [5][3100/3393] Elapsed 9m 16s (remain 0m 52s) Loss: 0.0013(0.0097) Grad: 4112.6313  LR: 0.00000001  \n","Epoch: [5][3200/3393] Elapsed 9m 34s (remain 0m 34s) Loss: 0.0188(0.0097) Grad: 4172.3047  LR: 0.00000000  \n","Epoch: [5][3300/3393] Elapsed 9m 51s (remain 0m 16s) Loss: 0.0124(0.0097) Grad: 5166.4028  LR: 0.00000000  \n","Epoch: [5][3392/3393] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0115(0.0097) Grad: 10954.6182  LR: 0.00000000  \n","EVAL: [0/255] Elapsed 0m 0s (remain 1m 25s) Loss: 0.1672(0.1672) \n","EVAL: [100/255] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1057(0.1030) \n","EVAL: [200/255] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1412(0.1016) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0097  avg_val_loss: 0.1016  time: 633s\n","Epoch 5 - Score: 0.8160\n","Epoch 5 - Save Best Score: 0.8160 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [254/255] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0068(0.1016) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 5 result ==========\n","Score: 0.8160\n","========== fold: 6 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3391] Elapsed 0m 0s (remain 23m 44s) Loss: 0.4148(0.4148) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3391] Elapsed 0m 18s (remain 10m 4s) Loss: 0.1395(0.2033) Grad: 3439.9167  LR: 0.00001500  \n","Epoch: [1][200/3391] Elapsed 0m 36s (remain 9m 38s) Loss: 0.0825(0.1592) Grad: 670.8246  LR: 0.00001500  \n","Epoch: [1][300/3391] Elapsed 0m 54s (remain 9m 16s) Loss: 0.1188(0.1347) Grad: 6669.5791  LR: 0.00001499  \n","Epoch: [1][400/3391] Elapsed 1m 11s (remain 8m 56s) Loss: 0.0898(0.1197) Grad: 2703.5022  LR: 0.00001498  \n","Epoch: [1][500/3391] Elapsed 1m 29s (remain 8m 38s) Loss: 0.0773(0.1100) Grad: 1063.5170  LR: 0.00001497  \n","Epoch: [1][600/3391] Elapsed 1m 47s (remain 8m 20s) Loss: 0.0573(0.1032) Grad: 2706.9150  LR: 0.00001496  \n","Epoch: [1][700/3391] Elapsed 2m 5s (remain 8m 1s) Loss: 0.0372(0.0993) Grad: 1529.5162  LR: 0.00001495  \n","Epoch: [1][800/3391] Elapsed 2m 23s (remain 7m 43s) Loss: 0.1036(0.0957) Grad: 1546.2936  LR: 0.00001493  \n","Epoch: [1][900/3391] Elapsed 2m 41s (remain 7m 25s) Loss: 0.0828(0.0929) Grad: 3167.4446  LR: 0.00001491  \n","Epoch: [1][1000/3391] Elapsed 2m 58s (remain 7m 6s) Loss: 0.0872(0.0907) Grad: 1976.8843  LR: 0.00001488  \n","Epoch: [1][1100/3391] Elapsed 3m 16s (remain 6m 49s) Loss: 0.0989(0.0894) Grad: 874.9812  LR: 0.00001486  \n","Epoch: [1][1200/3391] Elapsed 3m 34s (remain 6m 31s) Loss: 0.1111(0.0878) Grad: 3195.8135  LR: 0.00001483  \n","Epoch: [1][1300/3391] Elapsed 3m 52s (remain 6m 13s) Loss: 0.0536(0.0860) Grad: 393.4720  LR: 0.00001480  \n","Epoch: [1][1400/3391] Elapsed 4m 10s (remain 5m 56s) Loss: 0.0643(0.0848) Grad: 1019.8096  LR: 0.00001476  \n","Epoch: [1][1500/3391] Elapsed 4m 28s (remain 5m 38s) Loss: 0.1011(0.0841) Grad: 1333.6626  LR: 0.00001473  \n","Epoch: [1][1600/3391] Elapsed 4m 46s (remain 5m 20s) Loss: 0.0862(0.0831) Grad: 3208.2134  LR: 0.00001469  \n","Epoch: [1][1700/3391] Elapsed 5m 4s (remain 5m 2s) Loss: 0.0604(0.0822) Grad: 801.3021  LR: 0.00001465  \n","Epoch: [1][1800/3391] Elapsed 5m 22s (remain 4m 45s) Loss: 0.0663(0.0813) Grad: 1176.7318  LR: 0.00001461  \n","Epoch: [1][1900/3391] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0677(0.0808) Grad: 1656.7837  LR: 0.00001456  \n","Epoch: [1][2000/3391] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0900(0.0802) Grad: 1482.6648  LR: 0.00001451  \n","Epoch: [1][2100/3391] Elapsed 6m 16s (remain 3m 51s) Loss: 0.0415(0.0798) Grad: 2885.0608  LR: 0.00001446  \n","Epoch: [1][2200/3391] Elapsed 6m 34s (remain 3m 33s) Loss: 0.0978(0.0796) Grad: 2959.1377  LR: 0.00001441  \n","Epoch: [1][2300/3391] Elapsed 6m 52s (remain 3m 15s) Loss: 0.0665(0.0792) Grad: 2444.1194  LR: 0.00001435  \n","Epoch: [1][2400/3391] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0524(0.0787) Grad: 875.8237  LR: 0.00001430  \n","Epoch: [1][2500/3391] Elapsed 7m 27s (remain 2m 39s) Loss: 0.1221(0.0783) Grad: 4157.3047  LR: 0.00001424  \n","Epoch: [1][2600/3391] Elapsed 7m 45s (remain 2m 21s) Loss: 0.0240(0.0778) Grad: 1022.8137  LR: 0.00001417  \n","Epoch: [1][2700/3391] Elapsed 8m 3s (remain 2m 3s) Loss: 0.0297(0.0776) Grad: 1288.5109  LR: 0.00001411  \n","Epoch: [1][2800/3391] Elapsed 8m 20s (remain 1m 45s) Loss: 0.0432(0.0773) Grad: 1662.6565  LR: 0.00001404  \n","Epoch: [1][2900/3391] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0773(0.0771) Grad: 2523.2505  LR: 0.00001397  \n","Epoch: [1][3000/3391] Elapsed 8m 56s (remain 1m 9s) Loss: 0.0979(0.0769) Grad: 3222.1309  LR: 0.00001390  \n","Epoch: [1][3100/3391] Elapsed 9m 14s (remain 0m 51s) Loss: 0.0297(0.0766) Grad: 1833.4005  LR: 0.00001383  \n","Epoch: [1][3200/3391] Elapsed 9m 31s (remain 0m 33s) Loss: 0.0977(0.0763) Grad: 4359.6118  LR: 0.00001375  \n","Epoch: [1][3300/3391] Elapsed 9m 49s (remain 0m 16s) Loss: 0.0480(0.0759) Grad: 861.6282  LR: 0.00001367  \n","Epoch: [1][3390/3391] Elapsed 10m 5s (remain 0m 0s) Loss: 0.0460(0.0756) Grad: 2965.0598  LR: 0.00001360  \n","EVAL: [0/256] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1880(0.1880) \n","EVAL: [100/256] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1871(0.1359) \n","EVAL: [200/256] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1765(0.1381) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0756  avg_val_loss: 0.1354  time: 631s\n","Epoch 1 - Score: 0.0640\n","Epoch 1 - Save Best Score: 0.0640 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [255/256] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2126(0.1354) \n","Epoch: [2][0/3391] Elapsed 0m 0s (remain 25m 52s) Loss: 0.1053(0.1053) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3391] Elapsed 0m 18s (remain 10m 6s) Loss: 0.0523(0.0754) Grad: 21514.4590  LR: 0.00001352  \n","Epoch: [2][200/3391] Elapsed 0m 37s (remain 9m 48s) Loss: 0.0507(0.0708) Grad: 17216.6523  LR: 0.00001343  \n","Epoch: [2][300/3391] Elapsed 0m 55s (remain 9m 25s) Loss: 0.0786(0.0709) Grad: 24765.4258  LR: 0.00001335  \n","Epoch: [2][400/3391] Elapsed 1m 12s (remain 9m 4s) Loss: 0.0643(0.0704) Grad: 17581.3379  LR: 0.00001326  \n","Epoch: [2][500/3391] Elapsed 1m 30s (remain 8m 44s) Loss: 0.0828(0.0699) Grad: 26530.1504  LR: 0.00001317  \n","Epoch: [2][600/3391] Elapsed 1m 48s (remain 8m 25s) Loss: 0.0748(0.0696) Grad: 20432.4141  LR: 0.00001308  \n","Epoch: [2][700/3391] Elapsed 2m 6s (remain 8m 5s) Loss: 0.0365(0.0700) Grad: 13843.6211  LR: 0.00001298  \n","Epoch: [2][800/3391] Elapsed 2m 24s (remain 7m 47s) Loss: 0.0502(0.0697) Grad: 14272.8193  LR: 0.00001289  \n","Epoch: [2][900/3391] Elapsed 2m 42s (remain 7m 28s) Loss: 0.1101(0.0693) Grad: 20110.7188  LR: 0.00001279  \n","Epoch: [2][1000/3391] Elapsed 3m 0s (remain 7m 10s) Loss: 0.0346(0.0690) Grad: 10498.4258  LR: 0.00001269  \n","Epoch: [2][1100/3391] Elapsed 3m 18s (remain 6m 52s) Loss: 0.0784(0.0692) Grad: 41824.7461  LR: 0.00001259  \n","Epoch: [2][1200/3391] Elapsed 3m 36s (remain 6m 34s) Loss: 0.1110(0.0689) Grad: 27687.8398  LR: 0.00001248  \n","Epoch: [2][1300/3391] Elapsed 3m 54s (remain 6m 16s) Loss: 0.0522(0.0688) Grad: 18920.9219  LR: 0.00001238  \n","Epoch: [2][1400/3391] Elapsed 4m 12s (remain 5m 59s) Loss: 0.0677(0.0685) Grad: 15091.2314  LR: 0.00001227  \n","Epoch: [2][1500/3391] Elapsed 4m 31s (remain 5m 41s) Loss: 0.0558(0.0682) Grad: 28032.5801  LR: 0.00001216  \n","Epoch: [2][1600/3391] Elapsed 4m 49s (remain 5m 23s) Loss: 0.0721(0.0683) Grad: 25356.3574  LR: 0.00001205  \n","Epoch: [2][1700/3391] Elapsed 5m 7s (remain 5m 5s) Loss: 0.0768(0.0684) Grad: 11262.0254  LR: 0.00001194  \n","Epoch: [2][1800/3391] Elapsed 5m 25s (remain 4m 47s) Loss: 0.0983(0.0684) Grad: 27918.4395  LR: 0.00001183  \n","Epoch: [2][1900/3391] Elapsed 5m 43s (remain 4m 29s) Loss: 0.0412(0.0682) Grad: 5248.6812  LR: 0.00001171  \n","Epoch: [2][2000/3391] Elapsed 6m 1s (remain 4m 11s) Loss: 0.1025(0.0683) Grad: 13007.8477  LR: 0.00001160  \n","Epoch: [2][2100/3391] Elapsed 6m 19s (remain 3m 53s) Loss: 0.0627(0.0682) Grad: 13853.6055  LR: 0.00001148  \n","Epoch: [2][2200/3391] Elapsed 6m 37s (remain 3m 35s) Loss: 0.1191(0.0682) Grad: 24021.5059  LR: 0.00001136  \n","Epoch: [2][2300/3391] Elapsed 6m 55s (remain 3m 16s) Loss: 0.0778(0.0681) Grad: 21040.7090  LR: 0.00001124  \n","Epoch: [2][2400/3391] Elapsed 7m 13s (remain 2m 58s) Loss: 0.1339(0.0683) Grad: 27856.7852  LR: 0.00001112  \n","Epoch: [2][2500/3391] Elapsed 7m 31s (remain 2m 40s) Loss: 0.1093(0.0681) Grad: 24731.1523  LR: 0.00001100  \n","Epoch: [2][2600/3391] Elapsed 7m 49s (remain 2m 22s) Loss: 0.0789(0.0683) Grad: 10417.7871  LR: 0.00001087  \n","Epoch: [2][2700/3391] Elapsed 8m 7s (remain 2m 4s) Loss: 0.1013(0.0684) Grad: 23626.7148  LR: 0.00001075  \n","Epoch: [2][2800/3391] Elapsed 8m 24s (remain 1m 46s) Loss: 0.0684(0.0682) Grad: 7748.6865  LR: 0.00001062  \n","Epoch: [2][2900/3391] Elapsed 8m 42s (remain 1m 28s) Loss: 0.0484(0.0683) Grad: 10046.7959  LR: 0.00001050  \n","Epoch: [2][3000/3391] Elapsed 9m 0s (remain 1m 10s) Loss: 0.0240(0.0682) Grad: 19849.1621  LR: 0.00001037  \n","Epoch: [2][3100/3391] Elapsed 9m 18s (remain 0m 52s) Loss: 0.0790(0.0682) Grad: 15026.1699  LR: 0.00001024  \n","Epoch: [2][3200/3391] Elapsed 9m 36s (remain 0m 34s) Loss: 0.0463(0.0682) Grad: 10178.4199  LR: 0.00001011  \n","Epoch: [2][3300/3391] Elapsed 9m 53s (remain 0m 16s) Loss: 0.0383(0.0682) Grad: 6911.7764  LR: 0.00000998  \n","Epoch: [2][3390/3391] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0931(0.0683) Grad: 20129.2363  LR: 0.00000986  \n","EVAL: [0/256] Elapsed 0m 0s (remain 1m 23s) Loss: 0.1753(0.1753) \n","EVAL: [100/256] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1693(0.1235) \n","EVAL: [200/256] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1687(0.1256) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0683  avg_val_loss: 0.1230  time: 635s\n","Epoch 2 - Score: 0.0513\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [255/256] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1973(0.1230) \n","Epoch: [3][0/3391] Elapsed 0m 0s (remain 26m 24s) Loss: 0.0616(0.0616) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3391] Elapsed 0m 18s (remain 9m 57s) Loss: 0.0368(0.0694) Grad: 15065.7910  LR: 0.00000972  \n","Epoch: [3][200/3391] Elapsed 0m 36s (remain 9m 35s) Loss: 0.0413(0.0694) Grad: 14639.3750  LR: 0.00000959  \n","Epoch: [3][300/3391] Elapsed 0m 54s (remain 9m 15s) Loss: 0.0629(0.0688) Grad: 18152.6934  LR: 0.00000946  \n","Epoch: [3][400/3391] Elapsed 1m 12s (remain 8m 57s) Loss: 0.1175(0.0683) Grad: 28633.0723  LR: 0.00000932  \n","Epoch: [3][500/3391] Elapsed 1m 30s (remain 8m 39s) Loss: 0.0458(0.0684) Grad: 23237.6406  LR: 0.00000919  \n","Epoch: [3][600/3391] Elapsed 1m 47s (remain 8m 20s) Loss: 0.0734(0.0687) Grad: 23946.3359  LR: 0.00000905  \n","Epoch: [3][700/3391] Elapsed 2m 5s (remain 8m 2s) Loss: 0.0541(0.0685) Grad: 22121.1191  LR: 0.00000891  \n","Epoch: [3][800/3391] Elapsed 2m 23s (remain 7m 44s) Loss: 0.0606(0.0681) Grad: 12804.8164  LR: 0.00000878  \n","Epoch: [3][900/3391] Elapsed 2m 41s (remain 7m 26s) Loss: 0.0987(0.0681) Grad: 18391.0254  LR: 0.00000864  \n","Epoch: [3][1000/3391] Elapsed 2m 59s (remain 7m 8s) Loss: 0.0963(0.0683) Grad: 30292.5488  LR: 0.00000850  \n","Epoch: [3][1100/3391] Elapsed 3m 17s (remain 6m 51s) Loss: 0.0850(0.0681) Grad: 20268.9785  LR: 0.00000836  \n","Epoch: [3][1200/3391] Elapsed 3m 35s (remain 6m 33s) Loss: 0.0793(0.0683) Grad: 26262.8691  LR: 0.00000822  \n","Epoch: [3][1300/3391] Elapsed 3m 54s (remain 6m 15s) Loss: 0.0450(0.0681) Grad: 22627.0410  LR: 0.00000808  \n","Epoch: [3][1400/3391] Elapsed 4m 12s (remain 5m 58s) Loss: 0.0844(0.0683) Grad: 9738.1924  LR: 0.00000795  \n","Epoch: [3][1500/3391] Elapsed 4m 30s (remain 5m 40s) Loss: 0.0779(0.0684) Grad: 26835.3574  LR: 0.00000781  \n","Epoch: [3][1600/3391] Elapsed 4m 48s (remain 5m 22s) Loss: 0.0410(0.0683) Grad: 13846.6641  LR: 0.00000767  \n","Epoch: [3][1700/3391] Elapsed 5m 6s (remain 5m 4s) Loss: 0.0605(0.0684) Grad: 34063.6250  LR: 0.00000753  \n","Epoch: [3][1800/3391] Elapsed 5m 24s (remain 4m 46s) Loss: 0.1127(0.0684) Grad: 14517.1289  LR: 0.00000739  \n","Epoch: [3][1900/3391] Elapsed 5m 42s (remain 4m 28s) Loss: 0.0589(0.0684) Grad: 13144.5176  LR: 0.00000725  \n","Epoch: [3][2000/3391] Elapsed 6m 1s (remain 4m 10s) Loss: 0.0296(0.0684) Grad: 3235.8386  LR: 0.00000711  \n","Epoch: [3][2100/3391] Elapsed 6m 18s (remain 3m 52s) Loss: 0.0671(0.0682) Grad: 10500.8408  LR: 0.00000697  \n","Epoch: [3][2200/3391] Elapsed 6m 36s (remain 3m 34s) Loss: 0.0630(0.0682) Grad: 17023.0195  LR: 0.00000683  \n","Epoch: [3][2300/3391] Elapsed 6m 54s (remain 3m 16s) Loss: 0.1171(0.0682) Grad: 33995.4062  LR: 0.00000669  \n","Epoch: [3][2400/3391] Elapsed 7m 12s (remain 2m 58s) Loss: 0.0291(0.0682) Grad: 10853.0078  LR: 0.00000655  \n","Epoch: [3][2500/3391] Elapsed 7m 29s (remain 2m 40s) Loss: 0.1040(0.0681) Grad: 31648.8086  LR: 0.00000642  \n","Epoch: [3][2600/3391] Elapsed 7m 47s (remain 2m 22s) Loss: 0.0326(0.0680) Grad: 13406.6621  LR: 0.00000628  \n","Epoch: [3][2700/3391] Elapsed 8m 5s (remain 2m 4s) Loss: 0.0440(0.0680) Grad: 16060.9883  LR: 0.00000614  \n","Epoch: [3][2800/3391] Elapsed 8m 23s (remain 1m 46s) Loss: 0.1343(0.0679) Grad: 11385.2988  LR: 0.00000600  \n","Epoch: [3][2900/3391] Elapsed 8m 41s (remain 1m 28s) Loss: 0.0815(0.0680) Grad: 14211.1201  LR: 0.00000587  \n","Epoch: [3][3000/3391] Elapsed 8m 58s (remain 1m 10s) Loss: 0.0526(0.0679) Grad: 11780.3203  LR: 0.00000573  \n","Epoch: [3][3100/3391] Elapsed 9m 16s (remain 0m 52s) Loss: 0.0340(0.0679) Grad: 13116.5752  LR: 0.00000560  \n","Epoch: [3][3200/3391] Elapsed 9m 34s (remain 0m 34s) Loss: 0.0429(0.0679) Grad: 7463.0024  LR: 0.00000546  \n","Epoch: [3][3300/3391] Elapsed 9m 52s (remain 0m 16s) Loss: 0.0800(0.0679) Grad: 6590.5371  LR: 0.00000533  \n","Epoch: [3][3390/3391] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0324(0.0681) Grad: 5658.9556  LR: 0.00000521  \n","EVAL: [0/256] Elapsed 0m 0s (remain 1m 25s) Loss: 0.1783(0.1783) \n","EVAL: [100/256] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1736(0.1264) \n","EVAL: [200/256] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1705(0.1286) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0681  avg_val_loss: 0.1259  time: 633s\n","Epoch 3 - Score: 0.0395\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [255/256] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2009(0.1259) \n","Epoch: [4][0/3391] Elapsed 0m 0s (remain 25m 29s) Loss: 0.0397(0.0397) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3391] Elapsed 0m 18s (remain 9m 55s) Loss: 0.0356(0.0665) Grad: 8094.2881  LR: 0.00000508  \n","Epoch: [4][200/3391] Elapsed 0m 36s (remain 9m 32s) Loss: 0.0937(0.0660) Grad: 7239.7227  LR: 0.00000494  \n","Epoch: [4][300/3391] Elapsed 0m 53s (remain 9m 13s) Loss: 0.0593(0.0664) Grad: 9458.2598  LR: 0.00000481  \n","Epoch: [4][400/3391] Elapsed 1m 11s (remain 8m 54s) Loss: 0.0565(0.0655) Grad: 13206.5430  LR: 0.00000468  \n","Epoch: [4][500/3391] Elapsed 1m 29s (remain 8m 36s) Loss: 0.0659(0.0661) Grad: 7486.1431  LR: 0.00000456  \n","Epoch: [4][600/3391] Elapsed 1m 47s (remain 8m 19s) Loss: 0.1071(0.0668) Grad: 22353.6758  LR: 0.00000443  \n","Epoch: [4][700/3391] Elapsed 2m 5s (remain 8m 1s) Loss: 0.0549(0.0667) Grad: 12294.4541  LR: 0.00000430  \n","Epoch: [4][800/3391] Elapsed 2m 23s (remain 7m 43s) Loss: 0.0392(0.0670) Grad: 4912.8750  LR: 0.00000418  \n","Epoch: [4][900/3391] Elapsed 2m 41s (remain 7m 26s) Loss: 0.0423(0.0677) Grad: 11517.5732  LR: 0.00000405  \n","Epoch: [4][1000/3391] Elapsed 2m 59s (remain 7m 9s) Loss: 0.0939(0.0676) Grad: 23552.1621  LR: 0.00000393  \n","Epoch: [4][1100/3391] Elapsed 3m 17s (remain 6m 51s) Loss: 0.0717(0.0676) Grad: 16033.3770  LR: 0.00000381  \n","Epoch: [4][1200/3391] Elapsed 3m 36s (remain 6m 34s) Loss: 0.0671(0.0678) Grad: 8691.1553  LR: 0.00000369  \n","Epoch: [4][1300/3391] Elapsed 3m 54s (remain 6m 16s) Loss: 0.0626(0.0679) Grad: 16943.1602  LR: 0.00000357  \n","Epoch: [4][1400/3391] Elapsed 4m 12s (remain 5m 59s) Loss: 0.0614(0.0676) Grad: 23569.0098  LR: 0.00000345  \n","Epoch: [4][1500/3391] Elapsed 4m 31s (remain 5m 41s) Loss: 0.0284(0.0678) Grad: 5274.7783  LR: 0.00000333  \n","Epoch: [4][1600/3391] Elapsed 4m 49s (remain 5m 23s) Loss: 0.0997(0.0678) Grad: 14461.2158  LR: 0.00000322  \n","Epoch: [4][1700/3391] Elapsed 5m 7s (remain 5m 5s) Loss: 0.0574(0.0677) Grad: 9205.9326  LR: 0.00000310  \n","Epoch: [4][1800/3391] Elapsed 5m 25s (remain 4m 47s) Loss: 0.0411(0.0680) Grad: 10338.1797  LR: 0.00000299  \n","Epoch: [4][1900/3391] Elapsed 5m 43s (remain 4m 29s) Loss: 0.0497(0.0679) Grad: 14044.7412  LR: 0.00000288  \n","Epoch: [4][2000/3391] Elapsed 6m 1s (remain 4m 11s) Loss: 0.0425(0.0678) Grad: 17587.1465  LR: 0.00000277  \n","Epoch: [4][2100/3391] Elapsed 6m 19s (remain 3m 52s) Loss: 0.0734(0.0677) Grad: 10872.7705  LR: 0.00000266  \n","Epoch: [4][2200/3391] Elapsed 6m 37s (remain 3m 34s) Loss: 0.0524(0.0680) Grad: 9229.5010  LR: 0.00000256  \n","Epoch: [4][2300/3391] Elapsed 6m 55s (remain 3m 16s) Loss: 0.0922(0.0679) Grad: 33333.0078  LR: 0.00000245  \n","Epoch: [4][2400/3391] Elapsed 7m 12s (remain 2m 58s) Loss: 0.0434(0.0677) Grad: 21456.8047  LR: 0.00000235  \n","Epoch: [4][2500/3391] Elapsed 7m 30s (remain 2m 40s) Loss: 0.0964(0.0677) Grad: 28241.6211  LR: 0.00000225  \n","Epoch: [4][2600/3391] Elapsed 7m 48s (remain 2m 22s) Loss: 0.0426(0.0678) Grad: 9469.6270  LR: 0.00000215  \n","Epoch: [4][2700/3391] Elapsed 8m 6s (remain 2m 4s) Loss: 0.0746(0.0676) Grad: 17143.7871  LR: 0.00000206  \n","Epoch: [4][2800/3391] Elapsed 8m 24s (remain 1m 46s) Loss: 0.1043(0.0675) Grad: 11154.8213  LR: 0.00000196  \n","Epoch: [4][2900/3391] Elapsed 8m 42s (remain 1m 28s) Loss: 0.0729(0.0676) Grad: 11273.4121  LR: 0.00000187  \n","Epoch: [4][3000/3391] Elapsed 8m 59s (remain 1m 10s) Loss: 0.0697(0.0677) Grad: 9987.5654  LR: 0.00000178  \n","Epoch: [4][3100/3391] Elapsed 9m 17s (remain 0m 52s) Loss: 0.0699(0.0677) Grad: 16242.1602  LR: 0.00000169  \n","Epoch: [4][3200/3391] Elapsed 9m 35s (remain 0m 34s) Loss: 0.0656(0.0677) Grad: 12929.1914  LR: 0.00000160  \n","Epoch: [4][3300/3391] Elapsed 9m 53s (remain 0m 16s) Loss: 0.0939(0.0677) Grad: 10357.9395  LR: 0.00000152  \n","Epoch: [4][3390/3391] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0291(0.0676) Grad: 9836.7314  LR: 0.00000144  \n","EVAL: [0/256] Elapsed 0m 0s (remain 1m 27s) Loss: 0.1757(0.1757) \n","EVAL: [100/256] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1700(0.1240) \n","EVAL: [200/256] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1690(0.1261) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0676  avg_val_loss: 0.1235  time: 634s\n","Epoch 4 - Score: 0.0604\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [255/256] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1979(0.1235) \n","Epoch: [5][0/3391] Elapsed 0m 0s (remain 25m 42s) Loss: 0.0678(0.0678) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3391] Elapsed 0m 18s (remain 9m 55s) Loss: 0.1194(0.0730) Grad: 25142.5957  LR: 0.00000136  \n","Epoch: [5][200/3391] Elapsed 0m 36s (remain 9m 33s) Loss: 0.1164(0.0714) Grad: 27147.4102  LR: 0.00000128  \n","Epoch: [5][300/3391] Elapsed 0m 53s (remain 9m 14s) Loss: 0.0164(0.0691) Grad: 8255.2969  LR: 0.00000120  \n","Epoch: [5][400/3391] Elapsed 1m 11s (remain 8m 56s) Loss: 0.0684(0.0687) Grad: 18240.8379  LR: 0.00000113  \n","Epoch: [5][500/3391] Elapsed 1m 29s (remain 8m 38s) Loss: 0.0783(0.0682) Grad: 16650.3457  LR: 0.00000106  \n","Epoch: [5][600/3391] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0262(0.0689) Grad: 6345.0215  LR: 0.00000099  \n","Epoch: [5][700/3391] Elapsed 2m 6s (remain 8m 4s) Loss: 0.0163(0.0687) Grad: 10492.0459  LR: 0.00000092  \n","Epoch: [5][800/3391] Elapsed 2m 24s (remain 7m 47s) Loss: 0.0743(0.0683) Grad: 21061.5742  LR: 0.00000085  \n","Epoch: [5][900/3391] Elapsed 2m 42s (remain 7m 29s) Loss: 0.0602(0.0682) Grad: 8728.8320  LR: 0.00000079  \n","Epoch: [5][1000/3391] Elapsed 3m 1s (remain 7m 12s) Loss: 0.0467(0.0681) Grad: 9566.7822  LR: 0.00000073  \n","Epoch: [5][1100/3391] Elapsed 3m 19s (remain 6m 54s) Loss: 0.1335(0.0681) Grad: 29174.6094  LR: 0.00000067  \n","Epoch: [5][1200/3391] Elapsed 3m 37s (remain 6m 36s) Loss: 0.0764(0.0682) Grad: 7743.7461  LR: 0.00000061  \n","Epoch: [5][1300/3391] Elapsed 3m 55s (remain 6m 18s) Loss: 0.1185(0.0681) Grad: 9079.1797  LR: 0.00000056  \n","Epoch: [5][1400/3391] Elapsed 4m 14s (remain 6m 0s) Loss: 0.0528(0.0682) Grad: 14979.2744  LR: 0.00000051  \n","Epoch: [5][1500/3391] Elapsed 4m 32s (remain 5m 42s) Loss: 0.1382(0.0680) Grad: 7192.8770  LR: 0.00000046  \n","Epoch: [5][1600/3391] Elapsed 4m 50s (remain 5m 24s) Loss: 0.0536(0.0679) Grad: 10159.5273  LR: 0.00000041  \n","Epoch: [5][1700/3391] Elapsed 5m 8s (remain 5m 6s) Loss: 0.0740(0.0675) Grad: 26399.9844  LR: 0.00000037  \n","Epoch: [5][1800/3391] Elapsed 5m 26s (remain 4m 47s) Loss: 0.1144(0.0677) Grad: 16853.5684  LR: 0.00000033  \n","Epoch: [5][1900/3391] Elapsed 5m 44s (remain 4m 29s) Loss: 0.0273(0.0676) Grad: 18080.2402  LR: 0.00000029  \n","Epoch: [5][2000/3391] Elapsed 6m 2s (remain 4m 11s) Loss: 0.0457(0.0677) Grad: 10552.1562  LR: 0.00000025  \n","Epoch: [5][2100/3391] Elapsed 6m 19s (remain 3m 53s) Loss: 0.0447(0.0676) Grad: 54314.9180  LR: 0.00000021  \n","Epoch: [5][2200/3391] Elapsed 6m 37s (remain 3m 35s) Loss: 0.0436(0.0677) Grad: 9863.6074  LR: 0.00000018  \n","Epoch: [5][2300/3391] Elapsed 6m 55s (remain 3m 16s) Loss: 0.0190(0.0676) Grad: 3006.8704  LR: 0.00000015  \n","Epoch: [5][2400/3391] Elapsed 7m 13s (remain 2m 58s) Loss: 0.0656(0.0676) Grad: 3448.0388  LR: 0.00000013  \n","Epoch: [5][2500/3391] Elapsed 7m 31s (remain 2m 40s) Loss: 0.0654(0.0676) Grad: 7500.8301  LR: 0.00000010  \n","Epoch: [5][2600/3391] Elapsed 7m 48s (remain 2m 22s) Loss: 0.0680(0.0676) Grad: 16064.4102  LR: 0.00000008  \n","Epoch: [5][2700/3391] Elapsed 8m 6s (remain 2m 4s) Loss: 0.0303(0.0676) Grad: 13264.9160  LR: 0.00000006  \n","Epoch: [5][2800/3391] Elapsed 8m 24s (remain 1m 46s) Loss: 0.0933(0.0677) Grad: 17037.0508  LR: 0.00000005  \n","Epoch: [5][2900/3391] Elapsed 8m 42s (remain 1m 28s) Loss: 0.0540(0.0676) Grad: 10699.2148  LR: 0.00000003  \n","Epoch: [5][3000/3391] Elapsed 8m 59s (remain 1m 10s) Loss: 0.0551(0.0674) Grad: 19779.9238  LR: 0.00000002  \n","Epoch: [5][3100/3391] Elapsed 9m 17s (remain 0m 52s) Loss: 0.1044(0.0674) Grad: 31032.4551  LR: 0.00000001  \n","Epoch: [5][3200/3391] Elapsed 9m 35s (remain 0m 34s) Loss: 0.0511(0.0673) Grad: 8630.4404  LR: 0.00000000  \n","Epoch: [5][3300/3391] Elapsed 9m 53s (remain 0m 16s) Loss: 0.0391(0.0672) Grad: 5954.4849  LR: 0.00000000  \n","Epoch: [5][3390/3391] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0904(0.0673) Grad: 15761.0127  LR: 0.00000000  \n","EVAL: [0/256] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1780(0.1780) \n","EVAL: [100/256] Elapsed 0m 9s (remain 0m 15s) Loss: 0.1732(0.1262) \n","EVAL: [200/256] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1703(0.1283) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0673  avg_val_loss: 0.1257  time: 634s\n","Epoch 5 - Score: 0.0506\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [255/256] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2006(0.1257) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 6 result ==========\n","Score: 0.0640\n","========== fold: 7 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3397] Elapsed 0m 0s (remain 23m 12s) Loss: 0.5225(0.5225) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3397] Elapsed 0m 18s (remain 9m 47s) Loss: 0.1506(0.2452) Grad: 9113.2178  LR: 0.00001500  \n","Epoch: [1][200/3397] Elapsed 0m 35s (remain 9m 27s) Loss: 0.0621(0.2228) Grad: 4051.9773  LR: 0.00001500  \n","Epoch: [1][300/3397] Elapsed 0m 53s (remain 9m 9s) Loss: 0.1194(0.1817) Grad: 76700.2969  LR: 0.00001499  \n","Epoch: [1][400/3397] Elapsed 1m 11s (remain 8m 51s) Loss: 0.1119(0.1614) Grad: 985.8603  LR: 0.00001498  \n","Epoch: [1][500/3397] Elapsed 1m 28s (remain 8m 32s) Loss: 0.0551(0.1440) Grad: 2542.1201  LR: 0.00001497  \n","Epoch: [1][600/3397] Elapsed 1m 46s (remain 8m 16s) Loss: 0.0842(0.1524) Grad: 7819.7964  LR: 0.00001496  \n","Epoch: [1][700/3397] Elapsed 2m 4s (remain 7m 59s) Loss: 0.1498(0.1553) Grad: 2634.1318  LR: 0.00001495  \n","Epoch: [1][800/3397] Elapsed 2m 22s (remain 7m 43s) Loss: 0.1148(0.1563) Grad: 5699.3770  LR: 0.00001493  \n","Epoch: [1][900/3397] Elapsed 2m 41s (remain 7m 26s) Loss: 0.1926(0.1554) Grad: 5348.2563  LR: 0.00001491  \n","Epoch: [1][1000/3397] Elapsed 2m 59s (remain 7m 8s) Loss: 0.1525(0.1533) Grad: 3593.8606  LR: 0.00001488  \n","Epoch: [1][1100/3397] Elapsed 3m 17s (remain 6m 50s) Loss: 0.0947(0.1500) Grad: 3869.3926  LR: 0.00001486  \n","Epoch: [1][1200/3397] Elapsed 3m 35s (remain 6m 33s) Loss: 0.1053(0.1469) Grad: 1172.9783  LR: 0.00001483  \n","Epoch: [1][1300/3397] Elapsed 3m 53s (remain 6m 15s) Loss: 0.0579(0.1431) Grad: 3311.7166  LR: 0.00001480  \n","Epoch: [1][1400/3397] Elapsed 4m 11s (remain 5m 57s) Loss: 0.0660(0.1397) Grad: 465.4870  LR: 0.00001477  \n","Epoch: [1][1500/3397] Elapsed 4m 29s (remain 5m 40s) Loss: 0.0434(0.1352) Grad: 1656.1187  LR: 0.00001473  \n","Epoch: [1][1600/3397] Elapsed 4m 47s (remain 5m 22s) Loss: 0.0541(0.1310) Grad: 450.5391  LR: 0.00001469  \n","Epoch: [1][1700/3397] Elapsed 5m 4s (remain 5m 4s) Loss: 0.0617(0.1273) Grad: 379.9567  LR: 0.00001465  \n","Epoch: [1][1800/3397] Elapsed 5m 22s (remain 4m 45s) Loss: 0.0725(0.1242) Grad: 608.6111  LR: 0.00001461  \n","Epoch: [1][1900/3397] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0856(0.1215) Grad: 794.5712  LR: 0.00001456  \n","Epoch: [1][2000/3397] Elapsed 5m 57s (remain 4m 9s) Loss: 0.0693(0.1191) Grad: 728.8469  LR: 0.00001451  \n","Epoch: [1][2100/3397] Elapsed 6m 15s (remain 3m 51s) Loss: 0.0371(0.1168) Grad: 543.1568  LR: 0.00001446  \n","Epoch: [1][2200/3397] Elapsed 6m 33s (remain 3m 33s) Loss: 0.0387(0.1146) Grad: 2210.2634  LR: 0.00001441  \n","Epoch: [1][2300/3397] Elapsed 6m 50s (remain 3m 15s) Loss: 0.0517(0.1128) Grad: 2230.7715  LR: 0.00001436  \n","Epoch: [1][2400/3397] Elapsed 7m 8s (remain 2m 57s) Loss: 0.0556(0.1106) Grad: 1641.3412  LR: 0.00001430  \n","Epoch: [1][2500/3397] Elapsed 7m 26s (remain 2m 39s) Loss: 0.0368(0.1085) Grad: 2254.2341  LR: 0.00001424  \n","Epoch: [1][2600/3397] Elapsed 7m 43s (remain 2m 21s) Loss: 0.0550(0.1066) Grad: 1894.8475  LR: 0.00001418  \n","Epoch: [1][2700/3397] Elapsed 8m 1s (remain 2m 4s) Loss: 0.0518(0.1047) Grad: 4098.2290  LR: 0.00001411  \n","Epoch: [1][2800/3397] Elapsed 8m 19s (remain 1m 46s) Loss: 0.0596(0.1030) Grad: 13058.0703  LR: 0.00001404  \n","Epoch: [1][2900/3397] Elapsed 8m 37s (remain 1m 28s) Loss: 0.0106(0.1014) Grad: 757.4664  LR: 0.00001398  \n","Epoch: [1][3000/3397] Elapsed 8m 54s (remain 1m 10s) Loss: 0.0720(0.0998) Grad: 3633.8115  LR: 0.00001390  \n","Epoch: [1][3100/3397] Elapsed 9m 12s (remain 0m 52s) Loss: 0.0614(0.0982) Grad: 4241.9111  LR: 0.00001383  \n","Epoch: [1][3200/3397] Elapsed 9m 30s (remain 0m 34s) Loss: 0.0416(0.0969) Grad: 3881.1775  LR: 0.00001376  \n","Epoch: [1][3300/3397] Elapsed 9m 47s (remain 0m 17s) Loss: 0.0854(0.0953) Grad: 5597.7129  LR: 0.00001368  \n","Epoch: [1][3396/3397] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0884(0.0940) Grad: 6813.2617  LR: 0.00001360  \n","EVAL: [0/250] Elapsed 0m 0s (remain 1m 24s) Loss: 0.1388(0.1388) \n","EVAL: [100/250] Elapsed 0m 9s (remain 0m 14s) Loss: 0.1419(0.1041) \n","EVAL: [200/250] Elapsed 0m 19s (remain 0m 4s) Loss: 0.1529(0.1064) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0940  avg_val_loss: 0.1057  time: 629s\n","Epoch 1 - Score: 0.6264\n","Epoch 1 - Save Best Score: 0.6264 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [249/250] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1288(0.1057) \n","Epoch: [2][0/3397] Elapsed 0m 0s (remain 24m 56s) Loss: 0.0399(0.0399) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3397] Elapsed 0m 18s (remain 10m 2s) Loss: 0.0284(0.0448) Grad: 31217.2754  LR: 0.00001352  \n","Epoch: [2][200/3397] Elapsed 0m 36s (remain 9m 39s) Loss: 0.0461(0.0430) Grad: 19353.8047  LR: 0.00001343  \n","Epoch: [2][300/3397] Elapsed 0m 54s (remain 9m 16s) Loss: 0.0809(0.0430) Grad: 32052.7188  LR: 0.00001335  \n","Epoch: [2][400/3397] Elapsed 1m 11s (remain 8m 55s) Loss: 0.0412(0.0420) Grad: 15922.1807  LR: 0.00001326  \n","Epoch: [2][500/3397] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0450(0.0411) Grad: 20299.6270  LR: 0.00001317  \n","Epoch: [2][600/3397] Elapsed 1m 47s (remain 8m 20s) Loss: 0.0465(0.0417) Grad: 7679.8130  LR: 0.00001308  \n","Epoch: [2][700/3397] Elapsed 2m 5s (remain 8m 3s) Loss: 0.0421(0.0420) Grad: 10034.4658  LR: 0.00001298  \n","Epoch: [2][800/3397] Elapsed 2m 23s (remain 7m 45s) Loss: 0.0224(0.0416) Grad: 12223.3096  LR: 0.00001289  \n","Epoch: [2][900/3397] Elapsed 2m 41s (remain 7m 27s) Loss: 0.0657(0.0412) Grad: 27954.9238  LR: 0.00001279  \n","Epoch: [2][1000/3397] Elapsed 2m 59s (remain 7m 10s) Loss: 0.0260(0.0408) Grad: 12996.0693  LR: 0.00001269  \n","Epoch: [2][1100/3397] Elapsed 3m 17s (remain 6m 52s) Loss: 0.0188(0.0405) Grad: 9243.9697  LR: 0.00001259  \n","Epoch: [2][1200/3397] Elapsed 3m 35s (remain 6m 34s) Loss: 0.0301(0.0401) Grad: 28060.3770  LR: 0.00001249  \n","Epoch: [2][1300/3397] Elapsed 3m 53s (remain 6m 16s) Loss: 0.0080(0.0396) Grad: 9467.6943  LR: 0.00001238  \n","Epoch: [2][1400/3397] Elapsed 4m 11s (remain 5m 58s) Loss: 0.0514(0.0393) Grad: 10689.5195  LR: 0.00001227  \n","Epoch: [2][1500/3397] Elapsed 4m 29s (remain 5m 40s) Loss: 0.0220(0.0393) Grad: 5065.9907  LR: 0.00001217  \n","Epoch: [2][1600/3397] Elapsed 4m 47s (remain 5m 22s) Loss: 0.0251(0.0388) Grad: 15596.4463  LR: 0.00001206  \n","Epoch: [2][1700/3397] Elapsed 5m 5s (remain 5m 4s) Loss: 0.0547(0.0384) Grad: 28114.6797  LR: 0.00001195  \n","Epoch: [2][1800/3397] Elapsed 5m 22s (remain 4m 46s) Loss: 0.0475(0.0381) Grad: 8642.5322  LR: 0.00001183  \n","Epoch: [2][1900/3397] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0266(0.0378) Grad: 21766.6094  LR: 0.00001172  \n","Epoch: [2][2000/3397] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0639(0.0378) Grad: 33386.0352  LR: 0.00001160  \n","Epoch: [2][2100/3397] Elapsed 6m 15s (remain 3m 51s) Loss: 0.0171(0.0376) Grad: 2434.4321  LR: 0.00001149  \n","Epoch: [2][2200/3397] Elapsed 6m 33s (remain 3m 33s) Loss: 0.0638(0.0373) Grad: 11876.4854  LR: 0.00001137  \n","Epoch: [2][2300/3397] Elapsed 6m 51s (remain 3m 15s) Loss: 0.0265(0.0372) Grad: 18376.2598  LR: 0.00001125  \n","Epoch: [2][2400/3397] Elapsed 7m 8s (remain 2m 57s) Loss: 0.0168(0.0369) Grad: 5855.6392  LR: 0.00001113  \n","Epoch: [2][2500/3397] Elapsed 7m 26s (remain 2m 39s) Loss: 0.0394(0.0367) Grad: 8342.6836  LR: 0.00001100  \n","Epoch: [2][2600/3397] Elapsed 7m 44s (remain 2m 22s) Loss: 0.0171(0.0366) Grad: 5503.8921  LR: 0.00001088  \n","Epoch: [2][2700/3397] Elapsed 8m 1s (remain 2m 4s) Loss: 0.0384(0.0364) Grad: 19674.3633  LR: 0.00001076  \n","Epoch: [2][2800/3397] Elapsed 8m 19s (remain 1m 46s) Loss: 0.0392(0.0361) Grad: 15282.7148  LR: 0.00001063  \n","Epoch: [2][2900/3397] Elapsed 8m 37s (remain 1m 28s) Loss: 0.0139(0.0359) Grad: 3270.7380  LR: 0.00001050  \n","Epoch: [2][3000/3397] Elapsed 8m 55s (remain 1m 10s) Loss: 0.0396(0.0357) Grad: 11979.7324  LR: 0.00001037  \n","Epoch: [2][3100/3397] Elapsed 9m 12s (remain 0m 52s) Loss: 0.0177(0.0356) Grad: 3753.6355  LR: 0.00001025  \n","Epoch: [2][3200/3397] Elapsed 9m 30s (remain 0m 34s) Loss: 0.0084(0.0354) Grad: 3378.4878  LR: 0.00001012  \n","Epoch: [2][3300/3397] Elapsed 9m 48s (remain 0m 17s) Loss: 0.0101(0.0352) Grad: 3839.9353  LR: 0.00000998  \n","Epoch: [2][3396/3397] Elapsed 10m 5s (remain 0m 0s) Loss: 0.0894(0.0350) Grad: 22718.6621  LR: 0.00000986  \n","EVAL: [0/250] Elapsed 0m 0s (remain 1m 16s) Loss: 0.1203(0.1203) \n","EVAL: [100/250] Elapsed 0m 9s (remain 0m 14s) Loss: 0.1358(0.1025) \n","EVAL: [200/250] Elapsed 0m 19s (remain 0m 4s) Loss: 0.1611(0.1055) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0350  avg_val_loss: 0.1048  time: 630s\n","Epoch 2 - Score: 0.7485\n","Epoch 2 - Save Best Score: 0.7485 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [249/250] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1291(0.1048) \n","Epoch: [3][0/3397] Elapsed 0m 0s (remain 26m 9s) Loss: 0.0074(0.0074) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3397] Elapsed 0m 18s (remain 9m 55s) Loss: 0.0380(0.0243) Grad: 9629.7227  LR: 0.00000972  \n","Epoch: [3][200/3397] Elapsed 0m 36s (remain 9m 41s) Loss: 0.0248(0.0252) Grad: 25688.9219  LR: 0.00000959  \n","Epoch: [3][300/3397] Elapsed 0m 54s (remain 9m 24s) Loss: 0.0177(0.0249) Grad: 12012.7900  LR: 0.00000946  \n","Epoch: [3][400/3397] Elapsed 1m 13s (remain 9m 5s) Loss: 0.0172(0.0248) Grad: 5108.5254  LR: 0.00000932  \n","Epoch: [3][500/3397] Elapsed 1m 31s (remain 8m 47s) Loss: 0.0117(0.0250) Grad: 3719.8772  LR: 0.00000919  \n","Epoch: [3][600/3397] Elapsed 1m 49s (remain 8m 28s) Loss: 0.0165(0.0248) Grad: 11821.7002  LR: 0.00000905  \n","Epoch: [3][700/3397] Elapsed 2m 7s (remain 8m 10s) Loss: 0.0179(0.0250) Grad: 7701.5151  LR: 0.00000892  \n","Epoch: [3][800/3397] Elapsed 2m 25s (remain 7m 51s) Loss: 0.0216(0.0249) Grad: 9714.7764  LR: 0.00000878  \n","Epoch: [3][900/3397] Elapsed 2m 43s (remain 7m 33s) Loss: 0.0217(0.0249) Grad: 9774.2168  LR: 0.00000864  \n","Epoch: [3][1000/3397] Elapsed 3m 1s (remain 7m 15s) Loss: 0.0182(0.0251) Grad: 5947.7759  LR: 0.00000850  \n","Epoch: [3][1100/3397] Elapsed 3m 19s (remain 6m 57s) Loss: 0.0222(0.0249) Grad: 6793.6362  LR: 0.00000837  \n","Epoch: [3][1200/3397] Elapsed 3m 38s (remain 6m 38s) Loss: 0.0223(0.0250) Grad: 10139.5811  LR: 0.00000823  \n","Epoch: [3][1300/3397] Elapsed 3m 55s (remain 6m 19s) Loss: 0.0369(0.0250) Grad: 9104.6904  LR: 0.00000809  \n","Epoch: [3][1400/3397] Elapsed 4m 13s (remain 6m 1s) Loss: 0.0192(0.0250) Grad: 7029.8804  LR: 0.00000795  \n","Epoch: [3][1500/3397] Elapsed 4m 31s (remain 5m 42s) Loss: 0.0061(0.0249) Grad: 22513.4941  LR: 0.00000781  \n","Epoch: [3][1600/3397] Elapsed 4m 49s (remain 5m 24s) Loss: 0.0391(0.0248) Grad: 7598.9688  LR: 0.00000767  \n","Epoch: [3][1700/3397] Elapsed 5m 6s (remain 5m 6s) Loss: 0.0406(0.0249) Grad: 13253.2578  LR: 0.00000753  \n","Epoch: [3][1800/3397] Elapsed 5m 24s (remain 4m 47s) Loss: 0.0180(0.0248) Grad: 6778.2925  LR: 0.00000739  \n","Epoch: [3][1900/3397] Elapsed 5m 42s (remain 4m 29s) Loss: 0.0149(0.0246) Grad: 4871.9058  LR: 0.00000725  \n","Epoch: [3][2000/3397] Elapsed 6m 0s (remain 4m 11s) Loss: 0.0337(0.0246) Grad: 14975.1436  LR: 0.00000712  \n","Epoch: [3][2100/3397] Elapsed 6m 18s (remain 3m 53s) Loss: 0.0163(0.0246) Grad: 6735.1235  LR: 0.00000698  \n","Epoch: [3][2200/3397] Elapsed 6m 35s (remain 3m 35s) Loss: 0.0075(0.0244) Grad: 19523.0117  LR: 0.00000684  \n","Epoch: [3][2300/3397] Elapsed 6m 53s (remain 3m 16s) Loss: 0.0132(0.0244) Grad: 14725.4580  LR: 0.00000670  \n","Epoch: [3][2400/3397] Elapsed 7m 11s (remain 2m 58s) Loss: 0.0392(0.0243) Grad: 16765.5781  LR: 0.00000656  \n","Epoch: [3][2500/3397] Elapsed 7m 28s (remain 2m 40s) Loss: 0.0213(0.0242) Grad: 7249.7974  LR: 0.00000642  \n","Epoch: [3][2600/3397] Elapsed 7m 46s (remain 2m 22s) Loss: 0.0074(0.0241) Grad: 3740.3093  LR: 0.00000629  \n","Epoch: [3][2700/3397] Elapsed 8m 4s (remain 2m 4s) Loss: 0.0118(0.0241) Grad: 2768.6401  LR: 0.00000615  \n","Epoch: [3][2800/3397] Elapsed 8m 22s (remain 1m 46s) Loss: 0.0158(0.0240) Grad: 8270.9111  LR: 0.00000601  \n","Epoch: [3][2900/3397] Elapsed 8m 39s (remain 1m 28s) Loss: 0.0343(0.0240) Grad: 33521.1172  LR: 0.00000588  \n","Epoch: [3][3000/3397] Elapsed 8m 57s (remain 1m 10s) Loss: 0.0224(0.0240) Grad: 9888.9336  LR: 0.00000574  \n","Epoch: [3][3100/3397] Elapsed 9m 15s (remain 0m 53s) Loss: 0.0169(0.0240) Grad: 8340.5020  LR: 0.00000561  \n","Epoch: [3][3200/3397] Elapsed 9m 33s (remain 0m 35s) Loss: 0.0258(0.0239) Grad: 20767.2637  LR: 0.00000547  \n","Epoch: [3][3300/3397] Elapsed 9m 50s (remain 0m 17s) Loss: 0.0288(0.0239) Grad: 2782.3479  LR: 0.00000534  \n","Epoch: [3][3396/3397] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0088(0.0238) Grad: 3545.9854  LR: 0.00000521  \n","EVAL: [0/250] Elapsed 0m 0s (remain 1m 19s) Loss: 0.1162(0.1162) \n","EVAL: [100/250] Elapsed 0m 9s (remain 0m 14s) Loss: 0.1392(0.0997) \n","EVAL: [200/250] Elapsed 0m 19s (remain 0m 4s) Loss: 0.1504(0.1017) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0238  avg_val_loss: 0.1009  time: 632s\n","Epoch 3 - Score: 0.7736\n","Epoch 3 - Save Best Score: 0.7736 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [249/250] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1267(0.1009) \n","Epoch: [4][0/3397] Elapsed 0m 0s (remain 25m 26s) Loss: 0.0100(0.0100) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3397] Elapsed 0m 18s (remain 10m 10s) Loss: 0.0478(0.0175) Grad: inf  LR: 0.00000508  \n","Epoch: [4][200/3397] Elapsed 0m 37s (remain 9m 49s) Loss: 0.0040(0.0179) Grad: 5999.5811  LR: 0.00000495  \n","Epoch: [4][300/3397] Elapsed 0m 55s (remain 9m 26s) Loss: 0.0160(0.0178) Grad: 11203.5029  LR: 0.00000482  \n","Epoch: [4][400/3397] Elapsed 1m 13s (remain 9m 6s) Loss: 0.0048(0.0177) Grad: 1826.4347  LR: 0.00000469  \n","Epoch: [4][500/3397] Elapsed 1m 31s (remain 8m 48s) Loss: 0.0090(0.0177) Grad: 9758.3740  LR: 0.00000456  \n","Epoch: [4][600/3397] Elapsed 1m 49s (remain 8m 28s) Loss: 0.0052(0.0179) Grad: 4569.8550  LR: 0.00000443  \n","Epoch: [4][700/3397] Elapsed 2m 7s (remain 8m 10s) Loss: 0.0068(0.0180) Grad: 6368.6538  LR: 0.00000430  \n","Epoch: [4][800/3397] Elapsed 2m 25s (remain 7m 51s) Loss: 0.0037(0.0180) Grad: 4325.1885  LR: 0.00000418  \n","Epoch: [4][900/3397] Elapsed 2m 43s (remain 7m 33s) Loss: 0.0097(0.0181) Grad: 3697.6731  LR: 0.00000405  \n","Epoch: [4][1000/3397] Elapsed 3m 1s (remain 7m 14s) Loss: 0.0102(0.0180) Grad: 9582.0234  LR: 0.00000393  \n","Epoch: [4][1100/3397] Elapsed 3m 19s (remain 6m 56s) Loss: 0.0184(0.0179) Grad: 5098.9165  LR: 0.00000381  \n","Epoch: [4][1200/3397] Elapsed 3m 37s (remain 6m 37s) Loss: 0.0037(0.0177) Grad: 1335.0282  LR: 0.00000369  \n","Epoch: [4][1300/3397] Elapsed 3m 55s (remain 6m 18s) Loss: 0.0317(0.0176) Grad: 14185.7500  LR: 0.00000357  \n","Epoch: [4][1400/3397] Elapsed 4m 12s (remain 6m 0s) Loss: 0.0063(0.0175) Grad: 5069.1040  LR: 0.00000345  \n","Epoch: [4][1500/3397] Elapsed 4m 30s (remain 5m 41s) Loss: 0.0031(0.0175) Grad: 2469.8013  LR: 0.00000334  \n","Epoch: [4][1600/3397] Elapsed 4m 48s (remain 5m 23s) Loss: 0.0084(0.0175) Grad: 13445.0195  LR: 0.00000322  \n","Epoch: [4][1700/3397] Elapsed 5m 6s (remain 5m 5s) Loss: 0.0117(0.0175) Grad: 7205.9204  LR: 0.00000311  \n","Epoch: [4][1800/3397] Elapsed 5m 24s (remain 4m 47s) Loss: 0.0125(0.0174) Grad: 10065.2334  LR: 0.00000300  \n","Epoch: [4][1900/3397] Elapsed 5m 41s (remain 4m 29s) Loss: 0.0157(0.0174) Grad: 18962.7051  LR: 0.00000288  \n","Epoch: [4][2000/3397] Elapsed 5m 59s (remain 4m 10s) Loss: 0.0060(0.0174) Grad: 3906.0601  LR: 0.00000278  \n","Epoch: [4][2100/3397] Elapsed 6m 17s (remain 3m 52s) Loss: 0.0207(0.0173) Grad: 16470.3535  LR: 0.00000267  \n","Epoch: [4][2200/3397] Elapsed 6m 35s (remain 3m 34s) Loss: 0.0184(0.0172) Grad: 12419.2119  LR: 0.00000256  \n","Epoch: [4][2300/3397] Elapsed 6m 52s (remain 3m 16s) Loss: 0.0103(0.0173) Grad: 8224.5830  LR: 0.00000246  \n","Epoch: [4][2400/3397] Elapsed 7m 10s (remain 2m 58s) Loss: 0.0057(0.0172) Grad: 13530.3994  LR: 0.00000236  \n","Epoch: [4][2500/3397] Elapsed 7m 28s (remain 2m 40s) Loss: 0.0271(0.0172) Grad: 4790.4624  LR: 0.00000226  \n","Epoch: [4][2600/3397] Elapsed 7m 45s (remain 2m 22s) Loss: 0.0161(0.0172) Grad: 15809.8018  LR: 0.00000216  \n","Epoch: [4][2700/3397] Elapsed 8m 3s (remain 2m 4s) Loss: 0.0096(0.0172) Grad: 16401.6738  LR: 0.00000206  \n","Epoch: [4][2800/3397] Elapsed 8m 21s (remain 1m 46s) Loss: 0.0058(0.0172) Grad: 10240.5098  LR: 0.00000197  \n","Epoch: [4][2900/3397] Elapsed 8m 39s (remain 1m 28s) Loss: 0.0153(0.0172) Grad: 7793.7300  LR: 0.00000187  \n","Epoch: [4][3000/3397] Elapsed 8m 56s (remain 1m 10s) Loss: 0.0121(0.0172) Grad: 3086.2070  LR: 0.00000178  \n","Epoch: [4][3100/3397] Elapsed 9m 14s (remain 0m 52s) Loss: 0.0119(0.0171) Grad: 2357.9197  LR: 0.00000169  \n","Epoch: [4][3200/3397] Elapsed 9m 32s (remain 0m 35s) Loss: 0.0362(0.0171) Grad: 12319.6719  LR: 0.00000161  \n","Epoch: [4][3300/3397] Elapsed 9m 49s (remain 0m 17s) Loss: 0.0132(0.0171) Grad: 7127.1313  LR: 0.00000152  \n","Epoch: [4][3396/3397] Elapsed 10m 6s (remain 0m 0s) Loss: 0.0080(0.0171) Grad: 7135.2168  LR: 0.00000144  \n","EVAL: [0/250] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1082(0.1082) \n","EVAL: [100/250] Elapsed 0m 9s (remain 0m 14s) Loss: 0.1291(0.0917) \n","EVAL: [200/250] Elapsed 0m 19s (remain 0m 4s) Loss: 0.1321(0.0937) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0171  avg_val_loss: 0.0930  time: 631s\n","Epoch 4 - Score: 0.7721\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [249/250] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1141(0.0930) \n","Epoch: [5][0/3397] Elapsed 0m 0s (remain 25m 50s) Loss: 0.0070(0.0070) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3397] Elapsed 0m 18s (remain 10m 0s) Loss: 0.0087(0.0151) Grad: 9354.4697  LR: 0.00000136  \n","Epoch: [5][200/3397] Elapsed 0m 36s (remain 9m 40s) Loss: 0.0078(0.0146) Grad: 4632.0273  LR: 0.00000128  \n","Epoch: [5][300/3397] Elapsed 0m 54s (remain 9m 22s) Loss: 0.0129(0.0143) Grad: 4984.7109  LR: 0.00000120  \n","Epoch: [5][400/3397] Elapsed 1m 12s (remain 9m 3s) Loss: 0.0195(0.0143) Grad: 12096.5322  LR: 0.00000113  \n","Epoch: [5][500/3397] Elapsed 1m 30s (remain 8m 45s) Loss: 0.0105(0.0140) Grad: 7003.7051  LR: 0.00000106  \n","Epoch: [5][600/3397] Elapsed 1m 48s (remain 8m 26s) Loss: 0.0138(0.0140) Grad: 13008.0322  LR: 0.00000099  \n","Epoch: [5][700/3397] Elapsed 2m 6s (remain 8m 8s) Loss: 0.0080(0.0141) Grad: 1679.7684  LR: 0.00000092  \n","Epoch: [5][800/3397] Elapsed 2m 25s (remain 7m 50s) Loss: 0.0208(0.0141) Grad: 15557.6953  LR: 0.00000085  \n","Epoch: [5][900/3397] Elapsed 2m 43s (remain 7m 31s) Loss: 0.0082(0.0142) Grad: 4636.1064  LR: 0.00000079  \n","Epoch: [5][1000/3397] Elapsed 3m 1s (remain 7m 13s) Loss: 0.0273(0.0141) Grad: 15619.9004  LR: 0.00000073  \n","Epoch: [5][1100/3397] Elapsed 3m 19s (remain 6m 55s) Loss: 0.0123(0.0141) Grad: 10415.6543  LR: 0.00000067  \n","Epoch: [5][1200/3397] Elapsed 3m 36s (remain 6m 36s) Loss: 0.0122(0.0141) Grad: 5665.0986  LR: 0.00000061  \n","Epoch: [5][1300/3397] Elapsed 3m 54s (remain 6m 17s) Loss: 0.0098(0.0143) Grad: 2877.7192  LR: 0.00000056  \n","Epoch: [5][1400/3397] Elapsed 4m 12s (remain 5m 59s) Loss: 0.0127(0.0141) Grad: 12051.9434  LR: 0.00000051  \n","Epoch: [5][1500/3397] Elapsed 4m 29s (remain 5m 40s) Loss: 0.0318(0.0141) Grad: 8173.9639  LR: 0.00000046  \n","Epoch: [5][1600/3397] Elapsed 4m 47s (remain 5m 22s) Loss: 0.0021(0.0142) Grad: 1608.0187  LR: 0.00000041  \n","Epoch: [5][1700/3397] Elapsed 5m 5s (remain 5m 4s) Loss: 0.0149(0.0141) Grad: 8690.4102  LR: 0.00000037  \n","Epoch: [5][1800/3397] Elapsed 5m 22s (remain 4m 46s) Loss: 0.0033(0.0141) Grad: 3638.6470  LR: 0.00000033  \n","Epoch: [5][1900/3397] Elapsed 5m 40s (remain 4m 27s) Loss: 0.0120(0.0141) Grad: 9500.2852  LR: 0.00000029  \n","Epoch: [5][2000/3397] Elapsed 5m 58s (remain 4m 9s) Loss: 0.0109(0.0141) Grad: 3666.7256  LR: 0.00000025  \n","Epoch: [5][2100/3397] Elapsed 6m 15s (remain 3m 51s) Loss: 0.0347(0.0141) Grad: 9982.6621  LR: 0.00000022  \n","Epoch: [5][2200/3397] Elapsed 6m 33s (remain 3m 33s) Loss: 0.0162(0.0140) Grad: 5627.3706  LR: 0.00000018  \n","Epoch: [5][2300/3397] Elapsed 6m 51s (remain 3m 15s) Loss: 0.0157(0.0140) Grad: 11338.2627  LR: 0.00000016  \n","Epoch: [5][2400/3397] Elapsed 7m 9s (remain 2m 58s) Loss: 0.0108(0.0140) Grad: 11769.5479  LR: 0.00000013  \n","Epoch: [5][2500/3397] Elapsed 7m 26s (remain 2m 40s) Loss: 0.0217(0.0140) Grad: 13934.0986  LR: 0.00000010  \n","Epoch: [5][2600/3397] Elapsed 7m 44s (remain 2m 22s) Loss: 0.0085(0.0140) Grad: 4249.3911  LR: 0.00000008  \n","Epoch: [5][2700/3397] Elapsed 8m 2s (remain 2m 4s) Loss: 0.0137(0.0139) Grad: 5581.9727  LR: 0.00000006  \n","Epoch: [5][2800/3397] Elapsed 8m 19s (remain 1m 46s) Loss: 0.0120(0.0138) Grad: 5391.7817  LR: 0.00000005  \n","Epoch: [5][2900/3397] Elapsed 8m 37s (remain 1m 28s) Loss: 0.0643(0.0139) Grad: 22268.2383  LR: 0.00000003  \n","Epoch: [5][3000/3397] Elapsed 8m 55s (remain 1m 10s) Loss: 0.0101(0.0138) Grad: 8248.4160  LR: 0.00000002  \n","Epoch: [5][3100/3397] Elapsed 9m 13s (remain 0m 52s) Loss: 0.0094(0.0138) Grad: 12919.9336  LR: 0.00000001  \n","Epoch: [5][3200/3397] Elapsed 9m 30s (remain 0m 34s) Loss: 0.0892(0.0138) Grad: 29752.1289  LR: 0.00000001  \n","Epoch: [5][3300/3397] Elapsed 9m 48s (remain 0m 17s) Loss: 0.0111(0.0138) Grad: 4305.6050  LR: 0.00000000  \n","Epoch: [5][3396/3397] Elapsed 10m 5s (remain 0m 0s) Loss: 0.0173(0.0138) Grad: 5157.6201  LR: 0.00000000  \n","EVAL: [0/250] Elapsed 0m 0s (remain 1m 20s) Loss: 0.1125(0.1125) \n","EVAL: [100/250] Elapsed 0m 9s (remain 0m 14s) Loss: 0.1328(0.0959) \n","EVAL: [200/250] Elapsed 0m 19s (remain 0m 4s) Loss: 0.1344(0.0978) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0138  avg_val_loss: 0.0971  time: 630s\n","Epoch 5 - Score: 0.7789\n","Epoch 5 - Save Best Score: 0.7789 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [249/250] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1204(0.0971) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 7 result ==========\n","Score: 0.7789\n","========== fold: 8 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3399] Elapsed 0m 0s (remain 26m 13s) Loss: 0.4639(0.4639) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3399] Elapsed 0m 19s (remain 10m 23s) Loss: 0.1248(0.1760) Grad: 5255.0952  LR: 0.00001500  \n","Epoch: [1][200/3399] Elapsed 0m 37s (remain 9m 53s) Loss: 0.0757(0.1324) Grad: 4258.2788  LR: 0.00001500  \n","Epoch: [1][300/3399] Elapsed 0m 55s (remain 9m 29s) Loss: 0.0649(0.1138) Grad: 11764.3936  LR: 0.00001499  \n","Epoch: [1][400/3399] Elapsed 1m 13s (remain 9m 7s) Loss: 0.0589(0.1068) Grad: 8394.2881  LR: 0.00001498  \n","Epoch: [1][500/3399] Elapsed 1m 31s (remain 8m 47s) Loss: 0.0961(0.0981) Grad: 15887.0674  LR: 0.00001497  \n","Epoch: [1][600/3399] Elapsed 1m 49s (remain 8m 28s) Loss: 0.0817(0.0924) Grad: 6954.2402  LR: 0.00001496  \n","Epoch: [1][700/3399] Elapsed 2m 7s (remain 8m 9s) Loss: 0.0383(0.0873) Grad: 4996.5581  LR: 0.00001495  \n","Epoch: [1][800/3399] Elapsed 2m 25s (remain 7m 50s) Loss: 0.0367(0.0841) Grad: 7637.0596  LR: 0.00001493  \n","Epoch: [1][900/3399] Elapsed 2m 43s (remain 7m 32s) Loss: 0.0540(0.0805) Grad: 11043.1240  LR: 0.00001491  \n","Epoch: [1][1000/3399] Elapsed 3m 1s (remain 7m 13s) Loss: 0.0383(0.0771) Grad: 2993.1992  LR: 0.00001488  \n","Epoch: [1][1100/3399] Elapsed 3m 18s (remain 6m 54s) Loss: 0.0690(0.0740) Grad: 5615.5981  LR: 0.00001486  \n","Epoch: [1][1200/3399] Elapsed 3m 36s (remain 6m 35s) Loss: 0.0825(0.0715) Grad: 10466.0996  LR: 0.00001483  \n","Epoch: [1][1300/3399] Elapsed 3m 53s (remain 6m 16s) Loss: 0.0186(0.0690) Grad: 2953.6145  LR: 0.00001480  \n","Epoch: [1][1400/3399] Elapsed 4m 11s (remain 5m 58s) Loss: 0.0379(0.0669) Grad: 2363.2395  LR: 0.00001477  \n","Epoch: [1][1500/3399] Elapsed 4m 28s (remain 5m 40s) Loss: 0.0267(0.0655) Grad: 4737.8345  LR: 0.00001473  \n","Epoch: [1][1600/3399] Elapsed 4m 46s (remain 5m 21s) Loss: 0.0131(0.0636) Grad: 1881.2031  LR: 0.00001469  \n","Epoch: [1][1700/3399] Elapsed 5m 4s (remain 5m 3s) Loss: 0.0490(0.0621) Grad: 8963.3613  LR: 0.00001465  \n","Epoch: [1][1800/3399] Elapsed 5m 21s (remain 4m 45s) Loss: 0.0188(0.0607) Grad: 3058.7769  LR: 0.00001461  \n","Epoch: [1][1900/3399] Elapsed 5m 39s (remain 4m 27s) Loss: 0.0193(0.0594) Grad: 1077.5538  LR: 0.00001456  \n","Epoch: [1][2000/3399] Elapsed 5m 56s (remain 4m 9s) Loss: 0.0416(0.0582) Grad: 9300.9844  LR: 0.00001451  \n","Epoch: [1][2100/3399] Elapsed 6m 14s (remain 3m 51s) Loss: 0.0133(0.0569) Grad: 1844.3119  LR: 0.00001446  \n","Epoch: [1][2200/3399] Elapsed 6m 32s (remain 3m 33s) Loss: 0.0407(0.0557) Grad: 4073.2949  LR: 0.00001441  \n","Epoch: [1][2300/3399] Elapsed 6m 49s (remain 3m 15s) Loss: 0.0148(0.0546) Grad: 1952.8866  LR: 0.00001436  \n","Epoch: [1][2400/3399] Elapsed 7m 7s (remain 2m 57s) Loss: 0.0231(0.0536) Grad: 9854.2852  LR: 0.00001430  \n","Epoch: [1][2500/3399] Elapsed 7m 24s (remain 2m 39s) Loss: 0.0447(0.0527) Grad: 4938.1685  LR: 0.00001424  \n","Epoch: [1][2600/3399] Elapsed 7m 42s (remain 2m 21s) Loss: 0.0248(0.0519) Grad: 8451.6348  LR: 0.00001418  \n","Epoch: [1][2700/3399] Elapsed 7m 59s (remain 2m 4s) Loss: 0.0313(0.0512) Grad: 8050.7832  LR: 0.00001411  \n","Epoch: [1][2800/3399] Elapsed 8m 17s (remain 1m 46s) Loss: 0.0096(0.0504) Grad: 7018.6421  LR: 0.00001405  \n","Epoch: [1][2900/3399] Elapsed 8m 35s (remain 1m 28s) Loss: 0.0229(0.0497) Grad: 7382.2485  LR: 0.00001398  \n","Epoch: [1][3000/3399] Elapsed 8m 52s (remain 1m 10s) Loss: 0.0143(0.0490) Grad: 1994.2000  LR: 0.00001391  \n","Epoch: [1][3100/3399] Elapsed 9m 10s (remain 0m 52s) Loss: 0.0307(0.0484) Grad: 10725.5557  LR: 0.00001383  \n","Epoch: [1][3200/3399] Elapsed 9m 27s (remain 0m 35s) Loss: 0.0209(0.0477) Grad: 4081.6841  LR: 0.00001376  \n","Epoch: [1][3300/3399] Elapsed 9m 45s (remain 0m 17s) Loss: 0.0244(0.0470) Grad: 9269.9873  LR: 0.00001368  \n","Epoch: [1][3398/3399] Elapsed 10m 2s (remain 0m 0s) Loss: 0.0260(0.0465) Grad: 5179.2983  LR: 0.00001360  \n","EVAL: [0/248] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0462(0.0462) \n","EVAL: [100/248] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0801(0.0872) \n","EVAL: [200/248] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0786(0.0951) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0465  avg_val_loss: 0.0969  time: 627s\n","Epoch 1 - Score: 0.7777\n","Epoch 1 - Save Best Score: 0.7777 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0236(0.0969) \n","Epoch: [2][0/3399] Elapsed 0m 0s (remain 26m 58s) Loss: 0.0409(0.0409) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3399] Elapsed 0m 18s (remain 10m 15s) Loss: 0.0319(0.0249) Grad: 21898.7031  LR: 0.00001352  \n","Epoch: [2][200/3399] Elapsed 0m 37s (remain 9m 56s) Loss: 0.0354(0.0237) Grad: 29005.9883  LR: 0.00001343  \n","Epoch: [2][300/3399] Elapsed 0m 55s (remain 9m 30s) Loss: 0.0099(0.0237) Grad: 14867.8066  LR: 0.00001335  \n","Epoch: [2][400/3399] Elapsed 1m 13s (remain 9m 9s) Loss: 0.0121(0.0230) Grad: 19200.7207  LR: 0.00001326  \n","Epoch: [2][500/3399] Elapsed 1m 31s (remain 8m 49s) Loss: 0.0352(0.0226) Grad: 11242.1025  LR: 0.00001317  \n","Epoch: [2][600/3399] Elapsed 1m 49s (remain 8m 29s) Loss: 0.0055(0.0227) Grad: 7912.4253  LR: 0.00001308  \n","Epoch: [2][700/3399] Elapsed 2m 7s (remain 8m 10s) Loss: 0.0104(0.0227) Grad: 10615.0781  LR: 0.00001298  \n","Epoch: [2][800/3399] Elapsed 2m 25s (remain 7m 51s) Loss: 0.0403(0.0228) Grad: 16080.0352  LR: 0.00001289  \n","Epoch: [2][900/3399] Elapsed 2m 43s (remain 7m 32s) Loss: 0.0098(0.0228) Grad: 5251.1030  LR: 0.00001279  \n","Epoch: [2][1000/3399] Elapsed 3m 1s (remain 7m 13s) Loss: 0.0113(0.0227) Grad: 14418.8770  LR: 0.00001269  \n","Epoch: [2][1100/3399] Elapsed 3m 18s (remain 6m 54s) Loss: 0.0285(0.0228) Grad: 15633.7393  LR: 0.00001259  \n","Epoch: [2][1200/3399] Elapsed 3m 36s (remain 6m 35s) Loss: 0.0201(0.0228) Grad: 19193.6816  LR: 0.00001249  \n","Epoch: [2][1300/3399] Elapsed 3m 53s (remain 6m 17s) Loss: 0.0370(0.0229) Grad: 19783.7051  LR: 0.00001238  \n","Epoch: [2][1400/3399] Elapsed 4m 11s (remain 5m 58s) Loss: 0.0177(0.0230) Grad: 21757.3418  LR: 0.00001228  \n","Epoch: [2][1500/3399] Elapsed 4m 29s (remain 5m 40s) Loss: 0.0107(0.0228) Grad: 15675.3994  LR: 0.00001217  \n","Epoch: [2][1600/3399] Elapsed 4m 46s (remain 5m 22s) Loss: 0.0042(0.0227) Grad: 6340.5176  LR: 0.00001206  \n","Epoch: [2][1700/3399] Elapsed 5m 4s (remain 5m 3s) Loss: 0.0106(0.0228) Grad: 18425.5723  LR: 0.00001195  \n","Epoch: [2][1800/3399] Elapsed 5m 21s (remain 4m 45s) Loss: 0.0084(0.0227) Grad: 12601.8535  LR: 0.00001183  \n","Epoch: [2][1900/3399] Elapsed 5m 39s (remain 4m 27s) Loss: 0.0401(0.0226) Grad: 8002.2705  LR: 0.00001172  \n","Epoch: [2][2000/3399] Elapsed 5m 57s (remain 4m 9s) Loss: 0.0303(0.0226) Grad: 15645.1084  LR: 0.00001160  \n","Epoch: [2][2100/3399] Elapsed 6m 14s (remain 3m 51s) Loss: 0.0247(0.0227) Grad: 27295.2324  LR: 0.00001149  \n","Epoch: [2][2200/3399] Elapsed 6m 32s (remain 3m 33s) Loss: 0.0157(0.0226) Grad: 13552.7432  LR: 0.00001137  \n","Epoch: [2][2300/3399] Elapsed 6m 49s (remain 3m 15s) Loss: 0.0128(0.0226) Grad: 5351.7129  LR: 0.00001125  \n","Epoch: [2][2400/3399] Elapsed 7m 7s (remain 2m 57s) Loss: 0.0077(0.0227) Grad: 13490.7744  LR: 0.00001113  \n","Epoch: [2][2500/3399] Elapsed 7m 25s (remain 2m 39s) Loss: 0.0294(0.0226) Grad: 18231.6074  LR: 0.00001101  \n","Epoch: [2][2600/3399] Elapsed 7m 42s (remain 2m 21s) Loss: 0.0359(0.0226) Grad: 26445.0684  LR: 0.00001088  \n","Epoch: [2][2700/3399] Elapsed 8m 0s (remain 2m 4s) Loss: 0.0116(0.0226) Grad: 2357.4434  LR: 0.00001076  \n","Epoch: [2][2800/3399] Elapsed 8m 18s (remain 1m 46s) Loss: 0.0274(0.0227) Grad: 15364.5576  LR: 0.00001063  \n","Epoch: [2][2900/3399] Elapsed 8m 35s (remain 1m 28s) Loss: 0.0095(0.0227) Grad: 11213.3232  LR: 0.00001051  \n","Epoch: [2][3000/3399] Elapsed 8m 53s (remain 1m 10s) Loss: 0.0081(0.0227) Grad: 3898.0303  LR: 0.00001038  \n","Epoch: [2][3100/3399] Elapsed 9m 10s (remain 0m 52s) Loss: 0.0836(0.0227) Grad: 25153.3281  LR: 0.00001025  \n","Epoch: [2][3200/3399] Elapsed 9m 28s (remain 0m 35s) Loss: 0.0128(0.0227) Grad: 3365.2805  LR: 0.00001012  \n","Epoch: [2][3300/3399] Elapsed 9m 46s (remain 0m 17s) Loss: 0.0075(0.0226) Grad: 9731.2695  LR: 0.00000999  \n","Epoch: [2][3398/3399] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0096(0.0226) Grad: 2817.1228  LR: 0.00000986  \n","EVAL: [0/248] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0469(0.0469) \n","EVAL: [100/248] Elapsed 0m 10s (remain 0m 14s) Loss: 0.0822(0.0870) \n","EVAL: [200/248] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0764(0.0948) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0226  avg_val_loss: 0.0967  time: 628s\n","Epoch 2 - Score: 0.7838\n","Epoch 2 - Save Best Score: 0.7838 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0237(0.0967) \n","Epoch: [3][0/3399] Elapsed 0m 0s (remain 25m 38s) Loss: 0.0170(0.0170) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3399] Elapsed 0m 18s (remain 10m 9s) Loss: 0.0096(0.0171) Grad: 20067.8457  LR: 0.00000973  \n","Epoch: [3][200/3399] Elapsed 0m 36s (remain 9m 48s) Loss: 0.0068(0.0170) Grad: 10455.6885  LR: 0.00000959  \n","Epoch: [3][300/3399] Elapsed 0m 55s (remain 9m 26s) Loss: 0.0075(0.0172) Grad: 6111.5732  LR: 0.00000946  \n","Epoch: [3][400/3399] Elapsed 1m 13s (remain 9m 5s) Loss: 0.0236(0.0179) Grad: 12003.3838  LR: 0.00000932  \n","Epoch: [3][500/3399] Elapsed 1m 30s (remain 8m 46s) Loss: 0.0278(0.0183) Grad: 6923.7539  LR: 0.00000919  \n","Epoch: [3][600/3399] Elapsed 1m 48s (remain 8m 27s) Loss: 0.0148(0.0184) Grad: 10507.6836  LR: 0.00000905  \n","Epoch: [3][700/3399] Elapsed 2m 6s (remain 8m 8s) Loss: 0.0169(0.0185) Grad: 10237.8105  LR: 0.00000892  \n","Epoch: [3][800/3399] Elapsed 2m 24s (remain 7m 49s) Loss: 0.0591(0.0186) Grad: 29958.9258  LR: 0.00000878  \n","Epoch: [3][900/3399] Elapsed 2m 42s (remain 7m 30s) Loss: 0.0343(0.0185) Grad: 14896.2891  LR: 0.00000864  \n","Epoch: [3][1000/3399] Elapsed 3m 0s (remain 7m 11s) Loss: 0.0175(0.0183) Grad: 12508.3691  LR: 0.00000851  \n","Epoch: [3][1100/3399] Elapsed 3m 17s (remain 6m 52s) Loss: 0.0344(0.0183) Grad: 7479.9873  LR: 0.00000837  \n","Epoch: [3][1200/3399] Elapsed 3m 35s (remain 6m 33s) Loss: 0.0139(0.0182) Grad: 12566.4395  LR: 0.00000823  \n","Epoch: [3][1300/3399] Elapsed 3m 52s (remain 6m 15s) Loss: 0.0038(0.0179) Grad: 1597.1786  LR: 0.00000809  \n","Epoch: [3][1400/3399] Elapsed 4m 10s (remain 5m 57s) Loss: 0.0238(0.0179) Grad: 16123.2480  LR: 0.00000795  \n","Epoch: [3][1500/3399] Elapsed 4m 28s (remain 5m 39s) Loss: 0.0090(0.0180) Grad: 5155.7437  LR: 0.00000781  \n","Epoch: [3][1600/3399] Elapsed 4m 45s (remain 5m 20s) Loss: 0.0064(0.0179) Grad: 10189.3828  LR: 0.00000767  \n","Epoch: [3][1700/3399] Elapsed 5m 3s (remain 5m 2s) Loss: 0.0119(0.0179) Grad: 4159.0435  LR: 0.00000754  \n","Epoch: [3][1800/3399] Elapsed 5m 20s (remain 4m 44s) Loss: 0.0211(0.0179) Grad: 13460.3838  LR: 0.00000740  \n","Epoch: [3][1900/3399] Elapsed 5m 38s (remain 4m 26s) Loss: 0.0251(0.0179) Grad: 6794.5000  LR: 0.00000726  \n","Epoch: [3][2000/3399] Elapsed 5m 56s (remain 4m 8s) Loss: 0.0148(0.0178) Grad: 19377.1758  LR: 0.00000712  \n","Epoch: [3][2100/3399] Elapsed 6m 13s (remain 3m 50s) Loss: 0.0168(0.0178) Grad: 8726.0176  LR: 0.00000698  \n","Epoch: [3][2200/3399] Elapsed 6m 31s (remain 3m 33s) Loss: 0.0101(0.0178) Grad: 18220.0176  LR: 0.00000684  \n","Epoch: [3][2300/3399] Elapsed 6m 49s (remain 3m 15s) Loss: 0.0288(0.0178) Grad: 37145.3398  LR: 0.00000670  \n","Epoch: [3][2400/3399] Elapsed 7m 6s (remain 2m 57s) Loss: 0.0335(0.0178) Grad: 16245.2236  LR: 0.00000656  \n","Epoch: [3][2500/3399] Elapsed 7m 24s (remain 2m 39s) Loss: 0.0086(0.0178) Grad: 18300.1250  LR: 0.00000643  \n","Epoch: [3][2600/3399] Elapsed 7m 42s (remain 2m 21s) Loss: 0.0204(0.0177) Grad: 17147.6582  LR: 0.00000629  \n","Epoch: [3][2700/3399] Elapsed 8m 0s (remain 2m 4s) Loss: 0.0191(0.0177) Grad: 9840.7021  LR: 0.00000615  \n","Epoch: [3][2800/3399] Elapsed 8m 17s (remain 1m 46s) Loss: 0.0112(0.0176) Grad: 2539.7554  LR: 0.00000602  \n","Epoch: [3][2900/3399] Elapsed 8m 35s (remain 1m 28s) Loss: 0.0066(0.0176) Grad: 2729.5076  LR: 0.00000588  \n","Epoch: [3][3000/3399] Elapsed 8m 53s (remain 1m 10s) Loss: 0.0325(0.0176) Grad: 14507.5605  LR: 0.00000574  \n","Epoch: [3][3100/3399] Elapsed 9m 11s (remain 0m 52s) Loss: 0.0259(0.0176) Grad: 32919.4766  LR: 0.00000561  \n","Epoch: [3][3200/3399] Elapsed 9m 29s (remain 0m 35s) Loss: 0.0073(0.0176) Grad: 7680.5000  LR: 0.00000548  \n","Epoch: [3][3300/3399] Elapsed 9m 47s (remain 0m 17s) Loss: 0.0131(0.0176) Grad: 8651.6855  LR: 0.00000534  \n","Epoch: [3][3398/3399] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0048(0.0176) Grad: 4657.2222  LR: 0.00000521  \n","EVAL: [0/248] Elapsed 0m 0s (remain 1m 20s) Loss: 0.0425(0.0425) \n","EVAL: [100/248] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0758(0.0831) \n","EVAL: [200/248] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0754(0.0904) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0176  avg_val_loss: 0.0922  time: 629s\n","Epoch 3 - Score: 0.7886\n","Epoch 3 - Save Best Score: 0.7886 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0203(0.0922) \n","Epoch: [4][0/3399] Elapsed 0m 0s (remain 26m 39s) Loss: 0.0287(0.0287) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3399] Elapsed 0m 18s (remain 10m 11s) Loss: 0.0016(0.0120) Grad: 9275.1904  LR: 0.00000508  \n","Epoch: [4][200/3399] Elapsed 0m 37s (remain 9m 51s) Loss: 0.0063(0.0129) Grad: 2772.5100  LR: 0.00000495  \n","Epoch: [4][300/3399] Elapsed 0m 55s (remain 9m 28s) Loss: 0.0065(0.0129) Grad: 8893.6738  LR: 0.00000482  \n","Epoch: [4][400/3399] Elapsed 1m 13s (remain 9m 7s) Loss: 0.0051(0.0127) Grad: 11744.5566  LR: 0.00000469  \n","Epoch: [4][500/3399] Elapsed 1m 31s (remain 8m 47s) Loss: 0.0238(0.0127) Grad: 9371.5127  LR: 0.00000456  \n","Epoch: [4][600/3399] Elapsed 1m 48s (remain 8m 27s) Loss: 0.0132(0.0125) Grad: 16715.6074  LR: 0.00000443  \n","Epoch: [4][700/3399] Elapsed 2m 6s (remain 8m 7s) Loss: 0.0054(0.0126) Grad: 1871.7667  LR: 0.00000431  \n","Epoch: [4][800/3399] Elapsed 2m 24s (remain 7m 47s) Loss: 0.0213(0.0124) Grad: 9279.6572  LR: 0.00000418  \n","Epoch: [4][900/3399] Elapsed 2m 41s (remain 7m 28s) Loss: 0.0281(0.0124) Grad: 8606.0020  LR: 0.00000406  \n","Epoch: [4][1000/3399] Elapsed 2m 59s (remain 7m 9s) Loss: 0.0171(0.0126) Grad: 6171.2788  LR: 0.00000393  \n","Epoch: [4][1100/3399] Elapsed 3m 17s (remain 6m 51s) Loss: 0.0061(0.0126) Grad: 1733.6250  LR: 0.00000381  \n","Epoch: [4][1200/3399] Elapsed 3m 34s (remain 6m 32s) Loss: 0.0131(0.0126) Grad: 4207.5244  LR: 0.00000369  \n","Epoch: [4][1300/3399] Elapsed 3m 52s (remain 6m 14s) Loss: 0.0060(0.0126) Grad: 2105.8274  LR: 0.00000357  \n","Epoch: [4][1400/3399] Elapsed 4m 9s (remain 5m 56s) Loss: 0.0135(0.0127) Grad: 7309.8535  LR: 0.00000345  \n","Epoch: [4][1500/3399] Elapsed 4m 27s (remain 5m 38s) Loss: 0.0114(0.0127) Grad: 10454.7422  LR: 0.00000334  \n","Epoch: [4][1600/3399] Elapsed 4m 45s (remain 5m 20s) Loss: 0.0099(0.0127) Grad: 4996.5283  LR: 0.00000322  \n","Epoch: [4][1700/3399] Elapsed 5m 2s (remain 5m 2s) Loss: 0.0142(0.0128) Grad: 5568.6812  LR: 0.00000311  \n","Epoch: [4][1800/3399] Elapsed 5m 20s (remain 4m 44s) Loss: 0.0044(0.0127) Grad: 5516.0303  LR: 0.00000300  \n","Epoch: [4][1900/3399] Elapsed 5m 38s (remain 4m 26s) Loss: 0.0124(0.0128) Grad: 8730.1221  LR: 0.00000289  \n","Epoch: [4][2000/3399] Elapsed 5m 55s (remain 4m 8s) Loss: 0.0138(0.0128) Grad: 5437.4204  LR: 0.00000278  \n","Epoch: [4][2100/3399] Elapsed 6m 13s (remain 3m 50s) Loss: 0.0048(0.0128) Grad: 2701.0447  LR: 0.00000267  \n","Epoch: [4][2200/3399] Elapsed 6m 30s (remain 3m 32s) Loss: 0.0024(0.0127) Grad: 16958.5898  LR: 0.00000257  \n","Epoch: [4][2300/3399] Elapsed 6m 48s (remain 3m 14s) Loss: 0.0103(0.0127) Grad: 18771.0762  LR: 0.00000246  \n","Epoch: [4][2400/3399] Elapsed 7m 6s (remain 2m 57s) Loss: 0.0233(0.0127) Grad: 13127.9277  LR: 0.00000236  \n","Epoch: [4][2500/3399] Elapsed 7m 23s (remain 2m 39s) Loss: 0.0104(0.0127) Grad: 7157.9551  LR: 0.00000226  \n","Epoch: [4][2600/3399] Elapsed 7m 41s (remain 2m 21s) Loss: 0.0076(0.0127) Grad: 2254.7368  LR: 0.00000216  \n","Epoch: [4][2700/3399] Elapsed 7m 59s (remain 2m 3s) Loss: 0.0192(0.0127) Grad: 12394.7891  LR: 0.00000206  \n","Epoch: [4][2800/3399] Elapsed 8m 16s (remain 1m 46s) Loss: 0.0189(0.0127) Grad: 11347.7490  LR: 0.00000197  \n","Epoch: [4][2900/3399] Elapsed 8m 34s (remain 1m 28s) Loss: 0.0210(0.0127) Grad: 8175.9307  LR: 0.00000188  \n","Epoch: [4][3000/3399] Elapsed 8m 52s (remain 1m 10s) Loss: 0.0155(0.0127) Grad: 10299.3096  LR: 0.00000179  \n","Epoch: [4][3100/3399] Elapsed 9m 10s (remain 0m 52s) Loss: 0.0030(0.0127) Grad: 8043.4033  LR: 0.00000170  \n","Epoch: [4][3200/3399] Elapsed 9m 28s (remain 0m 35s) Loss: 0.0152(0.0126) Grad: 7829.1460  LR: 0.00000161  \n","Epoch: [4][3300/3399] Elapsed 9m 46s (remain 0m 17s) Loss: 0.0068(0.0127) Grad: 12735.3184  LR: 0.00000152  \n","Epoch: [4][3398/3399] Elapsed 10m 3s (remain 0m 0s) Loss: 0.0058(0.0127) Grad: 9570.7217  LR: 0.00000144  \n","EVAL: [0/248] Elapsed 0m 0s (remain 1m 19s) Loss: 0.0443(0.0443) \n","EVAL: [100/248] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0792(0.0874) \n","EVAL: [200/248] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0784(0.0945) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0127  avg_val_loss: 0.0963  time: 628s\n","Epoch 4 - Score: 0.8035\n","Epoch 4 - Save Best Score: 0.8035 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0233(0.0963) \n","Epoch: [5][0/3399] Elapsed 0m 0s (remain 28m 14s) Loss: 0.0106(0.0106) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3399] Elapsed 0m 18s (remain 10m 13s) Loss: 0.0014(0.0097) Grad: 2307.9600  LR: 0.00000136  \n","Epoch: [5][200/3399] Elapsed 0m 37s (remain 9m 52s) Loss: 0.0091(0.0100) Grad: 4110.5278  LR: 0.00000128  \n","Epoch: [5][300/3399] Elapsed 0m 55s (remain 9m 27s) Loss: 0.0105(0.0099) Grad: 29410.5293  LR: 0.00000121  \n","Epoch: [5][400/3399] Elapsed 1m 13s (remain 9m 6s) Loss: 0.0061(0.0101) Grad: 8686.3008  LR: 0.00000113  \n","Epoch: [5][500/3399] Elapsed 1m 31s (remain 8m 47s) Loss: 0.0063(0.0100) Grad: 19624.1875  LR: 0.00000106  \n","Epoch: [5][600/3399] Elapsed 1m 48s (remain 8m 26s) Loss: 0.0124(0.0101) Grad: 20783.7168  LR: 0.00000099  \n","Epoch: [5][700/3399] Elapsed 2m 6s (remain 8m 5s) Loss: 0.0643(0.0102) Grad: inf  LR: 0.00000092  \n","Epoch: [5][800/3399] Elapsed 2m 23s (remain 7m 46s) Loss: 0.0070(0.0102) Grad: 3643.2532  LR: 0.00000086  \n","Epoch: [5][900/3399] Elapsed 2m 41s (remain 7m 27s) Loss: 0.0090(0.0102) Grad: 11783.4717  LR: 0.00000079  \n","Epoch: [5][1000/3399] Elapsed 2m 59s (remain 7m 9s) Loss: 0.0039(0.0100) Grad: 8122.9058  LR: 0.00000073  \n","Epoch: [5][1100/3399] Elapsed 3m 16s (remain 6m 50s) Loss: 0.0073(0.0099) Grad: 7927.3442  LR: 0.00000067  \n","Epoch: [5][1200/3399] Elapsed 3m 34s (remain 6m 32s) Loss: 0.0060(0.0100) Grad: 8447.1318  LR: 0.00000062  \n","Epoch: [5][1300/3399] Elapsed 3m 52s (remain 6m 14s) Loss: 0.0016(0.0100) Grad: 4456.2012  LR: 0.00000056  \n","Epoch: [5][1400/3399] Elapsed 4m 9s (remain 5m 56s) Loss: 0.0089(0.0100) Grad: 16437.8457  LR: 0.00000051  \n","Epoch: [5][1500/3399] Elapsed 4m 27s (remain 5m 37s) Loss: 0.0035(0.0100) Grad: 5198.2568  LR: 0.00000046  \n","Epoch: [5][1600/3399] Elapsed 4m 44s (remain 5m 19s) Loss: 0.0104(0.0101) Grad: 4601.3320  LR: 0.00000041  \n","Epoch: [5][1700/3399] Elapsed 5m 2s (remain 5m 2s) Loss: 0.0112(0.0100) Grad: 12944.4346  LR: 0.00000037  \n","Epoch: [5][1800/3399] Elapsed 5m 20s (remain 4m 44s) Loss: 0.0042(0.0100) Grad: 5746.2920  LR: 0.00000033  \n","Epoch: [5][1900/3399] Elapsed 5m 37s (remain 4m 26s) Loss: 0.0069(0.0100) Grad: 7345.9985  LR: 0.00000029  \n","Epoch: [5][2000/3399] Elapsed 5m 55s (remain 4m 8s) Loss: 0.0284(0.0100) Grad: 3174.8984  LR: 0.00000025  \n","Epoch: [5][2100/3399] Elapsed 6m 12s (remain 3m 50s) Loss: 0.0108(0.0100) Grad: 12422.9551  LR: 0.00000022  \n","Epoch: [5][2200/3399] Elapsed 6m 30s (remain 3m 32s) Loss: 0.0097(0.0100) Grad: 9292.5488  LR: 0.00000019  \n","Epoch: [5][2300/3399] Elapsed 6m 48s (remain 3m 14s) Loss: 0.0329(0.0100) Grad: 6322.1196  LR: 0.00000016  \n","Epoch: [5][2400/3399] Elapsed 7m 5s (remain 2m 56s) Loss: 0.0071(0.0100) Grad: 4531.4048  LR: 0.00000013  \n","Epoch: [5][2500/3399] Elapsed 7m 23s (remain 2m 39s) Loss: 0.0073(0.0100) Grad: 6793.7153  LR: 0.00000010  \n","Epoch: [5][2600/3399] Elapsed 7m 41s (remain 2m 21s) Loss: 0.0098(0.0100) Grad: 11383.0000  LR: 0.00000008  \n","Epoch: [5][2700/3399] Elapsed 7m 58s (remain 2m 3s) Loss: 0.0098(0.0100) Grad: 17296.2109  LR: 0.00000006  \n","Epoch: [5][2800/3399] Elapsed 8m 16s (remain 1m 45s) Loss: 0.0161(0.0101) Grad: 25905.3223  LR: 0.00000005  \n","Epoch: [5][2900/3399] Elapsed 8m 33s (remain 1m 28s) Loss: 0.0063(0.0101) Grad: 3926.3088  LR: 0.00000003  \n","Epoch: [5][3000/3399] Elapsed 8m 51s (remain 1m 10s) Loss: 0.0047(0.0101) Grad: 7102.8032  LR: 0.00000002  \n","Epoch: [5][3100/3399] Elapsed 9m 9s (remain 0m 52s) Loss: 0.0044(0.0101) Grad: 10834.8076  LR: 0.00000001  \n","Epoch: [5][3200/3399] Elapsed 9m 27s (remain 0m 35s) Loss: 0.0113(0.0102) Grad: 5498.3389  LR: 0.00000001  \n","Epoch: [5][3300/3399] Elapsed 9m 45s (remain 0m 17s) Loss: 0.0055(0.0102) Grad: 7442.9248  LR: 0.00000000  \n","Epoch: [5][3398/3399] Elapsed 10m 3s (remain 0m 0s) Loss: 0.0081(0.0102) Grad: 3207.0552  LR: 0.00000000  \n","EVAL: [0/248] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0439(0.0439) \n","EVAL: [100/248] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0792(0.0871) \n","EVAL: [200/248] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0774(0.0938) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0102  avg_val_loss: 0.0956  time: 628s\n","Epoch 5 - Score: 0.8028\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0219(0.0956) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 8 result ==========\n","Score: 0.8035\n","========== fold: 9 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3414] Elapsed 0m 0s (remain 26m 23s) Loss: 0.3069(0.3069) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3414] Elapsed 0m 18s (remain 9m 59s) Loss: 0.1305(0.1818) Grad: 5128.2505  LR: 0.00001500  \n","Epoch: [1][200/3414] Elapsed 0m 36s (remain 9m 41s) Loss: 0.1364(0.1524) Grad: 7428.0786  LR: 0.00001500  \n","Epoch: [1][300/3414] Elapsed 0m 54s (remain 9m 23s) Loss: 0.0796(0.1268) Grad: 4114.2017  LR: 0.00001499  \n","Epoch: [1][400/3414] Elapsed 1m 12s (remain 9m 5s) Loss: 0.0602(0.1102) Grad: 3777.5674  LR: 0.00001498  \n","Epoch: [1][500/3414] Elapsed 1m 30s (remain 8m 46s) Loss: 0.0280(0.0991) Grad: 2536.6580  LR: 0.00001497  \n","Epoch: [1][600/3414] Elapsed 1m 48s (remain 8m 26s) Loss: 0.1123(0.0916) Grad: 4709.9692  LR: 0.00001496  \n","Epoch: [1][700/3414] Elapsed 2m 5s (remain 8m 7s) Loss: 0.0425(0.0852) Grad: 6400.5864  LR: 0.00001495  \n","Epoch: [1][800/3414] Elapsed 2m 23s (remain 7m 48s) Loss: 0.0225(0.0798) Grad: 1509.7571  LR: 0.00001493  \n","Epoch: [1][900/3414] Elapsed 2m 41s (remain 7m 30s) Loss: 0.0424(0.0756) Grad: 141046.5625  LR: 0.00001491  \n","Epoch: [1][1000/3414] Elapsed 2m 59s (remain 7m 12s) Loss: 0.0203(0.0721) Grad: 1428.6548  LR: 0.00001488  \n","Epoch: [1][1100/3414] Elapsed 3m 17s (remain 6m 53s) Loss: 0.0344(0.0691) Grad: 1393.5560  LR: 0.00001486  \n","Epoch: [1][1200/3414] Elapsed 3m 34s (remain 6m 35s) Loss: 0.0300(0.0663) Grad: 2372.3906  LR: 0.00001483  \n","Epoch: [1][1300/3414] Elapsed 3m 52s (remain 6m 17s) Loss: 0.0446(0.0642) Grad: 3476.0679  LR: 0.00001480  \n","Epoch: [1][1400/3414] Elapsed 4m 10s (remain 5m 59s) Loss: 0.0358(0.0623) Grad: 2343.7275  LR: 0.00001477  \n","Epoch: [1][1500/3414] Elapsed 4m 27s (remain 5m 41s) Loss: 0.0121(0.0605) Grad: 2936.6011  LR: 0.00001473  \n","Epoch: [1][1600/3414] Elapsed 4m 45s (remain 5m 23s) Loss: 0.0077(0.0591) Grad: 957.7029  LR: 0.00001469  \n","Epoch: [1][1700/3414] Elapsed 5m 3s (remain 5m 5s) Loss: 0.0213(0.0577) Grad: 1482.5231  LR: 0.00001465  \n","Epoch: [1][1800/3414] Elapsed 5m 21s (remain 4m 47s) Loss: 0.0419(0.0563) Grad: 1716.8224  LR: 0.00001461  \n","Epoch: [1][1900/3414] Elapsed 5m 38s (remain 4m 29s) Loss: 0.0323(0.0549) Grad: 1682.2433  LR: 0.00001457  \n","Epoch: [1][2000/3414] Elapsed 5m 56s (remain 4m 11s) Loss: 0.0167(0.0539) Grad: 2401.0225  LR: 0.00001452  \n","Epoch: [1][2100/3414] Elapsed 6m 14s (remain 3m 53s) Loss: 0.0141(0.0529) Grad: 1996.8661  LR: 0.00001447  \n","Epoch: [1][2200/3414] Elapsed 6m 31s (remain 3m 36s) Loss: 0.0278(0.0518) Grad: 6504.2139  LR: 0.00001442  \n","Epoch: [1][2300/3414] Elapsed 6m 49s (remain 3m 18s) Loss: 0.0344(0.0508) Grad: 4771.8076  LR: 0.00001436  \n","Epoch: [1][2400/3414] Elapsed 7m 7s (remain 3m 0s) Loss: 0.0151(0.0499) Grad: 1959.2031  LR: 0.00001430  \n","Epoch: [1][2500/3414] Elapsed 7m 25s (remain 2m 42s) Loss: 0.0119(0.0490) Grad: 2645.2686  LR: 0.00001425  \n","Epoch: [1][2600/3414] Elapsed 7m 42s (remain 2m 24s) Loss: 0.0342(0.0483) Grad: 3847.6345  LR: 0.00001418  \n","Epoch: [1][2700/3414] Elapsed 8m 0s (remain 2m 6s) Loss: 0.0276(0.0475) Grad: 4297.9053  LR: 0.00001412  \n","Epoch: [1][2800/3414] Elapsed 8m 18s (remain 1m 49s) Loss: 0.0503(0.0469) Grad: 2229.5859  LR: 0.00001405  \n","Epoch: [1][2900/3414] Elapsed 8m 35s (remain 1m 31s) Loss: 0.0110(0.0463) Grad: 2182.9104  LR: 0.00001399  \n","Epoch: [1][3000/3414] Elapsed 8m 53s (remain 1m 13s) Loss: 0.0082(0.0456) Grad: 2136.3035  LR: 0.00001391  \n","Epoch: [1][3100/3414] Elapsed 9m 11s (remain 0m 55s) Loss: 0.0334(0.0450) Grad: 4259.0635  LR: 0.00001384  \n","Epoch: [1][3200/3414] Elapsed 9m 29s (remain 0m 37s) Loss: 0.0021(0.0445) Grad: 1153.5585  LR: 0.00001377  \n","Epoch: [1][3300/3414] Elapsed 9m 47s (remain 0m 20s) Loss: 0.0309(0.0439) Grad: 4064.4460  LR: 0.00001369  \n","Epoch: [1][3400/3414] Elapsed 10m 5s (remain 0m 2s) Loss: 0.0295(0.0435) Grad: 3577.2893  LR: 0.00001361  \n","Epoch: [1][3413/3414] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0718(0.0434) Grad: 5559.3140  LR: 0.00001360  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0961(0.0961) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.0956(0.1071) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0225(0.1075) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0434  avg_val_loss: 0.1076  time: 631s\n","Epoch 1 - Score: 0.7498\n","Epoch 1 - Save Best Score: 0.7498 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1863(0.1076) \n","Epoch: [2][0/3414] Elapsed 0m 0s (remain 29m 30s) Loss: 0.0571(0.0571) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3414] Elapsed 0m 19s (remain 10m 25s) Loss: 0.0056(0.0244) Grad: 25633.7969  LR: 0.00001352  \n","Epoch: [2][200/3414] Elapsed 0m 37s (remain 10m 3s) Loss: 0.0322(0.0234) Grad: 37406.2969  LR: 0.00001343  \n","Epoch: [2][300/3414] Elapsed 0m 55s (remain 9m 36s) Loss: 0.0191(0.0233) Grad: 47369.9844  LR: 0.00001335  \n","Epoch: [2][400/3414] Elapsed 1m 13s (remain 9m 13s) Loss: 0.0420(0.0228) Grad: 75418.6016  LR: 0.00001326  \n","Epoch: [2][500/3414] Elapsed 1m 31s (remain 8m 51s) Loss: 0.0605(0.0227) Grad: 25332.3594  LR: 0.00001317  \n","Epoch: [2][600/3414] Elapsed 1m 48s (remain 8m 29s) Loss: 0.0367(0.0224) Grad: 38025.8906  LR: 0.00001308  \n","Epoch: [2][700/3414] Elapsed 2m 6s (remain 8m 10s) Loss: 0.0094(0.0220) Grad: 14993.8369  LR: 0.00001299  \n","Epoch: [2][800/3414] Elapsed 2m 24s (remain 7m 51s) Loss: 0.0190(0.0219) Grad: 25792.1816  LR: 0.00001289  \n","Epoch: [2][900/3414] Elapsed 2m 42s (remain 7m 32s) Loss: 0.0058(0.0216) Grad: 9847.8682  LR: 0.00001279  \n","Epoch: [2][1000/3414] Elapsed 3m 0s (remain 7m 14s) Loss: 0.0256(0.0216) Grad: 189511.3438  LR: 0.00001270  \n","Epoch: [2][1100/3414] Elapsed 3m 17s (remain 6m 55s) Loss: 0.0261(0.0214) Grad: 52205.8164  LR: 0.00001259  \n","Epoch: [2][1200/3414] Elapsed 3m 35s (remain 6m 37s) Loss: 0.0389(0.0212) Grad: 41301.8555  LR: 0.00001249  \n","Epoch: [2][1300/3414] Elapsed 3m 53s (remain 6m 19s) Loss: 0.0324(0.0211) Grad: 59061.7227  LR: 0.00001239  \n","Epoch: [2][1400/3414] Elapsed 4m 11s (remain 6m 1s) Loss: 0.0338(0.0209) Grad: 32859.2812  LR: 0.00001228  \n","Epoch: [2][1500/3414] Elapsed 4m 28s (remain 5m 42s) Loss: 0.0100(0.0207) Grad: 14522.3174  LR: 0.00001217  \n","Epoch: [2][1600/3414] Elapsed 4m 46s (remain 5m 24s) Loss: 0.0092(0.0206) Grad: 12944.4756  LR: 0.00001207  \n","Epoch: [2][1700/3414] Elapsed 5m 4s (remain 5m 6s) Loss: 0.0092(0.0204) Grad: 20801.3789  LR: 0.00001195  \n","Epoch: [2][1800/3414] Elapsed 5m 22s (remain 4m 48s) Loss: 0.0123(0.0204) Grad: 14746.2080  LR: 0.00001184  \n","Epoch: [2][1900/3414] Elapsed 5m 40s (remain 4m 30s) Loss: 0.0323(0.0204) Grad: 76907.4375  LR: 0.00001173  \n","Epoch: [2][2000/3414] Elapsed 5m 57s (remain 4m 12s) Loss: 0.0204(0.0203) Grad: 91061.0938  LR: 0.00001161  \n","Epoch: [2][2100/3414] Elapsed 6m 15s (remain 3m 54s) Loss: 0.0194(0.0203) Grad: 74354.6016  LR: 0.00001150  \n","Epoch: [2][2200/3414] Elapsed 6m 33s (remain 3m 36s) Loss: 0.0203(0.0203) Grad: 14616.3838  LR: 0.00001138  \n","Epoch: [2][2300/3414] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0301(0.0204) Grad: 16758.3320  LR: 0.00001126  \n","Epoch: [2][2400/3414] Elapsed 7m 8s (remain 3m 0s) Loss: 0.0237(0.0204) Grad: 19139.2520  LR: 0.00001114  \n","Epoch: [2][2500/3414] Elapsed 7m 26s (remain 2m 42s) Loss: 0.0124(0.0205) Grad: 9682.8887  LR: 0.00001102  \n","Epoch: [2][2600/3414] Elapsed 7m 43s (remain 2m 24s) Loss: 0.0152(0.0205) Grad: 6646.3462  LR: 0.00001090  \n","Epoch: [2][2700/3414] Elapsed 8m 1s (remain 2m 7s) Loss: 0.0206(0.0205) Grad: 10019.7588  LR: 0.00001077  \n","Epoch: [2][2800/3414] Elapsed 8m 20s (remain 1m 49s) Loss: 0.0242(0.0205) Grad: 25344.1230  LR: 0.00001065  \n","Epoch: [2][2900/3414] Elapsed 8m 38s (remain 1m 31s) Loss: 0.0307(0.0205) Grad: 8186.4888  LR: 0.00001052  \n","Epoch: [2][3000/3414] Elapsed 8m 56s (remain 1m 13s) Loss: 0.0147(0.0205) Grad: 9874.7617  LR: 0.00001039  \n","Epoch: [2][3100/3414] Elapsed 9m 14s (remain 0m 55s) Loss: 0.0146(0.0205) Grad: 8612.3887  LR: 0.00001027  \n","Epoch: [2][3200/3414] Elapsed 9m 32s (remain 0m 38s) Loss: 0.0085(0.0205) Grad: 5311.3965  LR: 0.00001014  \n","Epoch: [2][3300/3414] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0184(0.0206) Grad: 9515.6387  LR: 0.00001001  \n","Epoch: [2][3400/3414] Elapsed 10m 8s (remain 0m 2s) Loss: 0.0114(0.0206) Grad: 5716.1152  LR: 0.00000988  \n","Epoch: [2][3413/3414] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0158(0.0206) Grad: 5547.5825  LR: 0.00000986  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 32s) Loss: 0.1037(0.1037) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1024(0.1127) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0310(0.1129) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0206  avg_val_loss: 0.1130  time: 634s\n","Epoch 2 - Score: 0.7765\n","Epoch 2 - Save Best Score: 0.7765 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1988(0.1130) \n","Epoch: [3][0/3414] Elapsed 0m 0s (remain 28m 58s) Loss: 0.0124(0.0124) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3414] Elapsed 0m 19s (remain 10m 30s) Loss: 0.0245(0.0190) Grad: 37523.5898  LR: 0.00000973  \n","Epoch: [3][200/3414] Elapsed 0m 37s (remain 9m 59s) Loss: 0.0136(0.0178) Grad: 80443.5859  LR: 0.00000959  \n","Epoch: [3][300/3414] Elapsed 0m 55s (remain 9m 29s) Loss: 0.0204(0.0178) Grad: 65399.1172  LR: 0.00000946  \n","Epoch: [3][400/3414] Elapsed 1m 12s (remain 9m 6s) Loss: 0.0226(0.0173) Grad: 58787.3008  LR: 0.00000933  \n","Epoch: [3][500/3414] Elapsed 1m 30s (remain 8m 45s) Loss: 0.0122(0.0174) Grad: 30226.8418  LR: 0.00000919  \n","Epoch: [3][600/3414] Elapsed 1m 48s (remain 8m 25s) Loss: 0.0029(0.0172) Grad: 20959.7891  LR: 0.00000906  \n","Epoch: [3][700/3414] Elapsed 2m 5s (remain 8m 6s) Loss: 0.0198(0.0170) Grad: 107051.0938  LR: 0.00000892  \n","Epoch: [3][800/3414] Elapsed 2m 23s (remain 7m 47s) Loss: 0.0112(0.0169) Grad: 32084.0859  LR: 0.00000878  \n","Epoch: [3][900/3414] Elapsed 2m 41s (remain 7m 29s) Loss: 0.0096(0.0169) Grad: 21775.3320  LR: 0.00000865  \n","Epoch: [3][1000/3414] Elapsed 2m 58s (remain 7m 11s) Loss: 0.0141(0.0169) Grad: 14600.9316  LR: 0.00000851  \n","Epoch: [3][1100/3414] Elapsed 3m 16s (remain 6m 52s) Loss: 0.0075(0.0169) Grad: 14718.3652  LR: 0.00000837  \n","Epoch: [3][1200/3414] Elapsed 3m 34s (remain 6m 34s) Loss: 0.0156(0.0170) Grad: 7285.5854  LR: 0.00000824  \n","Epoch: [3][1300/3414] Elapsed 3m 51s (remain 6m 16s) Loss: 0.0203(0.0169) Grad: 25246.3477  LR: 0.00000810  \n","Epoch: [3][1400/3414] Elapsed 4m 9s (remain 5m 58s) Loss: 0.0438(0.0170) Grad: 116821.3438  LR: 0.00000796  \n","Epoch: [3][1500/3414] Elapsed 4m 27s (remain 5m 40s) Loss: 0.0515(0.0170) Grad: 43151.2656  LR: 0.00000782  \n","Epoch: [3][1600/3414] Elapsed 4m 44s (remain 5m 22s) Loss: 0.0113(0.0169) Grad: 13911.7812  LR: 0.00000768  \n","Epoch: [3][1700/3414] Elapsed 5m 2s (remain 5m 4s) Loss: 0.0149(0.0169) Grad: 19314.9668  LR: 0.00000754  \n","Epoch: [3][1800/3414] Elapsed 5m 20s (remain 4m 46s) Loss: 0.0338(0.0169) Grad: 31038.7656  LR: 0.00000741  \n","Epoch: [3][1900/3414] Elapsed 5m 37s (remain 4m 28s) Loss: 0.0210(0.0169) Grad: 21317.1973  LR: 0.00000727  \n","Epoch: [3][2000/3414] Elapsed 5m 55s (remain 4m 10s) Loss: 0.0126(0.0170) Grad: 22783.3574  LR: 0.00000713  \n","Epoch: [3][2100/3414] Elapsed 6m 13s (remain 3m 53s) Loss: 0.0237(0.0169) Grad: 25727.8555  LR: 0.00000699  \n","Epoch: [3][2200/3414] Elapsed 6m 30s (remain 3m 35s) Loss: 0.0050(0.0169) Grad: 16574.8125  LR: 0.00000685  \n","Epoch: [3][2300/3414] Elapsed 6m 48s (remain 3m 17s) Loss: 0.0099(0.0168) Grad: 16619.8262  LR: 0.00000672  \n","Epoch: [3][2400/3414] Elapsed 7m 6s (remain 2m 59s) Loss: 0.0391(0.0168) Grad: 31318.1035  LR: 0.00000658  \n","Epoch: [3][2500/3414] Elapsed 7m 24s (remain 2m 42s) Loss: 0.0131(0.0167) Grad: 15657.2129  LR: 0.00000644  \n","Epoch: [3][2600/3414] Elapsed 7m 42s (remain 2m 24s) Loss: 0.0393(0.0168) Grad: 28643.6172  LR: 0.00000630  \n","Epoch: [3][2700/3414] Elapsed 8m 0s (remain 2m 6s) Loss: 0.0473(0.0169) Grad: 26245.5781  LR: 0.00000617  \n","Epoch: [3][2800/3414] Elapsed 8m 19s (remain 1m 49s) Loss: 0.0179(0.0169) Grad: 27671.9668  LR: 0.00000603  \n","Epoch: [3][2900/3414] Elapsed 8m 37s (remain 1m 31s) Loss: 0.0044(0.0169) Grad: 11066.5195  LR: 0.00000590  \n","Epoch: [3][3000/3414] Elapsed 8m 55s (remain 1m 13s) Loss: 0.0021(0.0168) Grad: 9415.1230  LR: 0.00000576  \n","Epoch: [3][3100/3414] Elapsed 9m 13s (remain 0m 55s) Loss: 0.0103(0.0169) Grad: 54082.9414  LR: 0.00000563  \n","Epoch: [3][3200/3414] Elapsed 9m 31s (remain 0m 38s) Loss: 0.0134(0.0169) Grad: 33500.1641  LR: 0.00000549  \n","Epoch: [3][3300/3414] Elapsed 9m 49s (remain 0m 20s) Loss: 0.0054(0.0169) Grad: 14888.9346  LR: 0.00000536  \n","Epoch: [3][3400/3414] Elapsed 10m 7s (remain 0m 2s) Loss: 0.0162(0.0168) Grad: 61070.3789  LR: 0.00000523  \n","Epoch: [3][3413/3414] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0181(0.0168) Grad: 37455.5703  LR: 0.00000521  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 23s) Loss: 0.0978(0.0978) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.0968(0.1043) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0223(0.1050) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0168  avg_val_loss: 0.1050  time: 632s\n","Epoch 3 - Score: 0.7696\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1850(0.1050) \n","Epoch: [4][0/3414] Elapsed 0m 0s (remain 26m 38s) Loss: 0.0397(0.0397) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3414] Elapsed 0m 18s (remain 9m 54s) Loss: 0.0179(0.0139) Grad: 31351.0938  LR: 0.00000508  \n","Epoch: [4][200/3414] Elapsed 0m 35s (remain 9m 32s) Loss: 0.0187(0.0134) Grad: 40801.6172  LR: 0.00000495  \n","Epoch: [4][300/3414] Elapsed 0m 53s (remain 9m 13s) Loss: 0.0076(0.0134) Grad: 37654.9492  LR: 0.00000482  \n","Epoch: [4][400/3414] Elapsed 1m 11s (remain 8m 54s) Loss: 0.0033(0.0135) Grad: 24822.7012  LR: 0.00000469  \n","Epoch: [4][500/3414] Elapsed 1m 28s (remain 8m 36s) Loss: 0.0111(0.0136) Grad: 19297.3984  LR: 0.00000456  \n","Epoch: [4][600/3414] Elapsed 1m 46s (remain 8m 18s) Loss: 0.0062(0.0136) Grad: 16245.1562  LR: 0.00000443  \n","Epoch: [4][700/3414] Elapsed 2m 4s (remain 8m 0s) Loss: 0.0151(0.0136) Grad: 29774.3887  LR: 0.00000431  \n","Epoch: [4][800/3414] Elapsed 2m 21s (remain 7m 43s) Loss: 0.0089(0.0137) Grad: 28554.8301  LR: 0.00000418  \n","Epoch: [4][900/3414] Elapsed 2m 39s (remain 7m 25s) Loss: 0.0021(0.0136) Grad: 9592.2129  LR: 0.00000406  \n","Epoch: [4][1000/3414] Elapsed 2m 57s (remain 7m 7s) Loss: 0.0046(0.0135) Grad: 20282.5781  LR: 0.00000394  \n","Epoch: [4][1100/3414] Elapsed 3m 14s (remain 6m 49s) Loss: 0.0119(0.0136) Grad: 30879.8867  LR: 0.00000382  \n","Epoch: [4][1200/3414] Elapsed 3m 32s (remain 6m 31s) Loss: 0.0120(0.0135) Grad: 23998.0801  LR: 0.00000370  \n","Epoch: [4][1300/3414] Elapsed 3m 50s (remain 6m 14s) Loss: 0.0062(0.0135) Grad: 20309.5684  LR: 0.00000358  \n","Epoch: [4][1400/3414] Elapsed 4m 8s (remain 5m 56s) Loss: 0.0102(0.0136) Grad: 79735.2031  LR: 0.00000346  \n","Epoch: [4][1500/3414] Elapsed 4m 25s (remain 5m 38s) Loss: 0.0121(0.0135) Grad: 28639.0820  LR: 0.00000334  \n","Epoch: [4][1600/3414] Elapsed 4m 43s (remain 5m 20s) Loss: 0.0174(0.0135) Grad: 33547.4336  LR: 0.00000323  \n","Epoch: [4][1700/3414] Elapsed 5m 1s (remain 5m 3s) Loss: 0.0230(0.0136) Grad: 40012.3359  LR: 0.00000312  \n","Epoch: [4][1800/3414] Elapsed 5m 18s (remain 4m 45s) Loss: 0.0114(0.0137) Grad: 59691.0977  LR: 0.00000301  \n","Epoch: [4][1900/3414] Elapsed 5m 36s (remain 4m 27s) Loss: 0.0165(0.0136) Grad: 46705.7500  LR: 0.00000290  \n","Epoch: [4][2000/3414] Elapsed 5m 53s (remain 4m 9s) Loss: 0.0051(0.0136) Grad: 23292.7285  LR: 0.00000279  \n","Epoch: [4][2100/3414] Elapsed 6m 11s (remain 3m 52s) Loss: 0.0084(0.0136) Grad: 37103.4453  LR: 0.00000268  \n","Epoch: [4][2200/3414] Elapsed 6m 29s (remain 3m 34s) Loss: 0.0021(0.0135) Grad: 12615.1396  LR: 0.00000257  \n","Epoch: [4][2300/3414] Elapsed 6m 47s (remain 3m 17s) Loss: 0.0031(0.0134) Grad: 16113.3232  LR: 0.00000247  \n","Epoch: [4][2400/3414] Elapsed 7m 6s (remain 2m 59s) Loss: 0.0125(0.0134) Grad: 41259.0625  LR: 0.00000237  \n","Epoch: [4][2500/3414] Elapsed 7m 24s (remain 2m 42s) Loss: 0.0203(0.0134) Grad: 32953.7930  LR: 0.00000227  \n","Epoch: [4][2600/3414] Elapsed 7m 42s (remain 2m 24s) Loss: 0.0042(0.0133) Grad: 19814.0234  LR: 0.00000217  \n","Epoch: [4][2700/3414] Elapsed 8m 0s (remain 2m 6s) Loss: 0.0062(0.0133) Grad: 27410.4668  LR: 0.00000207  \n","Epoch: [4][2800/3414] Elapsed 8m 18s (remain 1m 49s) Loss: 0.0023(0.0133) Grad: 15699.5605  LR: 0.00000198  \n","Epoch: [4][2900/3414] Elapsed 8m 36s (remain 1m 31s) Loss: 0.0004(0.0133) Grad: 4379.5605  LR: 0.00000189  \n","Epoch: [4][3000/3414] Elapsed 8m 54s (remain 1m 13s) Loss: 0.0085(0.0133) Grad: 27021.1094  LR: 0.00000180  \n","Epoch: [4][3100/3414] Elapsed 9m 12s (remain 0m 55s) Loss: 0.0095(0.0132) Grad: 33294.8633  LR: 0.00000171  \n","Epoch: [4][3200/3414] Elapsed 9m 30s (remain 0m 37s) Loss: 0.0032(0.0132) Grad: 16755.3691  LR: 0.00000162  \n","Epoch: [4][3300/3414] Elapsed 9m 48s (remain 0m 20s) Loss: 0.0318(0.0132) Grad: 139201.4375  LR: 0.00000154  \n","Epoch: [4][3400/3414] Elapsed 10m 6s (remain 0m 2s) Loss: 0.0056(0.0131) Grad: 26739.6328  LR: 0.00000145  \n","Epoch: [4][3413/3414] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0133(0.0131) Grad: 31358.5645  LR: 0.00000144  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 28s) Loss: 0.0973(0.0973) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.0946(0.1034) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0249(0.1042) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0131  avg_val_loss: 0.1044  time: 631s\n","Epoch 4 - Score: 0.7752\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1822(0.1044) \n","Epoch: [5][0/3414] Elapsed 0m 0s (remain 27m 3s) Loss: 0.0049(0.0049) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3414] Elapsed 0m 18s (remain 9m 56s) Loss: 0.0137(0.0093) Grad: 39975.8672  LR: 0.00000136  \n","Epoch: [5][200/3414] Elapsed 0m 35s (remain 9m 33s) Loss: 0.0268(0.0104) Grad: 33498.1758  LR: 0.00000128  \n","Epoch: [5][300/3414] Elapsed 0m 53s (remain 9m 14s) Loss: 0.0285(0.0108) Grad: 36182.3086  LR: 0.00000121  \n","Epoch: [5][400/3414] Elapsed 1m 11s (remain 8m 56s) Loss: 0.0023(0.0110) Grad: 15189.0449  LR: 0.00000113  \n","Epoch: [5][500/3414] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0019(0.0110) Grad: 11210.8291  LR: 0.00000106  \n","Epoch: [5][600/3414] Elapsed 1m 46s (remain 8m 19s) Loss: 0.0021(0.0111) Grad: 14602.5273  LR: 0.00000099  \n","Epoch: [5][700/3414] Elapsed 2m 4s (remain 8m 2s) Loss: 0.0051(0.0109) Grad: 17064.4453  LR: 0.00000092  \n","Epoch: [5][800/3414] Elapsed 2m 22s (remain 7m 44s) Loss: 0.0073(0.0110) Grad: 29412.5801  LR: 0.00000086  \n","Epoch: [5][900/3414] Elapsed 2m 40s (remain 7m 26s) Loss: 0.0134(0.0110) Grad: 42090.1484  LR: 0.00000079  \n","Epoch: [5][1000/3414] Elapsed 2m 57s (remain 7m 8s) Loss: 0.0156(0.0110) Grad: 67441.9766  LR: 0.00000073  \n","Epoch: [5][1100/3414] Elapsed 3m 15s (remain 6m 51s) Loss: 0.0148(0.0110) Grad: 38054.1680  LR: 0.00000067  \n","Epoch: [5][1200/3414] Elapsed 3m 33s (remain 6m 33s) Loss: 0.0060(0.0109) Grad: 70292.1875  LR: 0.00000062  \n","Epoch: [5][1300/3414] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0023(0.0110) Grad: 28736.9727  LR: 0.00000056  \n","Epoch: [5][1400/3414] Elapsed 4m 8s (remain 5m 57s) Loss: 0.0054(0.0111) Grad: 37877.4570  LR: 0.00000051  \n","Epoch: [5][1500/3414] Elapsed 4m 26s (remain 5m 39s) Loss: 0.0021(0.0111) Grad: 12608.2998  LR: 0.00000046  \n","Epoch: [5][1600/3414] Elapsed 4m 44s (remain 5m 21s) Loss: 0.0115(0.0111) Grad: 15744.8438  LR: 0.00000042  \n","Epoch: [5][1700/3414] Elapsed 5m 2s (remain 5m 4s) Loss: 0.0107(0.0111) Grad: 28425.1523  LR: 0.00000037  \n","Epoch: [5][1800/3414] Elapsed 5m 19s (remain 4m 46s) Loss: 0.0115(0.0111) Grad: 26971.1406  LR: 0.00000033  \n","Epoch: [5][1900/3414] Elapsed 5m 37s (remain 4m 28s) Loss: 0.0102(0.0111) Grad: 29244.1504  LR: 0.00000029  \n","Epoch: [5][2000/3414] Elapsed 5m 55s (remain 4m 11s) Loss: 0.0069(0.0111) Grad: 17942.4922  LR: 0.00000025  \n","Epoch: [5][2100/3414] Elapsed 6m 13s (remain 3m 53s) Loss: 0.0075(0.0111) Grad: 25803.9746  LR: 0.00000022  \n","Epoch: [5][2200/3414] Elapsed 6m 32s (remain 3m 36s) Loss: 0.0047(0.0111) Grad: 22392.4551  LR: 0.00000019  \n","Epoch: [5][2300/3414] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0125(0.0110) Grad: 34522.8750  LR: 0.00000016  \n","Epoch: [5][2400/3414] Elapsed 7m 8s (remain 3m 0s) Loss: 0.0037(0.0110) Grad: 24638.8184  LR: 0.00000013  \n","Epoch: [5][2500/3414] Elapsed 7m 26s (remain 2m 43s) Loss: 0.0108(0.0110) Grad: 107390.0625  LR: 0.00000011  \n","Epoch: [5][2600/3414] Elapsed 7m 45s (remain 2m 25s) Loss: 0.0033(0.0110) Grad: 13369.0371  LR: 0.00000008  \n","Epoch: [5][2700/3414] Elapsed 8m 3s (remain 2m 7s) Loss: 0.0096(0.0110) Grad: 36890.8516  LR: 0.00000007  \n","Epoch: [5][2800/3414] Elapsed 8m 21s (remain 1m 49s) Loss: 0.0082(0.0111) Grad: 14805.2725  LR: 0.00000005  \n","Epoch: [5][2900/3414] Elapsed 8m 39s (remain 1m 31s) Loss: 0.0280(0.0111) Grad: 50202.7773  LR: 0.00000003  \n","Epoch: [5][3000/3414] Elapsed 8m 57s (remain 1m 13s) Loss: 0.0075(0.0111) Grad: 26116.6680  LR: 0.00000002  \n","Epoch: [5][3100/3414] Elapsed 9m 15s (remain 0m 56s) Loss: 0.0096(0.0111) Grad: 33429.4609  LR: 0.00000001  \n","Epoch: [5][3200/3414] Elapsed 9m 33s (remain 0m 38s) Loss: 0.0093(0.0111) Grad: 18314.3496  LR: 0.00000001  \n","Epoch: [5][3300/3414] Elapsed 9m 51s (remain 0m 20s) Loss: 0.0225(0.0111) Grad: 60985.2305  LR: 0.00000000  \n","Epoch: [5][3400/3414] Elapsed 10m 8s (remain 0m 2s) Loss: 0.0114(0.0111) Grad: 51626.5195  LR: 0.00000000  \n","Epoch: [5][3413/3414] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0133(0.0111) Grad: 32283.0918  LR: 0.00000000  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0975(0.0975) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.0951(0.1044) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0254(0.1052) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0111  avg_val_loss: 0.1053  time: 634s\n","Epoch 5 - Score: 0.7777\n","Epoch 5 - Save Best Score: 0.7777 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1829(0.1053) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 9 result ==========\n","Score: 0.7777\n","========== fold: 10 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3414] Elapsed 0m 0s (remain 25m 19s) Loss: 0.1909(0.1909) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3414] Elapsed 0m 18s (remain 10m 9s) Loss: 0.0828(0.0844) Grad: 10730.9854  LR: 0.00001500  \n","Epoch: [1][200/3414] Elapsed 0m 36s (remain 9m 40s) Loss: 0.0311(0.0800) Grad: 13010.0352  LR: 0.00001500  \n","Epoch: [1][300/3414] Elapsed 0m 54s (remain 9m 18s) Loss: 0.0896(0.0736) Grad: 4731.2095  LR: 0.00001499  \n","Epoch: [1][400/3414] Elapsed 1m 11s (remain 8m 58s) Loss: 0.0347(0.0692) Grad: 1600.4315  LR: 0.00001498  \n","Epoch: [1][500/3414] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0708(0.0654) Grad: 3029.2424  LR: 0.00001497  \n","Epoch: [1][600/3414] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0480(0.0627) Grad: 4524.9502  LR: 0.00001496  \n","Epoch: [1][700/3414] Elapsed 2m 4s (remain 8m 2s) Loss: 0.0269(0.0599) Grad: 11975.2822  LR: 0.00001495  \n","Epoch: [1][800/3414] Elapsed 2m 22s (remain 7m 45s) Loss: 0.0356(0.0581) Grad: 3915.3967  LR: 0.00001493  \n","Epoch: [1][900/3414] Elapsed 2m 40s (remain 7m 27s) Loss: 0.0184(0.0559) Grad: 5759.7861  LR: 0.00001491  \n","Epoch: [1][1000/3414] Elapsed 2m 58s (remain 7m 9s) Loss: 0.0504(0.0542) Grad: 10585.5596  LR: 0.00001488  \n","Epoch: [1][1100/3414] Elapsed 3m 15s (remain 6m 51s) Loss: 0.0380(0.0530) Grad: 10924.2148  LR: 0.00001486  \n","Epoch: [1][1200/3414] Elapsed 3m 33s (remain 6m 33s) Loss: 0.0299(0.0517) Grad: 6157.2100  LR: 0.00001483  \n","Epoch: [1][1300/3414] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0465(0.0502) Grad: 4608.7256  LR: 0.00001480  \n","Epoch: [1][1400/3414] Elapsed 4m 9s (remain 5m 57s) Loss: 0.0210(0.0493) Grad: 4694.5435  LR: 0.00001477  \n","Epoch: [1][1500/3414] Elapsed 4m 26s (remain 5m 39s) Loss: 0.0612(0.0488) Grad: 9822.9482  LR: 0.00001473  \n","Epoch: [1][1600/3414] Elapsed 4m 44s (remain 5m 21s) Loss: 0.0061(0.0480) Grad: 3214.9561  LR: 0.00001469  \n","Epoch: [1][1700/3414] Elapsed 5m 1s (remain 5m 4s) Loss: 0.0191(0.0472) Grad: 9675.8066  LR: 0.00001465  \n","Epoch: [1][1800/3414] Elapsed 5m 19s (remain 4m 46s) Loss: 0.0210(0.0467) Grad: 6613.0220  LR: 0.00001461  \n","Epoch: [1][1900/3414] Elapsed 5m 37s (remain 4m 28s) Loss: 0.1082(0.0461) Grad: 10468.6133  LR: 0.00001457  \n","Epoch: [1][2000/3414] Elapsed 5m 55s (remain 4m 11s) Loss: 0.0360(0.0455) Grad: 9366.1416  LR: 0.00001452  \n","Epoch: [1][2100/3414] Elapsed 6m 13s (remain 3m 53s) Loss: 0.0194(0.0449) Grad: 8190.3057  LR: 0.00001447  \n","Epoch: [1][2200/3414] Elapsed 6m 31s (remain 3m 35s) Loss: 0.0451(0.0441) Grad: 14775.4609  LR: 0.00001442  \n","Epoch: [1][2300/3414] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0068(0.0435) Grad: 8680.6885  LR: 0.00001436  \n","Epoch: [1][2400/3414] Elapsed 7m 7s (remain 3m 0s) Loss: 0.0401(0.0428) Grad: 15247.8848  LR: 0.00001430  \n","Epoch: [1][2500/3414] Elapsed 7m 26s (remain 2m 42s) Loss: 0.0121(0.0423) Grad: 5283.6875  LR: 0.00001425  \n","Epoch: [1][2600/3414] Elapsed 7m 44s (remain 2m 25s) Loss: 0.0104(0.0418) Grad: 9440.9980  LR: 0.00001418  \n","Epoch: [1][2700/3414] Elapsed 8m 2s (remain 2m 7s) Loss: 0.0201(0.0413) Grad: 10615.7686  LR: 0.00001412  \n","Epoch: [1][2800/3414] Elapsed 8m 20s (remain 1m 49s) Loss: 0.0325(0.0408) Grad: 16435.8379  LR: 0.00001405  \n","Epoch: [1][2900/3414] Elapsed 8m 38s (remain 1m 31s) Loss: 0.0113(0.0404) Grad: 3945.6152  LR: 0.00001399  \n","Epoch: [1][3000/3414] Elapsed 8m 55s (remain 1m 13s) Loss: 0.0677(0.0400) Grad: 9801.9600  LR: 0.00001391  \n","Epoch: [1][3100/3414] Elapsed 9m 13s (remain 0m 55s) Loss: 0.0560(0.0396) Grad: 41268.3555  LR: 0.00001384  \n","Epoch: [1][3200/3414] Elapsed 9m 31s (remain 0m 38s) Loss: 0.0274(0.0394) Grad: 11857.1260  LR: 0.00001377  \n","Epoch: [1][3300/3414] Elapsed 9m 48s (remain 0m 20s) Loss: 0.0774(0.0393) Grad: 12598.0361  LR: 0.00001369  \n","Epoch: [1][3400/3414] Elapsed 10m 6s (remain 0m 2s) Loss: 0.0495(0.0391) Grad: 11811.7090  LR: 0.00001361  \n","Epoch: [1][3413/3414] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0556(0.0391) Grad: 12364.7354  LR: 0.00001360  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1056(0.1056) \n","EVAL: [100/233] Elapsed 0m 9s (remain 0m 13s) Loss: 0.1142(0.1052) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.1506(0.1085) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0391  avg_val_loss: 0.1087  time: 632s\n","Epoch 1 - Score: 0.7662\n","Epoch 1 - Save Best Score: 0.7662 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0600(0.1087) \n","Epoch: [2][0/3414] Elapsed 0m 0s (remain 27m 14s) Loss: 0.0147(0.0147) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3414] Elapsed 0m 18s (remain 10m 4s) Loss: 0.0386(0.0257) Grad: 27792.6797  LR: 0.00001352  \n","Epoch: [2][200/3414] Elapsed 0m 36s (remain 9m 44s) Loss: 0.0234(0.0256) Grad: 15086.0166  LR: 0.00001343  \n","Epoch: [2][300/3414] Elapsed 0m 54s (remain 9m 21s) Loss: 0.0205(0.0261) Grad: 21983.2852  LR: 0.00001335  \n","Epoch: [2][400/3414] Elapsed 1m 11s (remain 9m 0s) Loss: 0.0094(0.0256) Grad: 4812.2451  LR: 0.00001326  \n","Epoch: [2][500/3414] Elapsed 1m 29s (remain 8m 41s) Loss: 0.0153(0.0255) Grad: 9368.6162  LR: 0.00001317  \n","Epoch: [2][600/3414] Elapsed 1m 47s (remain 8m 23s) Loss: 0.0858(0.0254) Grad: 13652.2041  LR: 0.00001308  \n","Epoch: [2][700/3414] Elapsed 2m 5s (remain 8m 5s) Loss: 0.0133(0.0250) Grad: 11607.4404  LR: 0.00001299  \n","Epoch: [2][800/3414] Elapsed 2m 23s (remain 7m 46s) Loss: 0.0652(0.0249) Grad: 17352.7852  LR: 0.00001289  \n","Epoch: [2][900/3414] Elapsed 2m 40s (remain 7m 28s) Loss: 0.0134(0.0245) Grad: 10313.8164  LR: 0.00001279  \n","Epoch: [2][1000/3414] Elapsed 2m 58s (remain 7m 10s) Loss: 0.0348(0.0245) Grad: 18009.5645  LR: 0.00001269  \n","Epoch: [2][1100/3414] Elapsed 3m 16s (remain 6m 52s) Loss: 0.0358(0.0246) Grad: 18745.1406  LR: 0.00001259  \n","Epoch: [2][1200/3414] Elapsed 3m 34s (remain 6m 34s) Loss: 0.0092(0.0243) Grad: 6793.6772  LR: 0.00001249  \n","Epoch: [2][1300/3414] Elapsed 3m 51s (remain 6m 16s) Loss: 0.0440(0.0243) Grad: 22026.7246  LR: 0.00001239  \n","Epoch: [2][1400/3414] Elapsed 4m 9s (remain 5m 58s) Loss: 0.0191(0.0240) Grad: 6303.3384  LR: 0.00001228  \n","Epoch: [2][1500/3414] Elapsed 4m 27s (remain 5m 40s) Loss: 0.0196(0.0238) Grad: 19643.3496  LR: 0.00001217  \n","Epoch: [2][1600/3414] Elapsed 4m 45s (remain 5m 22s) Loss: 0.0233(0.0237) Grad: 5784.2681  LR: 0.00001207  \n","Epoch: [2][1700/3414] Elapsed 5m 2s (remain 5m 4s) Loss: 0.0134(0.0237) Grad: 8391.3516  LR: 0.00001195  \n","Epoch: [2][1800/3414] Elapsed 5m 20s (remain 4m 47s) Loss: 0.0049(0.0236) Grad: 3566.3994  LR: 0.00001184  \n","Epoch: [2][1900/3414] Elapsed 5m 38s (remain 4m 29s) Loss: 0.0573(0.0234) Grad: 45797.7422  LR: 0.00001173  \n","Epoch: [2][2000/3414] Elapsed 5m 57s (remain 4m 12s) Loss: 0.0396(0.0235) Grad: 14213.8740  LR: 0.00001161  \n","Epoch: [2][2100/3414] Elapsed 6m 15s (remain 3m 54s) Loss: 0.0265(0.0236) Grad: 9383.6270  LR: 0.00001150  \n","Epoch: [2][2200/3414] Elapsed 6m 33s (remain 3m 36s) Loss: 0.0087(0.0236) Grad: 1231.5215  LR: 0.00001138  \n","Epoch: [2][2300/3414] Elapsed 6m 51s (remain 3m 18s) Loss: 0.0188(0.0237) Grad: 11833.2402  LR: 0.00001126  \n","Epoch: [2][2400/3414] Elapsed 7m 9s (remain 3m 1s) Loss: 0.0307(0.0238) Grad: 22227.8281  LR: 0.00001114  \n","Epoch: [2][2500/3414] Elapsed 7m 27s (remain 2m 43s) Loss: 0.0338(0.0240) Grad: 10512.3037  LR: 0.00001102  \n","Epoch: [2][2600/3414] Elapsed 7m 45s (remain 2m 25s) Loss: 0.0219(0.0240) Grad: 9413.4814  LR: 0.00001090  \n","Epoch: [2][2700/3414] Elapsed 8m 3s (remain 2m 7s) Loss: 0.0096(0.0241) Grad: 2086.8835  LR: 0.00001077  \n","Epoch: [2][2800/3414] Elapsed 8m 21s (remain 1m 49s) Loss: 0.0406(0.0242) Grad: 11147.9629  LR: 0.00001065  \n","Epoch: [2][2900/3414] Elapsed 8m 39s (remain 1m 31s) Loss: 0.0238(0.0243) Grad: 4875.8618  LR: 0.00001052  \n","Epoch: [2][3000/3414] Elapsed 8m 57s (remain 1m 13s) Loss: 0.0439(0.0243) Grad: 13924.6191  LR: 0.00001039  \n","Epoch: [2][3100/3414] Elapsed 9m 14s (remain 0m 56s) Loss: 0.0113(0.0243) Grad: 5095.9834  LR: 0.00001026  \n","Epoch: [2][3200/3414] Elapsed 9m 32s (remain 0m 38s) Loss: 0.0090(0.0244) Grad: 3317.9775  LR: 0.00001014  \n","Epoch: [2][3300/3414] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0508(0.0245) Grad: 2719.2871  LR: 0.00001001  \n","Epoch: [2][3400/3414] Elapsed 10m 8s (remain 0m 2s) Loss: 0.0126(0.0244) Grad: 2529.7122  LR: 0.00000987  \n","Epoch: [2][3413/3414] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0333(0.0244) Grad: 9425.5293  LR: 0.00000986  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 23s) Loss: 0.1032(0.1032) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1334(0.1021) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.1505(0.1060) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0244  avg_val_loss: 0.1060  time: 633s\n","Epoch 2 - Score: 0.7725\n","Epoch 2 - Save Best Score: 0.7725 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0583(0.1060) \n","Epoch: [3][0/3414] Elapsed 0m 0s (remain 27m 21s) Loss: 0.0354(0.0354) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3414] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0269(0.0195) Grad: 16138.7822  LR: 0.00000972  \n","Epoch: [3][200/3414] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0077(0.0187) Grad: 8398.1738  LR: 0.00000959  \n","Epoch: [3][300/3414] Elapsed 0m 54s (remain 9m 21s) Loss: 0.0090(0.0188) Grad: 5288.5869  LR: 0.00000946  \n","Epoch: [3][400/3414] Elapsed 1m 11s (remain 9m 0s) Loss: 0.0116(0.0184) Grad: 12516.4980  LR: 0.00000932  \n","Epoch: [3][500/3414] Elapsed 1m 29s (remain 8m 41s) Loss: 0.0082(0.0185) Grad: 3319.2085  LR: 0.00000919  \n","Epoch: [3][600/3414] Elapsed 1m 47s (remain 8m 22s) Loss: 0.0171(0.0180) Grad: 10808.2891  LR: 0.00000905  \n","Epoch: [3][700/3414] Elapsed 2m 4s (remain 8m 3s) Loss: 0.0336(0.0183) Grad: 13549.7119  LR: 0.00000892  \n","Epoch: [3][800/3414] Elapsed 2m 22s (remain 7m 45s) Loss: 0.0311(0.0181) Grad: 26392.3906  LR: 0.00000878  \n","Epoch: [3][900/3414] Elapsed 2m 40s (remain 7m 27s) Loss: 0.0072(0.0181) Grad: 5801.7861  LR: 0.00000865  \n","Epoch: [3][1000/3414] Elapsed 2m 58s (remain 7m 9s) Loss: 0.0393(0.0181) Grad: 12569.9053  LR: 0.00000851  \n","Epoch: [3][1100/3414] Elapsed 3m 15s (remain 6m 51s) Loss: 0.0049(0.0180) Grad: 8042.4697  LR: 0.00000837  \n","Epoch: [3][1200/3414] Elapsed 3m 33s (remain 6m 33s) Loss: 0.0060(0.0180) Grad: 7313.8228  LR: 0.00000823  \n","Epoch: [3][1300/3414] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0116(0.0179) Grad: 8016.0576  LR: 0.00000810  \n","Epoch: [3][1400/3414] Elapsed 4m 8s (remain 5m 57s) Loss: 0.0112(0.0178) Grad: 13046.6426  LR: 0.00000796  \n","Epoch: [3][1500/3414] Elapsed 4m 26s (remain 5m 39s) Loss: 0.0099(0.0177) Grad: 2864.1426  LR: 0.00000782  \n","Epoch: [3][1600/3414] Elapsed 4m 43s (remain 5m 21s) Loss: 0.0033(0.0177) Grad: 2685.6653  LR: 0.00000768  \n","Epoch: [3][1700/3414] Elapsed 5m 1s (remain 5m 3s) Loss: 0.0084(0.0176) Grad: 2715.7822  LR: 0.00000754  \n","Epoch: [3][1800/3414] Elapsed 5m 19s (remain 4m 46s) Loss: 0.0217(0.0175) Grad: 31265.9199  LR: 0.00000741  \n","Epoch: [3][1900/3414] Elapsed 5m 37s (remain 4m 28s) Loss: 0.0117(0.0175) Grad: 14644.0244  LR: 0.00000727  \n","Epoch: [3][2000/3414] Elapsed 5m 55s (remain 4m 11s) Loss: 0.0091(0.0174) Grad: 6969.7969  LR: 0.00000713  \n","Epoch: [3][2100/3414] Elapsed 6m 13s (remain 3m 53s) Loss: 0.0093(0.0174) Grad: 8747.6162  LR: 0.00000699  \n","Epoch: [3][2200/3414] Elapsed 6m 31s (remain 3m 36s) Loss: 0.0223(0.0174) Grad: 18388.7988  LR: 0.00000685  \n","Epoch: [3][2300/3414] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0209(0.0172) Grad: 20923.3965  LR: 0.00000671  \n","Epoch: [3][2400/3414] Elapsed 7m 8s (remain 3m 0s) Loss: 0.0383(0.0172) Grad: 16820.9961  LR: 0.00000658  \n","Epoch: [3][2500/3414] Elapsed 7m 26s (remain 2m 42s) Loss: 0.0166(0.0171) Grad: 3300.2954  LR: 0.00000644  \n","Epoch: [3][2600/3414] Elapsed 7m 44s (remain 2m 25s) Loss: 0.0401(0.0171) Grad: 14069.0117  LR: 0.00000630  \n","Epoch: [3][2700/3414] Elapsed 8m 2s (remain 2m 7s) Loss: 0.0108(0.0171) Grad: 9665.1045  LR: 0.00000617  \n","Epoch: [3][2800/3414] Elapsed 8m 20s (remain 1m 49s) Loss: 0.0126(0.0171) Grad: 8187.4736  LR: 0.00000603  \n","Epoch: [3][2900/3414] Elapsed 8m 38s (remain 1m 31s) Loss: 0.0235(0.0171) Grad: 13539.9131  LR: 0.00000589  \n","Epoch: [3][3000/3414] Elapsed 8m 55s (remain 1m 13s) Loss: 0.0086(0.0170) Grad: 3791.6448  LR: 0.00000576  \n","Epoch: [3][3100/3414] Elapsed 9m 13s (remain 0m 55s) Loss: 0.0147(0.0170) Grad: 7469.5815  LR: 0.00000563  \n","Epoch: [3][3200/3414] Elapsed 9m 31s (remain 0m 38s) Loss: 0.0219(0.0169) Grad: 10391.8604  LR: 0.00000549  \n","Epoch: [3][3300/3414] Elapsed 9m 48s (remain 0m 20s) Loss: 0.0213(0.0169) Grad: 10764.2891  LR: 0.00000536  \n","Epoch: [3][3400/3414] Elapsed 10m 6s (remain 0m 2s) Loss: 0.0097(0.0168) Grad: 4407.7158  LR: 0.00000523  \n","Epoch: [3][3413/3414] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0221(0.0168) Grad: 8115.3306  LR: 0.00000521  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 24s) Loss: 0.1006(0.1006) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1307(0.1037) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.1480(0.1072) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0168  avg_val_loss: 0.1074  time: 632s\n","Epoch 3 - Score: 0.7928\n","Epoch 3 - Save Best Score: 0.7928 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0578(0.1074) \n","Epoch: [4][0/3414] Elapsed 0m 0s (remain 27m 9s) Loss: 0.0549(0.0549) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3414] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0084(0.0126) Grad: 13056.1172  LR: 0.00000508  \n","Epoch: [4][200/3414] Elapsed 0m 36s (remain 9m 42s) Loss: 0.0061(0.0129) Grad: 3134.4553  LR: 0.00000495  \n","Epoch: [4][300/3414] Elapsed 0m 54s (remain 9m 20s) Loss: 0.0061(0.0130) Grad: 10216.4102  LR: 0.00000482  \n","Epoch: [4][400/3414] Elapsed 1m 11s (remain 8m 59s) Loss: 0.0361(0.0128) Grad: 20257.6113  LR: 0.00000469  \n","Epoch: [4][500/3414] Elapsed 1m 29s (remain 8m 40s) Loss: 0.0131(0.0130) Grad: 5004.7832  LR: 0.00000456  \n","Epoch: [4][600/3414] Elapsed 1m 47s (remain 8m 22s) Loss: 0.0580(0.0131) Grad: 19957.5957  LR: 0.00000443  \n","Epoch: [4][700/3414] Elapsed 2m 4s (remain 8m 3s) Loss: 0.0013(0.0128) Grad: 2336.1204  LR: 0.00000431  \n","Epoch: [4][800/3414] Elapsed 2m 22s (remain 7m 45s) Loss: 0.0219(0.0129) Grad: 9227.0967  LR: 0.00000418  \n","Epoch: [4][900/3414] Elapsed 2m 40s (remain 7m 27s) Loss: 0.0446(0.0129) Grad: 39314.7070  LR: 0.00000406  \n","Epoch: [4][1000/3414] Elapsed 2m 58s (remain 7m 9s) Loss: 0.0139(0.0129) Grad: 7475.9814  LR: 0.00000394  \n","Epoch: [4][1100/3414] Elapsed 3m 15s (remain 6m 51s) Loss: 0.0110(0.0129) Grad: 10476.0332  LR: 0.00000382  \n","Epoch: [4][1200/3414] Elapsed 3m 33s (remain 6m 33s) Loss: 0.0228(0.0128) Grad: 10211.4609  LR: 0.00000370  \n","Epoch: [4][1300/3414] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0128(0.0129) Grad: 7361.6411  LR: 0.00000358  \n","Epoch: [4][1400/3414] Elapsed 4m 8s (remain 5m 57s) Loss: 0.0203(0.0130) Grad: 12510.6807  LR: 0.00000346  \n","Epoch: [4][1500/3414] Elapsed 4m 26s (remain 5m 39s) Loss: 0.0085(0.0130) Grad: 2066.9539  LR: 0.00000334  \n","Epoch: [4][1600/3414] Elapsed 4m 44s (remain 5m 21s) Loss: 0.0101(0.0131) Grad: 17778.8770  LR: 0.00000323  \n","Epoch: [4][1700/3414] Elapsed 5m 1s (remain 5m 3s) Loss: 0.0072(0.0131) Grad: 10199.5049  LR: 0.00000312  \n","Epoch: [4][1800/3414] Elapsed 5m 19s (remain 4m 46s) Loss: 0.0154(0.0130) Grad: 6494.8428  LR: 0.00000300  \n","Epoch: [4][1900/3414] Elapsed 5m 37s (remain 4m 28s) Loss: 0.0496(0.0129) Grad: 34760.2109  LR: 0.00000289  \n","Epoch: [4][2000/3414] Elapsed 5m 55s (remain 4m 11s) Loss: 0.0074(0.0129) Grad: 14475.4512  LR: 0.00000279  \n","Epoch: [4][2100/3414] Elapsed 6m 14s (remain 3m 53s) Loss: 0.0079(0.0128) Grad: 6317.7954  LR: 0.00000268  \n","Epoch: [4][2200/3414] Elapsed 6m 32s (remain 3m 36s) Loss: 0.0171(0.0128) Grad: 41316.2773  LR: 0.00000257  \n","Epoch: [4][2300/3414] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0284(0.0128) Grad: 25327.7578  LR: 0.00000247  \n","Epoch: [4][2400/3414] Elapsed 7m 8s (remain 3m 0s) Loss: 0.0088(0.0128) Grad: 7008.4995  LR: 0.00000237  \n","Epoch: [4][2500/3414] Elapsed 7m 26s (remain 2m 43s) Loss: 0.0056(0.0127) Grad: 5416.4717  LR: 0.00000227  \n","Epoch: [4][2600/3414] Elapsed 7m 44s (remain 2m 25s) Loss: 0.0055(0.0128) Grad: 10584.1875  LR: 0.00000217  \n","Epoch: [4][2700/3414] Elapsed 8m 2s (remain 2m 7s) Loss: 0.0016(0.0128) Grad: 3450.3096  LR: 0.00000207  \n","Epoch: [4][2800/3414] Elapsed 8m 21s (remain 1m 49s) Loss: 0.0041(0.0129) Grad: 6989.5347  LR: 0.00000198  \n","Epoch: [4][2900/3414] Elapsed 8m 38s (remain 1m 31s) Loss: 0.0060(0.0129) Grad: 5869.0557  LR: 0.00000189  \n","Epoch: [4][3000/3414] Elapsed 8m 56s (remain 1m 13s) Loss: 0.0198(0.0129) Grad: 14924.5293  LR: 0.00000180  \n","Epoch: [4][3100/3414] Elapsed 9m 14s (remain 0m 55s) Loss: 0.0124(0.0129) Grad: 3151.5889  LR: 0.00000171  \n","Epoch: [4][3200/3414] Elapsed 9m 32s (remain 0m 38s) Loss: 0.0058(0.0129) Grad: 7992.1274  LR: 0.00000162  \n","Epoch: [4][3300/3414] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0085(0.0129) Grad: 5792.9438  LR: 0.00000153  \n","Epoch: [4][3400/3414] Elapsed 10m 7s (remain 0m 2s) Loss: 0.0010(0.0128) Grad: 3771.1594  LR: 0.00000145  \n","Epoch: [4][3413/3414] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0032(0.0128) Grad: 4823.4434  LR: 0.00000144  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 21s) Loss: 0.1010(0.1010) \n","EVAL: [100/233] Elapsed 0m 9s (remain 0m 13s) Loss: 0.1230(0.1020) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.1458(0.1055) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0128  avg_val_loss: 0.1057  time: 633s\n","Epoch 4 - Score: 0.7947\n","Epoch 4 - Save Best Score: 0.7947 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0553(0.1057) \n","Epoch: [5][0/3414] Elapsed 0m 0s (remain 27m 33s) Loss: 0.0064(0.0064) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3414] Elapsed 0m 18s (remain 10m 16s) Loss: 0.0101(0.0097) Grad: 9729.1084  LR: 0.00000136  \n","Epoch: [5][200/3414] Elapsed 0m 36s (remain 9m 50s) Loss: 0.0372(0.0101) Grad: 21525.4375  LR: 0.00000128  \n","Epoch: [5][300/3414] Elapsed 0m 54s (remain 9m 26s) Loss: 0.0279(0.0103) Grad: 10535.2520  LR: 0.00000121  \n","Epoch: [5][400/3414] Elapsed 1m 12s (remain 9m 3s) Loss: 0.0043(0.0103) Grad: 2867.9434  LR: 0.00000113  \n","Epoch: [5][500/3414] Elapsed 1m 30s (remain 8m 44s) Loss: 0.0321(0.0102) Grad: 24031.4668  LR: 0.00000106  \n","Epoch: [5][600/3414] Elapsed 1m 47s (remain 8m 24s) Loss: 0.0134(0.0101) Grad: 4500.1191  LR: 0.00000099  \n","Epoch: [5][700/3414] Elapsed 2m 5s (remain 8m 5s) Loss: 0.0105(0.0101) Grad: 17213.4355  LR: 0.00000092  \n","Epoch: [5][800/3414] Elapsed 2m 23s (remain 7m 47s) Loss: 0.0102(0.0102) Grad: 10309.2764  LR: 0.00000086  \n","Epoch: [5][900/3414] Elapsed 2m 41s (remain 7m 29s) Loss: 0.0096(0.0102) Grad: 5931.4111  LR: 0.00000079  \n","Epoch: [5][1000/3414] Elapsed 2m 58s (remain 7m 10s) Loss: 0.0168(0.0102) Grad: 9320.2871  LR: 0.00000073  \n","Epoch: [5][1100/3414] Elapsed 3m 16s (remain 6m 52s) Loss: 0.0283(0.0102) Grad: 4367.5566  LR: 0.00000067  \n","Epoch: [5][1200/3414] Elapsed 3m 34s (remain 6m 34s) Loss: 0.0093(0.0103) Grad: 14417.1602  LR: 0.00000062  \n","Epoch: [5][1300/3414] Elapsed 3m 51s (remain 6m 16s) Loss: 0.0369(0.0103) Grad: 4615.9248  LR: 0.00000056  \n","Epoch: [5][1400/3414] Elapsed 4m 9s (remain 5m 58s) Loss: 0.0020(0.0103) Grad: 4461.4341  LR: 0.00000051  \n","Epoch: [5][1500/3414] Elapsed 4m 27s (remain 5m 40s) Loss: 0.0105(0.0103) Grad: 5650.0835  LR: 0.00000046  \n","Epoch: [5][1600/3414] Elapsed 4m 44s (remain 5m 22s) Loss: 0.0068(0.0103) Grad: 10846.2998  LR: 0.00000042  \n","Epoch: [5][1700/3414] Elapsed 5m 2s (remain 5m 4s) Loss: 0.0179(0.0103) Grad: 24028.3945  LR: 0.00000037  \n","Epoch: [5][1800/3414] Elapsed 5m 20s (remain 4m 46s) Loss: 0.0043(0.0103) Grad: 2331.5981  LR: 0.00000033  \n","Epoch: [5][1900/3414] Elapsed 5m 38s (remain 4m 29s) Loss: 0.0038(0.0103) Grad: 2275.1973  LR: 0.00000029  \n","Epoch: [5][2000/3414] Elapsed 5m 56s (remain 4m 11s) Loss: 0.0012(0.0103) Grad: 3289.5549  LR: 0.00000025  \n","Epoch: [5][2100/3414] Elapsed 6m 14s (remain 3m 54s) Loss: 0.0072(0.0103) Grad: 26216.4609  LR: 0.00000022  \n","Epoch: [5][2200/3414] Elapsed 6m 32s (remain 3m 36s) Loss: 0.0083(0.0103) Grad: 17711.0332  LR: 0.00000019  \n","Epoch: [5][2300/3414] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0147(0.0103) Grad: 27532.2676  LR: 0.00000016  \n","Epoch: [5][2400/3414] Elapsed 7m 8s (remain 3m 0s) Loss: 0.0030(0.0103) Grad: 8229.4297  LR: 0.00000013  \n","Epoch: [5][2500/3414] Elapsed 7m 27s (remain 2m 43s) Loss: 0.0048(0.0104) Grad: 9807.3984  LR: 0.00000011  \n","Epoch: [5][2600/3414] Elapsed 7m 45s (remain 2m 25s) Loss: 0.0078(0.0104) Grad: 12428.1641  LR: 0.00000008  \n","Epoch: [5][2700/3414] Elapsed 8m 3s (remain 2m 7s) Loss: 0.0157(0.0104) Grad: 8493.9561  LR: 0.00000007  \n","Epoch: [5][2800/3414] Elapsed 8m 21s (remain 1m 49s) Loss: 0.0065(0.0104) Grad: 20321.7422  LR: 0.00000005  \n","Epoch: [5][2900/3414] Elapsed 8m 39s (remain 1m 31s) Loss: 0.0203(0.0104) Grad: 25889.3516  LR: 0.00000003  \n","Epoch: [5][3000/3414] Elapsed 8m 57s (remain 1m 13s) Loss: 0.0120(0.0104) Grad: 9346.3818  LR: 0.00000002  \n","Epoch: [5][3100/3414] Elapsed 9m 14s (remain 0m 55s) Loss: 0.0026(0.0104) Grad: 8758.0957  LR: 0.00000001  \n","Epoch: [5][3200/3414] Elapsed 9m 32s (remain 0m 38s) Loss: 0.0106(0.0103) Grad: 10739.5332  LR: 0.00000001  \n","Epoch: [5][3300/3414] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0080(0.0104) Grad: 19732.7695  LR: 0.00000000  \n","Epoch: [5][3400/3414] Elapsed 10m 8s (remain 0m 2s) Loss: 0.0290(0.0104) Grad: 36541.7852  LR: 0.00000000  \n","Epoch: [5][3413/3414] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0101(0.0104) Grad: 21481.6660  LR: 0.00000000  \n","EVAL: [0/233] Elapsed 0m 0s (remain 1m 22s) Loss: 0.1012(0.1012) \n","EVAL: [100/233] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1224(0.1018) \n","EVAL: [200/233] Elapsed 0m 19s (remain 0m 3s) Loss: 0.1460(0.1054) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0104  avg_val_loss: 0.1055  time: 633s\n","Epoch 5 - Score: 0.7947\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [232/233] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0554(0.1055) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 10 result ==========\n","Score: 0.7947\n","========== fold: 11 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3412] Elapsed 0m 0s (remain 26m 2s) Loss: 0.3870(0.3870) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3412] Elapsed 0m 18s (remain 9m 52s) Loss: 0.0543(0.1286) Grad: 10648.4609  LR: 0.00001500  \n","Epoch: [1][200/3412] Elapsed 0m 35s (remain 9m 32s) Loss: 0.0599(0.1012) Grad: 3205.5942  LR: 0.00001500  \n","Epoch: [1][300/3412] Elapsed 0m 53s (remain 9m 14s) Loss: 0.0345(0.0895) Grad: 5754.4194  LR: 0.00001499  \n","Epoch: [1][400/3412] Elapsed 1m 11s (remain 8m 55s) Loss: 0.0854(0.0816) Grad: 3226.4529  LR: 0.00001498  \n","Epoch: [1][500/3412] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0393(0.0780) Grad: 6010.8804  LR: 0.00001497  \n","Epoch: [1][600/3412] Elapsed 1m 46s (remain 8m 20s) Loss: 0.0799(0.0738) Grad: 7607.5073  LR: 0.00001496  \n","Epoch: [1][700/3412] Elapsed 2m 4s (remain 8m 2s) Loss: 0.0315(0.0701) Grad: 9570.2754  LR: 0.00001495  \n","Epoch: [1][800/3412] Elapsed 2m 22s (remain 7m 44s) Loss: 0.0478(0.0666) Grad: 3200.5747  LR: 0.00001493  \n","Epoch: [1][900/3412] Elapsed 2m 40s (remain 7m 26s) Loss: 0.0148(0.0636) Grad: 6844.1606  LR: 0.00001491  \n","Epoch: [1][1000/3412] Elapsed 2m 58s (remain 7m 9s) Loss: 0.0157(0.0613) Grad: 2003.3369  LR: 0.00001488  \n","Epoch: [1][1100/3412] Elapsed 3m 15s (remain 6m 51s) Loss: 0.0872(0.0596) Grad: 4063.0461  LR: 0.00001486  \n","Epoch: [1][1200/3412] Elapsed 3m 33s (remain 6m 33s) Loss: 0.0197(0.0577) Grad: 6824.4365  LR: 0.00001483  \n","Epoch: [1][1300/3412] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0303(0.0564) Grad: 4151.6216  LR: 0.00001480  \n","Epoch: [1][1400/3412] Elapsed 4m 9s (remain 5m 57s) Loss: 0.0388(0.0555) Grad: 10286.2422  LR: 0.00001477  \n","Epoch: [1][1500/3412] Elapsed 4m 27s (remain 5m 40s) Loss: 0.0198(0.0544) Grad: 1430.8727  LR: 0.00001473  \n","Epoch: [1][1600/3412] Elapsed 4m 44s (remain 5m 22s) Loss: 0.0289(0.0531) Grad: 3968.0530  LR: 0.00001469  \n","Epoch: [1][1700/3412] Elapsed 5m 2s (remain 5m 4s) Loss: 0.0386(0.0522) Grad: 4068.3452  LR: 0.00001465  \n","Epoch: [1][1800/3412] Elapsed 5m 20s (remain 4m 47s) Loss: 0.0545(0.0511) Grad: 9149.7314  LR: 0.00001461  \n","Epoch: [1][1900/3412] Elapsed 5m 39s (remain 4m 29s) Loss: 0.0396(0.0502) Grad: 3827.2908  LR: 0.00001457  \n","Epoch: [1][2000/3412] Elapsed 5m 57s (remain 4m 12s) Loss: 0.0554(0.0492) Grad: 4896.3188  LR: 0.00001452  \n","Epoch: [1][2100/3412] Elapsed 6m 15s (remain 3m 54s) Loss: 0.0522(0.0484) Grad: 12884.5996  LR: 0.00001447  \n","Epoch: [1][2200/3412] Elapsed 6m 33s (remain 3m 36s) Loss: 0.0319(0.0474) Grad: 10919.7432  LR: 0.00001442  \n","Epoch: [1][2300/3412] Elapsed 6m 51s (remain 3m 18s) Loss: 0.0119(0.0467) Grad: 4751.6401  LR: 0.00001436  \n","Epoch: [1][2400/3412] Elapsed 7m 9s (remain 3m 1s) Loss: 0.0305(0.0460) Grad: 10958.2969  LR: 0.00001430  \n","Epoch: [1][2500/3412] Elapsed 7m 27s (remain 2m 43s) Loss: 0.0268(0.0452) Grad: 7598.5469  LR: 0.00001424  \n","Epoch: [1][2600/3412] Elapsed 7m 46s (remain 2m 25s) Loss: 0.0259(0.0446) Grad: 5309.0952  LR: 0.00001418  \n","Epoch: [1][2700/3412] Elapsed 8m 4s (remain 2m 7s) Loss: 0.0240(0.0440) Grad: 2909.4292  LR: 0.00001412  \n","Epoch: [1][2800/3412] Elapsed 8m 21s (remain 1m 49s) Loss: 0.0266(0.0435) Grad: 10159.0283  LR: 0.00001405  \n","Epoch: [1][2900/3412] Elapsed 8m 39s (remain 1m 31s) Loss: 0.0126(0.0429) Grad: 2814.5149  LR: 0.00001398  \n","Epoch: [1][3000/3412] Elapsed 8m 57s (remain 1m 13s) Loss: 0.0231(0.0425) Grad: 2632.1189  LR: 0.00001391  \n","Epoch: [1][3100/3412] Elapsed 9m 14s (remain 0m 55s) Loss: 0.0241(0.0420) Grad: 6805.4512  LR: 0.00001384  \n","Epoch: [1][3200/3412] Elapsed 9m 32s (remain 0m 37s) Loss: 0.0301(0.0415) Grad: 9000.0293  LR: 0.00001377  \n","Epoch: [1][3300/3412] Elapsed 9m 50s (remain 0m 19s) Loss: 0.0232(0.0411) Grad: 4778.4136  LR: 0.00001369  \n","Epoch: [1][3400/3412] Elapsed 10m 7s (remain 0m 1s) Loss: 0.0110(0.0408) Grad: 3551.1187  LR: 0.00001361  \n","Epoch: [1][3411/3412] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0298(0.0407) Grad: 7509.6255  LR: 0.00001360  \n","EVAL: [0/235] Elapsed 0m 0s (remain 1m 25s) Loss: 0.0732(0.0732) \n","EVAL: [100/235] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1176(0.1069) \n","EVAL: [200/235] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0996(0.1033) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0407  avg_val_loss: 0.1023  time: 633s\n","Epoch 1 - Score: 0.7590\n","Epoch 1 - Save Best Score: 0.7590 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [234/235] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0129(0.1023) \n","Epoch: [2][0/3412] Elapsed 0m 0s (remain 27m 59s) Loss: 0.0488(0.0488) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3412] Elapsed 0m 18s (remain 10m 2s) Loss: 0.0129(0.0248) Grad: 12374.2803  LR: 0.00001352  \n","Epoch: [2][200/3412] Elapsed 0m 36s (remain 9m 41s) Loss: 0.0216(0.0237) Grad: 15266.6953  LR: 0.00001343  \n","Epoch: [2][300/3412] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0304(0.0241) Grad: 46665.2148  LR: 0.00001335  \n","Epoch: [2][400/3412] Elapsed 1m 11s (remain 8m 59s) Loss: 0.0168(0.0236) Grad: 14226.5781  LR: 0.00001326  \n","Epoch: [2][500/3412] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0177(0.0235) Grad: 3766.5308  LR: 0.00001317  \n","Epoch: [2][600/3412] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0331(0.0232) Grad: 21210.1113  LR: 0.00001308  \n","Epoch: [2][700/3412] Elapsed 2m 4s (remain 8m 3s) Loss: 0.0172(0.0232) Grad: 22812.0840  LR: 0.00001299  \n","Epoch: [2][800/3412] Elapsed 2m 22s (remain 7m 44s) Loss: 0.0039(0.0227) Grad: 9399.9443  LR: 0.00001289  \n","Epoch: [2][900/3412] Elapsed 2m 40s (remain 7m 26s) Loss: 0.0042(0.0228) Grad: 2671.1677  LR: 0.00001279  \n","Epoch: [2][1000/3412] Elapsed 2m 57s (remain 7m 8s) Loss: 0.0387(0.0229) Grad: 21071.1484  LR: 0.00001269  \n","Epoch: [2][1100/3412] Elapsed 3m 15s (remain 6m 50s) Loss: 0.0118(0.0229) Grad: 17089.9453  LR: 0.00001259  \n","Epoch: [2][1200/3412] Elapsed 3m 33s (remain 6m 32s) Loss: 0.0033(0.0227) Grad: 8998.2266  LR: 0.00001249  \n","Epoch: [2][1300/3412] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0088(0.0228) Grad: 11497.4258  LR: 0.00001239  \n","Epoch: [2][1400/3412] Elapsed 4m 8s (remain 5m 57s) Loss: 0.0237(0.0225) Grad: 12853.2793  LR: 0.00001228  \n","Epoch: [2][1500/3412] Elapsed 4m 26s (remain 5m 39s) Loss: 0.0163(0.0225) Grad: 12318.5605  LR: 0.00001217  \n","Epoch: [2][1600/3412] Elapsed 4m 45s (remain 5m 22s) Loss: 0.0431(0.0225) Grad: 20005.7969  LR: 0.00001207  \n","Epoch: [2][1700/3412] Elapsed 5m 3s (remain 5m 5s) Loss: 0.0163(0.0224) Grad: 7834.8525  LR: 0.00001195  \n","Epoch: [2][1800/3412] Elapsed 5m 21s (remain 4m 47s) Loss: 0.0077(0.0226) Grad: 14358.5127  LR: 0.00001184  \n","Epoch: [2][1900/3412] Elapsed 5m 39s (remain 4m 29s) Loss: 0.0044(0.0226) Grad: 13520.9062  LR: 0.00001173  \n","Epoch: [2][2000/3412] Elapsed 5m 57s (remain 4m 12s) Loss: 0.0117(0.0226) Grad: 18960.3594  LR: 0.00001161  \n","Epoch: [2][2100/3412] Elapsed 6m 15s (remain 3m 54s) Loss: 0.0470(0.0225) Grad: 107200.7891  LR: 0.00001150  \n","Epoch: [2][2200/3412] Elapsed 6m 33s (remain 3m 36s) Loss: 0.0114(0.0224) Grad: 15664.6191  LR: 0.00001138  \n","Epoch: [2][2300/3412] Elapsed 6m 51s (remain 3m 18s) Loss: 0.0189(0.0224) Grad: 16912.4004  LR: 0.00001126  \n","Epoch: [2][2400/3412] Elapsed 7m 9s (remain 3m 0s) Loss: 0.0165(0.0223) Grad: 10797.9922  LR: 0.00001114  \n","Epoch: [2][2500/3412] Elapsed 7m 27s (remain 2m 43s) Loss: 0.0195(0.0223) Grad: 3327.6099  LR: 0.00001102  \n","Epoch: [2][2600/3412] Elapsed 7m 45s (remain 2m 25s) Loss: 0.0117(0.0223) Grad: 22697.2305  LR: 0.00001089  \n","Epoch: [2][2700/3412] Elapsed 8m 3s (remain 2m 7s) Loss: 0.0015(0.0223) Grad: 843.8514  LR: 0.00001077  \n","Epoch: [2][2800/3412] Elapsed 8m 21s (remain 1m 49s) Loss: 0.0266(0.0222) Grad: 30292.8203  LR: 0.00001065  \n","Epoch: [2][2900/3412] Elapsed 8m 38s (remain 1m 31s) Loss: 0.0527(0.0221) Grad: 18368.6523  LR: 0.00001052  \n","Epoch: [2][3000/3412] Elapsed 8m 56s (remain 1m 13s) Loss: 0.0104(0.0221) Grad: 4821.8237  LR: 0.00001039  \n","Epoch: [2][3100/3412] Elapsed 9m 14s (remain 0m 55s) Loss: 0.0087(0.0221) Grad: 5467.6890  LR: 0.00001026  \n","Epoch: [2][3200/3412] Elapsed 9m 31s (remain 0m 37s) Loss: 0.0190(0.0220) Grad: 7623.9824  LR: 0.00001013  \n","Epoch: [2][3300/3412] Elapsed 9m 49s (remain 0m 19s) Loss: 0.0198(0.0222) Grad: 3669.3403  LR: 0.00001000  \n","Epoch: [2][3400/3412] Elapsed 10m 7s (remain 0m 1s) Loss: 0.0335(0.0223) Grad: 17114.4180  LR: 0.00000987  \n","Epoch: [2][3411/3412] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0286(0.0223) Grad: 4210.2319  LR: 0.00000986  \n","EVAL: [0/235] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0793(0.0793) \n","EVAL: [100/235] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1376(0.1184) \n","EVAL: [200/235] Elapsed 0m 19s (remain 0m 3s) Loss: 0.1108(0.1139) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0223  avg_val_loss: 0.1131  time: 632s\n","Epoch 2 - Score: 0.7601\n","Epoch 2 - Save Best Score: 0.7601 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [234/235] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0153(0.1131) \n","Epoch: [3][0/3412] Elapsed 0m 0s (remain 26m 55s) Loss: 0.0131(0.0131) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3412] Elapsed 0m 18s (remain 10m 4s) Loss: 0.0099(0.0215) Grad: 4968.1558  LR: 0.00000973  \n","Epoch: [3][200/3412] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0315(0.0198) Grad: 22411.9570  LR: 0.00000959  \n","Epoch: [3][300/3412] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0115(0.0195) Grad: 3502.7798  LR: 0.00000946  \n","Epoch: [3][400/3412] Elapsed 1m 11s (remain 8m 58s) Loss: 0.0139(0.0191) Grad: 14678.3311  LR: 0.00000933  \n","Epoch: [3][500/3412] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0368(0.0186) Grad: 19335.0879  LR: 0.00000919  \n","Epoch: [3][600/3412] Elapsed 1m 46s (remain 8m 20s) Loss: 0.0092(0.0181) Grad: 10929.4521  LR: 0.00000906  \n","Epoch: [3][700/3412] Elapsed 2m 4s (remain 8m 1s) Loss: 0.0238(0.0180) Grad: 8726.6553  LR: 0.00000892  \n","Epoch: [3][800/3412] Elapsed 2m 22s (remain 7m 43s) Loss: 0.0282(0.0181) Grad: 10482.8027  LR: 0.00000878  \n","Epoch: [3][900/3412] Elapsed 2m 39s (remain 7m 25s) Loss: 0.0130(0.0179) Grad: 12477.9639  LR: 0.00000865  \n","Epoch: [3][1000/3412] Elapsed 2m 57s (remain 7m 7s) Loss: 0.0129(0.0180) Grad: 15168.3906  LR: 0.00000851  \n","Epoch: [3][1100/3412] Elapsed 3m 15s (remain 6m 50s) Loss: 0.0269(0.0180) Grad: 8074.7593  LR: 0.00000837  \n","Epoch: [3][1200/3412] Elapsed 3m 33s (remain 6m 32s) Loss: 0.0558(0.0179) Grad: 123869.7578  LR: 0.00000824  \n","Epoch: [3][1300/3412] Elapsed 3m 50s (remain 6m 14s) Loss: 0.0120(0.0178) Grad: 4902.4785  LR: 0.00000810  \n","Epoch: [3][1400/3412] Elapsed 4m 8s (remain 5m 56s) Loss: 0.0299(0.0178) Grad: 13455.9951  LR: 0.00000796  \n","Epoch: [3][1500/3412] Elapsed 4m 26s (remain 5m 38s) Loss: 0.0247(0.0177) Grad: 23385.4785  LR: 0.00000782  \n","Epoch: [3][1600/3412] Elapsed 4m 44s (remain 5m 21s) Loss: 0.0342(0.0176) Grad: 31820.2539  LR: 0.00000768  \n","Epoch: [3][1700/3412] Elapsed 5m 2s (remain 5m 4s) Loss: 0.0442(0.0176) Grad: 39001.4180  LR: 0.00000754  \n","Epoch: [3][1800/3412] Elapsed 5m 20s (remain 4m 46s) Loss: 0.0100(0.0176) Grad: 3790.6831  LR: 0.00000741  \n","Epoch: [3][1900/3412] Elapsed 5m 38s (remain 4m 29s) Loss: 0.0096(0.0176) Grad: 7249.5571  LR: 0.00000727  \n","Epoch: [3][2000/3412] Elapsed 5m 56s (remain 4m 11s) Loss: 0.0300(0.0176) Grad: 19258.9180  LR: 0.00000713  \n","Epoch: [3][2100/3412] Elapsed 6m 14s (remain 3m 53s) Loss: 0.0112(0.0177) Grad: 12756.4092  LR: 0.00000699  \n","Epoch: [3][2200/3412] Elapsed 6m 32s (remain 3m 36s) Loss: 0.0122(0.0176) Grad: 13328.7080  LR: 0.00000685  \n","Epoch: [3][2300/3412] Elapsed 6m 50s (remain 3m 18s) Loss: 0.0114(0.0177) Grad: 6387.7573  LR: 0.00000671  \n","Epoch: [3][2400/3412] Elapsed 7m 8s (remain 3m 0s) Loss: 0.0133(0.0177) Grad: 12357.1621  LR: 0.00000658  \n","Epoch: [3][2500/3412] Elapsed 7m 26s (remain 2m 42s) Loss: 0.0187(0.0176) Grad: 12453.4268  LR: 0.00000644  \n","Epoch: [3][2600/3412] Elapsed 7m 44s (remain 2m 24s) Loss: 0.0112(0.0176) Grad: 17227.7598  LR: 0.00000630  \n","Epoch: [3][2700/3412] Elapsed 8m 2s (remain 2m 7s) Loss: 0.0156(0.0175) Grad: 13592.7012  LR: 0.00000617  \n","Epoch: [3][2800/3412] Elapsed 8m 20s (remain 1m 49s) Loss: 0.0211(0.0176) Grad: 8337.9727  LR: 0.00000603  \n","Epoch: [3][2900/3412] Elapsed 8m 37s (remain 1m 31s) Loss: 0.0113(0.0176) Grad: 17333.6523  LR: 0.00000589  \n","Epoch: [3][3000/3412] Elapsed 8m 55s (remain 1m 13s) Loss: 0.0066(0.0175) Grad: 3685.7925  LR: 0.00000576  \n","Epoch: [3][3100/3412] Elapsed 9m 13s (remain 0m 55s) Loss: 0.0086(0.0175) Grad: 8244.2666  LR: 0.00000563  \n","Epoch: [3][3200/3412] Elapsed 9m 30s (remain 0m 37s) Loss: 0.0035(0.0175) Grad: 6533.7246  LR: 0.00000549  \n","Epoch: [3][3300/3412] Elapsed 9m 48s (remain 0m 19s) Loss: 0.0079(0.0174) Grad: 7059.3970  LR: 0.00000536  \n","Epoch: [3][3400/3412] Elapsed 10m 6s (remain 0m 1s) Loss: 0.0331(0.0174) Grad: 26292.5820  LR: 0.00000523  \n","Epoch: [3][3411/3412] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0157(0.0174) Grad: 21967.6836  LR: 0.00000521  \n","EVAL: [0/235] Elapsed 0m 0s (remain 1m 25s) Loss: 0.0692(0.0692) \n","EVAL: [100/235] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1094(0.0993) \n","EVAL: [200/235] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0909(0.0963) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0174  avg_val_loss: 0.0955  time: 631s\n","Epoch 3 - Score: 0.7821\n","Epoch 3 - Save Best Score: 0.7821 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [234/235] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0134(0.0955) \n","Epoch: [4][0/3412] Elapsed 0m 0s (remain 28m 14s) Loss: 0.0352(0.0352) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3412] Elapsed 0m 18s (remain 10m 1s) Loss: 0.0065(0.0132) Grad: 11280.9873  LR: 0.00000508  \n","Epoch: [4][200/3412] Elapsed 0m 36s (remain 9m 46s) Loss: 0.0309(0.0122) Grad: 46348.2031  LR: 0.00000495  \n","Epoch: [4][300/3412] Elapsed 0m 54s (remain 9m 20s) Loss: 0.0205(0.0120) Grad: 12129.4766  LR: 0.00000482  \n","Epoch: [4][400/3412] Elapsed 1m 11s (remain 8m 58s) Loss: 0.0022(0.0119) Grad: 1365.0615  LR: 0.00000469  \n","Epoch: [4][500/3412] Elapsed 1m 29s (remain 8m 38s) Loss: 0.0044(0.0120) Grad: 4332.2485  LR: 0.00000456  \n","Epoch: [4][600/3412] Elapsed 1m 46s (remain 8m 19s) Loss: 0.0027(0.0122) Grad: 7120.7026  LR: 0.00000443  \n","Epoch: [4][700/3412] Elapsed 2m 4s (remain 8m 0s) Loss: 0.0090(0.0125) Grad: 12054.1738  LR: 0.00000431  \n","Epoch: [4][800/3412] Elapsed 2m 21s (remain 7m 42s) Loss: 0.0264(0.0126) Grad: 32238.9414  LR: 0.00000418  \n","Epoch: [4][900/3412] Elapsed 2m 39s (remain 7m 24s) Loss: 0.0132(0.0125) Grad: 8801.0947  LR: 0.00000406  \n","Epoch: [4][1000/3412] Elapsed 2m 56s (remain 7m 6s) Loss: 0.0057(0.0124) Grad: 9984.9463  LR: 0.00000394  \n","Epoch: [4][1100/3412] Elapsed 3m 14s (remain 6m 48s) Loss: 0.0025(0.0124) Grad: 1938.9236  LR: 0.00000382  \n","Epoch: [4][1200/3412] Elapsed 3m 31s (remain 6m 30s) Loss: 0.0125(0.0124) Grad: 7067.4287  LR: 0.00000370  \n","Epoch: [4][1300/3412] Elapsed 3m 49s (remain 6m 12s) Loss: 0.0125(0.0124) Grad: 10394.3623  LR: 0.00000358  \n","Epoch: [4][1400/3412] Elapsed 4m 7s (remain 5m 55s) Loss: 0.0041(0.0125) Grad: 5991.9849  LR: 0.00000346  \n","Epoch: [4][1500/3412] Elapsed 4m 25s (remain 5m 38s) Loss: 0.0202(0.0125) Grad: 23471.5742  LR: 0.00000334  \n","Epoch: [4][1600/3412] Elapsed 4m 43s (remain 5m 20s) Loss: 0.0151(0.0124) Grad: 10517.8340  LR: 0.00000323  \n","Epoch: [4][1700/3412] Elapsed 5m 1s (remain 5m 3s) Loss: 0.0046(0.0124) Grad: 9738.2148  LR: 0.00000312  \n","Epoch: [4][1800/3412] Elapsed 5m 19s (remain 4m 46s) Loss: 0.0208(0.0124) Grad: 20604.1211  LR: 0.00000301  \n","Epoch: [4][1900/3412] Elapsed 5m 37s (remain 4m 28s) Loss: 0.0088(0.0125) Grad: 2807.6042  LR: 0.00000290  \n","Epoch: [4][2000/3412] Elapsed 5m 55s (remain 4m 10s) Loss: 0.0030(0.0125) Grad: 5414.2822  LR: 0.00000279  \n","Epoch: [4][2100/3412] Elapsed 6m 13s (remain 3m 53s) Loss: 0.0065(0.0125) Grad: 7218.1484  LR: 0.00000268  \n","Epoch: [4][2200/3412] Elapsed 6m 31s (remain 3m 35s) Loss: 0.0180(0.0125) Grad: 13560.6924  LR: 0.00000257  \n","Epoch: [4][2300/3412] Elapsed 6m 49s (remain 3m 17s) Loss: 0.0074(0.0126) Grad: 1852.4724  LR: 0.00000247  \n","Epoch: [4][2400/3412] Elapsed 7m 7s (remain 3m 0s) Loss: 0.0179(0.0127) Grad: 25634.6895  LR: 0.00000237  \n","Epoch: [4][2500/3412] Elapsed 7m 25s (remain 2m 42s) Loss: 0.0075(0.0127) Grad: 6635.9360  LR: 0.00000227  \n","Epoch: [4][2600/3412] Elapsed 7m 43s (remain 2m 24s) Loss: 0.0028(0.0126) Grad: 2709.3965  LR: 0.00000217  \n","Epoch: [4][2700/3412] Elapsed 8m 0s (remain 2m 6s) Loss: 0.0298(0.0127) Grad: 21942.7422  LR: 0.00000207  \n","Epoch: [4][2800/3412] Elapsed 8m 18s (remain 1m 48s) Loss: 0.0042(0.0127) Grad: 12619.4375  LR: 0.00000198  \n","Epoch: [4][2900/3412] Elapsed 8m 36s (remain 1m 30s) Loss: 0.0099(0.0127) Grad: 8509.2275  LR: 0.00000189  \n","Epoch: [4][3000/3412] Elapsed 8m 53s (remain 1m 13s) Loss: 0.0149(0.0127) Grad: 8255.6221  LR: 0.00000180  \n","Epoch: [4][3100/3412] Elapsed 9m 11s (remain 0m 55s) Loss: 0.0025(0.0127) Grad: 3155.8762  LR: 0.00000171  \n","Epoch: [4][3200/3412] Elapsed 9m 29s (remain 0m 37s) Loss: 0.0061(0.0126) Grad: 2955.1260  LR: 0.00000162  \n","Epoch: [4][3300/3412] Elapsed 9m 47s (remain 0m 19s) Loss: 0.0071(0.0126) Grad: 12686.1514  LR: 0.00000154  \n","Epoch: [4][3400/3412] Elapsed 10m 4s (remain 0m 1s) Loss: 0.0163(0.0126) Grad: 14783.6641  LR: 0.00000145  \n","Epoch: [4][3411/3412] Elapsed 10m 6s (remain 0m 0s) Loss: 0.0017(0.0126) Grad: 4742.8901  LR: 0.00000144  \n","EVAL: [0/235] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0730(0.0730) \n","EVAL: [100/235] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1117(0.1053) \n","EVAL: [200/235] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0940(0.1016) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0126  avg_val_loss: 0.1007  time: 630s\n","Epoch 4 - Score: 0.7794\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [234/235] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0171(0.1007) \n","Epoch: [5][0/3412] Elapsed 0m 0s (remain 29m 23s) Loss: 0.0157(0.0157) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3412] Elapsed 0m 18s (remain 10m 2s) Loss: 0.0091(0.0092) Grad: 19261.8262  LR: 0.00000136  \n","Epoch: [5][200/3412] Elapsed 0m 36s (remain 9m 37s) Loss: 0.0268(0.0104) Grad: 19375.0586  LR: 0.00000128  \n","Epoch: [5][300/3412] Elapsed 0m 53s (remain 9m 16s) Loss: 0.0078(0.0108) Grad: 14467.0205  LR: 0.00000121  \n","Epoch: [5][400/3412] Elapsed 1m 11s (remain 8m 57s) Loss: 0.0028(0.0107) Grad: 15103.6758  LR: 0.00000113  \n","Epoch: [5][500/3412] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0007(0.0105) Grad: 2675.9062  LR: 0.00000106  \n","Epoch: [5][600/3412] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0024(0.0104) Grad: 5799.7959  LR: 0.00000099  \n","Epoch: [5][700/3412] Elapsed 2m 4s (remain 8m 3s) Loss: 0.0087(0.0102) Grad: 5422.1470  LR: 0.00000092  \n","Epoch: [5][800/3412] Elapsed 2m 22s (remain 7m 45s) Loss: 0.0070(0.0103) Grad: 11328.1963  LR: 0.00000086  \n","Epoch: [5][900/3412] Elapsed 2m 40s (remain 7m 27s) Loss: 0.0072(0.0102) Grad: 9116.7744  LR: 0.00000079  \n","Epoch: [5][1000/3412] Elapsed 2m 58s (remain 7m 8s) Loss: 0.0008(0.0102) Grad: 7935.4692  LR: 0.00000073  \n","Epoch: [5][1100/3412] Elapsed 3m 15s (remain 6m 50s) Loss: 0.0175(0.0102) Grad: 17762.6348  LR: 0.00000067  \n","Epoch: [5][1200/3412] Elapsed 3m 33s (remain 6m 33s) Loss: 0.0067(0.0102) Grad: 8926.7246  LR: 0.00000062  \n","Epoch: [5][1300/3412] Elapsed 3m 51s (remain 6m 15s) Loss: 0.0010(0.0103) Grad: 3280.8503  LR: 0.00000056  \n","Epoch: [5][1400/3412] Elapsed 4m 8s (remain 5m 57s) Loss: 0.0221(0.0103) Grad: 27214.3633  LR: 0.00000051  \n","Epoch: [5][1500/3412] Elapsed 4m 27s (remain 5m 40s) Loss: 0.0127(0.0103) Grad: 29813.3477  LR: 0.00000046  \n","Epoch: [5][1600/3412] Elapsed 4m 45s (remain 5m 22s) Loss: 0.0077(0.0103) Grad: 5896.7192  LR: 0.00000042  \n","Epoch: [5][1700/3412] Elapsed 5m 3s (remain 5m 5s) Loss: 0.0142(0.0102) Grad: 26105.3652  LR: 0.00000037  \n","Epoch: [5][1800/3412] Elapsed 5m 21s (remain 4m 47s) Loss: 0.0036(0.0102) Grad: 6435.2202  LR: 0.00000033  \n","Epoch: [5][1900/3412] Elapsed 5m 40s (remain 4m 30s) Loss: 0.0033(0.0103) Grad: 12365.3486  LR: 0.00000029  \n","Epoch: [5][2000/3412] Elapsed 5m 58s (remain 4m 12s) Loss: 0.0060(0.0102) Grad: 9833.1523  LR: 0.00000025  \n","Epoch: [5][2100/3412] Elapsed 6m 16s (remain 3m 54s) Loss: 0.0195(0.0102) Grad: 34272.8516  LR: 0.00000022  \n","Epoch: [5][2200/3412] Elapsed 6m 34s (remain 3m 36s) Loss: 0.0157(0.0102) Grad: 26206.9785  LR: 0.00000019  \n","Epoch: [5][2300/3412] Elapsed 6m 52s (remain 3m 19s) Loss: 0.0108(0.0102) Grad: 16522.9023  LR: 0.00000016  \n","Epoch: [5][2400/3412] Elapsed 7m 10s (remain 3m 1s) Loss: 0.0036(0.0102) Grad: 4346.3755  LR: 0.00000013  \n","Epoch: [5][2500/3412] Elapsed 7m 28s (remain 2m 43s) Loss: 0.0064(0.0102) Grad: 8645.6650  LR: 0.00000011  \n","Epoch: [5][2600/3412] Elapsed 7m 46s (remain 2m 25s) Loss: 0.0104(0.0103) Grad: 20626.9492  LR: 0.00000008  \n","Epoch: [5][2700/3412] Elapsed 8m 4s (remain 2m 7s) Loss: 0.0076(0.0102) Grad: 7955.7104  LR: 0.00000007  \n","Epoch: [5][2800/3412] Elapsed 8m 22s (remain 1m 49s) Loss: 0.0438(0.0103) Grad: 30155.5293  LR: 0.00000005  \n","Epoch: [5][2900/3412] Elapsed 8m 39s (remain 1m 31s) Loss: 0.0135(0.0103) Grad: 33840.9922  LR: 0.00000003  \n","Epoch: [5][3000/3412] Elapsed 8m 57s (remain 1m 13s) Loss: 0.0084(0.0102) Grad: 20064.1504  LR: 0.00000002  \n","Epoch: [5][3100/3412] Elapsed 9m 15s (remain 0m 55s) Loss: 0.0053(0.0102) Grad: 5141.4746  LR: 0.00000001  \n","Epoch: [5][3200/3412] Elapsed 9m 33s (remain 0m 37s) Loss: 0.0118(0.0102) Grad: 5159.0068  LR: 0.00000001  \n","Epoch: [5][3300/3412] Elapsed 9m 50s (remain 0m 19s) Loss: 0.0073(0.0102) Grad: 2192.6980  LR: 0.00000000  \n","Epoch: [5][3400/3412] Elapsed 10m 8s (remain 0m 1s) Loss: 0.0019(0.0102) Grad: 4436.8730  LR: 0.00000000  \n","Epoch: [5][3411/3412] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0049(0.0102) Grad: 3023.6775  LR: 0.00000000  \n","EVAL: [0/235] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0745(0.0745) \n","EVAL: [100/235] Elapsed 0m 10s (remain 0m 13s) Loss: 0.1123(0.1058) \n","EVAL: [200/235] Elapsed 0m 19s (remain 0m 3s) Loss: 0.0947(0.1022) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0102  avg_val_loss: 0.1013  time: 634s\n","Epoch 5 - Score: 0.7816\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [234/235] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0175(0.1013) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 11 result ==========\n","Score: 0.7821\n","========== fold: 12 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3390] Elapsed 0m 0s (remain 24m 52s) Loss: 0.4038(0.4038) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3390] Elapsed 0m 17s (remain 9m 43s) Loss: 0.1155(0.1111) Grad: 11967.3203  LR: 0.00001500  \n","Epoch: [1][200/3390] Elapsed 0m 35s (remain 9m 25s) Loss: 0.0638(0.0878) Grad: 3497.2141  LR: 0.00001500  \n","Epoch: [1][300/3390] Elapsed 0m 53s (remain 9m 8s) Loss: 0.0588(0.0763) Grad: 4810.4199  LR: 0.00001499  \n","Epoch: [1][400/3390] Elapsed 1m 11s (remain 8m 50s) Loss: 0.0275(0.0697) Grad: 1908.1415  LR: 0.00001498  \n","Epoch: [1][500/3390] Elapsed 1m 28s (remain 8m 33s) Loss: 0.0347(0.0651) Grad: 2557.9155  LR: 0.00001497  \n","Epoch: [1][600/3390] Elapsed 1m 46s (remain 8m 14s) Loss: 0.0602(0.0608) Grad: 11815.5693  LR: 0.00001496  \n","Epoch: [1][700/3390] Elapsed 2m 4s (remain 7m 56s) Loss: 0.0190(0.0577) Grad: 1378.9695  LR: 0.00001495  \n","Epoch: [1][800/3390] Elapsed 2m 21s (remain 7m 38s) Loss: 0.0196(0.0553) Grad: 4423.1606  LR: 0.00001493  \n","Epoch: [1][900/3390] Elapsed 2m 39s (remain 7m 21s) Loss: 0.0517(0.0532) Grad: 7465.8081  LR: 0.00001491  \n","Epoch: [1][1000/3390] Elapsed 2m 57s (remain 7m 3s) Loss: 0.0348(0.0517) Grad: 6227.4092  LR: 0.00001488  \n","Epoch: [1][1100/3390] Elapsed 3m 14s (remain 6m 45s) Loss: 0.0386(0.0502) Grad: 1919.6241  LR: 0.00001486  \n","Epoch: [1][1200/3390] Elapsed 3m 32s (remain 6m 27s) Loss: 0.0313(0.0492) Grad: 1786.1539  LR: 0.00001483  \n","Epoch: [1][1300/3390] Elapsed 3m 50s (remain 6m 9s) Loss: 0.0163(0.0481) Grad: 5062.7798  LR: 0.00001480  \n","Epoch: [1][1400/3390] Elapsed 4m 8s (remain 5m 52s) Loss: 0.0299(0.0471) Grad: 3179.8774  LR: 0.00001476  \n","Epoch: [1][1500/3390] Elapsed 4m 26s (remain 5m 35s) Loss: 0.0524(0.0460) Grad: 8643.2725  LR: 0.00001473  \n","Epoch: [1][1600/3390] Elapsed 4m 44s (remain 5m 18s) Loss: 0.0212(0.0453) Grad: 5002.7051  LR: 0.00001469  \n","Epoch: [1][1700/3390] Elapsed 5m 2s (remain 5m 0s) Loss: 0.0289(0.0445) Grad: 2965.2119  LR: 0.00001465  \n","Epoch: [1][1800/3390] Elapsed 5m 20s (remain 4m 43s) Loss: 0.0268(0.0439) Grad: 4413.6870  LR: 0.00001461  \n","Epoch: [1][1900/3390] Elapsed 5m 38s (remain 4m 25s) Loss: 0.0637(0.0433) Grad: 5428.0117  LR: 0.00001456  \n","Epoch: [1][2000/3390] Elapsed 5m 56s (remain 4m 7s) Loss: 0.0501(0.0429) Grad: 9834.9961  LR: 0.00001451  \n","Epoch: [1][2100/3390] Elapsed 6m 15s (remain 3m 50s) Loss: 0.0396(0.0424) Grad: 7933.7930  LR: 0.00001446  \n","Epoch: [1][2200/3390] Elapsed 6m 33s (remain 3m 32s) Loss: 0.0229(0.0418) Grad: 6861.2480  LR: 0.00001441  \n","Epoch: [1][2300/3390] Elapsed 6m 51s (remain 3m 14s) Loss: 0.0076(0.0413) Grad: 4925.8398  LR: 0.00001435  \n","Epoch: [1][2400/3390] Elapsed 7m 9s (remain 2m 56s) Loss: 0.0134(0.0408) Grad: 7082.3838  LR: 0.00001430  \n","Epoch: [1][2500/3390] Elapsed 7m 26s (remain 2m 38s) Loss: 0.0141(0.0402) Grad: 6709.9585  LR: 0.00001423  \n","Epoch: [1][2600/3390] Elapsed 7m 44s (remain 2m 20s) Loss: 0.0019(0.0398) Grad: 502.5167  LR: 0.00001417  \n","Epoch: [1][2700/3390] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0356(0.0395) Grad: 6760.3066  LR: 0.00001411  \n","Epoch: [1][2800/3390] Elapsed 8m 19s (remain 1m 45s) Loss: 0.0215(0.0391) Grad: 9703.5215  LR: 0.00001404  \n","Epoch: [1][2900/3390] Elapsed 8m 37s (remain 1m 27s) Loss: 0.0491(0.0387) Grad: 12932.3271  LR: 0.00001397  \n","Epoch: [1][3000/3390] Elapsed 8m 55s (remain 1m 9s) Loss: 0.0173(0.0384) Grad: 3563.7705  LR: 0.00001390  \n","Epoch: [1][3100/3390] Elapsed 9m 12s (remain 0m 51s) Loss: 0.0157(0.0380) Grad: 5129.2261  LR: 0.00001383  \n","Epoch: [1][3200/3390] Elapsed 9m 30s (remain 0m 33s) Loss: 0.0134(0.0377) Grad: 2196.6758  LR: 0.00001375  \n","Epoch: [1][3300/3390] Elapsed 9m 47s (remain 0m 15s) Loss: 0.0171(0.0375) Grad: 5940.8013  LR: 0.00001367  \n","Epoch: [1][3389/3390] Elapsed 10m 3s (remain 0m 0s) Loss: 0.0338(0.0373) Grad: 16528.6426  LR: 0.00001360  \n","EVAL: [0/258] Elapsed 0m 0s (remain 1m 30s) Loss: 0.1180(0.1180) \n","EVAL: [100/258] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0306(0.0903) \n","EVAL: [200/258] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1621(0.0946) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0373  avg_val_loss: 0.0948  time: 629s\n","Epoch 1 - Score: 0.7707\n","Epoch 1 - Save Best Score: 0.7707 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [257/258] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0062(0.0948) \n","Epoch: [2][0/3390] Elapsed 0m 0s (remain 26m 28s) Loss: 0.0175(0.0175) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3390] Elapsed 0m 18s (remain 9m 50s) Loss: 0.0143(0.0223) Grad: 5455.2227  LR: 0.00001352  \n","Epoch: [2][200/3390] Elapsed 0m 36s (remain 9m 34s) Loss: 0.0207(0.0217) Grad: 11569.7041  LR: 0.00001343  \n","Epoch: [2][300/3390] Elapsed 0m 53s (remain 9m 12s) Loss: 0.0170(0.0220) Grad: 14977.3721  LR: 0.00001335  \n","Epoch: [2][400/3390] Elapsed 1m 11s (remain 8m 53s) Loss: 0.0233(0.0222) Grad: 12333.5742  LR: 0.00001326  \n","Epoch: [2][500/3390] Elapsed 1m 29s (remain 8m 33s) Loss: 0.0260(0.0221) Grad: 25302.5859  LR: 0.00001317  \n","Epoch: [2][600/3390] Elapsed 1m 46s (remain 8m 15s) Loss: 0.0445(0.0223) Grad: 24260.8750  LR: 0.00001308  \n","Epoch: [2][700/3390] Elapsed 2m 4s (remain 7m 56s) Loss: 0.0186(0.0220) Grad: 12908.5205  LR: 0.00001298  \n","Epoch: [2][800/3390] Elapsed 2m 21s (remain 7m 38s) Loss: 0.0450(0.0221) Grad: 21438.2441  LR: 0.00001289  \n","Epoch: [2][900/3390] Elapsed 2m 39s (remain 7m 20s) Loss: 0.0144(0.0221) Grad: 4411.7720  LR: 0.00001279  \n","Epoch: [2][1000/3390] Elapsed 2m 57s (remain 7m 3s) Loss: 0.0314(0.0221) Grad: 8798.2871  LR: 0.00001269  \n","Epoch: [2][1100/3390] Elapsed 3m 14s (remain 6m 44s) Loss: 0.0361(0.0223) Grad: 24551.8047  LR: 0.00001259  \n","Epoch: [2][1200/3390] Elapsed 3m 32s (remain 6m 26s) Loss: 0.0080(0.0220) Grad: 5800.0537  LR: 0.00001248  \n","Epoch: [2][1300/3390] Elapsed 3m 50s (remain 6m 9s) Loss: 0.0053(0.0222) Grad: 4114.8247  LR: 0.00001238  \n","Epoch: [2][1400/3390] Elapsed 4m 8s (remain 5m 52s) Loss: 0.0224(0.0221) Grad: 24988.0938  LR: 0.00001227  \n","Epoch: [2][1500/3390] Elapsed 4m 26s (remain 5m 35s) Loss: 0.0271(0.0222) Grad: 13331.2090  LR: 0.00001216  \n","Epoch: [2][1600/3390] Elapsed 4m 44s (remain 5m 17s) Loss: 0.0380(0.0220) Grad: 30203.5527  LR: 0.00001205  \n","Epoch: [2][1700/3390] Elapsed 5m 2s (remain 5m 0s) Loss: 0.0100(0.0219) Grad: 11955.2725  LR: 0.00001194  \n","Epoch: [2][1800/3390] Elapsed 5m 20s (remain 4m 42s) Loss: 0.0291(0.0218) Grad: 17575.2441  LR: 0.00001183  \n","Epoch: [2][1900/3390] Elapsed 5m 38s (remain 4m 25s) Loss: 0.0266(0.0218) Grad: 7798.5278  LR: 0.00001171  \n","Epoch: [2][2000/3390] Elapsed 5m 56s (remain 4m 7s) Loss: 0.0207(0.0220) Grad: 29324.8379  LR: 0.00001160  \n","Epoch: [2][2100/3390] Elapsed 6m 14s (remain 3m 49s) Loss: 0.0372(0.0219) Grad: 37619.5703  LR: 0.00001148  \n","Epoch: [2][2200/3390] Elapsed 6m 32s (remain 3m 32s) Loss: 0.0119(0.0219) Grad: 5409.5034  LR: 0.00001136  \n","Epoch: [2][2300/3390] Elapsed 6m 51s (remain 3m 14s) Loss: 0.0123(0.0218) Grad: 5326.0781  LR: 0.00001124  \n","Epoch: [2][2400/3390] Elapsed 7m 8s (remain 2m 56s) Loss: 0.0090(0.0218) Grad: 14831.0195  LR: 0.00001112  \n","Epoch: [2][2500/3390] Elapsed 7m 26s (remain 2m 38s) Loss: 0.0162(0.0218) Grad: 15717.3271  LR: 0.00001100  \n","Epoch: [2][2600/3390] Elapsed 7m 44s (remain 2m 20s) Loss: 0.0210(0.0218) Grad: 3663.8386  LR: 0.00001087  \n","Epoch: [2][2700/3390] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0107(0.0219) Grad: 18425.7051  LR: 0.00001075  \n","Epoch: [2][2800/3390] Elapsed 8m 19s (remain 1m 45s) Loss: 0.0144(0.0218) Grad: 4483.6997  LR: 0.00001062  \n","Epoch: [2][2900/3390] Elapsed 8m 37s (remain 1m 27s) Loss: 0.0242(0.0218) Grad: 7753.8062  LR: 0.00001049  \n","Epoch: [2][3000/3390] Elapsed 8m 55s (remain 1m 9s) Loss: 0.0140(0.0218) Grad: 21856.0645  LR: 0.00001037  \n","Epoch: [2][3100/3390] Elapsed 9m 13s (remain 0m 51s) Loss: 0.0423(0.0218) Grad: 29957.7441  LR: 0.00001024  \n","Epoch: [2][3200/3390] Elapsed 9m 31s (remain 0m 33s) Loss: 0.0150(0.0218) Grad: 8306.7148  LR: 0.00001011  \n","Epoch: [2][3300/3390] Elapsed 9m 48s (remain 0m 15s) Loss: 0.0479(0.0218) Grad: 27367.9082  LR: 0.00000997  \n","Epoch: [2][3389/3390] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0213(0.0218) Grad: 5339.9648  LR: 0.00000986  \n","EVAL: [0/258] Elapsed 0m 0s (remain 1m 31s) Loss: 0.1162(0.1162) \n","EVAL: [100/258] Elapsed 0m 10s (remain 0m 15s) Loss: 0.0225(0.0897) \n","EVAL: [200/258] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1818(0.0945) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0218  avg_val_loss: 0.0947  time: 630s\n","Epoch 2 - Score: 0.7887\n","Epoch 2 - Save Best Score: 0.7887 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [257/258] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0144(0.0947) \n","Epoch: [3][0/3390] Elapsed 0m 0s (remain 29m 18s) Loss: 0.0240(0.0240) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3390] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0342(0.0175) Grad: 61621.2695  LR: 0.00000972  \n","Epoch: [3][200/3390] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0209(0.0162) Grad: 31611.2285  LR: 0.00000959  \n","Epoch: [3][300/3390] Elapsed 0m 54s (remain 9m 19s) Loss: 0.0262(0.0162) Grad: 12980.7793  LR: 0.00000946  \n","Epoch: [3][400/3390] Elapsed 1m 12s (remain 8m 57s) Loss: 0.0064(0.0163) Grad: 3149.1790  LR: 0.00000932  \n","Epoch: [3][500/3390] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0118(0.0162) Grad: 3278.5623  LR: 0.00000919  \n","Epoch: [3][600/3390] Elapsed 1m 47s (remain 8m 18s) Loss: 0.0326(0.0165) Grad: 21593.9883  LR: 0.00000905  \n","Epoch: [3][700/3390] Elapsed 2m 5s (remain 8m 0s) Loss: 0.0168(0.0168) Grad: 29297.4512  LR: 0.00000891  \n","Epoch: [3][800/3390] Elapsed 2m 22s (remain 7m 41s) Loss: 0.0470(0.0170) Grad: 35191.0977  LR: 0.00000878  \n","Epoch: [3][900/3390] Elapsed 2m 40s (remain 7m 23s) Loss: 0.0090(0.0170) Grad: 6656.2627  LR: 0.00000864  \n","Epoch: [3][1000/3390] Elapsed 2m 58s (remain 7m 5s) Loss: 0.0067(0.0170) Grad: 21501.6523  LR: 0.00000850  \n","Epoch: [3][1100/3390] Elapsed 3m 16s (remain 6m 47s) Loss: 0.0093(0.0170) Grad: 12136.6768  LR: 0.00000836  \n","Epoch: [3][1200/3390] Elapsed 3m 33s (remain 6m 29s) Loss: 0.0221(0.0170) Grad: 6779.9927  LR: 0.00000822  \n","Epoch: [3][1300/3390] Elapsed 3m 51s (remain 6m 11s) Loss: 0.0042(0.0170) Grad: 9594.2871  LR: 0.00000808  \n","Epoch: [3][1400/3390] Elapsed 4m 9s (remain 5m 54s) Loss: 0.0104(0.0169) Grad: 21506.7695  LR: 0.00000794  \n","Epoch: [3][1500/3390] Elapsed 4m 28s (remain 5m 37s) Loss: 0.0050(0.0169) Grad: 1696.1163  LR: 0.00000781  \n","Epoch: [3][1600/3390] Elapsed 4m 46s (remain 5m 19s) Loss: 0.0060(0.0170) Grad: 16033.6797  LR: 0.00000767  \n","Epoch: [3][1700/3390] Elapsed 5m 4s (remain 5m 1s) Loss: 0.0195(0.0169) Grad: 17829.9043  LR: 0.00000753  \n","Epoch: [3][1800/3390] Elapsed 5m 22s (remain 4m 44s) Loss: 0.0039(0.0170) Grad: 7484.6035  LR: 0.00000739  \n","Epoch: [3][1900/3390] Elapsed 5m 40s (remain 4m 26s) Loss: 0.0480(0.0169) Grad: 15551.2236  LR: 0.00000725  \n","Epoch: [3][2000/3390] Elapsed 5m 58s (remain 4m 8s) Loss: 0.0330(0.0169) Grad: 17069.7441  LR: 0.00000711  \n","Epoch: [3][2100/3390] Elapsed 6m 16s (remain 3m 50s) Loss: 0.0357(0.0169) Grad: 12919.5156  LR: 0.00000697  \n","Epoch: [3][2200/3390] Elapsed 6m 34s (remain 3m 32s) Loss: 0.0031(0.0170) Grad: 7429.6548  LR: 0.00000683  \n","Epoch: [3][2300/3390] Elapsed 6m 52s (remain 3m 15s) Loss: 0.0170(0.0170) Grad: 17486.3926  LR: 0.00000669  \n","Epoch: [3][2400/3390] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0037(0.0170) Grad: 5199.7832  LR: 0.00000655  \n","Epoch: [3][2500/3390] Elapsed 7m 27s (remain 2m 39s) Loss: 0.0075(0.0170) Grad: 5793.5210  LR: 0.00000641  \n","Epoch: [3][2600/3390] Elapsed 7m 45s (remain 2m 21s) Loss: 0.0165(0.0169) Grad: 10529.9854  LR: 0.00000628  \n","Epoch: [3][2700/3390] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0218(0.0168) Grad: 22778.5859  LR: 0.00000614  \n","Epoch: [3][2800/3390] Elapsed 8m 20s (remain 1m 45s) Loss: 0.0271(0.0168) Grad: 12668.3691  LR: 0.00000600  \n","Epoch: [3][2900/3390] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0081(0.0169) Grad: 9477.6719  LR: 0.00000587  \n","Epoch: [3][3000/3390] Elapsed 8m 55s (remain 1m 9s) Loss: 0.0214(0.0169) Grad: 14419.6172  LR: 0.00000573  \n","Epoch: [3][3100/3390] Elapsed 9m 13s (remain 0m 51s) Loss: 0.0048(0.0169) Grad: 5012.5166  LR: 0.00000560  \n","Epoch: [3][3200/3390] Elapsed 9m 30s (remain 0m 33s) Loss: 0.0079(0.0169) Grad: 3951.4058  LR: 0.00000546  \n","Epoch: [3][3300/3390] Elapsed 9m 48s (remain 0m 15s) Loss: 0.0079(0.0168) Grad: 1896.4310  LR: 0.00000533  \n","Epoch: [3][3389/3390] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0113(0.0167) Grad: 4724.9941  LR: 0.00000521  \n","EVAL: [0/258] Elapsed 0m 0s (remain 1m 32s) Loss: 0.1152(0.1152) \n","EVAL: [100/258] Elapsed 0m 10s (remain 0m 15s) Loss: 0.0249(0.0883) \n","EVAL: [200/258] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1601(0.0932) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0167  avg_val_loss: 0.0936  time: 629s\n","Epoch 3 - Score: 0.7898\n","Epoch 3 - Save Best Score: 0.7898 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [257/258] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0070(0.0936) \n","Epoch: [4][0/3390] Elapsed 0m 0s (remain 27m 52s) Loss: 0.0441(0.0441) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3390] Elapsed 0m 18s (remain 10m 3s) Loss: 0.0354(0.0129) Grad: 44527.0977  LR: 0.00000508  \n","Epoch: [4][200/3390] Elapsed 0m 36s (remain 9m 42s) Loss: 0.0022(0.0126) Grad: 18775.6543  LR: 0.00000494  \n","Epoch: [4][300/3390] Elapsed 0m 54s (remain 9m 17s) Loss: 0.0344(0.0127) Grad: 5983.3984  LR: 0.00000481  \n","Epoch: [4][400/3390] Elapsed 1m 12s (remain 8m 57s) Loss: 0.0141(0.0127) Grad: 9545.7842  LR: 0.00000468  \n","Epoch: [4][500/3390] Elapsed 1m 29s (remain 8m 37s) Loss: 0.0246(0.0125) Grad: 18845.1211  LR: 0.00000455  \n","Epoch: [4][600/3390] Elapsed 1m 47s (remain 8m 18s) Loss: 0.0043(0.0124) Grad: 8211.0146  LR: 0.00000443  \n","Epoch: [4][700/3390] Elapsed 2m 5s (remain 8m 0s) Loss: 0.0051(0.0125) Grad: 10119.8096  LR: 0.00000430  \n","Epoch: [4][800/3390] Elapsed 2m 23s (remain 7m 42s) Loss: 0.0244(0.0125) Grad: 9778.5752  LR: 0.00000417  \n","Epoch: [4][900/3390] Elapsed 2m 40s (remain 7m 24s) Loss: 0.0163(0.0124) Grad: 5761.3950  LR: 0.00000405  \n","Epoch: [4][1000/3390] Elapsed 2m 58s (remain 7m 6s) Loss: 0.0121(0.0126) Grad: 7129.9702  LR: 0.00000393  \n","Epoch: [4][1100/3390] Elapsed 3m 16s (remain 6m 49s) Loss: 0.0071(0.0126) Grad: 9712.8828  LR: 0.00000381  \n","Epoch: [4][1200/3390] Elapsed 3m 34s (remain 6m 31s) Loss: 0.0063(0.0126) Grad: 4450.7690  LR: 0.00000368  \n","Epoch: [4][1300/3390] Elapsed 3m 53s (remain 6m 14s) Loss: 0.0119(0.0125) Grad: 6033.2026  LR: 0.00000357  \n","Epoch: [4][1400/3390] Elapsed 4m 11s (remain 5m 56s) Loss: 0.0075(0.0124) Grad: 6508.4214  LR: 0.00000345  \n","Epoch: [4][1500/3390] Elapsed 4m 29s (remain 5m 38s) Loss: 0.0069(0.0124) Grad: 10184.7354  LR: 0.00000333  \n","Epoch: [4][1600/3390] Elapsed 4m 47s (remain 5m 21s) Loss: 0.0099(0.0124) Grad: 3783.8025  LR: 0.00000322  \n","Epoch: [4][1700/3390] Elapsed 5m 5s (remain 5m 3s) Loss: 0.0185(0.0126) Grad: 8456.0859  LR: 0.00000310  \n","Epoch: [4][1800/3390] Elapsed 5m 23s (remain 4m 45s) Loss: 0.0133(0.0127) Grad: 5615.1323  LR: 0.00000299  \n","Epoch: [4][1900/3390] Elapsed 5m 41s (remain 4m 27s) Loss: 0.0065(0.0126) Grad: 8427.4531  LR: 0.00000288  \n","Epoch: [4][2000/3390] Elapsed 5m 59s (remain 4m 9s) Loss: 0.0088(0.0126) Grad: 14690.6543  LR: 0.00000277  \n","Epoch: [4][2100/3390] Elapsed 6m 17s (remain 3m 51s) Loss: 0.0256(0.0126) Grad: 18554.3242  LR: 0.00000266  \n","Epoch: [4][2200/3390] Elapsed 6m 34s (remain 3m 33s) Loss: 0.0069(0.0126) Grad: 12230.3193  LR: 0.00000256  \n","Epoch: [4][2300/3390] Elapsed 6m 52s (remain 3m 15s) Loss: 0.0067(0.0125) Grad: 13213.7002  LR: 0.00000245  \n","Epoch: [4][2400/3390] Elapsed 7m 10s (remain 2m 57s) Loss: 0.0141(0.0125) Grad: 10924.0273  LR: 0.00000235  \n","Epoch: [4][2500/3390] Elapsed 7m 27s (remain 2m 39s) Loss: 0.0271(0.0124) Grad: 33872.8555  LR: 0.00000225  \n","Epoch: [4][2600/3390] Elapsed 7m 45s (remain 2m 21s) Loss: 0.0180(0.0124) Grad: 45500.0391  LR: 0.00000215  \n","Epoch: [4][2700/3390] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0094(0.0123) Grad: 38817.7188  LR: 0.00000205  \n","Epoch: [4][2800/3390] Elapsed 8m 20s (remain 1m 45s) Loss: 0.0134(0.0124) Grad: 5368.7588  LR: 0.00000196  \n","Epoch: [4][2900/3390] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0055(0.0123) Grad: 4657.1299  LR: 0.00000187  \n","Epoch: [4][3000/3390] Elapsed 8m 55s (remain 1m 9s) Loss: 0.0039(0.0123) Grad: 3590.1565  LR: 0.00000178  \n","Epoch: [4][3100/3390] Elapsed 9m 13s (remain 0m 51s) Loss: 0.0043(0.0122) Grad: 9984.0166  LR: 0.00000169  \n","Epoch: [4][3200/3390] Elapsed 9m 30s (remain 0m 33s) Loss: 0.0142(0.0122) Grad: 5653.8354  LR: 0.00000160  \n","Epoch: [4][3300/3390] Elapsed 9m 48s (remain 0m 15s) Loss: 0.0101(0.0122) Grad: 3958.4199  LR: 0.00000151  \n","Epoch: [4][3389/3390] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0116(0.0122) Grad: 13364.6191  LR: 0.00000144  \n","EVAL: [0/258] Elapsed 0m 0s (remain 1m 32s) Loss: 0.1250(0.1250) \n","EVAL: [100/258] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0279(0.0915) \n","EVAL: [200/258] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1639(0.0966) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0122  avg_val_loss: 0.0970  time: 629s\n","Epoch 4 - Score: 0.7978\n","Epoch 4 - Save Best Score: 0.7978 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [257/258] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0089(0.0970) \n","Epoch: [5][0/3390] Elapsed 0m 0s (remain 28m 1s) Loss: 0.0209(0.0209) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3390] Elapsed 0m 18s (remain 10m 4s) Loss: 0.0112(0.0102) Grad: 16594.9922  LR: 0.00000136  \n","Epoch: [5][200/3390] Elapsed 0m 36s (remain 9m 40s) Loss: 0.0067(0.0095) Grad: 12097.0869  LR: 0.00000128  \n","Epoch: [5][300/3390] Elapsed 0m 54s (remain 9m 17s) Loss: 0.0020(0.0094) Grad: 4463.5835  LR: 0.00000120  \n","Epoch: [5][400/3390] Elapsed 1m 11s (remain 8m 56s) Loss: 0.0141(0.0094) Grad: 5500.8779  LR: 0.00000113  \n","Epoch: [5][500/3390] Elapsed 1m 29s (remain 8m 36s) Loss: 0.0046(0.0093) Grad: 8315.6445  LR: 0.00000106  \n","Epoch: [5][600/3390] Elapsed 1m 47s (remain 8m 17s) Loss: 0.0006(0.0095) Grad: 2807.5378  LR: 0.00000099  \n","Epoch: [5][700/3390] Elapsed 2m 4s (remain 7m 59s) Loss: 0.0170(0.0095) Grad: 16916.2598  LR: 0.00000092  \n","Epoch: [5][800/3390] Elapsed 2m 22s (remain 7m 40s) Loss: 0.0151(0.0094) Grad: 17014.7402  LR: 0.00000085  \n","Epoch: [5][900/3390] Elapsed 2m 40s (remain 7m 22s) Loss: 0.0118(0.0094) Grad: 10879.0576  LR: 0.00000079  \n","Epoch: [5][1000/3390] Elapsed 2m 58s (remain 7m 5s) Loss: 0.0083(0.0094) Grad: 10134.5537  LR: 0.00000073  \n","Epoch: [5][1100/3390] Elapsed 3m 16s (remain 6m 48s) Loss: 0.0066(0.0095) Grad: 11464.3232  LR: 0.00000067  \n","Epoch: [5][1200/3390] Elapsed 3m 34s (remain 6m 31s) Loss: 0.0049(0.0095) Grad: 4065.3494  LR: 0.00000061  \n","Epoch: [5][1300/3390] Elapsed 3m 52s (remain 6m 13s) Loss: 0.0267(0.0096) Grad: 14540.9775  LR: 0.00000056  \n","Epoch: [5][1400/3390] Elapsed 4m 10s (remain 5m 55s) Loss: 0.0200(0.0096) Grad: 7391.2969  LR: 0.00000051  \n","Epoch: [5][1500/3390] Elapsed 4m 28s (remain 5m 38s) Loss: 0.0081(0.0096) Grad: 9386.9590  LR: 0.00000046  \n","Epoch: [5][1600/3390] Elapsed 4m 46s (remain 5m 20s) Loss: 0.0005(0.0095) Grad: 1893.2546  LR: 0.00000041  \n","Epoch: [5][1700/3390] Elapsed 5m 4s (remain 5m 2s) Loss: 0.0192(0.0097) Grad: 24930.9824  LR: 0.00000037  \n","Epoch: [5][1800/3390] Elapsed 5m 23s (remain 4m 45s) Loss: 0.0162(0.0097) Grad: 17504.6543  LR: 0.00000032  \n","Epoch: [5][1900/3390] Elapsed 5m 41s (remain 4m 27s) Loss: 0.0030(0.0097) Grad: 2201.7009  LR: 0.00000029  \n","Epoch: [5][2000/3390] Elapsed 5m 59s (remain 4m 9s) Loss: 0.0012(0.0097) Grad: 2116.7065  LR: 0.00000025  \n","Epoch: [5][2100/3390] Elapsed 6m 16s (remain 3m 51s) Loss: 0.0120(0.0096) Grad: 21852.1602  LR: 0.00000021  \n","Epoch: [5][2200/3390] Elapsed 6m 34s (remain 3m 32s) Loss: 0.0134(0.0096) Grad: 13758.8457  LR: 0.00000018  \n","Epoch: [5][2300/3390] Elapsed 6m 51s (remain 3m 14s) Loss: 0.0105(0.0096) Grad: 26271.8379  LR: 0.00000015  \n","Epoch: [5][2400/3390] Elapsed 7m 9s (remain 2m 57s) Loss: 0.0029(0.0096) Grad: 4062.1047  LR: 0.00000013  \n","Epoch: [5][2500/3390] Elapsed 7m 27s (remain 2m 39s) Loss: 0.0087(0.0096) Grad: 14833.0781  LR: 0.00000010  \n","Epoch: [5][2600/3390] Elapsed 7m 45s (remain 2m 21s) Loss: 0.0138(0.0097) Grad: 9263.7861  LR: 0.00000008  \n","Epoch: [5][2700/3390] Elapsed 8m 2s (remain 2m 3s) Loss: 0.0072(0.0097) Grad: 6705.8838  LR: 0.00000006  \n","Epoch: [5][2800/3390] Elapsed 8m 20s (remain 1m 45s) Loss: 0.0091(0.0097) Grad: 10517.9746  LR: 0.00000004  \n","Epoch: [5][2900/3390] Elapsed 8m 38s (remain 1m 27s) Loss: 0.0143(0.0097) Grad: 4747.3882  LR: 0.00000003  \n","Epoch: [5][3000/3390] Elapsed 8m 56s (remain 1m 9s) Loss: 0.0174(0.0097) Grad: 11549.3477  LR: 0.00000002  \n","Epoch: [5][3100/3390] Elapsed 9m 13s (remain 0m 51s) Loss: 0.0066(0.0097) Grad: 16446.1758  LR: 0.00000001  \n","Epoch: [5][3200/3390] Elapsed 9m 31s (remain 0m 33s) Loss: 0.0107(0.0097) Grad: 2105.3328  LR: 0.00000000  \n","Epoch: [5][3300/3390] Elapsed 9m 49s (remain 0m 15s) Loss: 0.0049(0.0097) Grad: 4366.8735  LR: 0.00000000  \n","Epoch: [5][3389/3390] Elapsed 10m 4s (remain 0m 0s) Loss: 0.0047(0.0097) Grad: 8469.6270  LR: 0.00000000  \n","EVAL: [0/258] Elapsed 0m 0s (remain 1m 31s) Loss: 0.1230(0.1230) \n","EVAL: [100/258] Elapsed 0m 9s (remain 0m 15s) Loss: 0.0273(0.0905) \n","EVAL: [200/258] Elapsed 0m 19s (remain 0m 5s) Loss: 0.1621(0.0956) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0097  avg_val_loss: 0.0960  time: 630s\n","Epoch 5 - Score: 0.7982\n","Epoch 5 - Save Best Score: 0.7982 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [257/258] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0085(0.0960) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 12 result ==========\n","Score: 0.7982\n","========== fold: 13 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3418] Elapsed 0m 0s (remain 25m 7s) Loss: 3.1328(3.1328) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3418] Elapsed 0m 18s (remain 9m 57s) Loss: 0.0876(0.8432) Grad: 3484.6340  LR: 0.00001500  \n","Epoch: [1][200/3418] Elapsed 0m 36s (remain 9m 37s) Loss: 0.0716(0.4759) Grad: 1312.4622  LR: 0.00001500  \n","Epoch: [1][300/3418] Elapsed 0m 53s (remain 9m 16s) Loss: 0.0721(0.3454) Grad: 1940.8646  LR: 0.00001499  \n","Epoch: [1][400/3418] Elapsed 1m 11s (remain 8m 56s) Loss: 0.0643(0.2780) Grad: 1561.8212  LR: 0.00001498  \n","Epoch: [1][500/3418] Elapsed 1m 29s (remain 8m 38s) Loss: 0.0280(0.2361) Grad: 1025.3669  LR: 0.00001497  \n","Epoch: [1][600/3418] Elapsed 1m 46s (remain 8m 19s) Loss: 0.0557(0.2091) Grad: 5483.9175  LR: 0.00001496  \n","Epoch: [1][700/3418] Elapsed 2m 4s (remain 8m 1s) Loss: 0.0578(0.1888) Grad: 2140.7976  LR: 0.00001495  \n","Epoch: [1][800/3418] Elapsed 2m 21s (remain 7m 43s) Loss: 0.1155(0.1729) Grad: 1337.8115  LR: 0.00001493  \n","Epoch: [1][900/3418] Elapsed 2m 39s (remain 7m 26s) Loss: 0.0565(0.1597) Grad: 871.9271  LR: 0.00001491  \n","Epoch: [1][1000/3418] Elapsed 2m 57s (remain 7m 9s) Loss: 0.0438(0.1487) Grad: 919.9314  LR: 0.00001489  \n","Epoch: [1][1100/3418] Elapsed 3m 15s (remain 6m 52s) Loss: 0.0511(0.1404) Grad: 1143.6243  LR: 0.00001486  \n","Epoch: [1][1200/3418] Elapsed 3m 34s (remain 6m 35s) Loss: 0.0447(0.1328) Grad: 960.1576  LR: 0.00001483  \n","Epoch: [1][1300/3418] Elapsed 3m 52s (remain 6m 17s) Loss: 0.0718(0.1261) Grad: 1392.6840  LR: 0.00001480  \n","Epoch: [1][1400/3418] Elapsed 4m 9s (remain 5m 59s) Loss: 0.0717(0.1201) Grad: 1804.5253  LR: 0.00001477  \n","Epoch: [1][1500/3418] Elapsed 4m 27s (remain 5m 42s) Loss: 0.0390(0.1150) Grad: 850.2527  LR: 0.00001473  \n","Epoch: [1][1600/3418] Elapsed 4m 46s (remain 5m 24s) Loss: 0.0256(0.1105) Grad: 899.8598  LR: 0.00001470  \n","Epoch: [1][1700/3418] Elapsed 5m 4s (remain 5m 7s) Loss: 0.0410(0.1064) Grad: 573.9185  LR: 0.00001466  \n","Epoch: [1][1800/3418] Elapsed 5m 22s (remain 4m 49s) Loss: 0.0304(0.1028) Grad: 577.6993  LR: 0.00001461  \n","Epoch: [1][1900/3418] Elapsed 5m 40s (remain 4m 31s) Loss: 0.0203(0.0994) Grad: 1237.6694  LR: 0.00001457  \n","Epoch: [1][2000/3418] Elapsed 5m 57s (remain 4m 13s) Loss: 0.0310(0.0963) Grad: 373.3449  LR: 0.00001452  \n","Epoch: [1][2100/3418] Elapsed 6m 15s (remain 3m 55s) Loss: 0.0459(0.0936) Grad: 1078.1029  LR: 0.00001447  \n","Epoch: [1][2200/3418] Elapsed 6m 33s (remain 3m 37s) Loss: 0.0255(0.0910) Grad: 1262.4061  LR: 0.00001442  \n","Epoch: [1][2300/3418] Elapsed 6m 50s (remain 3m 19s) Loss: 0.0327(0.0886) Grad: 703.6253  LR: 0.00001436  \n","Epoch: [1][2400/3418] Elapsed 7m 8s (remain 3m 1s) Loss: 0.0564(0.0863) Grad: 1744.9877  LR: 0.00001431  \n","Epoch: [1][2500/3418] Elapsed 7m 26s (remain 2m 43s) Loss: 0.0518(0.0843) Grad: 5591.0410  LR: 0.00001425  \n","Epoch: [1][2600/3418] Elapsed 7m 43s (remain 2m 25s) Loss: 0.0118(0.0823) Grad: 413.6083  LR: 0.00001419  \n","Epoch: [1][2700/3418] Elapsed 8m 1s (remain 2m 7s) Loss: 0.0213(0.0804) Grad: 1550.4978  LR: 0.00001412  \n","Epoch: [1][2800/3418] Elapsed 8m 18s (remain 1m 49s) Loss: 0.0335(0.0787) Grad: 789.7971  LR: 0.00001406  \n","Epoch: [1][2900/3418] Elapsed 8m 36s (remain 1m 32s) Loss: 0.0065(0.0771) Grad: 383.9213  LR: 0.00001399  \n","Epoch: [1][3000/3418] Elapsed 8m 54s (remain 1m 14s) Loss: 0.0232(0.0757) Grad: 1018.4008  LR: 0.00001392  \n","Epoch: [1][3100/3418] Elapsed 9m 11s (remain 0m 56s) Loss: 0.0288(0.0743) Grad: 1450.8066  LR: 0.00001384  \n","Epoch: [1][3200/3418] Elapsed 9m 29s (remain 0m 38s) Loss: 0.0228(0.0729) Grad: 671.4370  LR: 0.00001377  \n","Epoch: [1][3300/3418] Elapsed 9m 47s (remain 0m 20s) Loss: 0.0288(0.0717) Grad: 791.7133  LR: 0.00001369  \n","Epoch: [1][3400/3418] Elapsed 10m 4s (remain 0m 3s) Loss: 0.0247(0.0705) Grad: 1497.7675  LR: 0.00001361  \n","Epoch: [1][3417/3418] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0501(0.0703) Grad: 1431.6515  LR: 0.00001360  \n","EVAL: [0/230] Elapsed 0m 0s (remain 1m 21s) Loss: 0.1823(0.1823) \n","EVAL: [100/230] Elapsed 0m 9s (remain 0m 12s) Loss: 0.1886(0.1085) \n","EVAL: [200/230] Elapsed 0m 19s (remain 0m 2s) Loss: 0.0691(0.1026) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0703  avg_val_loss: 0.1022  time: 631s\n","Epoch 1 - Score: 0.7738\n","Epoch 1 - Save Best Score: 0.7738 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [229/230] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0174(0.1022) \n","Epoch: [2][0/3418] Elapsed 0m 0s (remain 26m 49s) Loss: 0.0231(0.0231) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3418] Elapsed 0m 18s (remain 10m 5s) Loss: 0.0249(0.0255) Grad: 73369.0078  LR: 0.00001352  \n","Epoch: [2][200/3418] Elapsed 0m 36s (remain 9m 50s) Loss: 0.0126(0.0260) Grad: 52521.9258  LR: 0.00001343  \n","Epoch: [2][300/3418] Elapsed 0m 54s (remain 9m 25s) Loss: 0.0102(0.0256) Grad: 27503.6465  LR: 0.00001335  \n","Epoch: [2][400/3418] Elapsed 1m 12s (remain 9m 4s) Loss: 0.0411(0.0255) Grad: 158290.5469  LR: 0.00001326  \n","Epoch: [2][500/3418] Elapsed 1m 30s (remain 8m 44s) Loss: 0.0344(0.0256) Grad: 74249.8828  LR: 0.00001317  \n","Epoch: [2][600/3418] Elapsed 1m 47s (remain 8m 25s) Loss: 0.0149(0.0251) Grad: 13589.9102  LR: 0.00001308  \n","Epoch: [2][700/3418] Elapsed 2m 5s (remain 8m 6s) Loss: 0.0135(0.0246) Grad: 46901.5938  LR: 0.00001299  \n","Epoch: [2][800/3418] Elapsed 2m 23s (remain 7m 47s) Loss: 0.0360(0.0243) Grad: 71417.9141  LR: 0.00001289  \n","Epoch: [2][900/3418] Elapsed 2m 40s (remain 7m 28s) Loss: 0.0542(0.0244) Grad: 44893.3555  LR: 0.00001279  \n","Epoch: [2][1000/3418] Elapsed 2m 58s (remain 7m 11s) Loss: 0.0354(0.0247) Grad: 34182.7227  LR: 0.00001270  \n","Epoch: [2][1100/3418] Elapsed 3m 16s (remain 6m 54s) Loss: 0.0214(0.0247) Grad: 53531.2305  LR: 0.00001260  \n","Epoch: [2][1200/3418] Elapsed 3m 34s (remain 6m 36s) Loss: 0.0113(0.0245) Grad: 43506.8242  LR: 0.00001249  \n","Epoch: [2][1300/3418] Elapsed 3m 53s (remain 6m 19s) Loss: 0.0165(0.0245) Grad: 29966.9004  LR: 0.00001239  \n","Epoch: [2][1400/3418] Elapsed 4m 11s (remain 6m 1s) Loss: 0.0182(0.0244) Grad: 15335.6807  LR: 0.00001228  \n","Epoch: [2][1500/3418] Elapsed 4m 29s (remain 5m 43s) Loss: 0.0203(0.0245) Grad: 47956.6133  LR: 0.00001218  \n","Epoch: [2][1600/3418] Elapsed 4m 47s (remain 5m 26s) Loss: 0.0081(0.0244) Grad: 21199.2012  LR: 0.00001207  \n","Epoch: [2][1700/3418] Elapsed 5m 5s (remain 5m 8s) Loss: 0.0215(0.0242) Grad: 19575.7109  LR: 0.00001196  \n","Epoch: [2][1800/3418] Elapsed 5m 23s (remain 4m 50s) Loss: 0.0119(0.0242) Grad: 35532.7812  LR: 0.00001184  \n","Epoch: [2][1900/3418] Elapsed 5m 41s (remain 4m 32s) Loss: 0.0168(0.0242) Grad: 40510.2344  LR: 0.00001173  \n","Epoch: [2][2000/3418] Elapsed 5m 59s (remain 4m 14s) Loss: 0.0138(0.0242) Grad: 15686.5967  LR: 0.00001162  \n","Epoch: [2][2100/3418] Elapsed 6m 17s (remain 3m 56s) Loss: 0.0189(0.0241) Grad: 25585.3184  LR: 0.00001150  \n","Epoch: [2][2200/3418] Elapsed 6m 35s (remain 3m 38s) Loss: 0.0343(0.0238) Grad: 32089.8516  LR: 0.00001138  \n","Epoch: [2][2300/3418] Elapsed 6m 53s (remain 3m 20s) Loss: 0.0205(0.0238) Grad: 38611.1367  LR: 0.00001126  \n","Epoch: [2][2400/3418] Elapsed 7m 10s (remain 3m 2s) Loss: 0.0076(0.0237) Grad: 12680.7529  LR: 0.00001114  \n","Epoch: [2][2500/3418] Elapsed 7m 28s (remain 2m 44s) Loss: 0.0055(0.0237) Grad: 11689.1426  LR: 0.00001102  \n","Epoch: [2][2600/3418] Elapsed 7m 46s (remain 2m 26s) Loss: 0.0153(0.0236) Grad: 116997.0078  LR: 0.00001090  \n","Epoch: [2][2700/3418] Elapsed 8m 4s (remain 2m 8s) Loss: 0.0262(0.0235) Grad: 37692.9922  LR: 0.00001078  \n","Epoch: [2][2800/3418] Elapsed 8m 21s (remain 1m 50s) Loss: 0.0086(0.0235) Grad: 34391.5352  LR: 0.00001065  \n","Epoch: [2][2900/3418] Elapsed 8m 39s (remain 1m 32s) Loss: 0.0187(0.0235) Grad: 52226.7734  LR: 0.00001052  \n","Epoch: [2][3000/3418] Elapsed 8m 57s (remain 1m 14s) Loss: 0.0117(0.0234) Grad: 31250.0586  LR: 0.00001040  \n","Epoch: [2][3100/3418] Elapsed 9m 14s (remain 0m 56s) Loss: 0.0257(0.0233) Grad: 80893.0781  LR: 0.00001027  \n","Epoch: [2][3200/3418] Elapsed 9m 32s (remain 0m 38s) Loss: 0.0206(0.0234) Grad: 52316.9336  LR: 0.00001014  \n","Epoch: [2][3300/3418] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0175(0.0233) Grad: 58232.2266  LR: 0.00001001  \n","Epoch: [2][3400/3418] Elapsed 10m 8s (remain 0m 3s) Loss: 0.0199(0.0232) Grad: 69872.8516  LR: 0.00000988  \n","Epoch: [2][3417/3418] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0404(0.0232) Grad: 76620.2812  LR: 0.00000986  \n","EVAL: [0/230] Elapsed 0m 0s (remain 1m 18s) Loss: 0.1667(0.1667) \n","EVAL: [100/230] Elapsed 0m 9s (remain 0m 12s) Loss: 0.1796(0.1044) \n","EVAL: [200/230] Elapsed 0m 19s (remain 0m 2s) Loss: 0.0635(0.0985) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0232  avg_val_loss: 0.0980  time: 634s\n","Epoch 2 - Score: 0.7915\n","Epoch 2 - Save Best Score: 0.7915 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [229/230] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0182(0.0980) \n","Epoch: [3][0/3418] Elapsed 0m 0s (remain 26m 5s) Loss: 0.0302(0.0302) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3418] Elapsed 0m 18s (remain 10m 4s) Loss: 0.0187(0.0223) Grad: 56645.8945  LR: 0.00000972  \n","Epoch: [3][200/3418] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0143(0.0219) Grad: 52812.0391  LR: 0.00000959  \n","Epoch: [3][300/3418] Elapsed 0m 54s (remain 9m 20s) Loss: 0.0133(0.0213) Grad: 57542.3477  LR: 0.00000946  \n","Epoch: [3][400/3418] Elapsed 1m 11s (remain 8m 59s) Loss: 0.0362(0.0208) Grad: 37913.2266  LR: 0.00000933  \n","Epoch: [3][500/3418] Elapsed 1m 29s (remain 8m 40s) Loss: 0.0209(0.0208) Grad: 36378.3281  LR: 0.00000919  \n","Epoch: [3][600/3418] Elapsed 1m 47s (remain 8m 21s) Loss: 0.0035(0.0207) Grad: 56452.5859  LR: 0.00000906  \n","Epoch: [3][700/3418] Elapsed 2m 4s (remain 8m 3s) Loss: 0.0729(0.0208) Grad: 112324.7500  LR: 0.00000892  \n","Epoch: [3][800/3418] Elapsed 2m 22s (remain 7m 46s) Loss: 0.0282(0.0208) Grad: 66129.1641  LR: 0.00000878  \n","Epoch: [3][900/3418] Elapsed 2m 40s (remain 7m 29s) Loss: 0.0219(0.0208) Grad: 42729.5820  LR: 0.00000865  \n","Epoch: [3][1000/3418] Elapsed 2m 59s (remain 7m 12s) Loss: 0.0113(0.0210) Grad: 74144.2422  LR: 0.00000851  \n","Epoch: [3][1100/3418] Elapsed 3m 17s (remain 6m 55s) Loss: 0.0117(0.0210) Grad: 39556.4062  LR: 0.00000837  \n","Epoch: [3][1200/3418] Elapsed 3m 35s (remain 6m 37s) Loss: 0.0153(0.0208) Grad: 21730.5000  LR: 0.00000824  \n","Epoch: [3][1300/3418] Elapsed 3m 53s (remain 6m 20s) Loss: 0.0143(0.0207) Grad: 44441.2617  LR: 0.00000810  \n","Epoch: [3][1400/3418] Elapsed 4m 11s (remain 6m 2s) Loss: 0.0160(0.0206) Grad: 40503.1016  LR: 0.00000796  \n","Epoch: [3][1500/3418] Elapsed 4m 30s (remain 5m 44s) Loss: 0.0256(0.0206) Grad: 94627.9922  LR: 0.00000782  \n","Epoch: [3][1600/3418] Elapsed 4m 48s (remain 5m 27s) Loss: 0.0328(0.0206) Grad: 62246.9102  LR: 0.00000768  \n","Epoch: [3][1700/3418] Elapsed 5m 6s (remain 5m 9s) Loss: 0.0054(0.0206) Grad: 41120.7891  LR: 0.00000755  \n","Epoch: [3][1800/3418] Elapsed 5m 24s (remain 4m 51s) Loss: 0.0687(0.0207) Grad: 80789.8672  LR: 0.00000741  \n","Epoch: [3][1900/3418] Elapsed 5m 42s (remain 4m 33s) Loss: 0.0368(0.0209) Grad: 64383.6367  LR: 0.00000727  \n","Epoch: [3][2000/3418] Elapsed 6m 0s (remain 4m 14s) Loss: 0.0101(0.0209) Grad: 51092.1562  LR: 0.00000713  \n","Epoch: [3][2100/3418] Elapsed 6m 17s (remain 3m 56s) Loss: 0.0303(0.0209) Grad: 105322.5078  LR: 0.00000699  \n","Epoch: [3][2200/3418] Elapsed 6m 35s (remain 3m 38s) Loss: 0.0211(0.0209) Grad: 99223.2578  LR: 0.00000686  \n","Epoch: [3][2300/3418] Elapsed 6m 53s (remain 3m 20s) Loss: 0.0189(0.0208) Grad: 254730.3906  LR: 0.00000672  \n","Epoch: [3][2400/3418] Elapsed 7m 10s (remain 3m 2s) Loss: 0.0382(0.0208) Grad: 45840.7148  LR: 0.00000658  \n","Epoch: [3][2500/3418] Elapsed 7m 28s (remain 2m 44s) Loss: 0.0156(0.0208) Grad: 55688.3516  LR: 0.00000644  \n","Epoch: [3][2600/3418] Elapsed 7m 46s (remain 2m 26s) Loss: 0.0138(0.0207) Grad: 59469.5977  LR: 0.00000631  \n","Epoch: [3][2700/3418] Elapsed 8m 4s (remain 2m 8s) Loss: 0.0182(0.0207) Grad: 45664.3789  LR: 0.00000617  \n","Epoch: [3][2800/3418] Elapsed 8m 22s (remain 1m 50s) Loss: 0.0428(0.0208) Grad: 90432.0859  LR: 0.00000603  \n","Epoch: [3][2900/3418] Elapsed 8m 39s (remain 1m 32s) Loss: 0.0041(0.0208) Grad: 51326.3633  LR: 0.00000590  \n","Epoch: [3][3000/3418] Elapsed 8m 57s (remain 1m 14s) Loss: 0.0573(0.0208) Grad: 69614.4844  LR: 0.00000576  \n","Epoch: [3][3100/3418] Elapsed 9m 15s (remain 0m 56s) Loss: 0.0158(0.0208) Grad: 73506.0859  LR: 0.00000563  \n","Epoch: [3][3200/3418] Elapsed 9m 33s (remain 0m 38s) Loss: 0.0115(0.0208) Grad: 46614.2969  LR: 0.00000550  \n","Epoch: [3][3300/3418] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0143(0.0208) Grad: 32360.1719  LR: 0.00000536  \n","Epoch: [3][3400/3418] Elapsed 10m 8s (remain 0m 3s) Loss: 0.0140(0.0208) Grad: 20272.2070  LR: 0.00000523  \n","Epoch: [3][3417/3418] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0154(0.0208) Grad: 18407.4863  LR: 0.00000521  \n","EVAL: [0/230] Elapsed 0m 0s (remain 1m 17s) Loss: 0.1652(0.1652) \n","EVAL: [100/230] Elapsed 0m 9s (remain 0m 12s) Loss: 0.1789(0.1020) \n","EVAL: [200/230] Elapsed 0m 19s (remain 0m 2s) Loss: 0.0628(0.0960) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0208  avg_val_loss: 0.0955  time: 634s\n","Epoch 3 - Score: 0.7886\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [229/230] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0205(0.0955) \n","Epoch: [4][0/3418] Elapsed 0m 0s (remain 25m 57s) Loss: 0.0218(0.0218) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3418] Elapsed 0m 18s (remain 9m 59s) Loss: 0.0101(0.0197) Grad: 45970.3516  LR: 0.00000508  \n","Epoch: [4][200/3418] Elapsed 0m 36s (remain 9m 36s) Loss: 0.0067(0.0187) Grad: 22369.9355  LR: 0.00000495  \n","Epoch: [4][300/3418] Elapsed 0m 53s (remain 9m 16s) Loss: 0.0317(0.0182) Grad: 54162.7617  LR: 0.00000482  \n","Epoch: [4][400/3418] Elapsed 1m 11s (remain 8m 58s) Loss: 0.0173(0.0183) Grad: 46416.3320  LR: 0.00000469  \n","Epoch: [4][500/3418] Elapsed 1m 29s (remain 8m 39s) Loss: 0.0254(0.0181) Grad: 88007.4141  LR: 0.00000456  \n","Epoch: [4][600/3418] Elapsed 1m 46s (remain 8m 21s) Loss: 0.0225(0.0180) Grad: 52049.0117  LR: 0.00000443  \n","Epoch: [4][700/3418] Elapsed 2m 5s (remain 8m 4s) Loss: 0.0087(0.0180) Grad: 32663.5371  LR: 0.00000431  \n","Epoch: [4][800/3418] Elapsed 2m 23s (remain 7m 48s) Loss: 0.0300(0.0180) Grad: 58912.4180  LR: 0.00000418  \n","Epoch: [4][900/3418] Elapsed 2m 41s (remain 7m 31s) Loss: 0.0274(0.0183) Grad: 108855.3906  LR: 0.00000406  \n","Epoch: [4][1000/3418] Elapsed 2m 59s (remain 7m 13s) Loss: 0.0583(0.0186) Grad: 70387.7812  LR: 0.00000394  \n","Epoch: [4][1100/3418] Elapsed 3m 17s (remain 6m 56s) Loss: 0.0095(0.0187) Grad: 32695.4785  LR: 0.00000382  \n","Epoch: [4][1200/3418] Elapsed 3m 35s (remain 6m 38s) Loss: 0.0153(0.0187) Grad: 17242.4180  LR: 0.00000370  \n","Epoch: [4][1300/3418] Elapsed 3m 54s (remain 6m 21s) Loss: 0.0118(0.0188) Grad: 10753.5088  LR: 0.00000358  \n","Epoch: [4][1400/3418] Elapsed 4m 12s (remain 6m 3s) Loss: 0.0106(0.0189) Grad: 11237.0098  LR: 0.00000346  \n","Epoch: [4][1500/3418] Elapsed 4m 30s (remain 5m 45s) Loss: 0.0517(0.0188) Grad: 49829.4961  LR: 0.00000335  \n","Epoch: [4][1600/3418] Elapsed 4m 48s (remain 5m 27s) Loss: 0.0151(0.0190) Grad: 41247.2891  LR: 0.00000323  \n","Epoch: [4][1700/3418] Elapsed 5m 6s (remain 5m 9s) Loss: 0.0046(0.0190) Grad: 10430.5283  LR: 0.00000312  \n","Epoch: [4][1800/3418] Elapsed 5m 24s (remain 4m 51s) Loss: 0.0186(0.0190) Grad: 18891.1758  LR: 0.00000301  \n","Epoch: [4][1900/3418] Elapsed 5m 41s (remain 4m 32s) Loss: 0.0124(0.0190) Grad: 20893.2012  LR: 0.00000290  \n","Epoch: [4][2000/3418] Elapsed 5m 59s (remain 4m 14s) Loss: 0.0208(0.0190) Grad: 70896.9062  LR: 0.00000279  \n","Epoch: [4][2100/3418] Elapsed 6m 17s (remain 3m 56s) Loss: 0.0294(0.0189) Grad: 53233.6719  LR: 0.00000268  \n","Epoch: [4][2200/3418] Elapsed 6m 35s (remain 3m 38s) Loss: 0.0178(0.0188) Grad: 42499.1211  LR: 0.00000258  \n","Epoch: [4][2300/3418] Elapsed 6m 53s (remain 3m 20s) Loss: 0.0093(0.0189) Grad: 17081.1582  LR: 0.00000247  \n","Epoch: [4][2400/3418] Elapsed 7m 10s (remain 3m 2s) Loss: 0.0051(0.0189) Grad: 11047.5898  LR: 0.00000237  \n","Epoch: [4][2500/3418] Elapsed 7m 28s (remain 2m 44s) Loss: 0.0089(0.0189) Grad: 19977.7969  LR: 0.00000227  \n","Epoch: [4][2600/3418] Elapsed 7m 46s (remain 2m 26s) Loss: 0.0097(0.0188) Grad: 15289.8896  LR: 0.00000217  \n","Epoch: [4][2700/3418] Elapsed 8m 4s (remain 2m 8s) Loss: 0.0100(0.0188) Grad: 22163.5410  LR: 0.00000208  \n","Epoch: [4][2800/3418] Elapsed 8m 21s (remain 1m 50s) Loss: 0.0067(0.0188) Grad: 29098.6191  LR: 0.00000198  \n","Epoch: [4][2900/3418] Elapsed 8m 39s (remain 1m 32s) Loss: 0.0338(0.0187) Grad: 38778.0273  LR: 0.00000189  \n","Epoch: [4][3000/3418] Elapsed 8m 57s (remain 1m 14s) Loss: 0.0158(0.0187) Grad: 56377.7461  LR: 0.00000180  \n","Epoch: [4][3100/3418] Elapsed 9m 14s (remain 0m 56s) Loss: 0.0232(0.0187) Grad: 79536.5234  LR: 0.00000171  \n","Epoch: [4][3200/3418] Elapsed 9m 32s (remain 0m 38s) Loss: 0.0187(0.0186) Grad: 32452.7051  LR: 0.00000162  \n","Epoch: [4][3300/3418] Elapsed 9m 50s (remain 0m 20s) Loss: 0.0220(0.0187) Grad: 74253.9922  LR: 0.00000154  \n","Epoch: [4][3400/3418] Elapsed 10m 8s (remain 0m 3s) Loss: 0.0092(0.0186) Grad: 33766.4922  LR: 0.00000146  \n","Epoch: [4][3417/3418] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0108(0.0186) Grad: 30374.8047  LR: 0.00000144  \n","EVAL: [0/230] Elapsed 0m 0s (remain 1m 17s) Loss: 0.1636(0.1636) \n","EVAL: [100/230] Elapsed 0m 9s (remain 0m 12s) Loss: 0.1796(0.1033) \n","EVAL: [200/230] Elapsed 0m 19s (remain 0m 2s) Loss: 0.0626(0.0975) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0186  avg_val_loss: 0.0970  time: 634s\n","Epoch 4 - Score: 0.7975\n","Epoch 4 - Save Best Score: 0.7975 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [229/230] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0197(0.0970) \n","Epoch: [5][0/3418] Elapsed 0m 0s (remain 27m 17s) Loss: 0.0168(0.0168) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3418] Elapsed 0m 18s (remain 10m 10s) Loss: 0.0113(0.0145) Grad: 25961.0449  LR: 0.00000136  \n","Epoch: [5][200/3418] Elapsed 0m 36s (remain 9m 46s) Loss: 0.0146(0.0160) Grad: nan  LR: 0.00000128  \n","Epoch: [5][300/3418] Elapsed 0m 54s (remain 9m 22s) Loss: 0.0088(0.0154) Grad: 10126.3115  LR: 0.00000121  \n","Epoch: [5][400/3418] Elapsed 1m 12s (remain 9m 2s) Loss: 0.0099(0.0150) Grad: 15761.7500  LR: 0.00000113  \n","Epoch: [5][500/3418] Elapsed 1m 29s (remain 8m 42s) Loss: 0.0523(0.0152) Grad: 66206.9844  LR: 0.00000106  \n","Epoch: [5][600/3418] Elapsed 1m 47s (remain 8m 22s) Loss: 0.0176(0.0157) Grad: 30262.7109  LR: 0.00000099  \n","Epoch: [5][700/3418] Elapsed 2m 5s (remain 8m 5s) Loss: 0.0190(0.0157) Grad: 32796.1719  LR: 0.00000092  \n","Epoch: [5][800/3418] Elapsed 2m 23s (remain 7m 48s) Loss: 0.0160(0.0157) Grad: 31079.0820  LR: 0.00000086  \n","Epoch: [5][900/3418] Elapsed 2m 41s (remain 7m 31s) Loss: 0.0078(0.0159) Grad: 18431.1895  LR: 0.00000079  \n","Epoch: [5][1000/3418] Elapsed 2m 59s (remain 7m 13s) Loss: 0.0034(0.0158) Grad: 7921.8901  LR: 0.00000073  \n","Epoch: [5][1100/3418] Elapsed 3m 17s (remain 6m 56s) Loss: 0.0176(0.0158) Grad: 24782.9902  LR: 0.00000067  \n","Epoch: [5][1200/3418] Elapsed 3m 35s (remain 6m 38s) Loss: 0.0127(0.0159) Grad: 15659.7783  LR: 0.00000062  \n","Epoch: [5][1300/3418] Elapsed 3m 54s (remain 6m 20s) Loss: 0.0114(0.0157) Grad: 21406.2793  LR: 0.00000056  \n","Epoch: [5][1400/3418] Elapsed 4m 12s (remain 6m 2s) Loss: 0.0061(0.0157) Grad: 8585.5684  LR: 0.00000051  \n","Epoch: [5][1500/3418] Elapsed 4m 30s (remain 5m 45s) Loss: 0.0016(0.0157) Grad: 8605.6553  LR: 0.00000046  \n","Epoch: [5][1600/3418] Elapsed 4m 48s (remain 5m 27s) Loss: 0.0139(0.0156) Grad: 17244.9941  LR: 0.00000042  \n","Epoch: [5][1700/3418] Elapsed 5m 6s (remain 5m 9s) Loss: 0.0121(0.0156) Grad: 28366.8457  LR: 0.00000037  \n","Epoch: [5][1800/3418] Elapsed 5m 24s (remain 4m 51s) Loss: 0.0147(0.0156) Grad: 16540.3457  LR: 0.00000033  \n","Epoch: [5][1900/3418] Elapsed 5m 41s (remain 4m 32s) Loss: 0.0134(0.0157) Grad: 13546.1982  LR: 0.00000029  \n","Epoch: [5][2000/3418] Elapsed 5m 59s (remain 4m 14s) Loss: 0.0203(0.0156) Grad: 16275.3877  LR: 0.00000025  \n","Epoch: [5][2100/3418] Elapsed 6m 17s (remain 3m 56s) Loss: 0.0097(0.0157) Grad: 28136.7656  LR: 0.00000022  \n","Epoch: [5][2200/3418] Elapsed 6m 35s (remain 3m 38s) Loss: 0.0038(0.0157) Grad: 8487.1973  LR: 0.00000019  \n","Epoch: [5][2300/3418] Elapsed 6m 53s (remain 3m 20s) Loss: 0.0165(0.0156) Grad: 77800.5938  LR: 0.00000016  \n","Epoch: [5][2400/3418] Elapsed 7m 10s (remain 3m 2s) Loss: 0.0070(0.0157) Grad: 31802.3340  LR: 0.00000013  \n","Epoch: [5][2500/3418] Elapsed 7m 28s (remain 2m 44s) Loss: 0.0150(0.0158) Grad: 48423.7422  LR: 0.00000011  \n","Epoch: [5][2600/3418] Elapsed 7m 46s (remain 2m 26s) Loss: 0.0066(0.0157) Grad: 36242.9141  LR: 0.00000009  \n","Epoch: [5][2700/3418] Elapsed 8m 4s (remain 2m 8s) Loss: 0.0219(0.0157) Grad: 58755.6680  LR: 0.00000007  \n","Epoch: [5][2800/3418] Elapsed 8m 22s (remain 1m 50s) Loss: 0.0311(0.0157) Grad: 173649.7031  LR: 0.00000005  \n","Epoch: [5][2900/3418] Elapsed 8m 40s (remain 1m 32s) Loss: 0.0061(0.0157) Grad: 25904.3730  LR: 0.00000003  \n","Epoch: [5][3000/3418] Elapsed 8m 57s (remain 1m 14s) Loss: 0.0040(0.0158) Grad: 25015.4746  LR: 0.00000002  \n","Epoch: [5][3100/3418] Elapsed 9m 15s (remain 0m 56s) Loss: 0.0084(0.0158) Grad: 87142.2031  LR: 0.00000001  \n","Epoch: [5][3200/3418] Elapsed 9m 33s (remain 0m 38s) Loss: 0.0208(0.0158) Grad: 50302.5273  LR: 0.00000001  \n","Epoch: [5][3300/3418] Elapsed 9m 51s (remain 0m 20s) Loss: 0.0120(0.0158) Grad: 39614.6641  LR: 0.00000000  \n","Epoch: [5][3400/3418] Elapsed 10m 8s (remain 0m 3s) Loss: 0.0096(0.0159) Grad: 44834.5938  LR: 0.00000000  \n","Epoch: [5][3417/3418] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0193(0.0159) Grad: 52841.2617  LR: 0.00000000  \n","EVAL: [0/230] Elapsed 0m 0s (remain 1m 18s) Loss: 0.1628(0.1628) \n","EVAL: [100/230] Elapsed 0m 9s (remain 0m 12s) Loss: 0.1793(0.1031) \n","EVAL: [200/230] Elapsed 0m 19s (remain 0m 2s) Loss: 0.0614(0.0973) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0159  avg_val_loss: 0.0968  time: 634s\n","Epoch 5 - Score: 0.7987\n","Epoch 5 - Save Best Score: 0.7987 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [229/230] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0213(0.0968) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 13 result ==========\n","Score: 0.7987\n","========== fold: 14 training ==========\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3405] Elapsed 0m 0s (remain 25m 16s) Loss: 0.4099(0.4099) Grad: nan  LR: 0.00000030  \n","Epoch: [1][100/3405] Elapsed 0m 18s (remain 10m 13s) Loss: 0.1257(0.1570) Grad: 9839.6846  LR: 0.00001500  \n","Epoch: [1][200/3405] Elapsed 0m 36s (remain 9m 43s) Loss: 0.0813(0.1191) Grad: 2399.1306  LR: 0.00001500  \n","Epoch: [1][300/3405] Elapsed 0m 54s (remain 9m 21s) Loss: 0.1207(0.1027) Grad: 16822.8613  LR: 0.00001499  \n","Epoch: [1][400/3405] Elapsed 1m 12s (remain 8m 59s) Loss: 0.0815(0.1104) Grad: 9463.7705  LR: 0.00001498  \n","Epoch: [1][500/3405] Elapsed 1m 29s (remain 8m 39s) Loss: 0.1863(0.1110) Grad: 4565.9512  LR: 0.00001497  \n","Epoch: [1][600/3405] Elapsed 1m 47s (remain 8m 22s) Loss: 0.0403(0.1102) Grad: 7890.7651  LR: 0.00001496  \n","Epoch: [1][700/3405] Elapsed 2m 5s (remain 8m 5s) Loss: 0.0778(0.1048) Grad: 5248.5918  LR: 0.00001495  \n","Epoch: [1][800/3405] Elapsed 2m 23s (remain 7m 48s) Loss: 0.0380(0.0994) Grad: 2319.0679  LR: 0.00001493  \n","Epoch: [1][900/3405] Elapsed 2m 42s (remain 7m 30s) Loss: 0.0369(0.0938) Grad: 1874.7179  LR: 0.00001491  \n","Epoch: [1][1000/3405] Elapsed 3m 0s (remain 7m 12s) Loss: 0.0790(0.0892) Grad: 7739.1050  LR: 0.00001488  \n","Epoch: [1][1100/3405] Elapsed 3m 18s (remain 6m 55s) Loss: 0.0492(0.0856) Grad: 2389.6526  LR: 0.00001486  \n","Epoch: [1][1200/3405] Elapsed 3m 36s (remain 6m 37s) Loss: 0.0627(0.0820) Grad: 3164.9749  LR: 0.00001483  \n","Epoch: [1][1300/3405] Elapsed 3m 54s (remain 6m 19s) Loss: 0.0516(0.0791) Grad: 1403.8179  LR: 0.00001480  \n","Epoch: [1][1400/3405] Elapsed 4m 12s (remain 6m 1s) Loss: 0.0705(0.0762) Grad: 4679.9487  LR: 0.00001477  \n","Epoch: [1][1500/3405] Elapsed 4m 30s (remain 5m 43s) Loss: 0.0232(0.0736) Grad: 1542.0916  LR: 0.00001473  \n","Epoch: [1][1600/3405] Elapsed 4m 48s (remain 5m 25s) Loss: 0.0345(0.0717) Grad: 6352.0596  LR: 0.00001469  \n","Epoch: [1][1700/3405] Elapsed 5m 6s (remain 5m 6s) Loss: 0.0157(0.0696) Grad: 981.7532  LR: 0.00001465  \n","Epoch: [1][1800/3405] Elapsed 5m 24s (remain 4m 48s) Loss: 0.0469(0.0679) Grad: 3712.7891  LR: 0.00001461  \n","Epoch: [1][1900/3405] Elapsed 5m 41s (remain 4m 30s) Loss: 0.0685(0.0662) Grad: 2879.2712  LR: 0.00001456  \n","Epoch: [1][2000/3405] Elapsed 5m 59s (remain 4m 12s) Loss: 0.0508(0.0645) Grad: 29214.5938  LR: 0.00001452  \n","Epoch: [1][2100/3405] Elapsed 6m 17s (remain 3m 54s) Loss: 0.0291(0.0629) Grad: 4545.2905  LR: 0.00001447  \n","Epoch: [1][2200/3405] Elapsed 6m 35s (remain 3m 36s) Loss: 0.0511(0.0612) Grad: 3161.3728  LR: 0.00001441  \n","Epoch: [1][2300/3405] Elapsed 6m 52s (remain 3m 18s) Loss: 0.0345(0.0599) Grad: 3564.3782  LR: 0.00001436  \n","Epoch: [1][2400/3405] Elapsed 7m 10s (remain 2m 59s) Loss: 0.0267(0.0587) Grad: 2659.7305  LR: 0.00001430  \n","Epoch: [1][2500/3405] Elapsed 7m 28s (remain 2m 41s) Loss: 0.0217(0.0577) Grad: 4096.3169  LR: 0.00001424  \n","Epoch: [1][2600/3405] Elapsed 7m 45s (remain 2m 23s) Loss: 0.0111(0.0566) Grad: 2293.9331  LR: 0.00001418  \n","Epoch: [1][2700/3405] Elapsed 8m 3s (remain 2m 5s) Loss: 0.0458(0.0556) Grad: 8850.9160  LR: 0.00001412  \n","Epoch: [1][2800/3405] Elapsed 8m 21s (remain 1m 48s) Loss: 0.0389(0.0545) Grad: 2979.2939  LR: 0.00001405  \n","Epoch: [1][2900/3405] Elapsed 8m 38s (remain 1m 30s) Loss: 0.0452(0.0536) Grad: 5100.3911  LR: 0.00001398  \n","Epoch: [1][3000/3405] Elapsed 8m 56s (remain 1m 12s) Loss: 0.0126(0.0528) Grad: 1568.3716  LR: 0.00001391  \n","Epoch: [1][3100/3405] Elapsed 9m 14s (remain 0m 54s) Loss: 0.0325(0.0520) Grad: 5541.8354  LR: 0.00001384  \n","Epoch: [1][3200/3405] Elapsed 9m 31s (remain 0m 36s) Loss: 0.0496(0.0513) Grad: 45473.0625  LR: 0.00001376  \n","Epoch: [1][3300/3405] Elapsed 9m 49s (remain 0m 18s) Loss: 0.0432(0.0508) Grad: 6847.2549  LR: 0.00001368  \n","Epoch: [1][3400/3405] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0460(0.0503) Grad: 4364.8203  LR: 0.00001360  \n","Epoch: [1][3404/3405] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0261(0.0503) Grad: 2213.3691  LR: 0.00001360  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 28s) Loss: 0.0779(0.0779) \n","EVAL: [100/243] Elapsed 0m 10s (remain 0m 14s) Loss: 0.0526(0.0985) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0643(0.1007) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0503  avg_val_loss: 0.1028  time: 632s\n","Epoch 1 - Score: 0.7610\n","Epoch 1 - Save Best Score: 0.7610 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0091(0.1028) \n","Epoch: [2][0/3405] Elapsed 0m 0s (remain 26m 33s) Loss: 0.0167(0.0167) Grad: nan  LR: 0.00001360  \n","Epoch: [2][100/3405] Elapsed 0m 18s (remain 10m 9s) Loss: 0.0115(0.0229) Grad: 13058.0527  LR: 0.00001352  \n","Epoch: [2][200/3405] Elapsed 0m 36s (remain 9m 49s) Loss: 0.0418(0.0231) Grad: 48459.6562  LR: 0.00001343  \n","Epoch: [2][300/3405] Elapsed 0m 54s (remain 9m 23s) Loss: 0.0160(0.0230) Grad: 19880.9844  LR: 0.00001335  \n","Epoch: [2][400/3405] Elapsed 1m 12s (remain 9m 6s) Loss: 0.0393(0.0235) Grad: 42654.5352  LR: 0.00001326  \n","Epoch: [2][500/3405] Elapsed 1m 31s (remain 8m 48s) Loss: 0.0238(0.0227) Grad: 29586.2402  LR: 0.00001317  \n","Epoch: [2][600/3405] Elapsed 1m 49s (remain 8m 29s) Loss: 0.0343(0.0226) Grad: nan  LR: 0.00001308  \n","Epoch: [2][700/3405] Elapsed 2m 7s (remain 8m 11s) Loss: 0.0210(0.0225) Grad: 9459.9209  LR: 0.00001298  \n","Epoch: [2][800/3405] Elapsed 2m 25s (remain 7m 53s) Loss: 0.0094(0.0227) Grad: 3450.1929  LR: 0.00001289  \n","Epoch: [2][900/3405] Elapsed 2m 43s (remain 7m 34s) Loss: 0.0155(0.0231) Grad: 5706.7202  LR: 0.00001279  \n","Epoch: [2][1000/3405] Elapsed 3m 1s (remain 7m 16s) Loss: 0.0111(0.0232) Grad: 5562.7344  LR: 0.00001269  \n","Epoch: [2][1100/3405] Elapsed 3m 19s (remain 6m 58s) Loss: 0.0194(0.0234) Grad: 4623.8657  LR: 0.00001259  \n","Epoch: [2][1200/3405] Elapsed 3m 37s (remain 6m 40s) Loss: 0.0245(0.0233) Grad: 5169.9233  LR: 0.00001249  \n","Epoch: [2][1300/3405] Elapsed 3m 56s (remain 6m 21s) Loss: 0.0089(0.0233) Grad: 3600.6589  LR: 0.00001238  \n","Epoch: [2][1400/3405] Elapsed 4m 14s (remain 6m 3s) Loss: 0.0134(0.0232) Grad: 4518.6851  LR: 0.00001228  \n","Epoch: [2][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0166(0.0234) Grad: 4307.8335  LR: 0.00001217  \n","Epoch: [2][1600/3405] Elapsed 4m 49s (remain 5m 26s) Loss: 0.0233(0.0234) Grad: 6437.8682  LR: 0.00001206  \n","Epoch: [2][1700/3405] Elapsed 5m 7s (remain 5m 8s) Loss: 0.0176(0.0234) Grad: 6678.2637  LR: 0.00001195  \n","Epoch: [2][1800/3405] Elapsed 5m 25s (remain 4m 49s) Loss: 0.0244(0.0234) Grad: 13800.7109  LR: 0.00001184  \n","Epoch: [2][1900/3405] Elapsed 5m 43s (remain 4m 31s) Loss: 0.0060(0.0235) Grad: 1873.3423  LR: 0.00001172  \n","Epoch: [2][2000/3405] Elapsed 6m 0s (remain 4m 13s) Loss: 0.0676(0.0235) Grad: 12580.4443  LR: 0.00001161  \n","Epoch: [2][2100/3405] Elapsed 6m 18s (remain 3m 55s) Loss: 0.0163(0.0235) Grad: 3015.7646  LR: 0.00001149  \n","Epoch: [2][2200/3405] Elapsed 6m 36s (remain 3m 37s) Loss: 0.0090(0.0235) Grad: 4454.7480  LR: 0.00001137  \n","Epoch: [2][2300/3405] Elapsed 6m 54s (remain 3m 18s) Loss: 0.0340(0.0235) Grad: 6087.4131  LR: 0.00001125  \n","Epoch: [2][2400/3405] Elapsed 7m 12s (remain 3m 0s) Loss: 0.0114(0.0234) Grad: 3619.8679  LR: 0.00001113  \n","Epoch: [2][2500/3405] Elapsed 7m 30s (remain 2m 42s) Loss: 0.0609(0.0234) Grad: 8741.3174  LR: 0.00001101  \n","Epoch: [2][2600/3405] Elapsed 7m 47s (remain 2m 24s) Loss: 0.0134(0.0233) Grad: 6149.7632  LR: 0.00001089  \n","Epoch: [2][2700/3405] Elapsed 8m 5s (remain 2m 6s) Loss: 0.0117(0.0233) Grad: 6279.3647  LR: 0.00001076  \n","Epoch: [2][2800/3405] Elapsed 8m 23s (remain 1m 48s) Loss: 0.0296(0.0232) Grad: 15957.3467  LR: 0.00001064  \n","Epoch: [2][2900/3405] Elapsed 8m 41s (remain 1m 30s) Loss: 0.0402(0.0232) Grad: 11833.3154  LR: 0.00001051  \n","Epoch: [2][3000/3405] Elapsed 8m 59s (remain 1m 12s) Loss: 0.0302(0.0231) Grad: 24806.7148  LR: 0.00001038  \n","Epoch: [2][3100/3405] Elapsed 9m 17s (remain 0m 54s) Loss: 0.0240(0.0230) Grad: 11583.7920  LR: 0.00001025  \n","Epoch: [2][3200/3405] Elapsed 9m 34s (remain 0m 36s) Loss: 0.0132(0.0230) Grad: 8620.2490  LR: 0.00001012  \n","Epoch: [2][3300/3405] Elapsed 9m 52s (remain 0m 18s) Loss: 0.0042(0.0229) Grad: 4140.4033  LR: 0.00000999  \n","Epoch: [2][3400/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0349(0.0228) Grad: 18150.7598  LR: 0.00000986  \n","Epoch: [2][3404/3405] Elapsed 10m 11s (remain 0m 0s) Loss: 0.0090(0.0228) Grad: 6931.7466  LR: 0.00000986  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 23s) Loss: 0.0741(0.0741) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0461(0.0890) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0705(0.0913) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0228  avg_val_loss: 0.0934  time: 635s\n","Epoch 2 - Score: 0.7840\n","Epoch 2 - Save Best Score: 0.7840 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0068(0.0934) \n","Epoch: [3][0/3405] Elapsed 0m 0s (remain 26m 8s) Loss: 0.0070(0.0070) Grad: nan  LR: 0.00000986  \n","Epoch: [3][100/3405] Elapsed 0m 18s (remain 10m 18s) Loss: 0.0178(0.0188) Grad: 41248.2695  LR: 0.00000972  \n","Epoch: [3][200/3405] Elapsed 0m 37s (remain 9m 54s) Loss: 0.0028(0.0172) Grad: 15616.9756  LR: 0.00000959  \n","Epoch: [3][300/3405] Elapsed 0m 55s (remain 9m 32s) Loss: 0.0114(0.0168) Grad: 20968.3770  LR: 0.00000946  \n","Epoch: [3][400/3405] Elapsed 1m 13s (remain 9m 12s) Loss: 0.0231(0.0169) Grad: 24648.0859  LR: 0.00000932  \n","Epoch: [3][500/3405] Elapsed 1m 32s (remain 8m 54s) Loss: 0.0095(0.0170) Grad: 33118.3945  LR: 0.00000919  \n","Epoch: [3][600/3405] Elapsed 1m 50s (remain 8m 36s) Loss: 0.0096(0.0167) Grad: 81280.1016  LR: 0.00000905  \n","Epoch: [3][700/3405] Elapsed 2m 8s (remain 8m 16s) Loss: 0.0045(0.0167) Grad: 12741.5605  LR: 0.00000892  \n","Epoch: [3][800/3405] Elapsed 2m 26s (remain 7m 57s) Loss: 0.0116(0.0166) Grad: 26760.7305  LR: 0.00000878  \n","Epoch: [3][900/3405] Elapsed 2m 44s (remain 7m 37s) Loss: 0.0141(0.0166) Grad: 35056.1914  LR: 0.00000864  \n","Epoch: [3][1000/3405] Elapsed 3m 2s (remain 7m 19s) Loss: 0.0072(0.0166) Grad: 21048.5391  LR: 0.00000851  \n","Epoch: [3][1100/3405] Elapsed 3m 20s (remain 7m 0s) Loss: 0.0162(0.0164) Grad: 32635.3047  LR: 0.00000837  \n","Epoch: [3][1200/3405] Elapsed 3m 38s (remain 6m 40s) Loss: 0.0094(0.0162) Grad: 31448.6133  LR: 0.00000823  \n","Epoch: [3][1300/3405] Elapsed 3m 56s (remain 6m 21s) Loss: 0.0182(0.0162) Grad: 42786.4336  LR: 0.00000809  \n","Epoch: [3][1400/3405] Elapsed 4m 13s (remain 6m 2s) Loss: 0.0065(0.0163) Grad: 18786.6602  LR: 0.00000795  \n","Epoch: [3][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0248(0.0163) Grad: 49801.6016  LR: 0.00000781  \n","Epoch: [3][1600/3405] Elapsed 4m 48s (remain 5m 25s) Loss: 0.0189(0.0163) Grad: 25011.1094  LR: 0.00000768  \n","Epoch: [3][1700/3405] Elapsed 5m 6s (remain 5m 6s) Loss: 0.0269(0.0162) Grad: 16666.9824  LR: 0.00000754  \n","Epoch: [3][1800/3405] Elapsed 5m 24s (remain 4m 48s) Loss: 0.0261(0.0163) Grad: 35115.5586  LR: 0.00000740  \n","Epoch: [3][1900/3405] Elapsed 5m 41s (remain 4m 30s) Loss: 0.0104(0.0163) Grad: 17807.3809  LR: 0.00000726  \n","Epoch: [3][2000/3405] Elapsed 5m 59s (remain 4m 12s) Loss: 0.0114(0.0164) Grad: 14695.7852  LR: 0.00000712  \n","Epoch: [3][2100/3405] Elapsed 6m 17s (remain 3m 54s) Loss: 0.0129(0.0163) Grad: 14263.9014  LR: 0.00000698  \n","Epoch: [3][2200/3405] Elapsed 6m 35s (remain 3m 36s) Loss: 0.0053(0.0162) Grad: 5722.6055  LR: 0.00000684  \n","Epoch: [3][2300/3405] Elapsed 6m 52s (remain 3m 18s) Loss: 0.0084(0.0162) Grad: 9254.8877  LR: 0.00000671  \n","Epoch: [3][2400/3405] Elapsed 7m 10s (remain 3m 0s) Loss: 0.0164(0.0163) Grad: 24548.6641  LR: 0.00000657  \n","Epoch: [3][2500/3405] Elapsed 7m 28s (remain 2m 42s) Loss: 0.0258(0.0162) Grad: 22458.8652  LR: 0.00000643  \n","Epoch: [3][2600/3405] Elapsed 7m 46s (remain 2m 24s) Loss: 0.0049(0.0162) Grad: 7422.1333  LR: 0.00000629  \n","Epoch: [3][2700/3405] Elapsed 8m 3s (remain 2m 6s) Loss: 0.0199(0.0162) Grad: 30814.4727  LR: 0.00000616  \n","Epoch: [3][2800/3405] Elapsed 8m 21s (remain 1m 48s) Loss: 0.0326(0.0163) Grad: 32604.1543  LR: 0.00000602  \n","Epoch: [3][2900/3405] Elapsed 8m 39s (remain 1m 30s) Loss: 0.0070(0.0163) Grad: 4524.2310  LR: 0.00000588  \n","Epoch: [3][3000/3405] Elapsed 8m 57s (remain 1m 12s) Loss: 0.0112(0.0162) Grad: 5958.7832  LR: 0.00000575  \n","Epoch: [3][3100/3405] Elapsed 9m 15s (remain 0m 54s) Loss: 0.0182(0.0163) Grad: 18532.8535  LR: 0.00000561  \n","Epoch: [3][3200/3405] Elapsed 9m 33s (remain 0m 36s) Loss: 0.0080(0.0163) Grad: 5414.0083  LR: 0.00000548  \n","Epoch: [3][3300/3405] Elapsed 9m 50s (remain 0m 18s) Loss: 0.0184(0.0163) Grad: 9614.3164  LR: 0.00000535  \n","Epoch: [3][3400/3405] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0009(0.0163) Grad: 5624.7920  LR: 0.00000521  \n","Epoch: [3][3404/3405] Elapsed 10m 9s (remain 0m 0s) Loss: 0.0149(0.0163) Grad: 7037.1772  LR: 0.00000521  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0707(0.0707) \n","EVAL: [100/243] Elapsed 0m 9s (remain 0m 14s) Loss: 0.0440(0.0857) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0696(0.0880) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0163  avg_val_loss: 0.0900  time: 633s\n","Epoch 3 - Score: 0.7783\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0047(0.0900) \n","Epoch: [4][0/3405] Elapsed 0m 0s (remain 26m 34s) Loss: 0.0078(0.0078) Grad: nan  LR: 0.00000521  \n","Epoch: [4][100/3405] Elapsed 0m 18s (remain 10m 6s) Loss: 0.0061(0.0134) Grad: 38243.6992  LR: 0.00000508  \n","Epoch: [4][200/3405] Elapsed 0m 36s (remain 9m 46s) Loss: 0.0076(0.0138) Grad: 26425.1582  LR: 0.00000494  \n","Epoch: [4][300/3405] Elapsed 0m 54s (remain 9m 27s) Loss: 0.0051(0.0137) Grad: 24648.4980  LR: 0.00000481  \n","Epoch: [4][400/3405] Elapsed 1m 13s (remain 9m 8s) Loss: 0.0109(0.0133) Grad: 27798.9473  LR: 0.00000469  \n","Epoch: [4][500/3405] Elapsed 1m 31s (remain 8m 49s) Loss: 0.0073(0.0134) Grad: 34007.3594  LR: 0.00000456  \n","Epoch: [4][600/3405] Elapsed 1m 49s (remain 8m 31s) Loss: 0.0094(0.0134) Grad: 35604.3477  LR: 0.00000443  \n","Epoch: [4][700/3405] Elapsed 2m 7s (remain 8m 12s) Loss: 0.0052(0.0133) Grad: 15684.5088  LR: 0.00000430  \n","Epoch: [4][800/3405] Elapsed 2m 25s (remain 7m 54s) Loss: 0.0091(0.0135) Grad: 9520.2529  LR: 0.00000418  \n","Epoch: [4][900/3405] Elapsed 2m 44s (remain 7m 36s) Loss: 0.0070(0.0134) Grad: 14007.9873  LR: 0.00000406  \n","Epoch: [4][1000/3405] Elapsed 3m 2s (remain 7m 17s) Loss: 0.0346(0.0133) Grad: 54847.1094  LR: 0.00000393  \n","Epoch: [4][1100/3405] Elapsed 3m 20s (remain 6m 59s) Loss: 0.0171(0.0134) Grad: 21785.7773  LR: 0.00000381  \n","Epoch: [4][1200/3405] Elapsed 3m 38s (remain 6m 40s) Loss: 0.0131(0.0133) Grad: 24788.2285  LR: 0.00000369  \n","Epoch: [4][1300/3405] Elapsed 3m 56s (remain 6m 21s) Loss: 0.0136(0.0133) Grad: 17062.0996  LR: 0.00000357  \n","Epoch: [4][1400/3405] Elapsed 4m 13s (remain 6m 3s) Loss: 0.0200(0.0133) Grad: 11880.5020  LR: 0.00000345  \n","Epoch: [4][1500/3405] Elapsed 4m 31s (remain 5m 44s) Loss: 0.0178(0.0133) Grad: 15689.5752  LR: 0.00000334  \n","Epoch: [4][1600/3405] Elapsed 4m 49s (remain 5m 26s) Loss: 0.0114(0.0132) Grad: 8426.5674  LR: 0.00000322  \n","Epoch: [4][1700/3405] Elapsed 5m 7s (remain 5m 7s) Loss: 0.0172(0.0132) Grad: 22695.0137  LR: 0.00000311  \n","Epoch: [4][1800/3405] Elapsed 5m 25s (remain 4m 49s) Loss: 0.0184(0.0133) Grad: 17912.4922  LR: 0.00000300  \n","Epoch: [4][1900/3405] Elapsed 5m 43s (remain 4m 31s) Loss: 0.0009(0.0132) Grad: 3481.1851  LR: 0.00000289  \n","Epoch: [4][2000/3405] Elapsed 6m 0s (remain 4m 13s) Loss: 0.0043(0.0131) Grad: 5925.2856  LR: 0.00000278  \n","Epoch: [4][2100/3405] Elapsed 6m 18s (remain 3m 55s) Loss: 0.0025(0.0132) Grad: 8122.0244  LR: 0.00000267  \n","Epoch: [4][2200/3405] Elapsed 6m 36s (remain 3m 36s) Loss: 0.0022(0.0132) Grad: 7086.5347  LR: 0.00000257  \n","Epoch: [4][2300/3405] Elapsed 6m 54s (remain 3m 18s) Loss: 0.0267(0.0132) Grad: 15889.3457  LR: 0.00000246  \n","Epoch: [4][2400/3405] Elapsed 7m 12s (remain 3m 0s) Loss: 0.0264(0.0132) Grad: 12068.6123  LR: 0.00000236  \n","Epoch: [4][2500/3405] Elapsed 7m 30s (remain 2m 42s) Loss: 0.0127(0.0132) Grad: 12504.7461  LR: 0.00000226  \n","Epoch: [4][2600/3405] Elapsed 7m 47s (remain 2m 24s) Loss: 0.0022(0.0132) Grad: 10320.4707  LR: 0.00000216  \n","Epoch: [4][2700/3405] Elapsed 8m 5s (remain 2m 6s) Loss: 0.0091(0.0133) Grad: 27419.8105  LR: 0.00000207  \n","Epoch: [4][2800/3405] Elapsed 8m 23s (remain 1m 48s) Loss: 0.0019(0.0132) Grad: 22430.1309  LR: 0.00000197  \n","Epoch: [4][2900/3405] Elapsed 8m 41s (remain 1m 30s) Loss: 0.0127(0.0131) Grad: 25403.4785  LR: 0.00000188  \n","Epoch: [4][3000/3405] Elapsed 8m 58s (remain 1m 12s) Loss: 0.0064(0.0131) Grad: 23642.5273  LR: 0.00000179  \n","Epoch: [4][3100/3405] Elapsed 9m 16s (remain 0m 54s) Loss: 0.0172(0.0131) Grad: 65981.6406  LR: 0.00000170  \n","Epoch: [4][3200/3405] Elapsed 9m 34s (remain 0m 36s) Loss: 0.0062(0.0131) Grad: 22285.5898  LR: 0.00000161  \n","Epoch: [4][3300/3405] Elapsed 9m 52s (remain 0m 18s) Loss: 0.0089(0.0131) Grad: 29685.7500  LR: 0.00000153  \n","Epoch: [4][3400/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0059(0.0131) Grad: 18275.2305  LR: 0.00000144  \n","Epoch: [4][3404/3405] Elapsed 10m 10s (remain 0m 0s) Loss: 0.0070(0.0131) Grad: 29645.2148  LR: 0.00000144  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 23s) Loss: 0.0762(0.0762) \n","EVAL: [100/243] Elapsed 0m 10s (remain 0m 14s) Loss: 0.0481(0.0911) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0700(0.0934) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0131  avg_val_loss: 0.0955  time: 635s\n","Epoch 4 - Score: 0.7866\n","Epoch 4 - Save Best Score: 0.7866 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0060(0.0955) \n","Epoch: [5][0/3405] Elapsed 0m 0s (remain 28m 8s) Loss: 0.0216(0.0216) Grad: nan  LR: 0.00000144  \n","Epoch: [5][100/3405] Elapsed 0m 19s (remain 10m 26s) Loss: 0.0058(0.0116) Grad: 22228.3242  LR: 0.00000136  \n","Epoch: [5][200/3405] Elapsed 0m 37s (remain 9m 59s) Loss: 0.0122(0.0111) Grad: 32483.0273  LR: 0.00000128  \n","Epoch: [5][300/3405] Elapsed 0m 55s (remain 9m 34s) Loss: 0.0141(0.0111) Grad: 42271.0078  LR: 0.00000120  \n","Epoch: [5][400/3405] Elapsed 1m 13s (remain 9m 13s) Loss: 0.0015(0.0114) Grad: 14910.9053  LR: 0.00000113  \n","Epoch: [5][500/3405] Elapsed 1m 31s (remain 8m 52s) Loss: 0.0229(0.0114) Grad: 18475.1191  LR: 0.00000106  \n","Epoch: [5][600/3405] Elapsed 1m 49s (remain 8m 33s) Loss: 0.0100(0.0114) Grad: 15932.7217  LR: 0.00000099  \n","Epoch: [5][700/3405] Elapsed 2m 8s (remain 8m 14s) Loss: 0.0011(0.0113) Grad: 5672.3813  LR: 0.00000092  \n","Epoch: [5][800/3405] Elapsed 2m 26s (remain 7m 55s) Loss: 0.0109(0.0110) Grad: 29198.1289  LR: 0.00000085  \n","Epoch: [5][900/3405] Elapsed 2m 44s (remain 7m 35s) Loss: 0.0086(0.0111) Grad: 17047.1582  LR: 0.00000079  \n","Epoch: [5][1000/3405] Elapsed 3m 1s (remain 7m 16s) Loss: 0.0050(0.0111) Grad: 10687.3857  LR: 0.00000073  \n","Epoch: [5][1100/3405] Elapsed 3m 19s (remain 6m 57s) Loss: 0.0126(0.0112) Grad: 19692.8223  LR: 0.00000067  \n","Epoch: [5][1200/3405] Elapsed 3m 37s (remain 6m 38s) Loss: 0.0012(0.0112) Grad: 5095.9517  LR: 0.00000062  \n","Epoch: [5][1300/3405] Elapsed 3m 54s (remain 6m 20s) Loss: 0.0154(0.0112) Grad: 19977.7402  LR: 0.00000056  \n","Epoch: [5][1400/3405] Elapsed 4m 12s (remain 6m 1s) Loss: 0.0014(0.0111) Grad: 5130.4912  LR: 0.00000051  \n","Epoch: [5][1500/3405] Elapsed 4m 30s (remain 5m 42s) Loss: 0.0078(0.0112) Grad: 22617.5586  LR: 0.00000046  \n","Epoch: [5][1600/3405] Elapsed 4m 47s (remain 5m 24s) Loss: 0.0137(0.0112) Grad: 18075.7969  LR: 0.00000041  \n","Epoch: [5][1700/3405] Elapsed 5m 5s (remain 5m 6s) Loss: 0.0063(0.0111) Grad: 9037.9199  LR: 0.00000037  \n","Epoch: [5][1800/3405] Elapsed 5m 23s (remain 4m 48s) Loss: 0.0111(0.0111) Grad: 14755.3838  LR: 0.00000033  \n","Epoch: [5][1900/3405] Elapsed 5m 41s (remain 4m 29s) Loss: 0.0065(0.0111) Grad: 11741.5293  LR: 0.00000029  \n","Epoch: [5][2000/3405] Elapsed 5m 58s (remain 4m 11s) Loss: 0.0172(0.0111) Grad: 13536.7305  LR: 0.00000025  \n","Epoch: [5][2100/3405] Elapsed 6m 16s (remain 3m 53s) Loss: 0.0320(0.0111) Grad: 20274.0371  LR: 0.00000022  \n","Epoch: [5][2200/3405] Elapsed 6m 34s (remain 3m 35s) Loss: 0.0083(0.0110) Grad: 15475.2949  LR: 0.00000019  \n","Epoch: [5][2300/3405] Elapsed 6m 52s (remain 3m 17s) Loss: 0.0047(0.0110) Grad: 15143.8379  LR: 0.00000016  \n","Epoch: [5][2400/3405] Elapsed 7m 9s (remain 2m 59s) Loss: 0.0032(0.0110) Grad: 18496.7363  LR: 0.00000013  \n","Epoch: [5][2500/3405] Elapsed 7m 27s (remain 2m 41s) Loss: 0.0090(0.0110) Grad: 55900.4023  LR: 0.00000010  \n","Epoch: [5][2600/3405] Elapsed 7m 45s (remain 2m 23s) Loss: 0.0057(0.0109) Grad: 35821.6953  LR: 0.00000008  \n","Epoch: [5][2700/3405] Elapsed 8m 2s (remain 2m 5s) Loss: 0.0048(0.0109) Grad: 16249.3037  LR: 0.00000006  \n","Epoch: [5][2800/3405] Elapsed 8m 20s (remain 1m 47s) Loss: 0.0090(0.0110) Grad: 105035.1172  LR: 0.00000005  \n","Epoch: [5][2900/3405] Elapsed 8m 38s (remain 1m 29s) Loss: 0.0126(0.0110) Grad: 49660.2617  LR: 0.00000003  \n","Epoch: [5][3000/3405] Elapsed 8m 55s (remain 1m 12s) Loss: 0.0070(0.0110) Grad: 33845.3242  LR: 0.00000002  \n","Epoch: [5][3100/3405] Elapsed 9m 13s (remain 0m 54s) Loss: 0.0056(0.0109) Grad: 24968.2441  LR: 0.00000001  \n","Epoch: [5][3200/3405] Elapsed 9m 31s (remain 0m 36s) Loss: 0.0076(0.0109) Grad: 17417.9141  LR: 0.00000001  \n","Epoch: [5][3300/3405] Elapsed 9m 49s (remain 0m 18s) Loss: 0.0031(0.0110) Grad: 13964.5586  LR: 0.00000000  \n","Epoch: [5][3400/3405] Elapsed 10m 7s (remain 0m 0s) Loss: 0.0229(0.0110) Grad: 42627.8633  LR: 0.00000000  \n","Epoch: [5][3404/3405] Elapsed 10m 8s (remain 0m 0s) Loss: 0.0201(0.0110) Grad: 99054.1094  LR: 0.00000000  \n","EVAL: [0/243] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0765(0.0765) \n","EVAL: [100/243] Elapsed 0m 10s (remain 0m 14s) Loss: 0.0494(0.0920) \n","EVAL: [200/243] Elapsed 0m 19s (remain 0m 4s) Loss: 0.0693(0.0944) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0110  avg_val_loss: 0.0965  time: 632s\n","Epoch 5 - Score: 0.7831\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [242/243] Elapsed 0m 23s (remain 0m 0s) Loss: 0.0057(0.0965) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 14 result ==========\n","Score: 0.7866\n","========== CV ==========\n","Score: 0.7545\n"]},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a131d85cdd5d403c812587cb4f6180a1","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▅▄▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e█▇▃▂▂▃▃▂▂▂▂▃▂▁▂▁▂▂▁▁▂▂▂▂▁▂▁▂▂▁▁▂▁▁▂▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e▁▄▇█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▂▅▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] loss\u003c/td\u003e\u003ctd\u003e▅█▄▆▅▃▃▆▂▇▃▃▃▂▄▅▃▂▄▃▆▁▂▇▂▃▃▄▂▂▃▁▁▂▁▂▂▄▃▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] score\u003c/td\u003e\u003ctd\u003e▁▃███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_val_loss\u003c/td\u003e\u003ctd\u003e▄█▁▃▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] loss\u003c/td\u003e\u003ctd\u003e█▅▃▅▄▂▁▂▅▁▃▁▃▄▃▂▂▁▁▂▂▂▃▅▂▃▂▂▁▃▂▁▂▁▂▃▂▂▃▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] score\u003c/td\u003e\u003ctd\u003e▁▁█▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_val_loss\u003c/td\u003e\u003ctd\u003e▃▃▁█▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] loss\u003c/td\u003e\u003ctd\u003e█▅▆▅▅▅▂▃▃▂▃▆▆▄▅▄▂▄▂▃▂▂▂▂▁▃▂▂▃▂▂▅▂▃▃▃▂▁▃▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] score\u003c/td\u003e\u003ctd\u003e▁▆▆██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▄▁▃▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] loss\u003c/td\u003e\u003ctd\u003e█▂▆▄▂▅▂▃▂▅▁▂▃▂▅▂▂▂▂▂▄▃▂▃▂▂▁▁▂▅▂▂▃▁▂▂▁▂▄▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] score\u003c/td\u003e\u003ctd\u003e▁▆▅██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▃▁▄▅\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] loss\u003c/td\u003e\u003ctd\u003e▄█▃▂▃▃▂▂▂▂▂▁▂▂▁▂▂▂▂▂▁▁▂▂▂▂▁▁▁▂▁▁▂▁▁▁▁▁▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] score\u003c/td\u003e\u003ctd\u003e▁▇▆█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e██▁▃▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e▄█▃▃▄▁▃▂▂▃▃▃▂▁▃▂▂▂▂▂▂▂▁▁▁▂▁▁▂▁▂▂▁▂▂▁▂▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e▂▁▅▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▃▃▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e█▅▃▂▄▂▃▂▃▂▁▂▂▂▂▃▂▂▃▃▃▂▂▁▂▂▂▂▁▁▂▂▁▁▁▂▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e▁▇█▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▅█▂▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e██▄▄▂▂▄▁▂▄▃▃▂▃▆▃▂▂▅▃▄▁▂▂▁▃▂▃▃▂▃▂▁▁▁▁▁▁▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e▁▅██▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▅▁▂▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e█▇▆▄▅▃▄▃█▃▃▃▂▂▇▅▁▂▃▄▂▃▃▃▃▃▂▁▃▂▂▂▂▁▂▁▃▁▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e▁▁▄█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] loss\u003c/td\u003e\u003ctd\u003e▂█▇▄▁▅▄▇▄▄▂▅▄▂▆▆▂▅▅▂▂▃▅▁▁▅▃▁▂▂▂▂▂▃▁▁▂▅▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] score\u003c/td\u003e\u003ctd\u003e▁▃▆██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▃▁▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] loss\u003c/td\u003e\u003ctd\u003e█▁▂▄▄▃▃▅▄▄▃▃▄▃▅▂▄▄▃▆▄▃▃▃▃▆▅▂▃▆▃▄▃▆▁▁▆▄▃▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] score\u003c/td\u003e\u003ctd\u003e█▄▁▇▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_val_loss\u003c/td\u003e\u003ctd\u003e██▅▁▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] loss\u003c/td\u003e\u003ctd\u003e▇▃▄▃▅█▂▄▃▃▂▃▂▄▄▂▅▂▂▂▄▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▁▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] score\u003c/td\u003e\u003ctd\u003e▁▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_val_loss\u003c/td\u003e\u003ctd\u003e██▁▇▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] loss\u003c/td\u003e\u003ctd\u003e█▃▃▂▄▂▄▃▂▃▂▂▂▂▃▂▁▂▃▁▃▃▂▂▁▁▁▁▂▂▃▂▂▁▁▂▄▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] score\u003c/td\u003e\u003ctd\u003e▁▃▄██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_val_loss\u003c/td\u003e\u003ctd\u003e▄█▂▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] loss\u003c/td\u003e\u003ctd\u003e▃█▆▆▄▃▂▃▂▁▆▄▂▆▅▄▃▃▂▂▂▂▂▃▁▂▂▂▂▁▁▁▁▁▂▁▁▁▂▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] score\u003c/td\u003e\u003ctd\u003e▁█▆▇█\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01049\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.10091\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e0.00616\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e0.76676\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01038\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.10549\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] loss\u003c/td\u003e\u003ctd\u003e0.01006\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] score\u003c/td\u003e\u003ctd\u003e0.79467\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01019\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.10134\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] loss\u003c/td\u003e\u003ctd\u003e0.00491\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] score\u003c/td\u003e\u003ctd\u003e0.78157\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00973\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09599\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] loss\u003c/td\u003e\u003ctd\u003e0.00466\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] score\u003c/td\u003e\u003ctd\u003e0.79821\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01588\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09679\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] loss\u003c/td\u003e\u003ctd\u003e0.01935\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] score\u003c/td\u003e\u003ctd\u003e0.79869\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.011\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09647\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] loss\u003c/td\u003e\u003ctd\u003e0.0201\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] score\u003c/td\u003e\u003ctd\u003e0.78307\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01063\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09789\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e0.00111\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e0.80105\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01005\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09888\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e0.00479\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e0.80417\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00937\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09896\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e0.00658\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e0.79985\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00956\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.1029\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e0.00348\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e0.77697\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00968\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.10156\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] loss\u003c/td\u003e\u003ctd\u003e0.01154\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] score\u003c/td\u003e\u003ctd\u003e0.81602\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.06732\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.12568\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] loss\u003c/td\u003e\u003ctd\u003e0.09039\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] score\u003c/td\u003e\u003ctd\u003e0.05064\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.0138\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09711\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] loss\u003c/td\u003e\u003ctd\u003e0.01732\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] score\u003c/td\u003e\u003ctd\u003e0.77892\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01018\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.0956\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] loss\u003c/td\u003e\u003ctd\u003e0.00813\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] score\u003c/td\u003e\u003ctd\u003e0.80276\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01106\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.10529\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] loss\u003c/td\u003e\u003ctd\u003e0.01329\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] score\u003c/td\u003e\u003ctd\u003e0.77772\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced \u003cstrong style=\"color:#cdcd00\"\u003eroberta-large\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/bluehills/PPPM-MSE/runs/g9kejmh7\" target=\"_blank\"\u003ehttps://wandb.ai/bluehills/PPPM-MSE/runs/g9kejmh7\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20220609_150431-g9kejmh7/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:\u003c.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EJF7cYLQLW0c"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNUKsWWpTNOOCG6irkF3IwR","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"PPPM RoBERTa MSE.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00faf444e10c4765878b9fe928d7ba8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01249ff2d0e24f26947715e3e9bca595":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02811868b0294c36ad016a1c983ac44a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03b24f040341479c80c5ac572e7a5215":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e73b48c1db4449408953ed182a7a0a0a","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_584613c94ed94da79426dea215bd0abb","value":898823}},"06cd521bb81e42d4a4a88af3f608634f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0811ccd06072423f91875e5ed1ae72be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f19bb608858f427caadd3e7298b8a17e","placeholder":"​","style":"IPY_MODEL_a1d00984f7b64668976258047356da5d","value":" 36473/36473 [00:02\u0026lt;00:00, 12965.63it/s]"}},"0938a3b8062842f080137f66153ac47a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e328e777b37b4eb990f0e32421f1b740","placeholder":"​","style":"IPY_MODEL_960ca1ed4f864524a12a25c4c5e70d7a","value":"Downloading: 100%"}},"0b439a09a62a4b969088fc79c27f00b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f1a3b3435ce4f4782695f05a86f1582":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"131182c4321648f18a2a4d341219f07a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf0745e71f524768bf7016d421f4245d","IPY_MODEL_73f69dcf247044339f0de8054e6adea3","IPY_MODEL_17971ff9b285448c93589f79ccd88bcd"],"layout":"IPY_MODEL_b35c9b2bd2cf4f5f8f677b1624524099"}},"135da683b1dd42a1b8d5bc9af17fae50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142c41f5dc0d482db6f09a093a6e8a20":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16203bf69884487194a183f7e25e387f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"169648a8659043c6b6811c81ef3aeba1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17971ff9b285448c93589f79ccd88bcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a7e811d00a446419db861c7da6da4c1","placeholder":"​","style":"IPY_MODEL_6c945c774cb44451bbb278ad36437267","value":" 36473/36473 [00:02\u0026lt;00:00, 13651.88it/s]"}},"2581ddf3599946db940af14334907d25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26569e2d022c422491b48a82dcf77eca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2cc8b0c94634bfc93b506143158fdef","placeholder":"​","style":"IPY_MODEL_e6a6f16131ea456b99d6d1af8753ff5f","value":"Downloading: 100%"}},"27b61f51d13b43dcbd1644dead8e9709":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffbea50551834da39601db1fdfbe89c4","IPY_MODEL_69d3e1f493c0413eb237ee84a39d9f3c","IPY_MODEL_c12b49956553498989586ab45db44a2f"],"layout":"IPY_MODEL_9da9f27f3f594196b83ec35b224327c4"}},"2c7a2100e1fa40e3bcf0cea4808d5c68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ef1d2d5bc5e4c3484936d6be7266533":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46a582c544d940a8a7cfc39602725ef3","IPY_MODEL_4f5b3c98611640f89987aa29fb263373","IPY_MODEL_0811ccd06072423f91875e5ed1ae72be"],"layout":"IPY_MODEL_dcad67e5a1ec47169818b7ad743cd836"}},"306192c1f805429e962c0b27294418ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329caba545ec4cd1977fc64c184bb1fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33304da53fd34f18ad9b65956251786f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87974e570cec4572a0d1032f2c93463a","IPY_MODEL_03b24f040341479c80c5ac572e7a5215","IPY_MODEL_96d81602997a48b498cca6488eaee25a"],"layout":"IPY_MODEL_306192c1f805429e962c0b27294418ee"}},"396eca1a91de48489a6fffff82cfa42e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e827fbf0843c40febdd3a88a99958fc2","max":1425941629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f1a3b3435ce4f4782695f05a86f1582","value":1425941629}},"3a7e811d00a446419db861c7da6da4c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af1eaad6cef4803a242a293c3f80b0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40adcf22454648e290daf87a5da9e69a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4489517275b1467eb247ae2d41304d14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3af1eaad6cef4803a242a293c3f80b0b","placeholder":"​","style":"IPY_MODEL_dc959ba2f0f74f6284f1bf4086895fee","value":" 1.29M/1.29M [00:00\u0026lt;00:00, 1.19MB/s]"}},"46a582c544d940a8a7cfc39602725ef3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00faf444e10c4765878b9fe928d7ba8d","placeholder":"​","style":"IPY_MODEL_c32496076cf14a28af972dbcc1e715cd","value":"100%"}},"4f3cdd611a9b45bb9f4490b08fd17121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26569e2d022c422491b48a82dcf77eca","IPY_MODEL_d40e96c1ac6547fdbeda051b00afa6f2","IPY_MODEL_77508581ce784ff8bc3a9fbac90e83d1"],"layout":"IPY_MODEL_fca92018e57146369d2c6d4a4139211d"}},"4f5b3c98611640f89987aa29fb263373":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baea64bc4a0b4df5ad1080f934a9f9c3","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2581ddf3599946db940af14334907d25","value":36473}},"570114504dce49e5b956e71d14697639":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0938a3b8062842f080137f66153ac47a","IPY_MODEL_db2b369719bd4cdfb0ff8211e6900b56","IPY_MODEL_4489517275b1467eb247ae2d41304d14"],"layout":"IPY_MODEL_ad8e370bec6247938fcabcfee2ded8b4"}},"584613c94ed94da79426dea215bd0abb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5aefc5598416436d841069a43b7c30c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bb6e05cf50d4e44b27f6e65ebf98088":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e03fe5a8c24ff4b68cad1ec2287068":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01249ff2d0e24f26947715e3e9bca595","placeholder":"​","style":"IPY_MODEL_2c7a2100e1fa40e3bcf0cea4808d5c68","value":"Downloading: 100%"}},"651ca0fb08f046bc888ff0a7b1a3bfdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96a969d79fb74f548c143ac7c1513937","IPY_MODEL_a086269cf12f4cb18135a1973515a0f2","IPY_MODEL_d1f3f52d0b104020be24833ec2148d29"],"layout":"IPY_MODEL_f592dfa3d4d64e3eb6b4a994f057aed3"}},"69d3e1f493c0413eb237ee84a39d9f3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_888b4281a12b4d48b3c5a9ad389c9ef1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b439a09a62a4b969088fc79c27f00b5","value":456318}},"6a142a2f721b419294147f706986c643":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a9297aae52d432a804b633e9c8f7dd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c945c774cb44451bbb278ad36437267":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fb212c453e34542b28e5ff7002a4bb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73e953da4bcc49448e43f6bac38449d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73f69dcf247044339f0de8054e6adea3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cda97d5771284ec49de969425c6e53c8","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef7b320815764096ade48ca9ca49b08e","value":36473}},"76dbe73b645e4227a18ca7513c353cb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77508581ce784ff8bc3a9fbac90e83d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16203bf69884487194a183f7e25e387f","placeholder":"​","style":"IPY_MODEL_6a142a2f721b419294147f706986c643","value":" 482/482 [00:00\u0026lt;00:00, 17.1kB/s]"}},"87974e570cec4572a0d1032f2c93463a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06cd521bb81e42d4a4a88af3f608634f","placeholder":"​","style":"IPY_MODEL_9d87ef8880c8487bba2d8e5fd0dfbb66","value":"Downloading: 100%"}},"888b4281a12b4d48b3c5a9ad389c9ef1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1bf181591f4a778fb4493f2c5521a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"960ca1ed4f864524a12a25c4c5e70d7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96a969d79fb74f548c143ac7c1513937":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_329caba545ec4cd1977fc64c184bb1fc","placeholder":"​","style":"IPY_MODEL_f1b9e4f4445b4da5ad3b4f564c136930","value":"100%"}},"96aab8b2c07b42379466ede5f86f2c63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d81602997a48b498cca6488eaee25a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc83f60129664409a73fb27b07d7aaae","placeholder":"​","style":"IPY_MODEL_5bb6e05cf50d4e44b27f6e65ebf98088","value":" 878k/878k [00:00\u0026lt;00:00, 2.06MB/s]"}},"9d87ef8880c8487bba2d8e5fd0dfbb66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9da9f27f3f594196b83ec35b224327c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a086269cf12f4cb18135a1973515a0f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad2bfdfd00e14802846c42ac51b32a88","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_169648a8659043c6b6811c81ef3aeba1","value":136}},"a1d00984f7b64668976258047356da5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad2bfdfd00e14802846c42ac51b32a88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad8e370bec6247938fcabcfee2ded8b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b35c9b2bd2cf4f5f8f677b1624524099":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b48a1a633c7f4297b75d203087898ce5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baea64bc4a0b4df5ad1080f934a9f9c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc83f60129664409a73fb27b07d7aaae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c12b49956553498989586ab45db44a2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_135da683b1dd42a1b8d5bc9af17fae50","placeholder":"​","style":"IPY_MODEL_73e953da4bcc49448e43f6bac38449d3","value":" 446k/446k [00:00\u0026lt;00:00, 656kB/s]"}},"c32496076cf14a28af972dbcc1e715cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4567280d5e2474ea070361219ac11a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_142c41f5dc0d482db6f09a093a6e8a20","placeholder":"​","style":"IPY_MODEL_76dbe73b645e4227a18ca7513c353cb2","value":" 1.33G/1.33G [00:22\u0026lt;00:00, 65.7MB/s]"}},"cda97d5771284ec49de969425c6e53c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf0745e71f524768bf7016d421f4245d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e357a60bc55841cd89933cb5bcab8011","placeholder":"​","style":"IPY_MODEL_5aefc5598416436d841069a43b7c30c8","value":"100%"}},"d1368ce0618a40158f528d504de4b2af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61e03fe5a8c24ff4b68cad1ec2287068","IPY_MODEL_396eca1a91de48489a6fffff82cfa42e","IPY_MODEL_c4567280d5e2474ea070361219ac11a4"],"layout":"IPY_MODEL_40adcf22454648e290daf87a5da9e69a"}},"d1f3f52d0b104020be24833ec2148d29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fb212c453e34542b28e5ff7002a4bb0","placeholder":"​","style":"IPY_MODEL_8b1bf181591f4a778fb4493f2c5521a7","value":" 136/136 [00:00\u0026lt;00:00, 2566.57it/s]"}},"d2cc8b0c94634bfc93b506143158fdef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d40e96c1ac6547fdbeda051b00afa6f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f363bdee6e43427287d7ea68bd070e96","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b48a1a633c7f4297b75d203087898ce5","value":482}},"db2b369719bd4cdfb0ff8211e6900b56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96aab8b2c07b42379466ede5f86f2c63","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a9297aae52d432a804b633e9c8f7dd3","value":1355863}},"dc959ba2f0f74f6284f1bf4086895fee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcad67e5a1ec47169818b7ad743cd836":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfb4d737d66f4dea962be0b132b8ed50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e328e777b37b4eb990f0e32421f1b740":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e357a60bc55841cd89933cb5bcab8011":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6a6f16131ea456b99d6d1af8753ff5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e73b48c1db4449408953ed182a7a0a0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e827fbf0843c40febdd3a88a99958fc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef7b320815764096ade48ca9ca49b08e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f19bb608858f427caadd3e7298b8a17e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1b9e4f4445b4da5ad3b4f564c136930":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f363bdee6e43427287d7ea68bd070e96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f592dfa3d4d64e3eb6b4a994f057aed3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fca92018e57146369d2c6d4a4139211d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffbea50551834da39601db1fdfbe89c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02811868b0294c36ad016a1c983ac44a","placeholder":"​","style":"IPY_MODEL_dfb4d737d66f4dea962be0b132b8ed50","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}