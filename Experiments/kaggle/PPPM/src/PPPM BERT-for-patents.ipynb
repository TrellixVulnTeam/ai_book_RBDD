{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654859335478,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"4wtXQc5eILks"},"outputs":[],"source":["# !pip install kaggle\n","# from google.colab import files\n","# files.upload()"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654859335478,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"9ybT-kPrIRRF"},"outputs":[],"source":["# !ls -1ha kaggle.json"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3031,"status":"ok","timestamp":1654859338506,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ngruL3LzILgG","outputId":"07da4a78-c57e-4b70-bdf1-f1612e256c75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654859338506,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"t-pSk1HrImpC"},"outputs":[],"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# # Permission Warning 이 일어나지 않도록 \n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 본인이 참가한 모든 대회 보기 \n","# !kaggle competitions list"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3185,"status":"ok","timestamp":1654859341687,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"93TLgBfpILdp","outputId":"2e3246a7-fcd4-4357-f655-66738201ab37"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.18)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: GitPython\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: protobuf\u003c4.0dev,\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: shortuuid\u003e=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: sentry-sdk\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.12)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.2.0)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.0.9)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003eGitPython\u003e=1.0.0-\u003ewandb) (5.0.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2022.5.18.1)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n"]}],"source":["!pip3 install tokenizers wandb sentencepiece"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3659,"status":"ok","timestamp":1654859345341,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"dTDhaP31LevK","outputId":"4b29212c-c9c1-4452-9f63-4d740798b600"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.3)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.5.18.1)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859345341,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ABCV5MzcILYt"},"outputs":[],"source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859345341,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"Fe14zhChIld4"},"outputs":[],"source":["# !kaggle competitions download -c us-patent-phrase-to-phrase-matching\n","# !unzip us-patent-phrase-to-phrase-matching.zip\n","# !ls"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859345342,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"enX70dDOIlbH"},"outputs":[],"source":["# debert_v3_tokenizer_path = 'deberta-v2-v3-fast-tokenizer'\n","# %env TOKENIZERS_PARALLELISM=true\n","\n","# import shutil\n","# from pathlib import Path\n","\n","# transformers_path = Path('/usr/local/lib/python3.7/dist-packages/transformers')\n","# input_dir = Path('./deberta-v2-v3-fast-tokenizer')\n","\n","# convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","# conversion_path = transformers_path / convert_file.name\n","\n","# if conversion_path.exists():\n","#     conversion_path.unlink()\n","\n","# shutil.copy(convert_file, transformers_path)\n","# deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","# for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","#     filepath = deberta_v2_path/filename\n","    \n","#     if filepath.exists():\n","#         filepath.unlink()\n","#     shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859345342,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"g8uVyeNzILWZ"},"outputs":[],"source":["OUTPUT_DIR = './pppm-mse-2/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859345342,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"B9XJVEp-ILTm","outputId":"812f4837-b2cc-4b41-ca33-a0b304f0c35b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Jun 10 11:09:04 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') \u003e= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654859345342,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ad4bqKUJILRr"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    competition='PPPM'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"anferico/bert-for-patents\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=50\n","    epochs=4\n","    encoder_lr=1e-5 #2e-5\n","    decoder_lr=1e-5 #2e-5\n","    min_lr=5e-7\n","    eps=5e-7\n","    betas=(0.9, 0.999)\n","    batch_size=14\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=20\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15, 16, 17, 18, 19]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":3194,"status":"ok","timestamp":1654859348533,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qW8but_GILO1","outputId":"35ba749e-d667-4bbc-91bc-525866867e4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["login to wandb\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluehills\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.18"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/drive/My Drive/Kaggle/wandb/run-20220610_110906-277pe9og\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/bluehills/PPPM-MSE-2/runs/277pe9og\" target=\"_blank\"\u003eanferico/bert-for-patents\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/bluehills/PPPM-MSE-2\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    import wandb\n","    try:\n","        # from kaggle_secrets import UserSecretsClient\n","        # user_secrets = UserSecretsClient()\n","        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        # wandb.login(key=secret_value_0)\n","        print('login to wandb') \n","        wandb.login()\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W\u0026B account, go to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as wandb_api. \\nGet your W\u0026B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='PPPM-MSE-2', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"g_kIjiCGLHsk"},"source":["# Library"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3543,"status":"ok","timestamp":1654859352073,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"F3Ud6NtXILMj","outputId":"bc3987ec-7a4e-4072-da9b-c0562bf3a449"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.19.3\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","import torch.cuda.amp as amp\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForTokenClassification\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"0N-UkOUGLMTx"},"source":["# Utils"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654859352074,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"FO_u0OIhILJo"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"6epV68-8Lrk7"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":637},"executionInfo":{"elapsed":1715,"status":"ok","timestamp":1654859353786,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"-15eijrbILHp","outputId":"0be4a824-c24a-4217-de39-53939197d062"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (36473, 5)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-4e8a8011-e87a-4e34-8d26-dcfb18f63c97\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e8a8011-e87a-4e34-8d26-dcfb18f63c97')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-4e8a8011-e87a-4e34-8d26-dcfb18f63c97 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4e8a8011-e87a-4e34-8d26-dcfb18f63c97');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-bb9e5763-5fb9-4472-8e8e-e632e6e9f205\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb9e5763-5fb9-4472-8e8e-e632e6e9f205')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-bb9e5763-5fb9-4472-8e8e-e632e6e9f205 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bb9e5763-5fb9-4472-8e8e-e632e6e9f205');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-0551698e-1789-438f-bdcb-e2cf11ba464c\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0551698e-1789-438f-bdcb-e2cf11ba464c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-0551698e-1789-438f-bdcb-e2cf11ba464c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0551698e-1789-438f-bdcb-e2cf11ba464c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","submission = pd.read_csv('sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":3582,"status":"ok","timestamp":1654859357366,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"6T4B0z0yILFW","outputId":"af166b2d-1803-44b5-836b-0d5533e40090"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-d9851228-af31-48c9-9b2a-60a455f97f01\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9851228-af31-48c9-9b2a-60a455f97f01')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-d9851228-af31-48c9-9b2a-60a455f97f01 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d9851228-af31-48c9-9b2a-60a455f97f01');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-58e97c5d-1542-4ae2-b82c-a52720e4ef07\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58e97c5d-1542-4ae2-b82c-a52720e4ef07')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-58e97c5d-1542-4ae2-b82c-a52720e4ef07 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-58e97c5d-1542-4ae2-b82c-a52720e4ef07');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('./CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'./CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","def get_cpc_texts_nakama():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('./CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'./CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","# cpc_texts = get_cpc_texts_nakama()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859357366,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"46m7DZuOILDE","outputId":"e7f8e0e1-5e2e-4a7a-e1d9-eae4cc2b9b3a"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-80b1bb0b-6a96-4094-af71-ab886fc47481\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b1bb0b-6a96-4094-af71-ab886fc47481')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-80b1bb0b-6a96-4094-af71-ab886fc47481 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80b1bb0b-6a96-4094-af71-ab886fc47481');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text                                               text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  [CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  [CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  [CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  [CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  [CLS]abatement[cpc]HUMAN NECESSITIES. FURNITUR..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-0108ad81-6a81-4a14-9580-8ff0ebb6b323\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","      \u003ctd\u003e[CLS]opc drum[cpc]PHYSICS. OPTICS[SEP]inorgani...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]adjust gas flow[cpc]MECHANICAL ENGINEERIN...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]lower trunnion[cpc]PERFORMING OPERATIONS;...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","      \u003ctd\u003e[CLS]cap component[cpc]TEXTILES; PAPER. TREATM...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","      \u003ctd\u003e[CLS]neural stimulation[cpc]ELECTRICITY. ELECT...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0108ad81-6a81-4a14-9580-8ff0ebb6b323')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-0108ad81-6a81-4a14-9580-8ff0ebb6b323 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0108ad81-6a81-4a14-9580-8ff0ebb6b323');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text                                               text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS  [CLS]opc drum[cpc]PHYSICS. OPTICS[SEP]inorgani...\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...  [CLS]adjust gas flow[cpc]MECHANICAL ENGINEERIN...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...  [CLS]lower trunnion[cpc]PERFORMING OPERATIONS;...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...  [CLS]cap component[cpc]TEXTILES; PAPER. TREATM...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  [CLS]neural stimulation[cpc]ELECTRICITY. ELECT..."]},"metadata":{},"output_type":"display_data"}],"source":["train['text'] = '[CLS]' + train['anchor'] + '[cpc]' + train['context_text'] + '[SEP]'  + train['target'] + '[SEP]'\n","test['text'] = '[CLS]' + test['anchor'] + '[cpc]' + test['context_text'] + '[SEP]'  + test['target'] + '[SEP]'\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"isTSVEuINl2S"},"source":["# EDA"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654859357366,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"3rsR5QFLILAq","outputId":"63e25256-9090-4f73-d041-4b653ae15eee"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7f410d8f9410\u003e"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT6klEQVR4nO3cf6zd9X3f8eerdkkIJJiE7iqyWe0pbjYHVo1eAVWk7iauwJAKI5VGIFpM5tVSS7KsRWvMqokpCRJRS1lg+VFveDYRjaGsm61CSy3CFdpUE6BkmB+l3AEBeySksXHnkB919t4f53PbU9fm3nvOvef4+jwf0tX9fj/fz/f7/bzPOfbrfn+cb6oKSdJo+5FhD0CSNHyGgSTJMJAkGQaSJAwDSRKwdNgD6NVZZ51VK1eu7Gnd73znO5x22mnzO6ATnDWPhlGredTqhf5rfvzxx/+yqn7s6PZFGwYrV67kscce62ndyclJJiYm5ndAJzhrHg2jVvOo1Qv915zk68dq9zSRJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJJYxN9Alk5UKzffN7R9b1s3Wo9m0PzxyECSNHMYJNma5LUkT3W1/VaSP0/yZJL/lmRZ17IbkkwleS7JxV3t61rbVJLNXe2rkjzS2u9Ocsp8FihJmtlsjgy2AeuOatsNnFNV/xT4C+AGgCRrgCuB97V1Pp9kSZIlwOeAS4A1wFWtL8BngFur6j3AQWBjXxVJkuZsxjCoqoeBA0e1/UlVHWmze4AVbXo9sKOqvl9VLwJTwPntZ6qqXqiqHwA7gPVJAnwQuLetvx24vM+aJElzNB8XkP8FcHebXk4nHKbta20ArxzVfgHwLuD1rmDp7v/3JNkEbAIYGxtjcnKypwEfPny453UXK2senOvPPTJzpwUyau/zqNULC1dzX2GQ5DeBI8Bd8zOcN1dVW4AtAOPj49XrM719BvpoGFbN1w75bqJRep/9XM+fnsMgybXAzwFrq6pa837g7K5uK1obx2n/NrAsydJ2dNDdX5I0ID3dWppkHfAbwGVV9UbXol3AlUnekmQVsBr4KvAosLrdOXQKnYvMu1qIPARc0dbfAOzsrRRJUq9mc2vpl4E/Bd6bZF+SjcB/BN4O7E7ytSRfBKiqp4F7gGeAPwauq6oftr/6Pwo8ADwL3NP6AnwC+PUkU3SuIdwxrxVKkmY042miqrrqGM3H/Q+7qm4CbjpG+/3A/cdof4HO3UaSpCHxG8iSJMNAkuSD6kbG3v2HhnLL40s3f2jg+5Q0dx4ZSJIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkphFGCTZmuS1JE91tb0zye4kz7ffZ7b2JLktyVSSJ5Oc17XOhtb/+SQbutp/Ksnets5tSTLfRUqS3txsjgy2AeuOatsMPFhVq4EH2zzAJcDq9rMJ+AJ0wgO4EbgAOB+4cTpAWp9f7lrv6H1JkhbYjGFQVQ8DB45qXg9sb9Pbgcu72u+sjj3AsiTvBi4GdlfVgao6COwG1rVl76iqPVVVwJ1d25IkDcjSHtcbq6pX2/Q3gLE2vRx4pavfvtb2Zu37jtF+TEk20TniYGxsjMnJyZ4Gf/jw4Z7XXazGToXrzz0y8P0O83Ue1vs8jNd52qh9tketXli4mnsNg79RVZWk5mMws9jXFmALwPj4eE1MTPS0ncnJSXpdd7G6/a6d3LK377d7zl66emLg+5w2rPf52s33DXyf07atO22kPtuj+G95oWru9W6ib7ZTPLTfr7X2/cDZXf1WtLY3a19xjHZJ0gD1Gga7gOk7gjYAO7var2l3FV0IHGqnkx4ALkpyZrtwfBHwQFv2V0kubHcRXdO1LUnSgMx43iDJl4EJ4Kwk++jcFXQzcE+SjcDXgQ+37vcDlwJTwBvARwCq6kCSTwGPtn6frKrpi9K/SueOpVOBP2o/kqQBmjEMquqq4yxae4y+BVx3nO1sBbYeo/0x4JyZxiFJWjh+A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJ9BkGSX4tydNJnkry5SRvTbIqySNJppLcneSU1vctbX6qLV/ZtZ0bWvtzSS7uryRJ0lz1HAZJlgP/ChivqnOAJcCVwGeAW6vqPcBBYGNbZSNwsLXf2vqRZE1b733AOuDzSZb0Oi5J0tz1e5poKXBqkqXA24BXgQ8C97bl24HL2/T6Nk9bvjZJWvuOqvp+Vb0ITAHn9zkuSdIcLO11xaran+S3gZeB7wJ/AjwOvF5VR1q3fcDyNr0ceKWteyTJIeBdrX1P16a71/k7kmwCNgGMjY0xOTnZ09gPHz7c87qL1dipcP25R2buOM+G+ToP630exus8bdQ+26NWLyxczT2HQZIz6fxVvwp4Hfh9Oqd5FkxVbQG2AIyPj9fExERP25mcnKTXdRer2+/ayS17e367e/bS1RMD3+e0Yb3P126+b+D7nLZt3Wkj9dkexX/LC1VzP6eJfhZ4saq+VVV/DfwB8H5gWTttBLAC2N+m9wNnA7TlZwDf7m4/xjqSpAHoJwxeBi5M8rZ27n8t8AzwEHBF67MB2Nmmd7V52vKvVFW19ivb3UargNXAV/sYlyRpjvq5ZvBIknuBPwOOAE/QOYVzH7Ajyadb2x1tlTuALyWZAg7QuYOIqno6yT10guQIcF1V/bDXcUmS5q6vk8hVdSNw41HNL3CMu4Gq6nvALxxnOzcBN/UzFklS7/wGsiTJMJAkGQaSJPq8ZrBY7d1/aCj3gr9084cGvk9Jmg2PDCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0GQZJliW5N8mfJ3k2yU8neWeS3Umeb7/PbH2T5LYkU0meTHJe13Y2tP7PJ9nQb1GSpLnp98jgs8AfV9U/Bn4SeBbYDDxYVauBB9s8wCXA6vazCfgCQJJ3AjcCFwDnAzdOB4gkaTB6DoMkZwA/A9wBUFU/qKrXgfXA9tZtO3B5m14P3Fkde4BlSd4NXAzsrqoDVXUQ2A2s63VckqS5W9rHuquAbwH/JclPAo8DHwfGqurV1ucbwFibXg680rX+vtZ2vPa/J8kmOkcVjI2NMTk52dPAx06F68890tO6/eh1vPNhFGs+fPjwUPY/jNd52rBqHpZRqxcWruZ+wmApcB7wsap6JMln+dtTQgBUVSWpfgZ41Pa2AFsAxsfHa2Jioqft3H7XTm7Z20/pvXnp6omB73PaKNY8OTlJr5+Rfly7+b6B73PatnWnDaXmYRnWezxMC1VzP9cM9gH7quqRNn8vnXD4Zjv9Q/v9Wlu+Hzi7a/0Vre147ZKkAek5DKrqG8ArSd7bmtYCzwC7gOk7gjYAO9v0LuCadlfRhcChdjrpAeCiJGe2C8cXtTZJ0oD0e97gY8BdSU4BXgA+Qidg7kmyEfg68OHW937gUmAKeKP1paoOJPkU8Gjr98mqOtDnuCRJc9BXGFTV14DxYyxae4y+BVx3nO1sBbb2MxZJUu/8BrIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxD2GQZEmSJ5L8YZtfleSRJFNJ7k5ySmt/S5ufastXdm3jhtb+XJKL+x2TJGlu5uPI4OPAs13znwFurar3AAeBja19I3Cwtd/a+pFkDXAl8D5gHfD5JEvmYVySpFnqKwySrAA+BPznNh/gg8C9rct24PI2vb7N05avbf3XAzuq6vtV9SIwBZzfz7gkSXOztM/1/wPwG8Db2/y7gNer6kib3wcsb9PLgVcAqupIkkOt/3JgT9c2u9f5O5JsAjYBjI2NMTk52dOgx06F6889MnPHedbreOfDKNZ8+PDhoex/GK/ztGHVvHf/oYHvE2DVGUuG+hkbhoV6j3sOgyQ/B7xWVY8nmZi/IR1fVW0BtgCMj4/XxERvu739rp3csrffHJy7l66eGPg+p41izZOTk/T6GenHtZvvG/g+p21bd9pI1TyseodpoT7X/fzv8H7gsiSXAm8F3gF8FliWZGk7OlgB7G/99wNnA/uSLAXOAL7d1T6tex1J0gD0fM2gqm6oqhVVtZLOBeCvVNXVwEPAFa3bBmBnm97V5mnLv1JV1dqvbHcbrQJWA1/tdVySpLlbiPMGnwB2JPk08ARwR2u/A/hSkingAJ0AoaqeTnIP8AxwBLiuqn64AOOSJB3HvIRBVU0Ck236BY5xN1BVfQ/4heOsfxNw03yMRZI0d34DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0EQZJzk7yUJJnkjyd5OOt/Z1Jdid5vv0+s7UnyW1JppI8meS8rm1taP2fT7Kh/7IkSXPRz5HBEeD6qloDXAhcl2QNsBl4sKpWAw+2eYBLgNXtZxPwBeiEB3AjcAFwPnDjdIBIkgaj5zCoqler6s/a9P8FngWWA+uB7a3bduDyNr0euLM69gDLkrwbuBjYXVUHquogsBtY1+u4JElzl6rqfyPJSuBh4Bzg5apa1toDHKyqZUn+ELi5qv5HW/Yg8AlgAnhrVX26tf874LtV9dvH2M8mOkcVjI2N/dSOHTt6Gu9rBw7xze/2tGpfzl1+xuB32oxizYcPH+b0008f+H737j808H1OW3XGkpGqeVj1DlO/n+sPfOADj1fV+NHtS/saFZDkdOC/Av+6qv6q8/9/R1VVkv7T5m+3twXYAjA+Pl4TExM9bef2u3Zyy96+S5+zl66eGPg+p41izZOTk/T6GenHtZvvG/g+p21bd9pI1TyseodpoT7Xfd1NlORH6QTBXVX1B635m+30D+33a619P3B21+orWtvx2iVJA9LP3UQB7gCerarf6Vq0C5i+I2gDsLOr/Zp2V9GFwKGqehV4ALgoyZntwvFFrU2SNCD9nDd4P/BLwN4kX2tt/xa4GbgnyUbg68CH27L7gUuBKeAN4CMAVXUgyaeAR1u/T1bVgT7GJUmao57DoF0IznEWrz1G/wKuO862tgJbex2LJKk/fgNZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkpiHB9VJ0ihaOcSH8y0EjwwkSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIkTKAySrEvyXJKpJJuHPR5JGiUnRBgkWQJ8DrgEWANclWTNcEclSaPjhAgD4HxgqqpeqKofADuA9UMekySNjFTVsMdAkiuAdVX1L9v8LwEXVNVHj+q3CdjUZt8LPNfjLs8C/rLHdRcrax4No1bzqNUL/df841X1Y0c3Lu1jgwNXVVuALf1uJ8ljVTU+D0NaNKx5NIxazaNWLyxczSfKaaL9wNld8ytamyRpAE6UMHgUWJ1kVZJTgCuBXUMekySNjBPiNFFVHUnyUeABYAmwtaqeXsBd9n2qaRGy5tEwajWPWr2wQDWfEBeQJUnDdaKcJpIkDZFhIEk6ucNgpkdcJHlLkrvb8keSrBz8KOfPLOr99STPJHkyyYNJfnwY45xPs32MSZKfT1JJFv1tiLOpOcmH23v9dJLfG/QY59ssPtv/MMlDSZ5on+9LhzHO+ZJka5LXkjx1nOVJclt7PZ5Mcl7fO62qk/KHzoXo/w38I+AU4H8Ba47q86vAF9v0lcDdwx73Atf7AeBtbfpXFnO9s6259Xs78DCwBxgf9rgH8D6vBp4Azmzz/2DY4x5AzVuAX2nTa4CXhj3uPmv+GeA84KnjLL8U+CMgwIXAI/3u82Q+MpjNIy7WA9vb9L3A2iQZ4Bjn04z1VtVDVfVGm91D5/sci9lsH2PyKeAzwPcGObgFMpuafxn4XFUdBKiq1wY8xvk2m5oLeEebPgP4PwMc37yrqoeBA2/SZT1wZ3XsAZYleXc/+zyZw2A58ErX/L7Wdsw+VXUEOAS8ayCjm3+zqbfbRjp/WSxmM9bcDp/Prqr7BjmwBTSb9/kngJ9I8j+T7EmybmCjWxizqfnfA7+YZB9wP/CxwQxtaOb6731GJ8T3DDRYSX4RGAf++bDHspCS/AjwO8C1Qx7KoC2lc6pogs7R38NJzq2q14c6qoV1FbCtqm5J8tPAl5KcU1X/b9gDWyxO5iOD2Tzi4m/6JFlK5/Dy2wMZ3fyb1SM9kvws8JvAZVX1/QGNbaHMVPPbgXOAySQv0Tm3umuRX0Sezfu8D9hVVX9dVS8Cf0EnHBar2dS8EbgHoKr+FHgrnQe6nazm/RE+J3MYzOYRF7uADW36CuAr1a7OLEIz1pvknwG/SycIFvt5ZJih5qo6VFVnVdXKqlpJ5zrJZVX12HCGOy9m87n+73SOCkhyFp3TRi8McpDzbDY1vwysBUjyT+iEwbcGOsrB2gVc0+4quhA4VFWv9rPBk/Y0UR3nERdJPgk8VlW7gDvoHE5O0blYc+XwRtyfWdb7W8DpwO+36+QvV9VlQxt0n2ZZ80llljU/AFyU5Bngh8C/qarFesQ725qvB/5Tkl+jczH52kX8hx1Jvkwn0M9q10FuBH4UoKq+SOe6yKXAFPAG8JG+97mIXy9J0jw5mU8TSZJmyTCQJBkGkiTDQJKEYSBJwjCQJGEYSJKA/w/+hJpxtNMEiwAAAABJRU5ErkJggg==\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654859357366,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qco8TIYeIK-W","outputId":"c7ddca14-4945-4ff3-d1dd-bfc172032ac7"},"outputs":[{"data":{"text/plain":["B    8019\n","H    6195\n","G    6013\n","C    5288\n","A    4094\n","F    4054\n","E    1531\n","D    1279\n","Name: context, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"0X9jmLp9NrEE"},"source":["# CV Split"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654859357367,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"rnm4sSJdIK73"},"outputs":[],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654859357367,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"QkVs3kLeKPx3"},"outputs":[],"source":["# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","\n","# encoder = LabelEncoder()\n","# train['anchor_map'] = encoder.fit_transform(train['anchor'])\n","\n","# kf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (_, valid_index) in enumerate(kf.split(train, train['score_map'], groups=train['anchor_map'])):\n","#     train.loc[valid_index, 'fold'] = int(n)\n","\n","# train['fold'] = train['fold'].astype(int)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1654859357367,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"v335JEfPbJJw"},"outputs":[],"source":["# titles = pd.read_csv('./titles.csv')\n","# train = train.merge(titles, left_on='context', right_on='code')\n","# train['fold'] = -1\n","# kf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","\n","# for f, (t_, v_) in enumerate(kf.split(X=train, y=train['anchor'], groups=train['anchor'])):\n","#     train.loc[v_, 'fold'] = f\n","\n","# train['fold'].hist()\n","# train['text'] = train['anchor'] + '[SEP]' + train['title'].apply(str.lower)\n","# train = train[['id','anchor', 'target', 'context', 'score', 'title', 'fold', 'text']]"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4733,"status":"ok","timestamp":1654859362095,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"Gd7lcdeGiEZU","outputId":"66de4490-e479-4e2a-8db1-9dad91ac07f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["696 37\n","696 37\n","696 37\n","696 37\n","696 37\n","697 36\n","697 36\n","696 37\n","696 37\n","696 37\n","697 36\n","697 36\n","696 37\n","696 37\n","696 37\n","696 37\n","696 37\n","697 36\n","697 36\n","697 36\n","7     2026\n","15    2008\n","14    1989\n","9     1977\n","5     1976\n","0     1930\n","1     1917\n","16    1883\n","3     1820\n","2     1817\n","8     1809\n","18    1804\n","10    1788\n","4     1755\n","19    1750\n","12    1733\n","11    1728\n","17    1666\n","6     1655\n","13    1442\n","Name: fold, dtype: int64\n"]}],"source":["!pip3 install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train = train.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")\n","print(train.fold.value_counts())"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1654859362095,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"67wpP1q7IK5L"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"bIqxWfHqNzR2"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":4651,"status":"ok","timestamp":1654859366743,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"0LIvoPmoIFUv","outputId":"93ab8a98-bbe1-4247-ccd1-9c51f2dd0681"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"158491a6825c4035b102915bbc467843","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/327 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b658f2776a99434e90ced031eda5c9c1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/322k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"BvhCQypyN2nU"},"source":["# Dataset"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":6810,"status":"ok","timestamp":1654859373546,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"O9KbGQdeN195","outputId":"191513c8-06ee-47ba-e1af-c35c36b551eb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a588bcd5d7144e419605b1bf48cdfd33","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d7d9d82590f47dfa0195c7cc4c5baa9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d26ace1c0664b1d98b0f8bf585b37ac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_len: 117\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654859373546,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"twc1qFyRN17n"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654859373546,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"5iFhyETfN15V","outputId":"260c6291-5331-434c-c0c8-91c4508f6b20"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"m1x8L7BQOKr2"},"source":["# Model"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654859373546,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"GPMtgF_NbjBe"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self._init_weights(self.attention)\n","        self.linear = nn.Linear(self.config.hidden_size, 1)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_state = outputs[0]\n","\n","        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        \n","        out = sum_embeddings / sum_mask\n","        out = self.layer_norm1(out)\n","        output = self.fc(out)\n","        \n","        return output\n"]},{"cell_type":"markdown","metadata":{"id":"N80Z0ZF9OcjW"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":701,"status":"ok","timestamp":1654859374245,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"IjzXaGwxN10f"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","\n","\n","        labels = labels.to(torch.float16)\n","        # print(y_preds.view(-1, 1).dtype)\n","        # print(labels.view(-1, 1).dtype)\n","        # loss = criterion(y_preds.sigmoid().view(-1, 1), labels.view(-1, 1))\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        # print(loss.dtype)\n","\n","        \n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        labels = labels.to(torch.float16)\n","        loss = criterion(y_preds.sigmoid().view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        # preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        preds.append(y_preds.to('cpu').numpy())\n","\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        # preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        preds.append(y_preds.to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654859374245,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"K9fNekOSN1yT"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model \u0026 optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    # criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    criterion = nn.MSELoss(reduction=\"mean\")\n","    # criterion = FocalLossV1().cuda()\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score \u003c score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    try:\n","        predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                                map_location=torch.device('cpu'))['predictions']\n","        valid_folds['pred'] = predictions\n","    except:\n","        valid_folds['pred'] = -1\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":225},"id":"GIQnVGWmN1vf"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38d2f4ef68904fb29308bb7992c189b6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.29G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2467] Elapsed 0m 0s (remain 29m 23s) Loss: 0.3369(0.3369) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2467] Elapsed 0m 18s (remain 7m 12s) Loss: 0.0653(0.1559) Grad: 29346.4980  LR: 0.00001000  \n","Epoch: [1][200/2467] Elapsed 0m 35s (remain 6m 45s) Loss: 0.0984(0.1243) Grad: 46337.9648  LR: 0.00000999  \n","Epoch: [1][300/2467] Elapsed 0m 53s (remain 6m 24s) Loss: 0.0373(0.1060) Grad: 17891.6406  LR: 0.00000998  \n","Epoch: [1][400/2467] Elapsed 1m 11s (remain 6m 5s) Loss: 0.1285(0.0983) Grad: 41816.4961  LR: 0.00000997  \n","Epoch: [1][500/2467] Elapsed 1m 28s (remain 5m 47s) Loss: 0.0497(0.0901) Grad: 11338.1436  LR: 0.00000995  \n","Epoch: [1][600/2467] Elapsed 1m 45s (remain 5m 28s) Loss: 0.0636(0.0837) Grad: 27190.1426  LR: 0.00000992  \n","Epoch: [1][700/2467] Elapsed 2m 2s (remain 5m 9s) Loss: 0.0242(0.0781) Grad: 4191.6753  LR: 0.00000989  \n","Epoch: [1][800/2467] Elapsed 2m 20s (remain 4m 51s) Loss: 0.0864(0.0730) Grad: 36242.5625  LR: 0.00000986  \n","Epoch: [1][900/2467] Elapsed 2m 37s (remain 4m 33s) Loss: 0.0547(0.0702) Grad: 3364.1785  LR: 0.00000982  \n","Epoch: [1][1000/2467] Elapsed 2m 54s (remain 4m 15s) Loss: 0.0418(0.0670) Grad: 2748.6672  LR: 0.00000977  \n","Epoch: [1][1100/2467] Elapsed 3m 11s (remain 3m 57s) Loss: 0.0068(0.0643) Grad: 4304.4272  LR: 0.00000972  \n","Epoch: [1][1200/2467] Elapsed 3m 28s (remain 3m 40s) Loss: 0.0673(0.0619) Grad: 3181.6680  LR: 0.00000966  \n","Epoch: [1][1300/2467] Elapsed 3m 46s (remain 3m 22s) Loss: 0.1035(0.0597) Grad: 40151.3906  LR: 0.00000960  \n","Epoch: [1][1400/2467] Elapsed 4m 3s (remain 3m 4s) Loss: 0.0379(0.0581) Grad: 3153.6621  LR: 0.00000954  \n","Epoch: [1][1500/2467] Elapsed 4m 20s (remain 2m 47s) Loss: 0.0299(0.0563) Grad: 11728.6123  LR: 0.00000947  \n","Epoch: [1][1600/2467] Elapsed 4m 37s (remain 2m 29s) Loss: 0.0151(0.0547) Grad: 1658.8344  LR: 0.00000940  \n","Epoch: [1][1700/2467] Elapsed 4m 54s (remain 2m 12s) Loss: 0.0210(0.0532) Grad: 4767.3237  LR: 0.00000932  \n","Epoch: [1][1800/2467] Elapsed 5m 11s (remain 1m 55s) Loss: 0.0446(0.0523) Grad: 22698.6465  LR: 0.00000924  \n","Epoch: [1][1900/2467] Elapsed 5m 28s (remain 1m 37s) Loss: 0.0244(0.0512) Grad: 2152.8364  LR: 0.00000915  \n","Epoch: [1][2000/2467] Elapsed 5m 45s (remain 1m 20s) Loss: 0.0287(0.0503) Grad: 13569.8008  LR: 0.00000906  \n","Epoch: [1][2100/2467] Elapsed 6m 2s (remain 1m 3s) Loss: 0.0593(0.0493) Grad: 30103.3848  LR: 0.00000896  \n","Epoch: [1][2200/2467] Elapsed 6m 19s (remain 0m 45s) Loss: 0.0252(0.0482) Grad: 6101.2627  LR: 0.00000886  \n","Epoch: [1][2300/2467] Elapsed 6m 36s (remain 0m 28s) Loss: 0.0244(0.0473) Grad: 16446.3008  LR: 0.00000876  \n","Epoch: [1][2400/2467] Elapsed 6m 53s (remain 0m 11s) Loss: 0.0173(0.0464) Grad: 14027.1826  LR: 0.00000865  \n","Epoch: [1][2466/2467] Elapsed 7m 4s (remain 0m 0s) Loss: 0.0120(0.0459) Grad: 11322.2461  LR: 0.00000858  \n","EVAL: [0/138] Elapsed 0m 0s (remain 0m 44s) Loss: 0.1415(0.1415) \n","EVAL: [100/138] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0416(0.0924) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0459  avg_val_loss: 0.0921  time: 437s\n","Epoch 1 - Score: 0.8150\n","Epoch 1 - Save Best Score: 0.8150 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [137/138] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0379(0.0921) \n","Epoch: [2][0/2467] Elapsed 0m 0s (remain 17m 44s) Loss: 0.0134(0.0134) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2467] Elapsed 0m 17s (remain 6m 52s) Loss: 0.0377(0.0200) Grad: 12629.9990  LR: 0.00000846  \n","Epoch: [2][200/2467] Elapsed 0m 35s (remain 6m 36s) Loss: 0.0184(0.0197) Grad: 12748.1621  LR: 0.00000835  \n","Epoch: [2][300/2467] Elapsed 0m 52s (remain 6m 15s) Loss: 0.0123(0.0189) Grad: 12174.8066  LR: 0.00000823  \n","Epoch: [2][400/2467] Elapsed 1m 9s (remain 5m 56s) Loss: 0.0304(0.0189) Grad: 38169.9727  LR: 0.00000810  \n","Epoch: [2][500/2467] Elapsed 1m 26s (remain 5m 37s) Loss: 0.0149(0.0188) Grad: 11874.8867  LR: 0.00000797  \n","Epoch: [2][600/2467] Elapsed 1m 43s (remain 5m 19s) Loss: 0.0135(0.0187) Grad: 8309.2852  LR: 0.00000784  \n","Epoch: [2][700/2467] Elapsed 2m 0s (remain 5m 2s) Loss: 0.0245(0.0188) Grad: 71378.4609  LR: 0.00000771  \n","Epoch: [2][800/2467] Elapsed 2m 17s (remain 4m 45s) Loss: 0.0102(0.0189) Grad: 12569.7812  LR: 0.00000758  \n","Epoch: [2][900/2467] Elapsed 2m 34s (remain 4m 28s) Loss: 0.0069(0.0191) Grad: 20728.7559  LR: 0.00000744  \n","Epoch: [2][1000/2467] Elapsed 2m 51s (remain 4m 11s) Loss: 0.0380(0.0191) Grad: 32640.4883  LR: 0.00000730  \n","Epoch: [2][1100/2467] Elapsed 3m 8s (remain 3m 54s) Loss: 0.0182(0.0190) Grad: 25368.4434  LR: 0.00000715  \n","Epoch: [2][1200/2467] Elapsed 3m 25s (remain 3m 37s) Loss: 0.0417(0.0190) Grad: 25341.9980  LR: 0.00000701  \n","Epoch: [2][1300/2467] Elapsed 3m 42s (remain 3m 19s) Loss: 0.0188(0.0188) Grad: 28186.7910  LR: 0.00000686  \n","Epoch: [2][1400/2467] Elapsed 3m 59s (remain 3m 2s) Loss: 0.0143(0.0188) Grad: 6638.2305  LR: 0.00000671  \n","Epoch: [2][1500/2467] Elapsed 4m 16s (remain 2m 45s) Loss: 0.0391(0.0189) Grad: 6052.6973  LR: 0.00000656  \n","Epoch: [2][1600/2467] Elapsed 4m 33s (remain 2m 27s) Loss: 0.0113(0.0189) Grad: 6066.8628  LR: 0.00000641  \n","Epoch: [2][1700/2467] Elapsed 4m 50s (remain 2m 10s) Loss: 0.0246(0.0188) Grad: 15178.8799  LR: 0.00000625  \n","Epoch: [2][1800/2467] Elapsed 5m 7s (remain 1m 53s) Loss: 0.0106(0.0187) Grad: 36739.6406  LR: 0.00000610  \n","Epoch: [2][1900/2467] Elapsed 5m 24s (remain 1m 36s) Loss: 0.0309(0.0188) Grad: 11793.5518  LR: 0.00000594  \n","Epoch: [2][2000/2467] Elapsed 5m 41s (remain 1m 19s) Loss: 0.0191(0.0189) Grad: 48278.6250  LR: 0.00000578  \n","Epoch: [2][2100/2467] Elapsed 5m 59s (remain 1m 2s) Loss: 0.0247(0.0189) Grad: 65180.5742  LR: 0.00000562  \n","Epoch: [2][2200/2467] Elapsed 6m 16s (remain 0m 45s) Loss: 0.0127(0.0189) Grad: 20074.7227  LR: 0.00000547  \n","Epoch: [2][2300/2467] Elapsed 6m 32s (remain 0m 28s) Loss: 0.0142(0.0188) Grad: 17417.1133  LR: 0.00000531  \n","Epoch: [2][2400/2467] Elapsed 6m 50s (remain 0m 11s) Loss: 0.0204(0.0188) Grad: 10274.7285  LR: 0.00000515  \n","Epoch: [2][2466/2467] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0414(0.0188) Grad: 32184.2207  LR: 0.00000504  \n","EVAL: [0/138] Elapsed 0m 0s (remain 0m 40s) Loss: 0.1352(0.1352) \n","EVAL: [100/138] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0418(0.0900) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0188  avg_val_loss: 0.0899  time: 434s\n","Epoch 2 - Score: 0.8232\n","Epoch 2 - Save Best Score: 0.8232 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [137/138] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0415(0.0899) \n","Epoch: [3][0/2467] Elapsed 0m 0s (remain 17m 40s) Loss: 0.0174(0.0174) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2467] Elapsed 0m 18s (remain 7m 4s) Loss: 0.0181(0.0161) Grad: 85813.7422  LR: 0.00000488  \n","Epoch: [3][200/2467] Elapsed 0m 35s (remain 6m 43s) Loss: 0.0077(0.0157) Grad: 49904.6523  LR: 0.00000472  \n","Epoch: [3][300/2467] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0089(0.0152) Grad: 26527.0176  LR: 0.00000456  \n","Epoch: [3][400/2467] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0087(0.0147) Grad: 34080.5000  LR: 0.00000440  \n","Epoch: [3][500/2467] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0152(0.0147) Grad: 14571.4385  LR: 0.00000424  \n","Epoch: [3][600/2467] Elapsed 1m 43s (remain 5m 21s) Loss: 0.0186(0.0148) Grad: 50236.8086  LR: 0.00000408  \n","Epoch: [3][700/2467] Elapsed 2m 0s (remain 5m 3s) Loss: 0.0054(0.0148) Grad: 16997.2148  LR: 0.00000393  \n","Epoch: [3][800/2467] Elapsed 2m 17s (remain 4m 45s) Loss: 0.0482(0.0150) Grad: 42985.0039  LR: 0.00000377  \n","Epoch: [3][900/2467] Elapsed 2m 34s (remain 4m 27s) Loss: 0.0103(0.0148) Grad: 5971.3550  LR: 0.00000362  \n","Epoch: [3][1000/2467] Elapsed 2m 51s (remain 4m 10s) Loss: 0.0080(0.0148) Grad: 7253.8032  LR: 0.00000346  \n","Epoch: [3][1100/2467] Elapsed 3m 7s (remain 3m 53s) Loss: 0.0123(0.0147) Grad: 27143.9961  LR: 0.00000331  \n","Epoch: [3][1200/2467] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0141(0.0147) Grad: 27202.5078  LR: 0.00000316  \n","Epoch: [3][1300/2467] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0131(0.0146) Grad: 16890.8066  LR: 0.00000302  \n","Epoch: [3][1400/2467] Elapsed 3m 58s (remain 3m 1s) Loss: 0.0174(0.0146) Grad: 5994.1919  LR: 0.00000287  \n","Epoch: [3][1500/2467] Elapsed 4m 15s (remain 2m 44s) Loss: 0.0142(0.0146) Grad: 9903.4258  LR: 0.00000273  \n","Epoch: [3][1600/2467] Elapsed 4m 32s (remain 2m 27s) Loss: 0.0490(0.0146) Grad: 37317.2852  LR: 0.00000258  \n","Epoch: [3][1700/2467] Elapsed 4m 49s (remain 2m 10s) Loss: 0.0131(0.0146) Grad: 9541.4453  LR: 0.00000245  \n","Epoch: [3][1800/2467] Elapsed 5m 6s (remain 1m 53s) Loss: 0.0070(0.0145) Grad: 7228.5342  LR: 0.00000231  \n","Epoch: [3][1900/2467] Elapsed 5m 23s (remain 1m 36s) Loss: 0.0050(0.0145) Grad: 13340.1113  LR: 0.00000218  \n","Epoch: [3][2000/2467] Elapsed 5m 40s (remain 1m 19s) Loss: 0.0130(0.0145) Grad: 13357.0586  LR: 0.00000205  \n","Epoch: [3][2100/2467] Elapsed 5m 57s (remain 1m 2s) Loss: 0.0119(0.0144) Grad: 27496.1055  LR: 0.00000192  \n","Epoch: [3][2200/2467] Elapsed 6m 13s (remain 0m 45s) Loss: 0.0153(0.0143) Grad: 6899.1714  LR: 0.00000179  \n","Epoch: [3][2300/2467] Elapsed 6m 30s (remain 0m 28s) Loss: 0.0207(0.0143) Grad: 25512.8828  LR: 0.00000167  \n","Epoch: [3][2400/2467] Elapsed 6m 47s (remain 0m 11s) Loss: 0.0117(0.0143) Grad: 23450.0703  LR: 0.00000156  \n","Epoch: [3][2466/2467] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0135(0.0143) Grad: 10507.4404  LR: 0.00000148  \n","EVAL: [0/138] Elapsed 0m 0s (remain 0m 40s) Loss: 0.1339(0.1339) \n","EVAL: [100/138] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0444(0.0941) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0143  avg_val_loss: 0.0939  time: 431s\n","Epoch 3 - Score: 0.8235\n","Epoch 3 - Save Best Score: 0.8235 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [137/138] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0419(0.0939) \n","Epoch: [4][0/2467] Elapsed 0m 0s (remain 17m 40s) Loss: 0.0062(0.0062) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2467] Elapsed 0m 18s (remain 7m 1s) Loss: 0.0021(0.0112) Grad: 5516.6025  LR: 0.00000137  \n","Epoch: [4][200/2467] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0106(0.0112) Grad: 8384.3330  LR: 0.00000126  \n","Epoch: [4][300/2467] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0061(0.0111) Grad: 8057.0317  LR: 0.00000115  \n","Epoch: [4][400/2467] Elapsed 1m 9s (remain 5m 56s) Loss: 0.0150(0.0112) Grad: 51184.3594  LR: 0.00000105  \n","Epoch: [4][500/2467] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0142(0.0113) Grad: 89884.9219  LR: 0.00000096  \n","Epoch: [4][600/2467] Elapsed 1m 42s (remain 5m 18s) Loss: 0.0019(0.0112) Grad: 13858.8506  LR: 0.00000087  \n","Epoch: [4][700/2467] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0180(0.0113) Grad: 25881.6621  LR: 0.00000078  \n","Epoch: [4][800/2467] Elapsed 2m 15s (remain 4m 42s) Loss: 0.0063(0.0111) Grad: 14248.9688  LR: 0.00000069  \n","Epoch: [4][900/2467] Elapsed 2m 32s (remain 4m 24s) Loss: 0.0143(0.0111) Grad: 34864.1797  LR: 0.00000062  \n","Epoch: [4][1000/2467] Elapsed 2m 48s (remain 4m 7s) Loss: 0.0242(0.0111) Grad: 27547.1270  LR: 0.00000054  \n","Epoch: [4][1100/2467] Elapsed 3m 5s (remain 3m 50s) Loss: 0.0157(0.0112) Grad: 37413.1719  LR: 0.00000047  \n","Epoch: [4][1200/2467] Elapsed 3m 22s (remain 3m 33s) Loss: 0.0238(0.0112) Grad: 65495.4180  LR: 0.00000041  \n","Epoch: [4][1300/2467] Elapsed 3m 39s (remain 3m 17s) Loss: 0.0025(0.0112) Grad: 18102.4512  LR: 0.00000034  \n","Epoch: [4][1400/2467] Elapsed 3m 56s (remain 3m 0s) Loss: 0.0119(0.0112) Grad: 5209.3979  LR: 0.00000029  \n","Epoch: [4][1500/2467] Elapsed 4m 13s (remain 2m 43s) Loss: 0.0088(0.0112) Grad: 36112.1875  LR: 0.00000024  \n","Epoch: [4][1600/2467] Elapsed 4m 30s (remain 2m 26s) Loss: 0.0104(0.0112) Grad: 37863.6172  LR: 0.00000019  \n","Epoch: [4][1700/2467] Elapsed 4m 47s (remain 2m 9s) Loss: 0.0106(0.0112) Grad: 6305.6743  LR: 0.00000015  \n","Epoch: [4][1800/2467] Elapsed 5m 4s (remain 1m 52s) Loss: 0.0071(0.0112) Grad: 17327.6094  LR: 0.00000011  \n","Epoch: [4][1900/2467] Elapsed 5m 21s (remain 1m 35s) Loss: 0.0064(0.0112) Grad: 11809.3906  LR: 0.00000008  \n","Epoch: [4][2000/2467] Elapsed 5m 38s (remain 1m 18s) Loss: 0.0068(0.0112) Grad: 32811.7695  LR: 0.00000006  \n","Epoch: [4][2100/2467] Elapsed 5m 54s (remain 1m 1s) Loss: 0.0071(0.0112) Grad: 13795.9229  LR: 0.00000003  \n","Epoch: [4][2200/2467] Elapsed 6m 11s (remain 0m 44s) Loss: 0.0094(0.0111) Grad: 63389.8320  LR: 0.00000002  \n","Epoch: [4][2300/2467] Elapsed 6m 28s (remain 0m 28s) Loss: 0.0123(0.0111) Grad: 74719.8828  LR: 0.00000001  \n","Epoch: [4][2400/2467] Elapsed 6m 45s (remain 0m 11s) Loss: 0.0126(0.0110) Grad: 32853.3555  LR: 0.00000000  \n","Epoch: [4][2466/2467] Elapsed 6m 56s (remain 0m 0s) Loss: 0.0076(0.0111) Grad: 8158.3081  LR: 0.00000000  \n","EVAL: [0/138] Elapsed 0m 0s (remain 0m 41s) Loss: 0.1364(0.1364) \n","EVAL: [100/138] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0461(0.0958) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0111  avg_val_loss: 0.0957  time: 429s\n","Epoch 4 - Score: 0.8271\n","Epoch 4 - Save Best Score: 0.8271 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [137/138] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0429(0.0957) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.8271\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2468] Elapsed 0m 0s (remain 18m 16s) Loss: 0.4866(0.4866) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2468] Elapsed 0m 18s (remain 7m 3s) Loss: 0.1897(0.1866) Grad: 70786.8828  LR: 0.00001000  \n","Epoch: [1][200/2468] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0879(0.1392) Grad: 41989.7305  LR: 0.00000999  \n","Epoch: [1][300/2468] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0917(0.1206) Grad: 38328.0469  LR: 0.00000998  \n","Epoch: [1][400/2468] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0584(0.1099) Grad: 25457.5840  LR: 0.00000997  \n","Epoch: [1][500/2468] Elapsed 1m 26s (remain 5m 38s) Loss: 0.0691(0.0998) Grad: 31686.6504  LR: 0.00000995  \n","Epoch: [1][600/2468] Elapsed 1m 43s (remain 5m 20s) Loss: 0.0320(0.0917) Grad: 6515.6138  LR: 0.00000992  \n","Epoch: [1][700/2468] Elapsed 2m 0s (remain 5m 2s) Loss: 0.1227(0.0853) Grad: 45427.8164  LR: 0.00000989  \n","Epoch: [1][800/2468] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0465(0.0805) Grad: 11749.8691  LR: 0.00000986  \n","Epoch: [1][900/2468] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0610(0.0761) Grad: 7375.6611  LR: 0.00000982  \n","Epoch: [1][1000/2468] Elapsed 2m 50s (remain 4m 10s) Loss: 0.0223(0.0726) Grad: 2697.1782  LR: 0.00000977  \n","Epoch: [1][1100/2468] Elapsed 3m 8s (remain 3m 53s) Loss: 0.0398(0.0694) Grad: 19336.6016  LR: 0.00000972  \n","Epoch: [1][1200/2468] Elapsed 3m 25s (remain 3m 36s) Loss: 0.0512(0.0678) Grad: 26715.7168  LR: 0.00000967  \n","Epoch: [1][1300/2468] Elapsed 3m 42s (remain 3m 19s) Loss: 0.0327(0.0660) Grad: 19385.9141  LR: 0.00000961  \n","Epoch: [1][1400/2468] Elapsed 3m 59s (remain 3m 2s) Loss: 0.0235(0.0637) Grad: 7034.7393  LR: 0.00000954  \n","Epoch: [1][1500/2468] Elapsed 4m 16s (remain 2m 45s) Loss: 0.0508(0.0619) Grad: 22343.5195  LR: 0.00000947  \n","Epoch: [1][1600/2468] Elapsed 4m 33s (remain 2m 28s) Loss: 0.0344(0.0600) Grad: 6539.2319  LR: 0.00000940  \n","Epoch: [1][1700/2468] Elapsed 4m 50s (remain 2m 11s) Loss: 0.0259(0.0584) Grad: 19588.0371  LR: 0.00000932  \n","Epoch: [1][1800/2468] Elapsed 5m 7s (remain 1m 53s) Loss: 0.0436(0.0570) Grad: 27444.3105  LR: 0.00000924  \n","Epoch: [1][1900/2468] Elapsed 5m 24s (remain 1m 36s) Loss: 0.0077(0.0560) Grad: 1976.1288  LR: 0.00000915  \n","Epoch: [1][2000/2468] Elapsed 5m 41s (remain 1m 19s) Loss: 0.0597(0.0547) Grad: 21885.4062  LR: 0.00000906  \n","Epoch: [1][2100/2468] Elapsed 5m 58s (remain 1m 2s) Loss: 0.0140(0.0538) Grad: 2157.0378  LR: 0.00000896  \n","Epoch: [1][2200/2468] Elapsed 6m 15s (remain 0m 45s) Loss: 0.0511(0.0525) Grad: 50851.1055  LR: 0.00000886  \n","Epoch: [1][2300/2468] Elapsed 6m 32s (remain 0m 28s) Loss: 0.0271(0.0513) Grad: 29309.0508  LR: 0.00000876  \n","Epoch: [1][2400/2468] Elapsed 6m 48s (remain 0m 11s) Loss: 0.0089(0.0502) Grad: 2092.6357  LR: 0.00000865  \n","Epoch: [1][2467/2468] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0125(0.0495) Grad: 5826.3145  LR: 0.00000858  \n","EVAL: [0/137] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1074(0.1074) \n","EVAL: [100/137] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1503(0.0955) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0495  avg_val_loss: 0.0953  time: 433s\n","Epoch 1 - Score: 0.8175\n","Epoch 1 - Save Best Score: 0.8175 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [136/137] Elapsed 0m 12s (remain 0m 0s) Loss: 0.1176(0.0953) \n","Epoch: [2][0/2468] Elapsed 0m 0s (remain 18m 55s) Loss: 0.0327(0.0327) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2468] Elapsed 0m 17s (remain 6m 54s) Loss: 0.0313(0.0206) Grad: 110699.5938  LR: 0.00000846  \n","Epoch: [2][200/2468] Elapsed 0m 35s (remain 6m 40s) Loss: 0.0023(0.0205) Grad: 14215.6367  LR: 0.00000835  \n","Epoch: [2][300/2468] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0410(0.0203) Grad: 44853.4297  LR: 0.00000823  \n","Epoch: [2][400/2468] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0101(0.0200) Grad: 21701.9961  LR: 0.00000810  \n","Epoch: [2][500/2468] Elapsed 1m 26s (remain 5m 38s) Loss: 0.0101(0.0195) Grad: 23480.8984  LR: 0.00000797  \n","Epoch: [2][600/2468] Elapsed 1m 43s (remain 5m 20s) Loss: 0.0144(0.0196) Grad: 27103.9395  LR: 0.00000784  \n","Epoch: [2][700/2468] Elapsed 2m 0s (remain 5m 2s) Loss: 0.0276(0.0196) Grad: 31372.5957  LR: 0.00000771  \n","Epoch: [2][800/2468] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0094(0.0195) Grad: 6501.7925  LR: 0.00000758  \n","Epoch: [2][900/2468] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0220(0.0194) Grad: 17812.7871  LR: 0.00000744  \n","Epoch: [2][1000/2468] Elapsed 2m 50s (remain 4m 10s) Loss: 0.0275(0.0195) Grad: 7717.9316  LR: 0.00000730  \n","Epoch: [2][1100/2468] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0089(0.0195) Grad: 9223.4326  LR: 0.00000715  \n","Epoch: [2][1200/2468] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0218(0.0196) Grad: 42728.9570  LR: 0.00000701  \n","Epoch: [2][1300/2468] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0123(0.0195) Grad: 11991.7900  LR: 0.00000686  \n","Epoch: [2][1400/2468] Elapsed 3m 58s (remain 3m 1s) Loss: 0.0290(0.0195) Grad: 39248.0703  LR: 0.00000671  \n","Epoch: [2][1500/2468] Elapsed 4m 15s (remain 2m 44s) Loss: 0.0224(0.0197) Grad: 53029.8945  LR: 0.00000656  \n","Epoch: [2][1600/2468] Elapsed 4m 31s (remain 2m 27s) Loss: 0.0147(0.0196) Grad: 6952.4038  LR: 0.00000641  \n","Epoch: [2][1700/2468] Elapsed 4m 48s (remain 2m 10s) Loss: 0.0185(0.0197) Grad: 5294.5503  LR: 0.00000625  \n","Epoch: [2][1800/2468] Elapsed 5m 5s (remain 1m 53s) Loss: 0.0129(0.0195) Grad: 20425.2305  LR: 0.00000610  \n","Epoch: [2][1900/2468] Elapsed 5m 22s (remain 1m 36s) Loss: 0.0085(0.0196) Grad: 30255.6543  LR: 0.00000594  \n","Epoch: [2][2000/2468] Elapsed 5m 39s (remain 1m 19s) Loss: 0.0155(0.0195) Grad: 7486.1514  LR: 0.00000578  \n","Epoch: [2][2100/2468] Elapsed 5m 56s (remain 1m 2s) Loss: 0.0164(0.0194) Grad: 8295.0400  LR: 0.00000563  \n","Epoch: [2][2200/2468] Elapsed 6m 13s (remain 0m 45s) Loss: 0.0156(0.0195) Grad: 42272.8398  LR: 0.00000547  \n","Epoch: [2][2300/2468] Elapsed 6m 30s (remain 0m 28s) Loss: 0.0140(0.0195) Grad: 13960.1377  LR: 0.00000531  \n","Epoch: [2][2400/2468] Elapsed 6m 47s (remain 0m 11s) Loss: 0.0161(0.0194) Grad: 52241.6523  LR: 0.00000515  \n","Epoch: [2][2467/2468] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0179(0.0193) Grad: 40118.3398  LR: 0.00000504  \n","EVAL: [0/137] Elapsed 0m 0s (remain 0m 44s) Loss: 0.1079(0.1079) \n","EVAL: [100/137] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1524(0.1016) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0193  avg_val_loss: 0.1012  time: 431s\n","Epoch 2 - Score: 0.8256\n","Epoch 2 - Save Best Score: 0.8256 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [136/137] Elapsed 0m 12s (remain 0m 0s) Loss: 0.1183(0.1012) \n","Epoch: [3][0/2468] Elapsed 0m 0s (remain 18m 14s) Loss: 0.0168(0.0168) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2468] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0064(0.0154) Grad: 42286.3516  LR: 0.00000488  \n","Epoch: [3][200/2468] Elapsed 0m 35s (remain 6m 37s) Loss: 0.0125(0.0161) Grad: 30331.1465  LR: 0.00000472  \n","Epoch: [3][300/2468] Elapsed 0m 52s (remain 6m 15s) Loss: 0.0236(0.0155) Grad: 48875.2539  LR: 0.00000456  \n","Epoch: [3][400/2468] Elapsed 1m 9s (remain 5m 55s) Loss: 0.0138(0.0151) Grad: 5171.1162  LR: 0.00000440  \n","Epoch: [3][500/2468] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0158(0.0151) Grad: 39342.9961  LR: 0.00000424  \n","Epoch: [3][600/2468] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0307(0.0152) Grad: 28180.3477  LR: 0.00000408  \n","Epoch: [3][700/2468] Elapsed 1m 59s (remain 5m 1s) Loss: 0.0063(0.0153) Grad: 2748.3635  LR: 0.00000393  \n","Epoch: [3][800/2468] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0174(0.0154) Grad: 15144.9072  LR: 0.00000377  \n","Epoch: [3][900/2468] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0255(0.0154) Grad: 42704.9258  LR: 0.00000362  \n","Epoch: [3][1000/2468] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0093(0.0154) Grad: 11989.3848  LR: 0.00000347  \n","Epoch: [3][1100/2468] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0060(0.0152) Grad: 5102.9150  LR: 0.00000331  \n","Epoch: [3][1200/2468] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0160(0.0153) Grad: 36859.9297  LR: 0.00000316  \n","Epoch: [3][1300/2468] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0127(0.0153) Grad: 15732.0322  LR: 0.00000302  \n","Epoch: [3][1400/2468] Elapsed 3m 57s (remain 3m 1s) Loss: 0.0202(0.0154) Grad: 26138.9434  LR: 0.00000287  \n","Epoch: [3][1500/2468] Elapsed 4m 14s (remain 2m 44s) Loss: 0.0097(0.0152) Grad: 6399.7412  LR: 0.00000273  \n","Epoch: [3][1600/2468] Elapsed 4m 31s (remain 2m 26s) Loss: 0.0339(0.0152) Grad: 47155.8047  LR: 0.00000259  \n","Epoch: [3][1700/2468] Elapsed 4m 48s (remain 2m 9s) Loss: 0.0116(0.0151) Grad: 3534.7012  LR: 0.00000245  \n","Epoch: [3][1800/2468] Elapsed 5m 5s (remain 1m 52s) Loss: 0.0165(0.0152) Grad: 12350.1406  LR: 0.00000231  \n","Epoch: [3][1900/2468] Elapsed 5m 22s (remain 1m 36s) Loss: 0.0095(0.0152) Grad: 14551.3359  LR: 0.00000218  \n","Epoch: [3][2000/2468] Elapsed 5m 39s (remain 1m 19s) Loss: 0.0094(0.0150) Grad: 33361.0859  LR: 0.00000205  \n","Epoch: [3][2100/2468] Elapsed 5m 56s (remain 1m 2s) Loss: 0.0335(0.0150) Grad: 22019.9219  LR: 0.00000192  \n","Epoch: [3][2200/2468] Elapsed 6m 13s (remain 0m 45s) Loss: 0.0145(0.0150) Grad: 30388.0566  LR: 0.00000180  \n","Epoch: [3][2300/2468] Elapsed 6m 30s (remain 0m 28s) Loss: 0.0050(0.0150) Grad: 15084.5479  LR: 0.00000167  \n","Epoch: [3][2400/2468] Elapsed 6m 47s (remain 0m 11s) Loss: 0.0106(0.0149) Grad: 17315.7754  LR: 0.00000156  \n","Epoch: [3][2467/2468] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0150(0.0149) Grad: 21712.8809  LR: 0.00000148  \n","EVAL: [0/137] Elapsed 0m 0s (remain 0m 44s) Loss: 0.1043(0.1043) \n","EVAL: [100/137] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1471(0.0976) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0149  avg_val_loss: 0.0974  time: 432s\n","Epoch 3 - Score: 0.8364\n","Epoch 3 - Save Best Score: 0.8364 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [136/137] Elapsed 0m 12s (remain 0m 0s) Loss: 0.1187(0.0974) \n","Epoch: [4][0/2468] Elapsed 0m 0s (remain 18m 40s) Loss: 0.0302(0.0302) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2468] Elapsed 0m 17s (remain 6m 53s) Loss: 0.0157(0.0122) Grad: 18134.4922  LR: 0.00000137  \n","Epoch: [4][200/2468] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0047(0.0122) Grad: 26813.6152  LR: 0.00000126  \n","Epoch: [4][300/2468] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0164(0.0122) Grad: 70857.6328  LR: 0.00000115  \n","Epoch: [4][400/2468] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0133(0.0120) Grad: 37960.8125  LR: 0.00000105  \n","Epoch: [4][500/2468] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0068(0.0120) Grad: 34848.0078  LR: 0.00000096  \n","Epoch: [4][600/2468] Elapsed 1m 43s (remain 5m 21s) Loss: 0.0176(0.0118) Grad: 42684.7109  LR: 0.00000087  \n","Epoch: [4][700/2468] Elapsed 2m 0s (remain 5m 3s) Loss: 0.0246(0.0118) Grad: 20787.7402  LR: 0.00000078  \n","Epoch: [4][800/2468] Elapsed 2m 17s (remain 4m 45s) Loss: 0.0061(0.0118) Grad: 11797.7285  LR: 0.00000069  \n","Epoch: [4][900/2468] Elapsed 2m 34s (remain 4m 28s) Loss: 0.0046(0.0118) Grad: 6396.9492  LR: 0.00000062  \n","Epoch: [4][1000/2468] Elapsed 2m 51s (remain 4m 10s) Loss: 0.0155(0.0118) Grad: 15375.1895  LR: 0.00000054  \n","Epoch: [4][1100/2468] Elapsed 3m 8s (remain 3m 53s) Loss: 0.0077(0.0118) Grad: 22191.5723  LR: 0.00000047  \n","Epoch: [4][1200/2468] Elapsed 3m 24s (remain 3m 36s) Loss: 0.0106(0.0117) Grad: 13111.6465  LR: 0.00000041  \n","Epoch: [4][1300/2468] Elapsed 3m 41s (remain 3m 19s) Loss: 0.0111(0.0117) Grad: 35167.6211  LR: 0.00000034  \n","Epoch: [4][1400/2468] Elapsed 3m 58s (remain 3m 1s) Loss: 0.0104(0.0116) Grad: 21130.0938  LR: 0.00000029  \n","Epoch: [4][1500/2468] Elapsed 4m 15s (remain 2m 44s) Loss: 0.0065(0.0117) Grad: 42693.7031  LR: 0.00000024  \n","Epoch: [4][1600/2468] Elapsed 4m 32s (remain 2m 27s) Loss: 0.0056(0.0116) Grad: 15971.6982  LR: 0.00000019  \n","Epoch: [4][1700/2468] Elapsed 4m 49s (remain 2m 10s) Loss: 0.0248(0.0116) Grad: 49017.1914  LR: 0.00000015  \n","Epoch: [4][1800/2468] Elapsed 5m 6s (remain 1m 53s) Loss: 0.0192(0.0115) Grad: 26132.8223  LR: 0.00000011  \n","Epoch: [4][1900/2468] Elapsed 5m 23s (remain 1m 36s) Loss: 0.0206(0.0115) Grad: 74038.1641  LR: 0.00000008  \n","Epoch: [4][2000/2468] Elapsed 5m 40s (remain 1m 19s) Loss: 0.0026(0.0115) Grad: 4401.8262  LR: 0.00000006  \n","Epoch: [4][2100/2468] Elapsed 5m 57s (remain 1m 2s) Loss: 0.0049(0.0115) Grad: 8496.1816  LR: 0.00000003  \n","Epoch: [4][2200/2468] Elapsed 6m 14s (remain 0m 45s) Loss: 0.0053(0.0114) Grad: 5226.7095  LR: 0.00000002  \n","Epoch: [4][2300/2468] Elapsed 6m 31s (remain 0m 28s) Loss: 0.0079(0.0115) Grad: 3446.1045  LR: 0.00000001  \n","Epoch: [4][2400/2468] Elapsed 6m 47s (remain 0m 11s) Loss: 0.0266(0.0115) Grad: 5520.1973  LR: 0.00000000  \n","Epoch: [4][2467/2468] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0146(0.0115) Grad: 16574.8418  LR: 0.00000000  \n","EVAL: [0/137] Elapsed 0m 0s (remain 0m 45s) Loss: 0.1035(0.1035) \n","EVAL: [100/137] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1440(0.0958) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0115  avg_val_loss: 0.0956  time: 432s\n","Epoch 4 - Score: 0.8360\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [136/137] Elapsed 0m 12s (remain 0m 0s) Loss: 0.1143(0.0956) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Score: 0.8364\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2475] Elapsed 0m 0s (remain 17m 18s) Loss: 0.4033(0.4033) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2475] Elapsed 0m 17s (remain 6m 43s) Loss: 0.1312(0.1213) Grad: 33156.1055  LR: 0.00001000  \n","Epoch: [1][200/2475] Elapsed 0m 33s (remain 6m 24s) Loss: 0.0658(0.1068) Grad: 3392.5544  LR: 0.00000999  \n","Epoch: [1][300/2475] Elapsed 0m 50s (remain 6m 7s) Loss: 0.1044(0.1082) Grad: 41714.2695  LR: 0.00000998  \n","Epoch: [1][400/2475] Elapsed 1m 7s (remain 5m 50s) Loss: 0.0423(0.1007) Grad: 21420.7207  LR: 0.00000997  \n","Epoch: [1][500/2475] Elapsed 1m 24s (remain 5m 33s) Loss: 0.1632(0.0936) Grad: 56324.0820  LR: 0.00000995  \n","Epoch: [1][600/2475] Elapsed 1m 41s (remain 5m 15s) Loss: 0.0592(0.0889) Grad: 7015.4219  LR: 0.00000992  \n","Epoch: [1][700/2475] Elapsed 1m 57s (remain 4m 58s) Loss: 0.0529(0.0857) Grad: 6727.0342  LR: 0.00000989  \n","Epoch: [1][800/2475] Elapsed 2m 14s (remain 4m 41s) Loss: 0.0533(0.0813) Grad: 16802.6641  LR: 0.00000986  \n","Epoch: [1][900/2475] Elapsed 2m 31s (remain 4m 24s) Loss: 0.0703(0.0769) Grad: 28583.0332  LR: 0.00000982  \n","Epoch: [1][1000/2475] Elapsed 2m 48s (remain 4m 7s) Loss: 0.0234(0.0728) Grad: 4493.3457  LR: 0.00000977  \n","Epoch: [1][1100/2475] Elapsed 3m 5s (remain 3m 51s) Loss: 0.0543(0.0696) Grad: 15661.1807  LR: 0.00000972  \n","Epoch: [1][1200/2475] Elapsed 3m 22s (remain 3m 34s) Loss: 0.0187(0.0674) Grad: 8982.7480  LR: 0.00000967  \n","Epoch: [1][1300/2475] Elapsed 3m 39s (remain 3m 17s) Loss: 0.0177(0.0658) Grad: 4415.2100  LR: 0.00000961  \n","Epoch: [1][1400/2475] Elapsed 3m 56s (remain 3m 1s) Loss: 0.0271(0.0638) Grad: 3091.1404  LR: 0.00000954  \n","Epoch: [1][1500/2475] Elapsed 4m 13s (remain 2m 44s) Loss: 0.0326(0.0622) Grad: 15436.2793  LR: 0.00000947  \n","Epoch: [1][1600/2475] Elapsed 4m 30s (remain 2m 27s) Loss: 0.0793(0.0605) Grad: 33716.0039  LR: 0.00000940  \n","Epoch: [1][1700/2475] Elapsed 4m 47s (remain 2m 10s) Loss: 0.0287(0.0591) Grad: 2048.2212  LR: 0.00000932  \n","Epoch: [1][1800/2475] Elapsed 5m 4s (remain 1m 53s) Loss: 0.0168(0.0575) Grad: 5898.8916  LR: 0.00000924  \n","Epoch: [1][1900/2475] Elapsed 5m 21s (remain 1m 36s) Loss: 0.0267(0.0563) Grad: 4562.5464  LR: 0.00000915  \n","Epoch: [1][2000/2475] Elapsed 5m 37s (remain 1m 20s) Loss: 0.0529(0.0550) Grad: 12605.1582  LR: 0.00000906  \n","Epoch: [1][2100/2475] Elapsed 5m 54s (remain 1m 3s) Loss: 0.0236(0.0538) Grad: 4976.0176  LR: 0.00000897  \n","Epoch: [1][2200/2475] Elapsed 6m 11s (remain 0m 46s) Loss: 0.0337(0.0526) Grad: 4980.0757  LR: 0.00000887  \n","Epoch: [1][2300/2475] Elapsed 6m 28s (remain 0m 29s) Loss: 0.0276(0.0515) Grad: 29345.4141  LR: 0.00000877  \n","Epoch: [1][2400/2475] Elapsed 6m 45s (remain 0m 12s) Loss: 0.0137(0.0504) Grad: 8065.1216  LR: 0.00000866  \n","Epoch: [1][2474/2475] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0117(0.0497) Grad: 5641.8125  LR: 0.00000858  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 42s) Loss: 0.0805(0.0805) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1380(0.1006) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0497  avg_val_loss: 0.0996  time: 430s\n","Epoch 1 - Score: 0.8139\n","Epoch 1 - Save Best Score: 0.8139 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1007(0.0996) \n","Epoch: [2][0/2475] Elapsed 0m 0s (remain 19m 3s) Loss: 0.0342(0.0342) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2475] Elapsed 0m 17s (remain 6m 59s) Loss: 0.0193(0.0193) Grad: 13125.5576  LR: 0.00000846  \n","Epoch: [2][200/2475] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0125(0.0200) Grad: 32555.5781  LR: 0.00000835  \n","Epoch: [2][300/2475] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0120(0.0200) Grad: 25186.5137  LR: 0.00000823  \n","Epoch: [2][400/2475] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0398(0.0197) Grad: 7484.0630  LR: 0.00000810  \n","Epoch: [2][500/2475] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0194(0.0200) Grad: 47424.9375  LR: 0.00000798  \n","Epoch: [2][600/2475] Elapsed 1m 43s (remain 5m 21s) Loss: 0.0077(0.0203) Grad: 12795.1055  LR: 0.00000785  \n","Epoch: [2][700/2475] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0055(0.0199) Grad: 24445.8398  LR: 0.00000771  \n","Epoch: [2][800/2475] Elapsed 2m 17s (remain 4m 46s) Loss: 0.0380(0.0199) Grad: 9098.2891  LR: 0.00000758  \n","Epoch: [2][900/2475] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0090(0.0200) Grad: 30221.8887  LR: 0.00000744  \n","Epoch: [2][1000/2475] Elapsed 2m 51s (remain 4m 12s) Loss: 0.0094(0.0200) Grad: 13275.4385  LR: 0.00000730  \n","Epoch: [2][1100/2475] Elapsed 3m 8s (remain 3m 54s) Loss: 0.0194(0.0201) Grad: 22970.4863  LR: 0.00000716  \n","Epoch: [2][1200/2475] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0227(0.0201) Grad: 6312.7158  LR: 0.00000701  \n","Epoch: [2][1300/2475] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0167(0.0200) Grad: 10673.1416  LR: 0.00000687  \n","Epoch: [2][1400/2475] Elapsed 3m 58s (remain 3m 2s) Loss: 0.0253(0.0201) Grad: 31415.4961  LR: 0.00000672  \n","Epoch: [2][1500/2475] Elapsed 4m 15s (remain 2m 45s) Loss: 0.0202(0.0201) Grad: 15309.9023  LR: 0.00000657  \n","Epoch: [2][1600/2475] Elapsed 4m 32s (remain 2m 28s) Loss: 0.0096(0.0201) Grad: 26535.6504  LR: 0.00000641  \n","Epoch: [2][1700/2475] Elapsed 4m 49s (remain 2m 11s) Loss: 0.0095(0.0202) Grad: 5016.9917  LR: 0.00000626  \n","Epoch: [2][1800/2475] Elapsed 5m 6s (remain 1m 54s) Loss: 0.0075(0.0201) Grad: 10109.7852  LR: 0.00000611  \n","Epoch: [2][1900/2475] Elapsed 5m 23s (remain 1m 37s) Loss: 0.0157(0.0200) Grad: 12551.5234  LR: 0.00000595  \n","Epoch: [2][2000/2475] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0159(0.0200) Grad: 23521.7090  LR: 0.00000579  \n","Epoch: [2][2100/2475] Elapsed 5m 56s (remain 1m 3s) Loss: 0.0301(0.0199) Grad: 78098.0547  LR: 0.00000564  \n","Epoch: [2][2200/2475] Elapsed 6m 13s (remain 0m 46s) Loss: 0.0209(0.0200) Grad: 19650.6523  LR: 0.00000548  \n","Epoch: [2][2300/2475] Elapsed 6m 30s (remain 0m 29s) Loss: 0.0105(0.0199) Grad: 14958.8516  LR: 0.00000532  \n","Epoch: [2][2400/2475] Elapsed 6m 47s (remain 0m 12s) Loss: 0.0077(0.0198) Grad: 4696.9268  LR: 0.00000516  \n","Epoch: [2][2474/2475] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0410(0.0198) Grad: 9691.7744  LR: 0.00000504  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 42s) Loss: 0.0769(0.0769) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1257(0.0933) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0198  avg_val_loss: 0.0921  time: 432s\n","Epoch 2 - Score: 0.8297\n","Epoch 2 - Save Best Score: 0.8297 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0915(0.0921) \n","Epoch: [3][0/2475] Elapsed 0m 0s (remain 18m 29s) Loss: 0.0251(0.0251) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2475] Elapsed 0m 17s (remain 6m 57s) Loss: 0.0090(0.0188) Grad: 18142.9082  LR: 0.00000488  \n","Epoch: [3][200/2475] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0122(0.0168) Grad: 22109.1367  LR: 0.00000472  \n","Epoch: [3][300/2475] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0074(0.0165) Grad: 16252.8770  LR: 0.00000456  \n","Epoch: [3][400/2475] Elapsed 1m 9s (remain 5m 59s) Loss: 0.0121(0.0159) Grad: 5638.9766  LR: 0.00000440  \n","Epoch: [3][500/2475] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0107(0.0157) Grad: 11030.0215  LR: 0.00000424  \n","Epoch: [3][600/2475] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0175(0.0158) Grad: 24809.9570  LR: 0.00000409  \n","Epoch: [3][700/2475] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0061(0.0158) Grad: 11132.5000  LR: 0.00000393  \n","Epoch: [3][800/2475] Elapsed 2m 17s (remain 4m 46s) Loss: 0.0228(0.0159) Grad: 23610.2578  LR: 0.00000378  \n","Epoch: [3][900/2475] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0064(0.0159) Grad: 5724.1812  LR: 0.00000362  \n","Epoch: [3][1000/2475] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0203(0.0157) Grad: 5012.5229  LR: 0.00000347  \n","Epoch: [3][1100/2475] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0260(0.0157) Grad: 13957.5439  LR: 0.00000332  \n","Epoch: [3][1200/2475] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0214(0.0156) Grad: 30211.1543  LR: 0.00000317  \n","Epoch: [3][1300/2475] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0107(0.0155) Grad: 4917.8921  LR: 0.00000302  \n","Epoch: [3][1400/2475] Elapsed 3m 58s (remain 3m 2s) Loss: 0.0210(0.0154) Grad: 8541.1289  LR: 0.00000288  \n","Epoch: [3][1500/2475] Elapsed 4m 15s (remain 2m 45s) Loss: 0.0129(0.0154) Grad: 10902.9844  LR: 0.00000273  \n","Epoch: [3][1600/2475] Elapsed 4m 32s (remain 2m 28s) Loss: 0.0063(0.0153) Grad: 2125.0544  LR: 0.00000259  \n","Epoch: [3][1700/2475] Elapsed 4m 49s (remain 2m 11s) Loss: 0.0473(0.0153) Grad: 72227.2109  LR: 0.00000245  \n","Epoch: [3][1800/2475] Elapsed 5m 6s (remain 1m 54s) Loss: 0.0284(0.0154) Grad: 42289.9180  LR: 0.00000232  \n","Epoch: [3][1900/2475] Elapsed 5m 23s (remain 1m 37s) Loss: 0.0181(0.0154) Grad: 12582.5605  LR: 0.00000218  \n","Epoch: [3][2000/2475] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0067(0.0153) Grad: 27887.0840  LR: 0.00000205  \n","Epoch: [3][2100/2475] Elapsed 5m 56s (remain 1m 3s) Loss: 0.0159(0.0152) Grad: 64431.9336  LR: 0.00000193  \n","Epoch: [3][2200/2475] Elapsed 6m 13s (remain 0m 46s) Loss: 0.0219(0.0152) Grad: 45274.6992  LR: 0.00000180  \n","Epoch: [3][2300/2475] Elapsed 6m 30s (remain 0m 29s) Loss: 0.0105(0.0152) Grad: 25398.7383  LR: 0.00000168  \n","Epoch: [3][2400/2475] Elapsed 6m 47s (remain 0m 12s) Loss: 0.0087(0.0152) Grad: 24105.1387  LR: 0.00000156  \n","Epoch: [3][2474/2475] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0133(0.0151) Grad: 13859.5332  LR: 0.00000148  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 42s) Loss: 0.0829(0.0829) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1374(0.1028) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0151  avg_val_loss: 0.1016  time: 432s\n","Epoch 3 - Score: 0.8340\n","Epoch 3 - Save Best Score: 0.8340 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0962(0.1016) \n","Epoch: [4][0/2475] Elapsed 0m 0s (remain 18m 59s) Loss: 0.0126(0.0126) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2475] Elapsed 0m 17s (remain 6m 58s) Loss: 0.0087(0.0113) Grad: 6581.4888  LR: 0.00000137  \n","Epoch: [4][200/2475] Elapsed 0m 35s (remain 6m 42s) Loss: 0.0137(0.0116) Grad: 81173.4219  LR: 0.00000126  \n","Epoch: [4][300/2475] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0053(0.0116) Grad: 21659.2305  LR: 0.00000116  \n","Epoch: [4][400/2475] Elapsed 1m 9s (remain 5m 59s) Loss: 0.0054(0.0118) Grad: 13235.9512  LR: 0.00000106  \n","Epoch: [4][500/2475] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0073(0.0119) Grad: 6266.9561  LR: 0.00000096  \n","Epoch: [4][600/2475] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0095(0.0120) Grad: 24340.3594  LR: 0.00000087  \n","Epoch: [4][700/2475] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0131(0.0120) Grad: 18697.5117  LR: 0.00000078  \n","Epoch: [4][800/2475] Elapsed 2m 17s (remain 4m 46s) Loss: 0.0137(0.0120) Grad: 27065.0215  LR: 0.00000070  \n","Epoch: [4][900/2475] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0037(0.0117) Grad: 10785.3223  LR: 0.00000062  \n","Epoch: [4][1000/2475] Elapsed 2m 51s (remain 4m 11s) Loss: 0.0363(0.0117) Grad: 12153.8047  LR: 0.00000054  \n","Epoch: [4][1100/2475] Elapsed 3m 8s (remain 3m 54s) Loss: 0.0051(0.0118) Grad: 2243.4856  LR: 0.00000047  \n","Epoch: [4][1200/2475] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0090(0.0117) Grad: 15758.8242  LR: 0.00000041  \n","Epoch: [4][1300/2475] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0190(0.0117) Grad: 24364.5605  LR: 0.00000035  \n","Epoch: [4][1400/2475] Elapsed 3m 58s (remain 3m 2s) Loss: 0.0177(0.0117) Grad: 24310.8535  LR: 0.00000029  \n","Epoch: [4][1500/2475] Elapsed 4m 15s (remain 2m 45s) Loss: 0.0097(0.0118) Grad: 11586.3887  LR: 0.00000024  \n","Epoch: [4][1600/2475] Elapsed 4m 32s (remain 2m 28s) Loss: 0.0083(0.0117) Grad: 8461.5566  LR: 0.00000019  \n","Epoch: [4][1700/2475] Elapsed 4m 49s (remain 2m 11s) Loss: 0.0056(0.0117) Grad: 5371.4873  LR: 0.00000015  \n","Epoch: [4][1800/2475] Elapsed 5m 5s (remain 1m 54s) Loss: 0.0034(0.0116) Grad: 13143.1768  LR: 0.00000012  \n","Epoch: [4][1900/2475] Elapsed 5m 22s (remain 1m 37s) Loss: 0.0096(0.0116) Grad: 10655.6494  LR: 0.00000008  \n","Epoch: [4][2000/2475] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0042(0.0116) Grad: 6132.8735  LR: 0.00000006  \n","Epoch: [4][2100/2475] Elapsed 5m 57s (remain 1m 3s) Loss: 0.0039(0.0115) Grad: 5449.8848  LR: 0.00000004  \n","Epoch: [4][2200/2475] Elapsed 6m 14s (remain 0m 46s) Loss: 0.0237(0.0115) Grad: 20014.5820  LR: 0.00000002  \n","Epoch: [4][2300/2475] Elapsed 6m 31s (remain 0m 29s) Loss: 0.0037(0.0115) Grad: 5750.2178  LR: 0.00000001  \n","Epoch: [4][2400/2475] Elapsed 6m 48s (remain 0m 12s) Loss: 0.0081(0.0115) Grad: 54387.1914  LR: 0.00000000  \n","Epoch: [4][2474/2475] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0070(0.0115) Grad: 11551.3809  LR: 0.00000000  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 43s) Loss: 0.0814(0.0814) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1336(0.1011) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0115  avg_val_loss: 0.1000  time: 433s\n","Epoch 4 - Score: 0.8310\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0940(0.1000) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","Score: 0.8340\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2475] Elapsed 0m 0s (remain 17m 9s) Loss: 0.4932(0.4932) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2475] Elapsed 0m 17s (remain 6m 48s) Loss: 0.0887(0.1672) Grad: 10361.1709  LR: 0.00001000  \n","Epoch: [1][200/2475] Elapsed 0m 34s (remain 6m 29s) Loss: 0.1078(0.1257) Grad: 13173.4043  LR: 0.00000999  \n","Epoch: [1][300/2475] Elapsed 0m 51s (remain 6m 11s) Loss: 0.0426(0.1150) Grad: 1327.6882  LR: 0.00000998  \n","Epoch: [1][400/2475] Elapsed 1m 8s (remain 5m 54s) Loss: 0.0560(0.1006) Grad: 11467.5645  LR: 0.00000997  \n","Epoch: [1][500/2475] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0664(0.0939) Grad: 12001.6895  LR: 0.00000995  \n","Epoch: [1][600/2475] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0248(0.0874) Grad: 4807.1094  LR: 0.00000992  \n","Epoch: [1][700/2475] Elapsed 1m 59s (remain 5m 2s) Loss: 0.0303(0.0810) Grad: 7932.2866  LR: 0.00000989  \n","Epoch: [1][800/2475] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0324(0.0764) Grad: 8856.5488  LR: 0.00000986  \n","Epoch: [1][900/2475] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0371(0.0726) Grad: 2218.7495  LR: 0.00000982  \n","Epoch: [1][1000/2475] Elapsed 2m 50s (remain 4m 10s) Loss: 0.0953(0.0705) Grad: 18387.5293  LR: 0.00000977  \n","Epoch: [1][1100/2475] Elapsed 3m 7s (remain 3m 53s) Loss: 0.0352(0.0673) Grad: 1224.1746  LR: 0.00000972  \n","Epoch: [1][1200/2475] Elapsed 3m 24s (remain 3m 36s) Loss: 0.0397(0.0647) Grad: 3830.7136  LR: 0.00000967  \n","Epoch: [1][1300/2475] Elapsed 3m 41s (remain 3m 19s) Loss: 0.0422(0.0622) Grad: 4904.6113  LR: 0.00000961  \n","Epoch: [1][1400/2475] Elapsed 3m 58s (remain 3m 2s) Loss: 0.0181(0.0602) Grad: 6631.9351  LR: 0.00000954  \n","Epoch: [1][1500/2475] Elapsed 4m 15s (remain 2m 45s) Loss: 0.0449(0.0582) Grad: 8271.0498  LR: 0.00000947  \n","Epoch: [1][1600/2475] Elapsed 4m 31s (remain 2m 28s) Loss: 0.0265(0.0569) Grad: 4725.7441  LR: 0.00000940  \n","Epoch: [1][1700/2475] Elapsed 4m 48s (remain 2m 11s) Loss: 0.1177(0.0564) Grad: 27420.5977  LR: 0.00000932  \n","Epoch: [1][1800/2475] Elapsed 5m 5s (remain 1m 54s) Loss: 0.0329(0.0563) Grad: 1623.1088  LR: 0.00000924  \n","Epoch: [1][1900/2475] Elapsed 5m 22s (remain 1m 37s) Loss: 0.0324(0.0558) Grad: 5863.3281  LR: 0.00000915  \n","Epoch: [1][2000/2475] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0310(0.0547) Grad: 873.0315  LR: 0.00000906  \n","Epoch: [1][2100/2475] Elapsed 5m 56s (remain 1m 3s) Loss: 0.0476(0.0536) Grad: 13470.6270  LR: 0.00000897  \n","Epoch: [1][2200/2475] Elapsed 6m 14s (remain 0m 46s) Loss: 0.0216(0.0524) Grad: 5490.0864  LR: 0.00000887  \n","Epoch: [1][2300/2475] Elapsed 6m 31s (remain 0m 29s) Loss: 0.0286(0.0513) Grad: 5298.8027  LR: 0.00000877  \n","Epoch: [1][2400/2475] Elapsed 6m 48s (remain 0m 12s) Loss: 0.0148(0.0503) Grad: 9640.6289  LR: 0.00000866  \n","Epoch: [1][2474/2475] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0237(0.0495) Grad: 3691.4380  LR: 0.00000858  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1109(0.1109) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0855(0.0940) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0495  avg_val_loss: 0.0935  time: 433s\n","Epoch 1 - Score: 0.8099\n","Epoch 1 - Save Best Score: 0.8099 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0392(0.0935) \n","Epoch: [2][0/2475] Elapsed 0m 0s (remain 18m 44s) Loss: 0.0343(0.0343) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2475] Elapsed 0m 17s (remain 7m 2s) Loss: 0.0320(0.0202) Grad: 17590.1914  LR: 0.00000846  \n","Epoch: [2][200/2475] Elapsed 0m 35s (remain 6m 42s) Loss: 0.0112(0.0188) Grad: 17133.8535  LR: 0.00000835  \n","Epoch: [2][300/2475] Elapsed 0m 52s (remain 6m 20s) Loss: 0.0181(0.0190) Grad: 8161.3652  LR: 0.00000823  \n","Epoch: [2][400/2475] Elapsed 1m 9s (remain 5m 59s) Loss: 0.0087(0.0188) Grad: 20105.3105  LR: 0.00000810  \n","Epoch: [2][500/2475] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0171(0.0192) Grad: 13850.3252  LR: 0.00000798  \n","Epoch: [2][600/2475] Elapsed 1m 43s (remain 5m 21s) Loss: 0.0220(0.0191) Grad: 12710.8682  LR: 0.00000785  \n","Epoch: [2][700/2475] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0262(0.0190) Grad: 112129.2656  LR: 0.00000771  \n","Epoch: [2][800/2475] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0317(0.0190) Grad: 146449.2031  LR: 0.00000758  \n","Epoch: [2][900/2475] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0116(0.0189) Grad: 36725.7031  LR: 0.00000744  \n","Epoch: [2][1000/2475] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0095(0.0186) Grad: 20531.5000  LR: 0.00000730  \n","Epoch: [2][1100/2475] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0214(0.0187) Grad: 22988.7832  LR: 0.00000716  \n","Epoch: [2][1200/2475] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0139(0.0186) Grad: 29303.2227  LR: 0.00000701  \n","Epoch: [2][1300/2475] Elapsed 3m 42s (remain 3m 20s) Loss: 0.0257(0.0185) Grad: 35312.0938  LR: 0.00000687  \n","Epoch: [2][1400/2475] Elapsed 3m 59s (remain 3m 3s) Loss: 0.0067(0.0184) Grad: 12745.4365  LR: 0.00000672  \n","Epoch: [2][1500/2475] Elapsed 4m 16s (remain 2m 46s) Loss: 0.0166(0.0185) Grad: 26935.6406  LR: 0.00000657  \n","Epoch: [2][1600/2475] Elapsed 4m 33s (remain 2m 29s) Loss: 0.0133(0.0184) Grad: 61466.4805  LR: 0.00000641  \n","Epoch: [2][1700/2475] Elapsed 4m 50s (remain 2m 12s) Loss: 0.0104(0.0185) Grad: 31739.5527  LR: 0.00000626  \n","Epoch: [2][1800/2475] Elapsed 5m 7s (remain 1m 55s) Loss: 0.0313(0.0185) Grad: 12740.9111  LR: 0.00000611  \n","Epoch: [2][1900/2475] Elapsed 5m 24s (remain 1m 38s) Loss: 0.0072(0.0185) Grad: 81148.5938  LR: 0.00000595  \n","Epoch: [2][2000/2475] Elapsed 5m 41s (remain 1m 20s) Loss: 0.0483(0.0185) Grad: 44786.8633  LR: 0.00000579  \n","Epoch: [2][2100/2475] Elapsed 5m 58s (remain 1m 3s) Loss: 0.0139(0.0184) Grad: 44549.6562  LR: 0.00000563  \n","Epoch: [2][2200/2475] Elapsed 6m 16s (remain 0m 46s) Loss: 0.0083(0.0183) Grad: 7960.8555  LR: 0.00000548  \n","Epoch: [2][2300/2475] Elapsed 6m 33s (remain 0m 29s) Loss: 0.0146(0.0184) Grad: 25159.7246  LR: 0.00000532  \n","Epoch: [2][2400/2475] Elapsed 6m 50s (remain 0m 12s) Loss: 0.0140(0.0183) Grad: 12103.8311  LR: 0.00000516  \n","Epoch: [2][2474/2475] Elapsed 7m 3s (remain 0m 0s) Loss: 0.0241(0.0183) Grad: 16071.2402  LR: 0.00000504  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 41s) Loss: 0.1111(0.1111) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0833(0.0924) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0183  avg_val_loss: 0.0922  time: 435s\n","Epoch 2 - Score: 0.8208\n","Epoch 2 - Save Best Score: 0.8208 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0398(0.0922) \n","Epoch: [3][0/2475] Elapsed 0m 0s (remain 19m 5s) Loss: 0.0033(0.0033) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2475] Elapsed 0m 18s (remain 7m 7s) Loss: 0.0095(0.0159) Grad: 41383.3711  LR: 0.00000488  \n","Epoch: [3][200/2475] Elapsed 0m 36s (remain 6m 49s) Loss: 0.0260(0.0166) Grad: 97347.8047  LR: 0.00000472  \n","Epoch: [3][300/2475] Elapsed 0m 53s (remain 6m 24s) Loss: 0.0173(0.0168) Grad: 11166.2881  LR: 0.00000456  \n","Epoch: [3][400/2475] Elapsed 1m 10s (remain 6m 3s) Loss: 0.0258(0.0169) Grad: 21938.6484  LR: 0.00000440  \n","Epoch: [3][500/2475] Elapsed 1m 27s (remain 5m 44s) Loss: 0.0205(0.0166) Grad: 4303.3901  LR: 0.00000424  \n","Epoch: [3][600/2475] Elapsed 1m 44s (remain 5m 25s) Loss: 0.0102(0.0166) Grad: 26811.4180  LR: 0.00000409  \n","Epoch: [3][700/2475] Elapsed 2m 1s (remain 5m 7s) Loss: 0.0159(0.0165) Grad: 9797.6660  LR: 0.00000393  \n","Epoch: [3][800/2475] Elapsed 2m 18s (remain 4m 49s) Loss: 0.0102(0.0166) Grad: 5638.8149  LR: 0.00000378  \n","Epoch: [3][900/2475] Elapsed 2m 35s (remain 4m 31s) Loss: 0.0043(0.0166) Grad: 23932.1113  LR: 0.00000362  \n","Epoch: [3][1000/2475] Elapsed 2m 52s (remain 4m 14s) Loss: 0.0242(0.0168) Grad: 16484.2051  LR: 0.00000347  \n","Epoch: [3][1100/2475] Elapsed 3m 9s (remain 3m 56s) Loss: 0.0202(0.0169) Grad: 4100.8569  LR: 0.00000332  \n","Epoch: [3][1200/2475] Elapsed 3m 26s (remain 3m 39s) Loss: 0.0123(0.0169) Grad: 11479.6787  LR: 0.00000317  \n","Epoch: [3][1300/2475] Elapsed 3m 43s (remain 3m 22s) Loss: 0.0150(0.0170) Grad: 19012.0508  LR: 0.00000302  \n","Epoch: [3][1400/2475] Elapsed 4m 1s (remain 3m 4s) Loss: 0.0063(0.0169) Grad: 13225.3965  LR: 0.00000288  \n","Epoch: [3][1500/2475] Elapsed 4m 18s (remain 2m 47s) Loss: 0.0079(0.0169) Grad: 20912.0410  LR: 0.00000273  \n","Epoch: [3][1600/2475] Elapsed 4m 35s (remain 2m 30s) Loss: 0.0474(0.0168) Grad: 40579.6289  LR: 0.00000259  \n","Epoch: [3][1700/2475] Elapsed 4m 52s (remain 2m 13s) Loss: 0.0076(0.0168) Grad: 25622.4434  LR: 0.00000245  \n","Epoch: [3][1800/2475] Elapsed 5m 9s (remain 1m 55s) Loss: 0.0123(0.0167) Grad: 24313.6250  LR: 0.00000232  \n","Epoch: [3][1900/2475] Elapsed 5m 26s (remain 1m 38s) Loss: 0.0282(0.0168) Grad: 28321.9668  LR: 0.00000218  \n","Epoch: [3][2000/2475] Elapsed 5m 43s (remain 1m 21s) Loss: 0.0181(0.0167) Grad: 23836.8125  LR: 0.00000205  \n","Epoch: [3][2100/2475] Elapsed 6m 0s (remain 1m 4s) Loss: 0.0118(0.0167) Grad: 19891.7695  LR: 0.00000193  \n","Epoch: [3][2200/2475] Elapsed 6m 17s (remain 0m 46s) Loss: 0.0145(0.0166) Grad: 33881.1875  LR: 0.00000180  \n","Epoch: [3][2300/2475] Elapsed 6m 34s (remain 0m 29s) Loss: 0.0179(0.0166) Grad: 54740.0117  LR: 0.00000168  \n","Epoch: [3][2400/2475] Elapsed 6m 51s (remain 0m 12s) Loss: 0.0116(0.0165) Grad: 9657.1426  LR: 0.00000156  \n","Epoch: [3][2474/2475] Elapsed 7m 3s (remain 0m 0s) Loss: 0.0083(0.0165) Grad: 74832.7656  LR: 0.00000148  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 42s) Loss: 0.1097(0.1097) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0874(0.0964) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0165  avg_val_loss: 0.0962  time: 436s\n","Epoch 3 - Score: 0.8325\n","Epoch 3 - Save Best Score: 0.8325 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0403(0.0962) \n","Epoch: [4][0/2475] Elapsed 0m 0s (remain 18m 36s) Loss: 0.0097(0.0097) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2475] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0120(0.0129) Grad: 16315.5410  LR: 0.00000137  \n","Epoch: [4][200/2475] Elapsed 0m 35s (remain 6m 40s) Loss: 0.0124(0.0132) Grad: 26557.7773  LR: 0.00000126  \n","Epoch: [4][300/2475] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0140(0.0136) Grad: 19436.5391  LR: 0.00000115  \n","Epoch: [4][400/2475] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0039(0.0138) Grad: 10215.3525  LR: 0.00000105  \n","Epoch: [4][500/2475] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0075(0.0138) Grad: 16977.3711  LR: 0.00000096  \n","Epoch: [4][600/2475] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0197(0.0136) Grad: 31016.6172  LR: 0.00000087  \n","Epoch: [4][700/2475] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0156(0.0137) Grad: 28110.7949  LR: 0.00000078  \n","Epoch: [4][800/2475] Elapsed 2m 17s (remain 4m 46s) Loss: 0.0100(0.0138) Grad: 35529.2734  LR: 0.00000070  \n","Epoch: [4][900/2475] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0120(0.0138) Grad: 14815.4346  LR: 0.00000062  \n","Epoch: [4][1000/2475] Elapsed 2m 51s (remain 4m 12s) Loss: 0.0120(0.0137) Grad: 23894.5977  LR: 0.00000054  \n","Epoch: [4][1100/2475] Elapsed 3m 8s (remain 3m 54s) Loss: 0.0112(0.0137) Grad: 11229.0674  LR: 0.00000047  \n","Epoch: [4][1200/2475] Elapsed 3m 25s (remain 3m 37s) Loss: 0.0119(0.0137) Grad: 10902.3525  LR: 0.00000041  \n","Epoch: [4][1300/2475] Elapsed 3m 42s (remain 3m 20s) Loss: 0.0063(0.0136) Grad: 21128.9844  LR: 0.00000035  \n","Epoch: [4][1400/2475] Elapsed 3m 59s (remain 3m 3s) Loss: 0.0121(0.0136) Grad: 19904.9141  LR: 0.00000029  \n","Epoch: [4][1500/2475] Elapsed 4m 16s (remain 2m 46s) Loss: 0.0033(0.0135) Grad: 21270.5781  LR: 0.00000024  \n","Epoch: [4][1600/2475] Elapsed 4m 33s (remain 2m 29s) Loss: 0.0231(0.0135) Grad: 60326.8047  LR: 0.00000019  \n","Epoch: [4][1700/2475] Elapsed 4m 50s (remain 2m 12s) Loss: 0.0054(0.0135) Grad: 13602.7451  LR: 0.00000015  \n","Epoch: [4][1800/2475] Elapsed 5m 7s (remain 1m 55s) Loss: 0.0052(0.0135) Grad: 15835.3936  LR: 0.00000012  \n","Epoch: [4][1900/2475] Elapsed 5m 24s (remain 1m 37s) Loss: 0.0156(0.0134) Grad: 60562.7852  LR: 0.00000008  \n","Epoch: [4][2000/2475] Elapsed 5m 41s (remain 1m 20s) Loss: 0.0141(0.0134) Grad: 20178.1523  LR: 0.00000006  \n","Epoch: [4][2100/2475] Elapsed 5m 58s (remain 1m 3s) Loss: 0.0040(0.0134) Grad: 14296.9434  LR: 0.00000004  \n","Epoch: [4][2200/2475] Elapsed 6m 15s (remain 0m 46s) Loss: 0.0042(0.0133) Grad: 4094.6082  LR: 0.00000002  \n","Epoch: [4][2300/2475] Elapsed 6m 32s (remain 0m 29s) Loss: 0.0226(0.0133) Grad: 36680.4961  LR: 0.00000001  \n","Epoch: [4][2400/2475] Elapsed 6m 49s (remain 0m 12s) Loss: 0.0241(0.0133) Grad: 65341.1172  LR: 0.00000000  \n","Epoch: [4][2474/2475] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0107(0.0133) Grad: 27519.7988  LR: 0.00000000  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1090(0.1090) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0871(0.0965) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0133  avg_val_loss: 0.0963  time: 434s\n","Epoch 4 - Score: 0.8294\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0407(0.0963) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 3 result ==========\n","Score: 0.8325\n","========== fold: 4 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2479] Elapsed 0m 0s (remain 17m 20s) Loss: 0.2996(0.2996) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2479] Elapsed 0m 17s (remain 6m 47s) Loss: 0.0842(0.1401) Grad: 26828.1113  LR: 0.00001000  \n","Epoch: [1][200/2479] Elapsed 0m 34s (remain 6m 30s) Loss: 0.2323(0.1128) Grad: 80145.2891  LR: 0.00000999  \n","Epoch: [1][300/2479] Elapsed 0m 51s (remain 6m 11s) Loss: 0.0755(0.0972) Grad: 14664.4346  LR: 0.00000998  \n","Epoch: [1][400/2479] Elapsed 1m 8s (remain 5m 53s) Loss: 0.0468(0.0893) Grad: 8275.4727  LR: 0.00000997  \n","Epoch: [1][500/2479] Elapsed 1m 25s (remain 5m 36s) Loss: 0.0490(0.0850) Grad: 3128.3162  LR: 0.00000995  \n","Epoch: [1][600/2479] Elapsed 1m 42s (remain 5m 18s) Loss: 0.0574(0.0843) Grad: 19941.9199  LR: 0.00000992  \n","Epoch: [1][700/2479] Elapsed 1m 58s (remain 5m 1s) Loss: 0.0287(0.0790) Grad: 3973.5547  LR: 0.00000989  \n","Epoch: [1][800/2479] Elapsed 2m 15s (remain 4m 44s) Loss: 0.0536(0.0743) Grad: 20324.0723  LR: 0.00000986  \n","Epoch: [1][900/2479] Elapsed 2m 32s (remain 4m 27s) Loss: 0.0311(0.0708) Grad: 11618.6621  LR: 0.00000982  \n","Epoch: [1][1000/2479] Elapsed 2m 49s (remain 4m 10s) Loss: 0.0379(0.0675) Grad: 17822.7383  LR: 0.00000977  \n","Epoch: [1][1100/2479] Elapsed 3m 6s (remain 3m 53s) Loss: 0.0400(0.0649) Grad: 3161.7837  LR: 0.00000972  \n","Epoch: [1][1200/2479] Elapsed 3m 23s (remain 3m 36s) Loss: 0.0161(0.0625) Grad: 1228.3319  LR: 0.00000967  \n","Epoch: [1][1300/2479] Elapsed 3m 40s (remain 3m 19s) Loss: 0.0415(0.0607) Grad: 18658.3477  LR: 0.00000961  \n","Epoch: [1][1400/2479] Elapsed 3m 56s (remain 3m 2s) Loss: 0.0458(0.0586) Grad: 10436.6943  LR: 0.00000954  \n","Epoch: [1][1500/2479] Elapsed 4m 13s (remain 2m 45s) Loss: 0.0385(0.0569) Grad: 10316.6904  LR: 0.00000948  \n","Epoch: [1][1600/2479] Elapsed 4m 30s (remain 2m 28s) Loss: 0.0599(0.0557) Grad: 16425.3027  LR: 0.00000940  \n","Epoch: [1][1700/2479] Elapsed 4m 46s (remain 2m 11s) Loss: 0.0156(0.0545) Grad: 6432.0015  LR: 0.00000933  \n","Epoch: [1][1800/2479] Elapsed 5m 3s (remain 1m 54s) Loss: 0.0223(0.0533) Grad: 4760.5420  LR: 0.00000924  \n","Epoch: [1][1900/2479] Elapsed 5m 20s (remain 1m 37s) Loss: 0.0178(0.0522) Grad: 1729.8436  LR: 0.00000916  \n","Epoch: [1][2000/2479] Elapsed 5m 37s (remain 1m 20s) Loss: 0.0327(0.0510) Grad: 14189.9434  LR: 0.00000907  \n","Epoch: [1][2100/2479] Elapsed 5m 54s (remain 1m 3s) Loss: 0.0270(0.0500) Grad: 26259.5703  LR: 0.00000897  \n","Epoch: [1][2200/2479] Elapsed 6m 11s (remain 0m 46s) Loss: 0.0188(0.0490) Grad: 3413.2175  LR: 0.00000887  \n","Epoch: [1][2300/2479] Elapsed 6m 28s (remain 0m 30s) Loss: 0.0354(0.0479) Grad: 10629.3604  LR: 0.00000877  \n","Epoch: [1][2400/2479] Elapsed 6m 45s (remain 0m 13s) Loss: 0.0639(0.0471) Grad: 54674.8281  LR: 0.00000866  \n","Epoch: [1][2478/2479] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0378(0.0464) Grad: 6936.6685  LR: 0.00000858  \n","EVAL: [0/126] Elapsed 0m 0s (remain 0m 42s) Loss: 0.0940(0.0940) \n","EVAL: [100/126] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0609(0.1023) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0464  avg_val_loss: 0.1026  time: 430s\n","Epoch 1 - Score: 0.7996\n","Epoch 1 - Save Best Score: 0.7996 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [125/126] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1175(0.1026) \n","Epoch: [2][0/2479] Elapsed 0m 0s (remain 18m 27s) Loss: 0.0124(0.0124) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2479] Elapsed 0m 17s (remain 7m 0s) Loss: 0.0249(0.0221) Grad: 38447.6953  LR: 0.00000846  \n","Epoch: [2][200/2479] Elapsed 0m 35s (remain 6m 40s) Loss: 0.0204(0.0213) Grad: 5959.7061  LR: 0.00000835  \n","Epoch: [2][300/2479] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0334(0.0213) Grad: 74322.5547  LR: 0.00000823  \n","Epoch: [2][400/2479] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0254(0.0207) Grad: 6110.2764  LR: 0.00000810  \n","Epoch: [2][500/2479] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0132(0.0202) Grad: 36108.5859  LR: 0.00000798  \n","Epoch: [2][600/2479] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0115(0.0198) Grad: 20399.1484  LR: 0.00000785  \n","Epoch: [2][700/2479] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0514(0.0197) Grad: 75680.7188  LR: 0.00000772  \n","Epoch: [2][800/2479] Elapsed 2m 16s (remain 4m 46s) Loss: 0.0131(0.0197) Grad: 28085.4648  LR: 0.00000758  \n","Epoch: [2][900/2479] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0226(0.0197) Grad: 13691.7119  LR: 0.00000744  \n","Epoch: [2][1000/2479] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0202(0.0197) Grad: 70360.9375  LR: 0.00000730  \n","Epoch: [2][1100/2479] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0398(0.0196) Grad: 10487.2773  LR: 0.00000716  \n","Epoch: [2][1200/2479] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0320(0.0194) Grad: 59637.0586  LR: 0.00000702  \n","Epoch: [2][1300/2479] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0254(0.0195) Grad: 9622.3506  LR: 0.00000687  \n","Epoch: [2][1400/2479] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0310(0.0194) Grad: 5209.3550  LR: 0.00000672  \n","Epoch: [2][1500/2479] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0162(0.0193) Grad: 40226.8359  LR: 0.00000657  \n","Epoch: [2][1600/2479] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0184(0.0193) Grad: 38557.6953  LR: 0.00000642  \n","Epoch: [2][1700/2479] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0090(0.0192) Grad: 17175.2305  LR: 0.00000627  \n","Epoch: [2][1800/2479] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0118(0.0192) Grad: 8451.8096  LR: 0.00000611  \n","Epoch: [2][1900/2479] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0205(0.0192) Grad: 49496.5898  LR: 0.00000596  \n","Epoch: [2][2000/2479] Elapsed 5m 40s (remain 1m 21s) Loss: 0.0140(0.0192) Grad: 4107.6250  LR: 0.00000580  \n","Epoch: [2][2100/2479] Elapsed 5m 57s (remain 1m 4s) Loss: 0.0081(0.0191) Grad: 33514.7461  LR: 0.00000564  \n","Epoch: [2][2200/2479] Elapsed 6m 14s (remain 0m 47s) Loss: 0.0284(0.0190) Grad: 19947.2129  LR: 0.00000548  \n","Epoch: [2][2300/2479] Elapsed 6m 31s (remain 0m 30s) Loss: 0.0255(0.0190) Grad: 5573.3638  LR: 0.00000533  \n","Epoch: [2][2400/2479] Elapsed 6m 48s (remain 0m 13s) Loss: 0.0109(0.0190) Grad: 11319.0215  LR: 0.00000517  \n","Epoch: [2][2478/2479] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0092(0.0191) Grad: 22487.2676  LR: 0.00000504  \n","EVAL: [0/126] Elapsed 0m 0s (remain 0m 41s) Loss: 0.0875(0.0875) \n","EVAL: [100/126] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0534(0.0935) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0191  avg_val_loss: 0.0937  time: 434s\n","Epoch 2 - Score: 0.8085\n","Epoch 2 - Save Best Score: 0.8085 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [125/126] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1137(0.0937) \n","Epoch: [3][0/2479] Elapsed 0m 0s (remain 18m 50s) Loss: 0.0122(0.0122) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2479] Elapsed 0m 17s (remain 7m 3s) Loss: 0.0193(0.0151) Grad: 23803.7285  LR: 0.00000488  \n","Epoch: [3][200/2479] Elapsed 0m 35s (remain 6m 43s) Loss: 0.0137(0.0152) Grad: 8366.5186  LR: 0.00000472  \n","Epoch: [3][300/2479] Elapsed 0m 52s (remain 6m 20s) Loss: 0.0030(0.0151) Grad: 1970.0284  LR: 0.00000456  \n","Epoch: [3][400/2479] Elapsed 1m 9s (remain 6m 0s) Loss: 0.0068(0.0152) Grad: 25577.9180  LR: 0.00000441  \n","Epoch: [3][500/2479] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0096(0.0152) Grad: 36671.0820  LR: 0.00000425  \n","Epoch: [3][600/2479] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0148(0.0153) Grad: 45878.0703  LR: 0.00000409  \n","Epoch: [3][700/2479] Elapsed 1m 59s (remain 5m 4s) Loss: 0.0075(0.0151) Grad: 3679.9470  LR: 0.00000393  \n","Epoch: [3][800/2479] Elapsed 2m 16s (remain 4m 46s) Loss: 0.0095(0.0152) Grad: 29247.4648  LR: 0.00000378  \n","Epoch: [3][900/2479] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0078(0.0152) Grad: 4185.0513  LR: 0.00000363  \n","Epoch: [3][1000/2479] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0107(0.0151) Grad: 8695.5479  LR: 0.00000347  \n","Epoch: [3][1100/2479] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0088(0.0149) Grad: 26816.2129  LR: 0.00000332  \n","Epoch: [3][1200/2479] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0202(0.0148) Grad: 25233.4004  LR: 0.00000317  \n","Epoch: [3][1300/2479] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0187(0.0147) Grad: 30408.6992  LR: 0.00000303  \n","Epoch: [3][1400/2479] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0255(0.0148) Grad: 34099.0352  LR: 0.00000288  \n","Epoch: [3][1500/2479] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0195(0.0148) Grad: 11018.7656  LR: 0.00000274  \n","Epoch: [3][1600/2479] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0130(0.0147) Grad: 21648.2793  LR: 0.00000260  \n","Epoch: [3][1700/2479] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0089(0.0147) Grad: 21146.4570  LR: 0.00000246  \n","Epoch: [3][1800/2479] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0099(0.0147) Grad: 9914.8564  LR: 0.00000232  \n","Epoch: [3][1900/2479] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0360(0.0147) Grad: 24281.7207  LR: 0.00000219  \n","Epoch: [3][2000/2479] Elapsed 5m 40s (remain 1m 21s) Loss: 0.0051(0.0147) Grad: 25629.7812  LR: 0.00000206  \n","Epoch: [3][2100/2479] Elapsed 5m 57s (remain 1m 4s) Loss: 0.0027(0.0146) Grad: 7772.3799  LR: 0.00000193  \n","Epoch: [3][2200/2479] Elapsed 6m 14s (remain 0m 47s) Loss: 0.0307(0.0147) Grad: 12339.6230  LR: 0.00000181  \n","Epoch: [3][2300/2479] Elapsed 6m 31s (remain 0m 30s) Loss: 0.0110(0.0146) Grad: 24733.1621  LR: 0.00000169  \n","Epoch: [3][2400/2479] Elapsed 6m 48s (remain 0m 13s) Loss: 0.0110(0.0145) Grad: 4967.9951  LR: 0.00000157  \n","Epoch: [3][2478/2479] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0080(0.0145) Grad: 2951.3105  LR: 0.00000148  \n","EVAL: [0/126] Elapsed 0m 0s (remain 0m 41s) Loss: 0.0905(0.0905) \n","EVAL: [100/126] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0543(0.0935) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0145  avg_val_loss: 0.0940  time: 433s\n","Epoch 3 - Score: 0.8170\n","Epoch 3 - Save Best Score: 0.8170 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [125/126] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1083(0.0940) \n","Epoch: [4][0/2479] Elapsed 0m 0s (remain 19m 10s) Loss: 0.0098(0.0098) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2479] Elapsed 0m 18s (remain 7m 6s) Loss: 0.0146(0.0108) Grad: 81231.5859  LR: 0.00000137  \n","Epoch: [4][200/2479] Elapsed 0m 35s (remain 6m 44s) Loss: 0.0112(0.0107) Grad: 27495.8691  LR: 0.00000126  \n","Epoch: [4][300/2479] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0068(0.0113) Grad: 5167.3081  LR: 0.00000116  \n","Epoch: [4][400/2479] Elapsed 1m 8s (remain 5m 57s) Loss: 0.0136(0.0114) Grad: 13986.5654  LR: 0.00000106  \n","Epoch: [4][500/2479] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0062(0.0116) Grad: 6092.0664  LR: 0.00000096  \n","Epoch: [4][600/2479] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0098(0.0115) Grad: 17846.2344  LR: 0.00000087  \n","Epoch: [4][700/2479] Elapsed 1m 58s (remain 5m 1s) Loss: 0.0050(0.0113) Grad: 19358.4629  LR: 0.00000078  \n","Epoch: [4][800/2479] Elapsed 2m 15s (remain 4m 43s) Loss: 0.0184(0.0111) Grad: 50309.5664  LR: 0.00000070  \n","Epoch: [4][900/2479] Elapsed 2m 32s (remain 4m 26s) Loss: 0.0117(0.0111) Grad: 4750.4946  LR: 0.00000062  \n","Epoch: [4][1000/2479] Elapsed 2m 48s (remain 4m 9s) Loss: 0.0057(0.0110) Grad: 21345.5391  LR: 0.00000055  \n","Epoch: [4][1100/2479] Elapsed 3m 5s (remain 3m 51s) Loss: 0.0051(0.0110) Grad: 9206.2314  LR: 0.00000048  \n","Epoch: [4][1200/2479] Elapsed 3m 22s (remain 3m 35s) Loss: 0.0141(0.0110) Grad: 7047.7227  LR: 0.00000041  \n","Epoch: [4][1300/2479] Elapsed 3m 39s (remain 3m 18s) Loss: 0.0185(0.0109) Grad: 10314.8223  LR: 0.00000035  \n","Epoch: [4][1400/2479] Elapsed 3m 55s (remain 3m 1s) Loss: 0.0115(0.0110) Grad: 19082.5371  LR: 0.00000029  \n","Epoch: [4][1500/2479] Elapsed 4m 12s (remain 2m 44s) Loss: 0.0151(0.0109) Grad: 9163.8516  LR: 0.00000024  \n","Epoch: [4][1600/2479] Elapsed 4m 29s (remain 2m 27s) Loss: 0.0053(0.0110) Grad: 2935.4175  LR: 0.00000020  \n","Epoch: [4][1700/2479] Elapsed 4m 45s (remain 2m 10s) Loss: 0.0062(0.0110) Grad: 16207.8672  LR: 0.00000015  \n","Epoch: [4][1800/2479] Elapsed 5m 2s (remain 1m 53s) Loss: 0.0129(0.0110) Grad: 7869.5142  LR: 0.00000012  \n","Epoch: [4][1900/2479] Elapsed 5m 19s (remain 1m 37s) Loss: 0.0037(0.0109) Grad: 5723.8740  LR: 0.00000009  \n","Epoch: [4][2000/2479] Elapsed 5m 35s (remain 1m 20s) Loss: 0.0070(0.0110) Grad: 12361.4453  LR: 0.00000006  \n","Epoch: [4][2100/2479] Elapsed 5m 52s (remain 1m 3s) Loss: 0.0155(0.0110) Grad: 7489.8340  LR: 0.00000004  \n","Epoch: [4][2200/2479] Elapsed 6m 8s (remain 0m 46s) Loss: 0.0082(0.0110) Grad: 8911.1270  LR: 0.00000002  \n","Epoch: [4][2300/2479] Elapsed 6m 25s (remain 0m 29s) Loss: 0.0164(0.0110) Grad: 16932.5781  LR: 0.00000001  \n","Epoch: [4][2400/2479] Elapsed 6m 42s (remain 0m 13s) Loss: 0.0046(0.0110) Grad: 16081.5381  LR: 0.00000000  \n","Epoch: [4][2478/2479] Elapsed 6m 55s (remain 0m 0s) Loss: 0.0343(0.0110) Grad: 72154.7109  LR: 0.00000000  \n","EVAL: [0/126] Elapsed 0m 0s (remain 0m 41s) Loss: 0.0893(0.0893) \n","EVAL: [100/126] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0532(0.0930) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0110  avg_val_loss: 0.0936  time: 427s\n","Epoch 4 - Score: 0.8168\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [125/126] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1099(0.0936) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 4 result ==========\n","Score: 0.8170\n","========== fold: 5 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2464] Elapsed 0m 0s (remain 16m 34s) Loss: 0.5322(0.5322) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2464] Elapsed 0m 16s (remain 6m 36s) Loss: 0.1451(0.1643) Grad: 38325.7500  LR: 0.00001000  \n","Epoch: [1][200/2464] Elapsed 0m 33s (remain 6m 18s) Loss: 0.0758(0.1278) Grad: 12284.4209  LR: 0.00000999  \n","Epoch: [1][300/2464] Elapsed 0m 50s (remain 6m 1s) Loss: 0.0698(0.1088) Grad: 24472.5000  LR: 0.00000998  \n","Epoch: [1][400/2464] Elapsed 1m 6s (remain 5m 44s) Loss: 0.0157(0.1022) Grad: 5507.6362  LR: 0.00000997  \n","Epoch: [1][500/2464] Elapsed 1m 23s (remain 5m 27s) Loss: 0.0283(0.0974) Grad: 10647.0469  LR: 0.00000995  \n","Epoch: [1][600/2464] Elapsed 1m 40s (remain 5m 10s) Loss: 0.0250(0.0894) Grad: 7101.6733  LR: 0.00000992  \n","Epoch: [1][700/2464] Elapsed 1m 56s (remain 4m 54s) Loss: 0.0365(0.0831) Grad: 5727.0435  LR: 0.00000989  \n","Epoch: [1][800/2464] Elapsed 2m 13s (remain 4m 37s) Loss: 0.0345(0.0788) Grad: 4568.5010  LR: 0.00000986  \n","Epoch: [1][900/2464] Elapsed 2m 30s (remain 4m 20s) Loss: 0.0205(0.0755) Grad: 7620.8696  LR: 0.00000982  \n","Epoch: [1][1000/2464] Elapsed 2m 46s (remain 4m 3s) Loss: 0.0437(0.0721) Grad: 14793.8867  LR: 0.00000977  \n","Epoch: [1][1100/2464] Elapsed 3m 3s (remain 3m 47s) Loss: 0.0479(0.0691) Grad: 19257.2090  LR: 0.00000972  \n","Epoch: [1][1200/2464] Elapsed 3m 20s (remain 3m 30s) Loss: 0.0120(0.0668) Grad: 6442.7461  LR: 0.00000966  \n","Epoch: [1][1300/2464] Elapsed 3m 36s (remain 3m 13s) Loss: 0.0304(0.0648) Grad: 3612.0439  LR: 0.00000960  \n","Epoch: [1][1400/2464] Elapsed 3m 53s (remain 2m 57s) Loss: 0.0500(0.0633) Grad: 3915.6609  LR: 0.00000954  \n","Epoch: [1][1500/2464] Elapsed 4m 10s (remain 2m 40s) Loss: 0.0202(0.0619) Grad: 9781.6621  LR: 0.00000947  \n","Epoch: [1][1600/2464] Elapsed 4m 26s (remain 2m 23s) Loss: 0.0366(0.0598) Grad: 4938.3022  LR: 0.00000940  \n","Epoch: [1][1700/2464] Elapsed 4m 43s (remain 2m 7s) Loss: 0.0663(0.0583) Grad: 31279.9199  LR: 0.00000932  \n","Epoch: [1][1800/2464] Elapsed 5m 0s (remain 1m 50s) Loss: 0.0334(0.0568) Grad: 9813.3096  LR: 0.00000923  \n","Epoch: [1][1900/2464] Elapsed 5m 16s (remain 1m 33s) Loss: 0.0397(0.0561) Grad: 8320.7578  LR: 0.00000915  \n","Epoch: [1][2000/2464] Elapsed 5m 33s (remain 1m 17s) Loss: 0.0111(0.0547) Grad: 5969.1445  LR: 0.00000905  \n","Epoch: [1][2100/2464] Elapsed 5m 50s (remain 1m 0s) Loss: 0.0383(0.0534) Grad: 34981.5000  LR: 0.00000896  \n","Epoch: [1][2200/2464] Elapsed 6m 7s (remain 0m 43s) Loss: 0.0173(0.0523) Grad: 3352.5212  LR: 0.00000886  \n","Epoch: [1][2300/2464] Elapsed 6m 23s (remain 0m 27s) Loss: 0.0392(0.0513) Grad: 20204.2109  LR: 0.00000876  \n","Epoch: [1][2400/2464] Elapsed 6m 40s (remain 0m 10s) Loss: 0.0300(0.0504) Grad: 6422.8608  LR: 0.00000865  \n","Epoch: [1][2463/2464] Elapsed 6m 51s (remain 0m 0s) Loss: 0.0695(0.0497) Grad: 15201.1201  LR: 0.00000858  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 47s) Loss: 0.1144(0.1144) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0750(0.0905) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0497  avg_val_loss: 0.0924  time: 424s\n","Epoch 1 - Score: 0.7997\n","Epoch 1 - Save Best Score: 0.7997 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0575(0.0924) \n","Epoch: [2][0/2464] Elapsed 0m 0s (remain 18m 18s) Loss: 0.0245(0.0245) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2464] Elapsed 0m 17s (remain 6m 44s) Loss: 0.0091(0.0205) Grad: 12446.3789  LR: 0.00000846  \n","Epoch: [2][200/2464] Elapsed 0m 34s (remain 6m 30s) Loss: 0.0313(0.0208) Grad: 39950.6016  LR: 0.00000835  \n","Epoch: [2][300/2464] Elapsed 0m 51s (remain 6m 9s) Loss: 0.0302(0.0204) Grad: 43099.5781  LR: 0.00000822  \n","Epoch: [2][400/2464] Elapsed 1m 8s (remain 5m 50s) Loss: 0.0239(0.0206) Grad: 32332.6914  LR: 0.00000810  \n","Epoch: [2][500/2464] Elapsed 1m 24s (remain 5m 32s) Loss: 0.0313(0.0204) Grad: 17253.7148  LR: 0.00000797  \n","Epoch: [2][600/2464] Elapsed 1m 41s (remain 5m 14s) Loss: 0.0183(0.0203) Grad: 47747.9102  LR: 0.00000784  \n","Epoch: [2][700/2464] Elapsed 1m 58s (remain 4m 57s) Loss: 0.0057(0.0199) Grad: 27005.3535  LR: 0.00000771  \n","Epoch: [2][800/2464] Elapsed 2m 15s (remain 4m 40s) Loss: 0.0172(0.0197) Grad: 22394.0488  LR: 0.00000757  \n","Epoch: [2][900/2464] Elapsed 2m 31s (remain 4m 23s) Loss: 0.0160(0.0198) Grad: 24742.0801  LR: 0.00000744  \n","Epoch: [2][1000/2464] Elapsed 2m 48s (remain 4m 6s) Loss: 0.0333(0.0196) Grad: 22296.9785  LR: 0.00000729  \n","Epoch: [2][1100/2464] Elapsed 3m 5s (remain 3m 49s) Loss: 0.0146(0.0197) Grad: 11279.7734  LR: 0.00000715  \n","Epoch: [2][1200/2464] Elapsed 3m 22s (remain 3m 32s) Loss: 0.0137(0.0196) Grad: 7575.4033  LR: 0.00000701  \n","Epoch: [2][1300/2464] Elapsed 3m 38s (remain 3m 15s) Loss: 0.0186(0.0198) Grad: 6925.7339  LR: 0.00000686  \n","Epoch: [2][1400/2464] Elapsed 3m 55s (remain 2m 58s) Loss: 0.0058(0.0196) Grad: 16953.2363  LR: 0.00000671  \n","Epoch: [2][1500/2464] Elapsed 4m 12s (remain 2m 41s) Loss: 0.0181(0.0195) Grad: 17350.8477  LR: 0.00000656  \n","Epoch: [2][1600/2464] Elapsed 4m 29s (remain 2m 25s) Loss: 0.0145(0.0196) Grad: 13697.7607  LR: 0.00000640  \n","Epoch: [2][1700/2464] Elapsed 4m 45s (remain 2m 8s) Loss: 0.0337(0.0196) Grad: 13307.1465  LR: 0.00000625  \n","Epoch: [2][1800/2464] Elapsed 5m 2s (remain 1m 51s) Loss: 0.0334(0.0196) Grad: 42901.8672  LR: 0.00000609  \n","Epoch: [2][1900/2464] Elapsed 5m 19s (remain 1m 34s) Loss: 0.0394(0.0196) Grad: 52926.8164  LR: 0.00000594  \n","Epoch: [2][2000/2464] Elapsed 5m 36s (remain 1m 17s) Loss: 0.0229(0.0196) Grad: 9733.1221  LR: 0.00000578  \n","Epoch: [2][2100/2464] Elapsed 5m 52s (remain 1m 0s) Loss: 0.0266(0.0195) Grad: 21201.5879  LR: 0.00000562  \n","Epoch: [2][2200/2464] Elapsed 6m 9s (remain 0m 44s) Loss: 0.0217(0.0195) Grad: 16218.5127  LR: 0.00000546  \n","Epoch: [2][2300/2464] Elapsed 6m 26s (remain 0m 27s) Loss: 0.0131(0.0194) Grad: 10302.4180  LR: 0.00000530  \n","Epoch: [2][2400/2464] Elapsed 6m 43s (remain 0m 10s) Loss: 0.0171(0.0194) Grad: 26378.0254  LR: 0.00000514  \n","Epoch: [2][2463/2464] Elapsed 6m 53s (remain 0m 0s) Loss: 0.0330(0.0194) Grad: 46060.5977  LR: 0.00000504  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 45s) Loss: 0.1230(0.1230) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0865(0.1001) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0194  avg_val_loss: 0.1019  time: 427s\n","Epoch 2 - Score: 0.8102\n","Epoch 2 - Save Best Score: 0.8102 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0826(0.1019) \n","Epoch: [3][0/2464] Elapsed 0m 0s (remain 18m 49s) Loss: 0.0307(0.0307) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2464] Elapsed 0m 17s (remain 6m 57s) Loss: 0.0107(0.0133) Grad: 37199.7539  LR: 0.00000488  \n","Epoch: [3][200/2464] Elapsed 0m 35s (remain 6m 38s) Loss: 0.0184(0.0139) Grad: 99210.8438  LR: 0.00000472  \n","Epoch: [3][300/2464] Elapsed 0m 52s (remain 6m 15s) Loss: 0.0105(0.0141) Grad: 28649.4512  LR: 0.00000456  \n","Epoch: [3][400/2464] Elapsed 1m 9s (remain 5m 55s) Loss: 0.0098(0.0139) Grad: 66358.5156  LR: 0.00000440  \n","Epoch: [3][500/2464] Elapsed 1m 25s (remain 5m 36s) Loss: 0.0233(0.0141) Grad: 93553.1172  LR: 0.00000424  \n","Epoch: [3][600/2464] Elapsed 1m 42s (remain 5m 17s) Loss: 0.0203(0.0145) Grad: 11259.9502  LR: 0.00000408  \n","Epoch: [3][700/2464] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0083(0.0143) Grad: 42784.5391  LR: 0.00000393  \n","Epoch: [3][800/2464] Elapsed 2m 16s (remain 4m 42s) Loss: 0.0120(0.0144) Grad: 23747.4766  LR: 0.00000377  \n","Epoch: [3][900/2464] Elapsed 2m 32s (remain 4m 25s) Loss: 0.0164(0.0145) Grad: 5371.4507  LR: 0.00000362  \n","Epoch: [3][1000/2464] Elapsed 2m 49s (remain 4m 8s) Loss: 0.0338(0.0145) Grad: 70077.2812  LR: 0.00000346  \n","Epoch: [3][1100/2464] Elapsed 3m 6s (remain 3m 50s) Loss: 0.0084(0.0147) Grad: 26605.4980  LR: 0.00000331  \n","Epoch: [3][1200/2464] Elapsed 3m 23s (remain 3m 33s) Loss: 0.0163(0.0148) Grad: 18637.0488  LR: 0.00000316  \n","Epoch: [3][1300/2464] Elapsed 3m 40s (remain 3m 16s) Loss: 0.0120(0.0148) Grad: 22865.9805  LR: 0.00000301  \n","Epoch: [3][1400/2464] Elapsed 3m 56s (remain 2m 59s) Loss: 0.0111(0.0149) Grad: 25306.5195  LR: 0.00000287  \n","Epoch: [3][1500/2464] Elapsed 4m 13s (remain 2m 42s) Loss: 0.0282(0.0149) Grad: 21649.1543  LR: 0.00000272  \n","Epoch: [3][1600/2464] Elapsed 4m 30s (remain 2m 25s) Loss: 0.0092(0.0150) Grad: 17602.2070  LR: 0.00000258  \n","Epoch: [3][1700/2464] Elapsed 4m 47s (remain 2m 9s) Loss: 0.0335(0.0150) Grad: 60105.5781  LR: 0.00000244  \n","Epoch: [3][1800/2464] Elapsed 5m 4s (remain 1m 52s) Loss: 0.0158(0.0150) Grad: 16846.9941  LR: 0.00000231  \n","Epoch: [3][1900/2464] Elapsed 5m 21s (remain 1m 35s) Loss: 0.0250(0.0150) Grad: 34926.8125  LR: 0.00000217  \n","Epoch: [3][2000/2464] Elapsed 5m 37s (remain 1m 18s) Loss: 0.0419(0.0150) Grad: 36600.8438  LR: 0.00000204  \n","Epoch: [3][2100/2464] Elapsed 5m 54s (remain 1m 1s) Loss: 0.0096(0.0150) Grad: 3658.9937  LR: 0.00000191  \n","Epoch: [3][2200/2464] Elapsed 6m 11s (remain 0m 44s) Loss: 0.0044(0.0149) Grad: 5896.8887  LR: 0.00000179  \n","Epoch: [3][2300/2464] Elapsed 6m 28s (remain 0m 27s) Loss: 0.0020(0.0149) Grad: 5148.8091  LR: 0.00000167  \n","Epoch: [3][2400/2464] Elapsed 6m 45s (remain 0m 10s) Loss: 0.0226(0.0149) Grad: 35912.6680  LR: 0.00000155  \n","Epoch: [3][2463/2464] Elapsed 6m 55s (remain 0m 0s) Loss: 0.0093(0.0149) Grad: 12591.4170  LR: 0.00000148  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 47s) Loss: 0.1240(0.1240) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0851(0.0986) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0149  avg_val_loss: 0.1007  time: 429s\n","Epoch 3 - Score: 0.8163\n","Epoch 3 - Save Best Score: 0.8163 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0826(0.1007) \n","Epoch: [4][0/2464] Elapsed 0m 0s (remain 18m 34s) Loss: 0.0060(0.0060) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2464] Elapsed 0m 17s (remain 6m 53s) Loss: 0.0109(0.0117) Grad: 51778.0859  LR: 0.00000137  \n","Epoch: [4][200/2464] Elapsed 0m 35s (remain 6m 34s) Loss: 0.0205(0.0115) Grad: 26762.0527  LR: 0.00000126  \n","Epoch: [4][300/2464] Elapsed 0m 51s (remain 6m 13s) Loss: 0.0076(0.0118) Grad: 44712.5547  LR: 0.00000115  \n","Epoch: [4][400/2464] Elapsed 1m 8s (remain 5m 53s) Loss: 0.0169(0.0117) Grad: 55635.9219  LR: 0.00000105  \n","Epoch: [4][500/2464] Elapsed 1m 25s (remain 5m 35s) Loss: 0.0059(0.0118) Grad: 12039.1934  LR: 0.00000096  \n","Epoch: [4][600/2464] Elapsed 1m 42s (remain 5m 17s) Loss: 0.0056(0.0119) Grad: 33844.2695  LR: 0.00000086  \n","Epoch: [4][700/2464] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0161(0.0120) Grad: 50661.4727  LR: 0.00000078  \n","Epoch: [4][800/2464] Elapsed 2m 16s (remain 4m 42s) Loss: 0.0089(0.0120) Grad: 9775.6826  LR: 0.00000069  \n","Epoch: [4][900/2464] Elapsed 2m 33s (remain 4m 25s) Loss: 0.0114(0.0120) Grad: 21810.3242  LR: 0.00000061  \n","Epoch: [4][1000/2464] Elapsed 2m 49s (remain 4m 8s) Loss: 0.0218(0.0120) Grad: 20000.3848  LR: 0.00000054  \n","Epoch: [4][1100/2464] Elapsed 3m 6s (remain 3m 51s) Loss: 0.0139(0.0120) Grad: 34675.8633  LR: 0.00000047  \n","Epoch: [4][1200/2464] Elapsed 3m 23s (remain 3m 34s) Loss: 0.0028(0.0119) Grad: 3380.8801  LR: 0.00000040  \n","Epoch: [4][1300/2464] Elapsed 3m 40s (remain 3m 16s) Loss: 0.0093(0.0119) Grad: 17546.5488  LR: 0.00000034  \n","Epoch: [4][1400/2464] Elapsed 3m 57s (remain 2m 59s) Loss: 0.0060(0.0118) Grad: 39096.9219  LR: 0.00000029  \n","Epoch: [4][1500/2464] Elapsed 4m 14s (remain 2m 42s) Loss: 0.0144(0.0118) Grad: 13446.5723  LR: 0.00000024  \n","Epoch: [4][1600/2464] Elapsed 4m 30s (remain 2m 25s) Loss: 0.0100(0.0117) Grad: 37819.8477  LR: 0.00000019  \n","Epoch: [4][1700/2464] Elapsed 4m 47s (remain 2m 9s) Loss: 0.0029(0.0117) Grad: 10697.0986  LR: 0.00000015  \n","Epoch: [4][1800/2464] Elapsed 5m 4s (remain 1m 52s) Loss: 0.0045(0.0117) Grad: 20370.7422  LR: 0.00000011  \n","Epoch: [4][1900/2464] Elapsed 5m 21s (remain 1m 35s) Loss: 0.0116(0.0116) Grad: 17585.4531  LR: 0.00000008  \n","Epoch: [4][2000/2464] Elapsed 5m 37s (remain 1m 18s) Loss: 0.0229(0.0116) Grad: 82387.4922  LR: 0.00000005  \n","Epoch: [4][2100/2464] Elapsed 5m 54s (remain 1m 1s) Loss: 0.0030(0.0116) Grad: 4639.9150  LR: 0.00000003  \n","Epoch: [4][2200/2464] Elapsed 6m 11s (remain 0m 44s) Loss: 0.0106(0.0115) Grad: 43221.0859  LR: 0.00000002  \n","Epoch: [4][2300/2464] Elapsed 6m 28s (remain 0m 27s) Loss: 0.0088(0.0115) Grad: 28821.0059  LR: 0.00000001  \n","Epoch: [4][2400/2464] Elapsed 6m 44s (remain 0m 10s) Loss: 0.0098(0.0115) Grad: 28845.9062  LR: 0.00000000  \n","Epoch: [4][2463/2464] Elapsed 6m 55s (remain 0m 0s) Loss: 0.0038(0.0115) Grad: 7548.0669  LR: 0.00000000  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 45s) Loss: 0.1225(0.1225) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0832(0.0962) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0115  avg_val_loss: 0.0981  time: 429s\n","Epoch 4 - Score: 0.8184\n","Epoch 4 - Save Best Score: 0.8184 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0836(0.0981) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 5 result ==========\n","Score: 0.8184\n","========== fold: 6 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2487] Elapsed 0m 0s (remain 16m 53s) Loss: 1.0488(1.0488) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2487] Elapsed 0m 17s (remain 6m 54s) Loss: 0.0784(0.2316) Grad: 5161.5659  LR: 0.00001000  \n","Epoch: [1][200/2487] Elapsed 0m 34s (remain 6m 36s) Loss: 0.0992(0.1574) Grad: 11928.5713  LR: 0.00000999  \n","Epoch: [1][300/2487] Elapsed 0m 51s (remain 6m 14s) Loss: 0.0695(0.1364) Grad: 16460.9395  LR: 0.00000998  \n","Epoch: [1][400/2487] Elapsed 1m 8s (remain 5m 55s) Loss: 0.0306(0.1168) Grad: 2131.8782  LR: 0.00000997  \n","Epoch: [1][500/2487] Elapsed 1m 24s (remain 5m 36s) Loss: 0.0760(0.1037) Grad: 19490.9492  LR: 0.00000995  \n","Epoch: [1][600/2487] Elapsed 1m 41s (remain 5m 19s) Loss: 0.0478(0.0941) Grad: 3282.7717  LR: 0.00000992  \n","Epoch: [1][700/2487] Elapsed 1m 58s (remain 5m 1s) Loss: 0.0331(0.0865) Grad: 6913.5156  LR: 0.00000989  \n","Epoch: [1][800/2487] Elapsed 2m 15s (remain 4m 44s) Loss: 0.0439(0.0816) Grad: 7347.0386  LR: 0.00000986  \n","Epoch: [1][900/2487] Elapsed 2m 31s (remain 4m 27s) Loss: 0.0933(0.0768) Grad: 11715.8818  LR: 0.00000982  \n","Epoch: [1][1000/2487] Elapsed 2m 48s (remain 4m 10s) Loss: 0.0336(0.0735) Grad: 5497.6104  LR: 0.00000977  \n","Epoch: [1][1100/2487] Elapsed 3m 5s (remain 3m 53s) Loss: 0.0665(0.0699) Grad: 7842.1938  LR: 0.00000972  \n","Epoch: [1][1200/2487] Elapsed 3m 22s (remain 3m 36s) Loss: 0.0833(0.0675) Grad: 19203.7773  LR: 0.00000967  \n","Epoch: [1][1300/2487] Elapsed 3m 39s (remain 3m 19s) Loss: 0.0333(0.0649) Grad: 9945.9971  LR: 0.00000961  \n","Epoch: [1][1400/2487] Elapsed 3m 55s (remain 3m 2s) Loss: 0.0385(0.0627) Grad: 6090.5200  LR: 0.00000955  \n","Epoch: [1][1500/2487] Elapsed 4m 12s (remain 2m 45s) Loss: 0.0192(0.0609) Grad: 4536.2202  LR: 0.00000948  \n","Epoch: [1][1600/2487] Elapsed 4m 29s (remain 2m 29s) Loss: 0.0682(0.0594) Grad: 1042.7233  LR: 0.00000941  \n","Epoch: [1][1700/2487] Elapsed 4m 46s (remain 2m 12s) Loss: 0.0784(0.0580) Grad: 19048.5742  LR: 0.00000933  \n","Epoch: [1][1800/2487] Elapsed 5m 2s (remain 1m 55s) Loss: 0.0388(0.0566) Grad: 9665.7949  LR: 0.00000925  \n","Epoch: [1][1900/2487] Elapsed 5m 19s (remain 1m 38s) Loss: 0.0335(0.0551) Grad: 7056.1265  LR: 0.00000916  \n","Epoch: [1][2000/2487] Elapsed 5m 36s (remain 1m 21s) Loss: 0.0316(0.0537) Grad: 3725.9250  LR: 0.00000907  \n","Epoch: [1][2100/2487] Elapsed 5m 53s (remain 1m 4s) Loss: 0.0173(0.0524) Grad: 7468.1929  LR: 0.00000898  \n","Epoch: [1][2200/2487] Elapsed 6m 10s (remain 0m 48s) Loss: 0.0122(0.0512) Grad: 2089.3762  LR: 0.00000888  \n","Epoch: [1][2300/2487] Elapsed 6m 27s (remain 0m 31s) Loss: 0.0123(0.0500) Grad: 1324.9363  LR: 0.00000878  \n","Epoch: [1][2400/2487] Elapsed 6m 44s (remain 0m 14s) Loss: 0.0269(0.0491) Grad: 12292.2686  LR: 0.00000867  \n","Epoch: [1][2486/2487] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0392(0.0482) Grad: 11497.5674  LR: 0.00000858  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 40s) Loss: 0.1206(0.1206) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.0401(0.0921) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0482  avg_val_loss: 0.0932  time: 430s\n","Epoch 1 - Score: 0.8031\n","Epoch 1 - Save Best Score: 0.8031 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 10s (remain 0m 0s) Loss: 0.0778(0.0932) \n","Epoch: [2][0/2487] Elapsed 0m 0s (remain 18m 58s) Loss: 0.0113(0.0113) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2487] Elapsed 0m 17s (remain 6m 55s) Loss: 0.0152(0.0180) Grad: 9996.1797  LR: 0.00000846  \n","Epoch: [2][200/2487] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0112(0.0176) Grad: 9240.5439  LR: 0.00000835  \n","Epoch: [2][300/2487] Elapsed 0m 51s (remain 6m 15s) Loss: 0.0193(0.0182) Grad: 34939.5195  LR: 0.00000823  \n","Epoch: [2][400/2487] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0200(0.0182) Grad: 20796.1680  LR: 0.00000811  \n","Epoch: [2][500/2487] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0135(0.0180) Grad: 22371.6230  LR: 0.00000798  \n","Epoch: [2][600/2487] Elapsed 1m 41s (remain 5m 19s) Loss: 0.0163(0.0179) Grad: 13394.2461  LR: 0.00000785  \n","Epoch: [2][700/2487] Elapsed 1m 58s (remain 5m 1s) Loss: 0.0161(0.0180) Grad: 46158.6250  LR: 0.00000772  \n","Epoch: [2][800/2487] Elapsed 2m 15s (remain 4m 44s) Loss: 0.0132(0.0179) Grad: 21232.0781  LR: 0.00000758  \n","Epoch: [2][900/2487] Elapsed 2m 31s (remain 4m 27s) Loss: 0.0196(0.0179) Grad: 22520.7031  LR: 0.00000745  \n","Epoch: [2][1000/2487] Elapsed 2m 48s (remain 4m 10s) Loss: 0.0162(0.0180) Grad: 16906.1836  LR: 0.00000731  \n","Epoch: [2][1100/2487] Elapsed 3m 5s (remain 3m 53s) Loss: 0.0219(0.0179) Grad: 6458.3569  LR: 0.00000717  \n","Epoch: [2][1200/2487] Elapsed 3m 22s (remain 3m 36s) Loss: 0.0169(0.0178) Grad: 5706.6836  LR: 0.00000702  \n","Epoch: [2][1300/2487] Elapsed 3m 38s (remain 3m 19s) Loss: 0.0160(0.0177) Grad: 30531.2188  LR: 0.00000687  \n","Epoch: [2][1400/2487] Elapsed 3m 55s (remain 3m 2s) Loss: 0.0289(0.0178) Grad: 30449.9766  LR: 0.00000673  \n","Epoch: [2][1500/2487] Elapsed 4m 12s (remain 2m 45s) Loss: 0.0328(0.0178) Grad: 23094.8945  LR: 0.00000658  \n","Epoch: [2][1600/2487] Elapsed 4m 28s (remain 2m 28s) Loss: 0.0261(0.0178) Grad: 8654.3311  LR: 0.00000643  \n","Epoch: [2][1700/2487] Elapsed 4m 45s (remain 2m 11s) Loss: 0.0127(0.0178) Grad: 19930.9434  LR: 0.00000627  \n","Epoch: [2][1800/2487] Elapsed 5m 2s (remain 1m 55s) Loss: 0.0142(0.0178) Grad: 7809.5342  LR: 0.00000612  \n","Epoch: [2][1900/2487] Elapsed 5m 18s (remain 1m 38s) Loss: 0.0169(0.0179) Grad: 20041.3906  LR: 0.00000596  \n","Epoch: [2][2000/2487] Elapsed 5m 35s (remain 1m 21s) Loss: 0.0071(0.0179) Grad: 14891.4873  LR: 0.00000581  \n","Epoch: [2][2100/2487] Elapsed 5m 52s (remain 1m 4s) Loss: 0.0281(0.0179) Grad: 34061.6172  LR: 0.00000565  \n","Epoch: [2][2200/2487] Elapsed 6m 8s (remain 0m 47s) Loss: 0.0263(0.0179) Grad: 6863.7446  LR: 0.00000549  \n","Epoch: [2][2300/2487] Elapsed 6m 25s (remain 0m 31s) Loss: 0.0079(0.0179) Grad: 33118.1875  LR: 0.00000533  \n","Epoch: [2][2400/2487] Elapsed 6m 42s (remain 0m 14s) Loss: 0.0145(0.0179) Grad: 10848.5781  LR: 0.00000518  \n","Epoch: [2][2486/2487] Elapsed 6m 56s (remain 0m 0s) Loss: 0.0212(0.0179) Grad: 11184.1328  LR: 0.00000504  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 38s) Loss: 0.1334(0.1334) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.0402(0.0930) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0179  avg_val_loss: 0.0944  time: 428s\n","Epoch 2 - Score: 0.8102\n","Epoch 2 - Save Best Score: 0.8102 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 10s (remain 0m 0s) Loss: 0.0856(0.0944) \n","Epoch: [3][0/2487] Elapsed 0m 0s (remain 18m 48s) Loss: 0.0166(0.0166) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2487] Elapsed 0m 17s (remain 6m 54s) Loss: 0.0129(0.0152) Grad: 7313.3062  LR: 0.00000488  \n","Epoch: [3][200/2487] Elapsed 0m 35s (remain 6m 38s) Loss: 0.0145(0.0140) Grad: 52503.1875  LR: 0.00000472  \n","Epoch: [3][300/2487] Elapsed 0m 51s (remain 6m 16s) Loss: 0.0172(0.0142) Grad: 45021.5547  LR: 0.00000456  \n","Epoch: [3][400/2487] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0184(0.0143) Grad: 34972.4258  LR: 0.00000440  \n","Epoch: [3][500/2487] Elapsed 1m 25s (remain 5m 38s) Loss: 0.0118(0.0147) Grad: 13519.0957  LR: 0.00000425  \n","Epoch: [3][600/2487] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0101(0.0144) Grad: 8045.9961  LR: 0.00000409  \n","Epoch: [3][700/2487] Elapsed 1m 58s (remain 5m 2s) Loss: 0.0118(0.0145) Grad: 5246.5420  LR: 0.00000394  \n","Epoch: [3][800/2487] Elapsed 2m 15s (remain 4m 45s) Loss: 0.0087(0.0147) Grad: 31539.5566  LR: 0.00000378  \n","Epoch: [3][900/2487] Elapsed 2m 32s (remain 4m 28s) Loss: 0.0183(0.0147) Grad: 45018.0547  LR: 0.00000363  \n","Epoch: [3][1000/2487] Elapsed 2m 49s (remain 4m 11s) Loss: 0.0069(0.0148) Grad: 7143.8779  LR: 0.00000348  \n","Epoch: [3][1100/2487] Elapsed 3m 6s (remain 3m 54s) Loss: 0.0316(0.0148) Grad: 24581.7246  LR: 0.00000333  \n","Epoch: [3][1200/2487] Elapsed 3m 22s (remain 3m 37s) Loss: 0.0104(0.0148) Grad: 7052.7886  LR: 0.00000318  \n","Epoch: [3][1300/2487] Elapsed 3m 39s (remain 3m 20s) Loss: 0.0169(0.0148) Grad: 31638.1094  LR: 0.00000303  \n","Epoch: [3][1400/2487] Elapsed 3m 56s (remain 3m 3s) Loss: 0.0053(0.0147) Grad: 2745.2615  LR: 0.00000289  \n","Epoch: [3][1500/2487] Elapsed 4m 13s (remain 2m 46s) Loss: 0.0180(0.0147) Grad: 55422.5742  LR: 0.00000274  \n","Epoch: [3][1600/2487] Elapsed 4m 30s (remain 2m 29s) Loss: 0.0152(0.0147) Grad: 15744.6230  LR: 0.00000260  \n","Epoch: [3][1700/2487] Elapsed 4m 47s (remain 2m 12s) Loss: 0.0208(0.0147) Grad: 16062.0752  LR: 0.00000246  \n","Epoch: [3][1800/2487] Elapsed 5m 3s (remain 1m 55s) Loss: 0.0052(0.0147) Grad: 3489.5652  LR: 0.00000233  \n","Epoch: [3][1900/2487] Elapsed 5m 20s (remain 1m 38s) Loss: 0.0095(0.0147) Grad: 19862.8203  LR: 0.00000220  \n","Epoch: [3][2000/2487] Elapsed 5m 37s (remain 1m 21s) Loss: 0.0148(0.0148) Grad: 8180.0127  LR: 0.00000207  \n","Epoch: [3][2100/2487] Elapsed 5m 53s (remain 1m 5s) Loss: 0.0185(0.0148) Grad: 25397.2344  LR: 0.00000194  \n","Epoch: [3][2200/2487] Elapsed 6m 10s (remain 0m 48s) Loss: 0.0087(0.0147) Grad: 3765.1384  LR: 0.00000181  \n","Epoch: [3][2300/2487] Elapsed 6m 27s (remain 0m 31s) Loss: 0.0421(0.0148) Grad: 28623.9883  LR: 0.00000169  \n","Epoch: [3][2400/2487] Elapsed 6m 43s (remain 0m 14s) Loss: 0.0273(0.0148) Grad: 36318.8281  LR: 0.00000158  \n","Epoch: [3][2486/2487] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0140(0.0148) Grad: 5862.6279  LR: 0.00000148  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 39s) Loss: 0.1313(0.1313) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.0459(0.0991) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0148  avg_val_loss: 0.1004  time: 429s\n","Epoch 3 - Score: 0.8160\n","Epoch 3 - Save Best Score: 0.8160 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 10s (remain 0m 0s) Loss: 0.0880(0.1004) \n","Epoch: [4][0/2487] Elapsed 0m 0s (remain 19m 7s) Loss: 0.0232(0.0232) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2487] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0095(0.0132) Grad: 56274.6211  LR: 0.00000137  \n","Epoch: [4][200/2487] Elapsed 0m 34s (remain 6m 37s) Loss: 0.0059(0.0127) Grad: 26092.8555  LR: 0.00000126  \n","Epoch: [4][300/2487] Elapsed 0m 51s (remain 6m 15s) Loss: 0.0026(0.0122) Grad: 7142.0044  LR: 0.00000116  \n","Epoch: [4][400/2487] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0189(0.0121) Grad: 9441.3506  LR: 0.00000106  \n","Epoch: [4][500/2487] Elapsed 1m 25s (remain 5m 38s) Loss: 0.0169(0.0119) Grad: 48990.8086  LR: 0.00000096  \n","Epoch: [4][600/2487] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0080(0.0119) Grad: 11214.5195  LR: 0.00000087  \n","Epoch: [4][700/2487] Elapsed 1m 58s (remain 5m 3s) Loss: 0.0113(0.0119) Grad: 18599.5469  LR: 0.00000078  \n","Epoch: [4][800/2487] Elapsed 2m 15s (remain 4m 45s) Loss: 0.0030(0.0118) Grad: 20879.5527  LR: 0.00000070  \n","Epoch: [4][900/2487] Elapsed 2m 32s (remain 4m 28s) Loss: 0.0201(0.0119) Grad: 55332.6211  LR: 0.00000062  \n","Epoch: [4][1000/2487] Elapsed 2m 49s (remain 4m 11s) Loss: 0.0062(0.0119) Grad: 25403.7734  LR: 0.00000055  \n","Epoch: [4][1100/2487] Elapsed 3m 6s (remain 3m 54s) Loss: 0.0122(0.0117) Grad: 30236.4512  LR: 0.00000048  \n","Epoch: [4][1200/2487] Elapsed 3m 22s (remain 3m 37s) Loss: 0.0079(0.0117) Grad: 21205.9453  LR: 0.00000041  \n","Epoch: [4][1300/2487] Elapsed 3m 39s (remain 3m 20s) Loss: 0.0066(0.0118) Grad: 26949.0566  LR: 0.00000035  \n","Epoch: [4][1400/2487] Elapsed 3m 56s (remain 3m 3s) Loss: 0.0130(0.0117) Grad: 65081.4141  LR: 0.00000029  \n","Epoch: [4][1500/2487] Elapsed 4m 13s (remain 2m 46s) Loss: 0.0065(0.0118) Grad: 28220.0859  LR: 0.00000024  \n","Epoch: [4][1600/2487] Elapsed 4m 29s (remain 2m 29s) Loss: 0.0081(0.0118) Grad: 5509.2451  LR: 0.00000020  \n","Epoch: [4][1700/2487] Elapsed 4m 46s (remain 2m 12s) Loss: 0.0141(0.0118) Grad: 46976.6367  LR: 0.00000015  \n","Epoch: [4][1800/2487] Elapsed 5m 3s (remain 1m 55s) Loss: 0.0084(0.0118) Grad: 68242.3828  LR: 0.00000012  \n","Epoch: [4][1900/2487] Elapsed 5m 20s (remain 1m 38s) Loss: 0.0107(0.0118) Grad: 30888.5684  LR: 0.00000009  \n","Epoch: [4][2000/2487] Elapsed 5m 37s (remain 1m 21s) Loss: 0.0083(0.0118) Grad: 19328.3203  LR: 0.00000006  \n","Epoch: [4][2100/2487] Elapsed 5m 53s (remain 1m 4s) Loss: 0.0480(0.0118) Grad: 90465.6875  LR: 0.00000004  \n","Epoch: [4][2200/2487] Elapsed 6m 10s (remain 0m 48s) Loss: 0.0102(0.0118) Grad: 8411.7949  LR: 0.00000002  \n","Epoch: [4][2300/2487] Elapsed 6m 27s (remain 0m 31s) Loss: 0.0060(0.0118) Grad: 31554.2090  LR: 0.00000001  \n","Epoch: [4][2400/2487] Elapsed 6m 44s (remain 0m 14s) Loss: 0.0128(0.0118) Grad: 19340.3164  LR: 0.00000000  \n","Epoch: [4][2486/2487] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0117(0.0118) Grad: 37199.4883  LR: 0.00000000  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 39s) Loss: 0.1306(0.1306) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.0429(0.0946) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0118  avg_val_loss: 0.0959  time: 430s\n","Epoch 4 - Score: 0.8177\n","Epoch 4 - Save Best Score: 0.8177 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 10s (remain 0m 0s) Loss: 0.0869(0.0959) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 6 result ==========\n","Score: 0.8177\n","========== fold: 7 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2460] Elapsed 0m 0s (remain 17m 48s) Loss: 0.9204(0.9204) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2460] Elapsed 0m 17s (remain 6m 53s) Loss: 0.1111(0.2074) Grad: 3473.6072  LR: 0.00001000  \n","Epoch: [1][200/2460] Elapsed 0m 34s (remain 6m 29s) Loss: 0.0945(0.1458) Grad: 18031.6035  LR: 0.00000999  \n","Epoch: [1][300/2460] Elapsed 0m 51s (remain 6m 10s) Loss: 0.0627(0.1193) Grad: 9107.4434  LR: 0.00000998  \n","Epoch: [1][400/2460] Elapsed 1m 8s (remain 5m 51s) Loss: 0.0459(0.1051) Grad: 8082.3501  LR: 0.00000997  \n","Epoch: [1][500/2460] Elapsed 1m 25s (remain 5m 33s) Loss: 0.0255(0.0989) Grad: 7591.3550  LR: 0.00000995  \n","Epoch: [1][600/2460] Elapsed 1m 42s (remain 5m 16s) Loss: 0.0215(0.0893) Grad: 3194.4524  LR: 0.00000992  \n","Epoch: [1][700/2460] Elapsed 1m 59s (remain 4m 58s) Loss: 0.0467(0.0834) Grad: 5682.5562  LR: 0.00000989  \n","Epoch: [1][800/2460] Elapsed 2m 15s (remain 4m 41s) Loss: 0.0198(0.0787) Grad: 1575.6920  LR: 0.00000986  \n","Epoch: [1][900/2460] Elapsed 2m 32s (remain 4m 23s) Loss: 0.0392(0.0741) Grad: 2768.6287  LR: 0.00000981  \n","Epoch: [1][1000/2460] Elapsed 2m 49s (remain 4m 6s) Loss: 0.0366(0.0706) Grad: 9393.6426  LR: 0.00000977  \n","Epoch: [1][1100/2460] Elapsed 3m 6s (remain 3m 49s) Loss: 0.0241(0.0674) Grad: 4255.1123  LR: 0.00000972  \n","Epoch: [1][1200/2460] Elapsed 3m 22s (remain 3m 32s) Loss: 0.0275(0.0648) Grad: 1982.7069  LR: 0.00000966  \n","Epoch: [1][1300/2460] Elapsed 3m 39s (remain 3m 15s) Loss: 0.0130(0.0624) Grad: 894.0113  LR: 0.00000960  \n","Epoch: [1][1400/2460] Elapsed 3m 56s (remain 2m 58s) Loss: 0.0128(0.0601) Grad: 3010.8601  LR: 0.00000954  \n","Epoch: [1][1500/2460] Elapsed 4m 13s (remain 2m 41s) Loss: 0.0346(0.0588) Grad: 7024.3364  LR: 0.00000947  \n","Epoch: [1][1600/2460] Elapsed 4m 29s (remain 2m 24s) Loss: 0.0269(0.0572) Grad: 2108.1709  LR: 0.00000939  \n","Epoch: [1][1700/2460] Elapsed 4m 46s (remain 2m 7s) Loss: 0.0254(0.0555) Grad: 792.1683  LR: 0.00000931  \n","Epoch: [1][1800/2460] Elapsed 5m 3s (remain 1m 50s) Loss: 0.0382(0.0542) Grad: 8842.8184  LR: 0.00000923  \n","Epoch: [1][1900/2460] Elapsed 5m 19s (remain 1m 34s) Loss: 0.0693(0.0530) Grad: 12073.8604  LR: 0.00000914  \n","Epoch: [1][2000/2460] Elapsed 5m 36s (remain 1m 17s) Loss: 0.0415(0.0519) Grad: 7705.1475  LR: 0.00000905  \n","Epoch: [1][2100/2460] Elapsed 5m 53s (remain 1m 0s) Loss: 0.0183(0.0508) Grad: 10886.0098  LR: 0.00000896  \n","Epoch: [1][2200/2460] Elapsed 6m 10s (remain 0m 43s) Loss: 0.0223(0.0496) Grad: 953.9940  LR: 0.00000886  \n","Epoch: [1][2300/2460] Elapsed 6m 27s (remain 0m 26s) Loss: 0.0132(0.0485) Grad: 8125.6592  LR: 0.00000875  \n","Epoch: [1][2400/2460] Elapsed 6m 43s (remain 0m 9s) Loss: 0.0184(0.0476) Grad: 6045.5186  LR: 0.00000864  \n","Epoch: [1][2459/2460] Elapsed 6m 53s (remain 0m 0s) Loss: 0.0413(0.0470) Grad: 12788.4014  LR: 0.00000858  \n","EVAL: [0/145] Elapsed 0m 0s (remain 0m 46s) Loss: 0.0810(0.0810) \n","EVAL: [100/145] Elapsed 0m 9s (remain 0m 4s) Loss: 0.1225(0.1060) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0470  avg_val_loss: 0.1024  time: 427s\n","Epoch 1 - Score: 0.7757\n","Epoch 1 - Save Best Score: 0.7757 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [144/145] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0884(0.1024) \n","Epoch: [2][0/2460] Elapsed 0m 0s (remain 18m 30s) Loss: 0.0405(0.0405) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2460] Elapsed 0m 17s (remain 6m 54s) Loss: 0.0111(0.0188) Grad: 39209.8125  LR: 0.00000846  \n","Epoch: [2][200/2460] Elapsed 0m 35s (remain 6m 33s) Loss: 0.0112(0.0184) Grad: 9047.1104  LR: 0.00000835  \n","Epoch: [2][300/2460] Elapsed 0m 51s (remain 6m 12s) Loss: 0.0109(0.0182) Grad: 53223.1289  LR: 0.00000822  \n","Epoch: [2][400/2460] Elapsed 1m 8s (remain 5m 52s) Loss: 0.0126(0.0177) Grad: 23014.7520  LR: 0.00000810  \n","Epoch: [2][500/2460] Elapsed 1m 25s (remain 5m 34s) Loss: 0.0077(0.0176) Grad: 16331.1328  LR: 0.00000797  \n","Epoch: [2][600/2460] Elapsed 1m 42s (remain 5m 16s) Loss: 0.0278(0.0177) Grad: 91619.8906  LR: 0.00000784  \n","Epoch: [2][700/2460] Elapsed 1m 59s (remain 4m 58s) Loss: 0.0293(0.0178) Grad: 71497.1328  LR: 0.00000771  \n","Epoch: [2][800/2460] Elapsed 2m 15s (remain 4m 41s) Loss: 0.0155(0.0179) Grad: 10749.8643  LR: 0.00000757  \n","Epoch: [2][900/2460] Elapsed 2m 32s (remain 4m 24s) Loss: 0.0142(0.0179) Grad: 26536.8770  LR: 0.00000743  \n","Epoch: [2][1000/2460] Elapsed 2m 49s (remain 4m 7s) Loss: 0.0349(0.0180) Grad: 25828.5527  LR: 0.00000729  \n","Epoch: [2][1100/2460] Elapsed 3m 6s (remain 3m 50s) Loss: 0.0173(0.0180) Grad: 33602.2109  LR: 0.00000715  \n","Epoch: [2][1200/2460] Elapsed 3m 23s (remain 3m 33s) Loss: 0.0090(0.0179) Grad: 36687.7383  LR: 0.00000700  \n","Epoch: [2][1300/2460] Elapsed 3m 40s (remain 3m 16s) Loss: 0.0274(0.0178) Grad: 12316.4961  LR: 0.00000686  \n","Epoch: [2][1400/2460] Elapsed 3m 56s (remain 2m 59s) Loss: 0.0197(0.0180) Grad: 18305.7578  LR: 0.00000671  \n","Epoch: [2][1500/2460] Elapsed 4m 13s (remain 2m 42s) Loss: 0.0172(0.0179) Grad: 28140.4277  LR: 0.00000655  \n","Epoch: [2][1600/2460] Elapsed 4m 30s (remain 2m 25s) Loss: 0.0134(0.0179) Grad: 5246.4033  LR: 0.00000640  \n","Epoch: [2][1700/2460] Elapsed 4m 47s (remain 2m 8s) Loss: 0.0179(0.0179) Grad: 11737.5605  LR: 0.00000625  \n","Epoch: [2][1800/2460] Elapsed 5m 4s (remain 1m 51s) Loss: 0.0285(0.0179) Grad: 7189.1069  LR: 0.00000609  \n","Epoch: [2][1900/2460] Elapsed 5m 20s (remain 1m 34s) Loss: 0.0309(0.0178) Grad: 46442.7031  LR: 0.00000593  \n","Epoch: [2][2000/2460] Elapsed 5m 37s (remain 1m 17s) Loss: 0.0401(0.0178) Grad: 17838.7910  LR: 0.00000577  \n","Epoch: [2][2100/2460] Elapsed 5m 54s (remain 1m 0s) Loss: 0.0075(0.0178) Grad: 28589.2031  LR: 0.00000562  \n","Epoch: [2][2200/2460] Elapsed 6m 11s (remain 0m 43s) Loss: 0.0113(0.0178) Grad: 6274.2271  LR: 0.00000546  \n","Epoch: [2][2300/2460] Elapsed 6m 28s (remain 0m 26s) Loss: 0.0209(0.0177) Grad: 12249.6357  LR: 0.00000530  \n","Epoch: [2][2400/2460] Elapsed 6m 44s (remain 0m 9s) Loss: 0.0229(0.0178) Grad: 5588.6445  LR: 0.00000514  \n","Epoch: [2][2459/2460] Elapsed 6m 54s (remain 0m 0s) Loss: 0.0123(0.0177) Grad: 8247.3672  LR: 0.00000504  \n","EVAL: [0/145] Elapsed 0m 0s (remain 0m 47s) Loss: 0.0793(0.0793) \n","EVAL: [100/145] Elapsed 0m 9s (remain 0m 4s) Loss: 0.1167(0.0999) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0177  avg_val_loss: 0.0962  time: 428s\n","Epoch 2 - Score: 0.8114\n","Epoch 2 - Save Best Score: 0.8114 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [144/145] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0819(0.0962) \n","Epoch: [3][0/2460] Elapsed 0m 0s (remain 18m 47s) Loss: 0.0204(0.0204) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2460] Elapsed 0m 17s (remain 6m 53s) Loss: 0.0248(0.0139) Grad: 17492.4023  LR: 0.00000488  \n","Epoch: [3][200/2460] Elapsed 0m 35s (remain 6m 34s) Loss: 0.0310(0.0145) Grad: 50368.4648  LR: 0.00000472  \n","Epoch: [3][300/2460] Elapsed 0m 51s (remain 6m 11s) Loss: 0.0154(0.0148) Grad: 36440.6992  LR: 0.00000456  \n","Epoch: [3][400/2460] Elapsed 1m 8s (remain 5m 52s) Loss: 0.0066(0.0149) Grad: 12165.9521  LR: 0.00000440  \n","Epoch: [3][500/2460] Elapsed 1m 25s (remain 5m 33s) Loss: 0.0105(0.0146) Grad: 19896.7090  LR: 0.00000424  \n","Epoch: [3][600/2460] Elapsed 1m 42s (remain 5m 16s) Loss: 0.0107(0.0149) Grad: 11519.8389  LR: 0.00000408  \n","Epoch: [3][700/2460] Elapsed 1m 59s (remain 4m 58s) Loss: 0.0115(0.0150) Grad: 21670.0156  LR: 0.00000393  \n","Epoch: [3][800/2460] Elapsed 2m 15s (remain 4m 41s) Loss: 0.0161(0.0150) Grad: 48607.7070  LR: 0.00000377  \n","Epoch: [3][900/2460] Elapsed 2m 32s (remain 4m 24s) Loss: 0.0107(0.0151) Grad: 10536.3438  LR: 0.00000361  \n","Epoch: [3][1000/2460] Elapsed 2m 49s (remain 4m 7s) Loss: 0.0258(0.0150) Grad: 26865.5469  LR: 0.00000346  \n","Epoch: [3][1100/2460] Elapsed 3m 6s (remain 3m 50s) Loss: 0.0090(0.0150) Grad: 3704.7322  LR: 0.00000331  \n","Epoch: [3][1200/2460] Elapsed 3m 23s (remain 3m 33s) Loss: 0.0412(0.0150) Grad: 10401.9980  LR: 0.00000316  \n","Epoch: [3][1300/2460] Elapsed 3m 40s (remain 3m 16s) Loss: 0.0187(0.0150) Grad: 11753.7568  LR: 0.00000301  \n","Epoch: [3][1400/2460] Elapsed 3m 57s (remain 2m 59s) Loss: 0.0166(0.0150) Grad: 10496.7188  LR: 0.00000287  \n","Epoch: [3][1500/2460] Elapsed 4m 14s (remain 2m 42s) Loss: 0.0122(0.0150) Grad: 33587.6953  LR: 0.00000272  \n","Epoch: [3][1600/2460] Elapsed 4m 31s (remain 2m 25s) Loss: 0.0293(0.0149) Grad: 22848.1387  LR: 0.00000258  \n","Epoch: [3][1700/2460] Elapsed 4m 48s (remain 2m 8s) Loss: 0.0042(0.0149) Grad: 12158.1416  LR: 0.00000244  \n","Epoch: [3][1800/2460] Elapsed 5m 5s (remain 1m 51s) Loss: 0.0064(0.0148) Grad: 17364.9512  LR: 0.00000230  \n","Epoch: [3][1900/2460] Elapsed 5m 22s (remain 1m 34s) Loss: 0.0154(0.0149) Grad: 28943.8887  LR: 0.00000217  \n","Epoch: [3][2000/2460] Elapsed 5m 39s (remain 1m 17s) Loss: 0.0158(0.0149) Grad: 36173.7305  LR: 0.00000204  \n","Epoch: [3][2100/2460] Elapsed 5m 56s (remain 1m 0s) Loss: 0.0058(0.0149) Grad: 4826.5479  LR: 0.00000191  \n","Epoch: [3][2200/2460] Elapsed 6m 13s (remain 0m 43s) Loss: 0.0052(0.0149) Grad: 25100.3320  LR: 0.00000179  \n","Epoch: [3][2300/2460] Elapsed 6m 29s (remain 0m 26s) Loss: 0.0111(0.0148) Grad: 47772.4102  LR: 0.00000167  \n","Epoch: [3][2400/2460] Elapsed 6m 46s (remain 0m 9s) Loss: 0.0089(0.0148) Grad: 40240.3516  LR: 0.00000155  \n","Epoch: [3][2459/2460] Elapsed 6m 56s (remain 0m 0s) Loss: 0.0111(0.0148) Grad: 35712.7852  LR: 0.00000148  \n","EVAL: [0/145] Elapsed 0m 0s (remain 0m 46s) Loss: 0.0865(0.0865) \n","EVAL: [100/145] Elapsed 0m 9s (remain 0m 4s) Loss: 0.1244(0.1042) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0148  avg_val_loss: 0.1003  time: 430s\n","Epoch 3 - Score: 0.8058\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [144/145] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0832(0.1003) \n","Epoch: [4][0/2460] Elapsed 0m 0s (remain 18m 38s) Loss: 0.0050(0.0050) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2460] Elapsed 0m 17s (remain 6m 44s) Loss: 0.0073(0.0117) Grad: 12012.4004  LR: 0.00000137  \n","Epoch: [4][200/2460] Elapsed 0m 34s (remain 6m 23s) Loss: 0.0229(0.0117) Grad: 22221.4707  LR: 0.00000126  \n","Epoch: [4][300/2460] Elapsed 0m 51s (remain 6m 5s) Loss: 0.0146(0.0121) Grad: 24712.0254  LR: 0.00000115  \n","Epoch: [4][400/2460] Elapsed 1m 7s (remain 5m 48s) Loss: 0.0072(0.0121) Grad: 9834.5410  LR: 0.00000105  \n","Epoch: [4][500/2460] Elapsed 1m 24s (remain 5m 31s) Loss: 0.0241(0.0120) Grad: 97651.6406  LR: 0.00000096  \n","Epoch: [4][600/2460] Elapsed 1m 41s (remain 5m 14s) Loss: 0.0172(0.0119) Grad: 28475.4648  LR: 0.00000087  \n","Epoch: [4][700/2460] Elapsed 1m 58s (remain 4m 58s) Loss: 0.0108(0.0119) Grad: 7587.1914  LR: 0.00000078  \n","Epoch: [4][800/2460] Elapsed 2m 15s (remain 4m 41s) Loss: 0.0036(0.0119) Grad: 8170.9985  LR: 0.00000069  \n","Epoch: [4][900/2460] Elapsed 2m 32s (remain 4m 24s) Loss: 0.0100(0.0119) Grad: 11137.1289  LR: 0.00000061  \n","Epoch: [4][1000/2460] Elapsed 2m 49s (remain 4m 7s) Loss: 0.0082(0.0120) Grad: 49048.4570  LR: 0.00000054  \n","Epoch: [4][1100/2460] Elapsed 3m 6s (remain 3m 50s) Loss: 0.0278(0.0120) Grad: 42985.2695  LR: 0.00000047  \n","Epoch: [4][1200/2460] Elapsed 3m 23s (remain 3m 33s) Loss: 0.0159(0.0119) Grad: 31557.0977  LR: 0.00000040  \n","Epoch: [4][1300/2460] Elapsed 3m 41s (remain 3m 16s) Loss: 0.0130(0.0119) Grad: 12588.9717  LR: 0.00000034  \n","Epoch: [4][1400/2460] Elapsed 3m 58s (remain 3m 0s) Loss: 0.0118(0.0118) Grad: 14449.1836  LR: 0.00000029  \n","Epoch: [4][1500/2460] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0156(0.0119) Grad: 15110.4092  LR: 0.00000024  \n","Epoch: [4][1600/2460] Elapsed 4m 32s (remain 2m 26s) Loss: 0.0096(0.0118) Grad: 12720.8486  LR: 0.00000019  \n","Epoch: [4][1700/2460] Elapsed 4m 49s (remain 2m 9s) Loss: 0.0064(0.0119) Grad: 8670.6943  LR: 0.00000015  \n","Epoch: [4][1800/2460] Elapsed 5m 6s (remain 1m 52s) Loss: 0.0061(0.0118) Grad: 4249.1870  LR: 0.00000011  \n","Epoch: [4][1900/2460] Elapsed 5m 23s (remain 1m 35s) Loss: 0.0113(0.0118) Grad: 25972.2559  LR: 0.00000008  \n","Epoch: [4][2000/2460] Elapsed 5m 40s (remain 1m 18s) Loss: 0.0089(0.0118) Grad: 52475.5391  LR: 0.00000005  \n","Epoch: [4][2100/2460] Elapsed 5m 57s (remain 1m 1s) Loss: 0.0088(0.0119) Grad: 48796.8984  LR: 0.00000003  \n","Epoch: [4][2200/2460] Elapsed 6m 14s (remain 0m 44s) Loss: 0.0072(0.0119) Grad: 35105.3398  LR: 0.00000002  \n","Epoch: [4][2300/2460] Elapsed 6m 31s (remain 0m 27s) Loss: 0.0182(0.0119) Grad: 63776.7500  LR: 0.00000001  \n","Epoch: [4][2400/2460] Elapsed 6m 48s (remain 0m 10s) Loss: 0.0139(0.0119) Grad: 18920.9141  LR: 0.00000000  \n","Epoch: [4][2459/2460] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0206(0.0119) Grad: 17189.2910  LR: 0.00000000  \n","EVAL: [0/145] Elapsed 0m 0s (remain 0m 47s) Loss: 0.0841(0.0841) \n","EVAL: [100/145] Elapsed 0m 9s (remain 0m 4s) Loss: 0.1221(0.1021) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0119  avg_val_loss: 0.0984  time: 431s\n","Epoch 4 - Score: 0.8062\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [144/145] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0824(0.0984) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 7 result ==========\n","Score: 0.8114\n","========== fold: 8 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2476] Elapsed 0m 0s (remain 17m 7s) Loss: 1.3984(1.3984) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2476] Elapsed 0m 17s (remain 6m 41s) Loss: 0.1320(0.2153) Grad: 21810.0684  LR: 0.00001000  \n","Epoch: [1][200/2476] Elapsed 0m 33s (remain 6m 23s) Loss: 0.0612(0.1435) Grad: 12821.5635  LR: 0.00000999  \n","Epoch: [1][300/2476] Elapsed 0m 50s (remain 6m 6s) Loss: 0.0582(0.1178) Grad: 15317.2705  LR: 0.00000998  \n","Epoch: [1][400/2476] Elapsed 1m 7s (remain 5m 49s) Loss: 0.0788(0.1038) Grad: 7667.6592  LR: 0.00000997  \n","Epoch: [1][500/2476] Elapsed 1m 24s (remain 5m 33s) Loss: 0.1096(0.0981) Grad: 13513.6113  LR: 0.00000995  \n","Epoch: [1][600/2476] Elapsed 1m 41s (remain 5m 16s) Loss: 0.0437(0.0907) Grad: 11697.7422  LR: 0.00000992  \n","Epoch: [1][700/2476] Elapsed 1m 58s (remain 4m 59s) Loss: 0.0384(0.0842) Grad: 5757.8516  LR: 0.00000989  \n","Epoch: [1][800/2476] Elapsed 2m 15s (remain 4m 43s) Loss: 0.0447(0.0792) Grad: 4528.8467  LR: 0.00000986  \n","Epoch: [1][900/2476] Elapsed 2m 32s (remain 4m 26s) Loss: 0.0344(0.0749) Grad: 1389.3784  LR: 0.00000982  \n","Epoch: [1][1000/2476] Elapsed 2m 49s (remain 4m 9s) Loss: 0.0377(0.0708) Grad: 12144.3896  LR: 0.00000977  \n","Epoch: [1][1100/2476] Elapsed 3m 6s (remain 3m 52s) Loss: 0.0282(0.0679) Grad: 1261.5579  LR: 0.00000972  \n","Epoch: [1][1200/2476] Elapsed 3m 23s (remain 3m 35s) Loss: 0.0197(0.0655) Grad: 5114.6396  LR: 0.00000967  \n","Epoch: [1][1300/2476] Elapsed 3m 39s (remain 3m 18s) Loss: 0.0526(0.0635) Grad: 11280.9531  LR: 0.00000961  \n","Epoch: [1][1400/2476] Elapsed 3m 56s (remain 3m 1s) Loss: 0.0180(0.0617) Grad: 3528.8105  LR: 0.00000954  \n","Epoch: [1][1500/2476] Elapsed 4m 13s (remain 2m 44s) Loss: 0.0346(0.0602) Grad: 1962.0350  LR: 0.00000947  \n","Epoch: [1][1600/2476] Elapsed 4m 31s (remain 2m 28s) Loss: 0.0657(0.0587) Grad: 6619.9165  LR: 0.00000940  \n","Epoch: [1][1700/2476] Elapsed 4m 48s (remain 2m 11s) Loss: 0.0245(0.0571) Grad: 4893.5039  LR: 0.00000932  \n","Epoch: [1][1800/2476] Elapsed 5m 5s (remain 1m 54s) Loss: 0.0203(0.0559) Grad: 7557.9678  LR: 0.00000924  \n","Epoch: [1][1900/2476] Elapsed 5m 21s (remain 1m 37s) Loss: 0.0352(0.0543) Grad: 1591.0797  LR: 0.00000915  \n","Epoch: [1][2000/2476] Elapsed 5m 38s (remain 1m 20s) Loss: 0.0499(0.0531) Grad: 8881.3564  LR: 0.00000906  \n","Epoch: [1][2100/2476] Elapsed 5m 55s (remain 1m 3s) Loss: 0.0109(0.0518) Grad: 6058.7280  LR: 0.00000897  \n","Epoch: [1][2200/2476] Elapsed 6m 12s (remain 0m 46s) Loss: 0.0122(0.0507) Grad: 5374.0742  LR: 0.00000887  \n","Epoch: [1][2300/2476] Elapsed 6m 29s (remain 0m 29s) Loss: 0.0175(0.0496) Grad: 10082.3115  LR: 0.00000877  \n","Epoch: [1][2400/2476] Elapsed 6m 46s (remain 0m 12s) Loss: 0.0537(0.0485) Grad: 25913.3887  LR: 0.00000866  \n","Epoch: [1][2475/2476] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0175(0.0478) Grad: 13228.8896  LR: 0.00000858  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1001(0.1001) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0944(0.1024) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0478  avg_val_loss: 0.1042  time: 431s\n","Epoch 1 - Score: 0.8149\n","Epoch 1 - Save Best Score: 0.8149 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1186(0.1042) \n","Epoch: [2][0/2476] Elapsed 0m 0s (remain 18m 26s) Loss: 0.0159(0.0159) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2476] Elapsed 0m 17s (remain 6m 53s) Loss: 0.0219(0.0189) Grad: 17839.5059  LR: 0.00000846  \n","Epoch: [2][200/2476] Elapsed 0m 35s (remain 6m 36s) Loss: 0.0213(0.0184) Grad: 14604.5742  LR: 0.00000835  \n","Epoch: [2][300/2476] Elapsed 0m 51s (remain 6m 15s) Loss: 0.0155(0.0188) Grad: 3902.7712  LR: 0.00000823  \n","Epoch: [2][400/2476] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0149(0.0186) Grad: 14500.1895  LR: 0.00000810  \n","Epoch: [2][500/2476] Elapsed 1m 25s (remain 5m 38s) Loss: 0.0170(0.0184) Grad: 6839.6221  LR: 0.00000798  \n","Epoch: [2][600/2476] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0079(0.0183) Grad: 32352.0215  LR: 0.00000785  \n","Epoch: [2][700/2476] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0205(0.0181) Grad: 26511.8516  LR: 0.00000771  \n","Epoch: [2][800/2476] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0220(0.0182) Grad: 11932.1934  LR: 0.00000758  \n","Epoch: [2][900/2476] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0152(0.0181) Grad: 3672.8604  LR: 0.00000744  \n","Epoch: [2][1000/2476] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0215(0.0183) Grad: 33098.2344  LR: 0.00000730  \n","Epoch: [2][1100/2476] Elapsed 3m 7s (remain 3m 53s) Loss: 0.0132(0.0182) Grad: 9604.1064  LR: 0.00000716  \n","Epoch: [2][1200/2476] Elapsed 3m 24s (remain 3m 36s) Loss: 0.0189(0.0181) Grad: 43479.8594  LR: 0.00000701  \n","Epoch: [2][1300/2476] Elapsed 3m 41s (remain 3m 19s) Loss: 0.0242(0.0180) Grad: 32389.6348  LR: 0.00000687  \n","Epoch: [2][1400/2476] Elapsed 3m 57s (remain 3m 2s) Loss: 0.0355(0.0180) Grad: 68804.4844  LR: 0.00000672  \n","Epoch: [2][1500/2476] Elapsed 4m 14s (remain 2m 45s) Loss: 0.0211(0.0180) Grad: 15118.2383  LR: 0.00000657  \n","Epoch: [2][1600/2476] Elapsed 4m 31s (remain 2m 28s) Loss: 0.0250(0.0182) Grad: 8404.0654  LR: 0.00000642  \n","Epoch: [2][1700/2476] Elapsed 4m 48s (remain 2m 11s) Loss: 0.0060(0.0183) Grad: 2580.1150  LR: 0.00000626  \n","Epoch: [2][1800/2476] Elapsed 5m 5s (remain 1m 54s) Loss: 0.0186(0.0183) Grad: 9331.8359  LR: 0.00000611  \n","Epoch: [2][1900/2476] Elapsed 5m 22s (remain 1m 37s) Loss: 0.0250(0.0183) Grad: 18126.1230  LR: 0.00000595  \n","Epoch: [2][2000/2476] Elapsed 5m 39s (remain 1m 20s) Loss: 0.0190(0.0184) Grad: 37560.9805  LR: 0.00000579  \n","Epoch: [2][2100/2476] Elapsed 5m 56s (remain 1m 3s) Loss: 0.0126(0.0182) Grad: 83309.1406  LR: 0.00000564  \n","Epoch: [2][2200/2476] Elapsed 6m 13s (remain 0m 46s) Loss: 0.0239(0.0181) Grad: 31255.2930  LR: 0.00000548  \n","Epoch: [2][2300/2476] Elapsed 6m 30s (remain 0m 29s) Loss: 0.0317(0.0181) Grad: 120815.9844  LR: 0.00000532  \n","Epoch: [2][2400/2476] Elapsed 6m 47s (remain 0m 12s) Loss: 0.0162(0.0180) Grad: 11774.1699  LR: 0.00000516  \n","Epoch: [2][2475/2476] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0061(0.0180) Grad: 39360.3516  LR: 0.00000504  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 39s) Loss: 0.0982(0.0982) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0838(0.0933) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0180  avg_val_loss: 0.0953  time: 432s\n","Epoch 2 - Score: 0.8409\n","Epoch 2 - Save Best Score: 0.8409 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1135(0.0953) \n","Epoch: [3][0/2476] Elapsed 0m 0s (remain 18m 16s) Loss: 0.0210(0.0210) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2476] Elapsed 0m 17s (remain 7m 0s) Loss: 0.0067(0.0121) Grad: 21037.6426  LR: 0.00000488  \n","Epoch: [3][200/2476] Elapsed 0m 35s (remain 6m 42s) Loss: 0.0129(0.0133) Grad: 16688.9062  LR: 0.00000472  \n","Epoch: [3][300/2476] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0072(0.0135) Grad: 42704.3555  LR: 0.00000456  \n","Epoch: [3][400/2476] Elapsed 1m 9s (remain 5m 59s) Loss: 0.0084(0.0138) Grad: 57510.3477  LR: 0.00000440  \n","Epoch: [3][500/2476] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0186(0.0139) Grad: 40827.3555  LR: 0.00000424  \n","Epoch: [3][600/2476] Elapsed 1m 43s (remain 5m 21s) Loss: 0.0109(0.0140) Grad: 8945.3340  LR: 0.00000409  \n","Epoch: [3][700/2476] Elapsed 2m 0s (remain 5m 3s) Loss: 0.0065(0.0141) Grad: 7164.5513  LR: 0.00000393  \n","Epoch: [3][800/2476] Elapsed 2m 17s (remain 4m 46s) Loss: 0.0163(0.0145) Grad: 41341.1680  LR: 0.00000378  \n","Epoch: [3][900/2476] Elapsed 2m 33s (remain 4m 29s) Loss: 0.0166(0.0146) Grad: 4422.1890  LR: 0.00000362  \n","Epoch: [3][1000/2476] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0118(0.0147) Grad: 7812.7500  LR: 0.00000347  \n","Epoch: [3][1100/2476] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0207(0.0147) Grad: 14545.0361  LR: 0.00000332  \n","Epoch: [3][1200/2476] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0139(0.0147) Grad: 31102.4648  LR: 0.00000317  \n","Epoch: [3][1300/2476] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0145(0.0147) Grad: 13090.6582  LR: 0.00000302  \n","Epoch: [3][1400/2476] Elapsed 3m 58s (remain 3m 2s) Loss: 0.0054(0.0146) Grad: 13393.2500  LR: 0.00000288  \n","Epoch: [3][1500/2476] Elapsed 4m 15s (remain 2m 45s) Loss: 0.0250(0.0147) Grad: 28560.3906  LR: 0.00000273  \n","Epoch: [3][1600/2476] Elapsed 4m 32s (remain 2m 28s) Loss: 0.0153(0.0147) Grad: 34668.0508  LR: 0.00000259  \n","Epoch: [3][1700/2476] Elapsed 4m 48s (remain 2m 11s) Loss: 0.0130(0.0147) Grad: 6109.4165  LR: 0.00000245  \n","Epoch: [3][1800/2476] Elapsed 5m 5s (remain 1m 54s) Loss: 0.0113(0.0147) Grad: 31470.3730  LR: 0.00000232  \n","Epoch: [3][1900/2476] Elapsed 5m 22s (remain 1m 37s) Loss: 0.0276(0.0147) Grad: 61603.7031  LR: 0.00000218  \n","Epoch: [3][2000/2476] Elapsed 5m 39s (remain 1m 20s) Loss: 0.0144(0.0148) Grad: 9917.0674  LR: 0.00000205  \n","Epoch: [3][2100/2476] Elapsed 5m 56s (remain 1m 3s) Loss: 0.0302(0.0148) Grad: 7582.1396  LR: 0.00000193  \n","Epoch: [3][2200/2476] Elapsed 6m 13s (remain 0m 46s) Loss: 0.0328(0.0148) Grad: 57659.6680  LR: 0.00000180  \n","Epoch: [3][2300/2476] Elapsed 6m 30s (remain 0m 29s) Loss: 0.0174(0.0148) Grad: 14313.4385  LR: 0.00000168  \n","Epoch: [3][2400/2476] Elapsed 6m 47s (remain 0m 12s) Loss: 0.0162(0.0149) Grad: 23049.8184  LR: 0.00000156  \n","Epoch: [3][2475/2476] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0088(0.0148) Grad: 20883.8730  LR: 0.00000148  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 41s) Loss: 0.0968(0.0968) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0780(0.0925) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0148  avg_val_loss: 0.0944  time: 432s\n","Epoch 3 - Score: 0.8420\n","Epoch 3 - Save Best Score: 0.8420 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1113(0.0944) \n","Epoch: [4][0/2476] Elapsed 0m 0s (remain 18m 7s) Loss: 0.0270(0.0270) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2476] Elapsed 0m 18s (remain 7m 4s) Loss: 0.0172(0.0114) Grad: 46398.8906  LR: 0.00000137  \n","Epoch: [4][200/2476] Elapsed 0m 35s (remain 6m 44s) Loss: 0.0098(0.0119) Grad: 22627.0859  LR: 0.00000126  \n","Epoch: [4][300/2476] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0056(0.0119) Grad: 24622.9414  LR: 0.00000115  \n","Epoch: [4][400/2476] Elapsed 1m 9s (remain 5m 59s) Loss: 0.0212(0.0120) Grad: 25831.2695  LR: 0.00000105  \n","Epoch: [4][500/2476] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0277(0.0122) Grad: 60944.2969  LR: 0.00000096  \n","Epoch: [4][600/2476] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0208(0.0120) Grad: 13513.9717  LR: 0.00000087  \n","Epoch: [4][700/2476] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0094(0.0120) Grad: 37414.8477  LR: 0.00000078  \n","Epoch: [4][800/2476] Elapsed 2m 17s (remain 4m 46s) Loss: 0.0077(0.0120) Grad: 10054.7998  LR: 0.00000070  \n","Epoch: [4][900/2476] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0105(0.0120) Grad: 44927.9062  LR: 0.00000062  \n","Epoch: [4][1000/2476] Elapsed 2m 51s (remain 4m 11s) Loss: 0.0135(0.0119) Grad: 25290.8398  LR: 0.00000054  \n","Epoch: [4][1100/2476] Elapsed 3m 8s (remain 3m 54s) Loss: 0.0092(0.0120) Grad: 49651.6719  LR: 0.00000047  \n","Epoch: [4][1200/2476] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0211(0.0119) Grad: 18758.1621  LR: 0.00000041  \n","Epoch: [4][1300/2476] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0044(0.0120) Grad: 16893.5566  LR: 0.00000035  \n","Epoch: [4][1400/2476] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0058(0.0121) Grad: 21760.3184  LR: 0.00000029  \n","Epoch: [4][1500/2476] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0258(0.0120) Grad: 30569.7461  LR: 0.00000024  \n","Epoch: [4][1600/2476] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0117(0.0120) Grad: 19664.2148  LR: 0.00000019  \n","Epoch: [4][1700/2476] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0153(0.0120) Grad: 18216.0859  LR: 0.00000015  \n","Epoch: [4][1800/2476] Elapsed 5m 6s (remain 1m 54s) Loss: 0.0138(0.0120) Grad: 5380.9775  LR: 0.00000012  \n","Epoch: [4][1900/2476] Elapsed 5m 23s (remain 1m 37s) Loss: 0.0171(0.0120) Grad: 8889.2246  LR: 0.00000008  \n","Epoch: [4][2000/2476] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0109(0.0119) Grad: 33676.2031  LR: 0.00000006  \n","Epoch: [4][2100/2476] Elapsed 5m 57s (remain 1m 3s) Loss: 0.0058(0.0119) Grad: 20810.7734  LR: 0.00000004  \n","Epoch: [4][2200/2476] Elapsed 6m 14s (remain 0m 46s) Loss: 0.0152(0.0119) Grad: 24537.9590  LR: 0.00000002  \n","Epoch: [4][2300/2476] Elapsed 6m 31s (remain 0m 29s) Loss: 0.0017(0.0119) Grad: 14006.8271  LR: 0.00000001  \n","Epoch: [4][2400/2476] Elapsed 6m 48s (remain 0m 12s) Loss: 0.0109(0.0119) Grad: 14668.3760  LR: 0.00000000  \n","Epoch: [4][2475/2476] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0069(0.0119) Grad: 2581.4348  LR: 0.00000000  \n","EVAL: [0/130] Elapsed 0m 0s (remain 0m 41s) Loss: 0.0970(0.0970) \n","EVAL: [100/130] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0788(0.0933) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0119  avg_val_loss: 0.0953  time: 434s\n","Epoch 4 - Score: 0.8424\n","Epoch 4 - Save Best Score: 0.8424 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [129/130] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1130(0.0953) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 8 result ==========\n","Score: 0.8424\n","========== fold: 9 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2464] Elapsed 0m 0s (remain 17m 56s) Loss: 0.7202(0.7202) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2464] Elapsed 0m 18s (remain 7m 4s) Loss: 0.0731(0.1695) Grad: 11618.2490  LR: 0.00001000  \n","Epoch: [1][200/2464] Elapsed 0m 35s (remain 6m 38s) Loss: 0.1537(0.1323) Grad: 46084.6758  LR: 0.00000999  \n","Epoch: [1][300/2464] Elapsed 0m 52s (remain 6m 16s) Loss: 0.0298(0.1107) Grad: 4894.6206  LR: 0.00000998  \n","Epoch: [1][400/2464] Elapsed 1m 9s (remain 5m 56s) Loss: 0.0415(0.1019) Grad: 19686.0312  LR: 0.00000997  \n","Epoch: [1][500/2464] Elapsed 1m 26s (remain 5m 38s) Loss: 0.0261(0.0947) Grad: 2066.7390  LR: 0.00000995  \n","Epoch: [1][600/2464] Elapsed 1m 43s (remain 5m 20s) Loss: 0.0237(0.0882) Grad: 18857.2832  LR: 0.00000992  \n","Epoch: [1][700/2464] Elapsed 2m 0s (remain 5m 3s) Loss: 0.0290(0.0825) Grad: 13246.7744  LR: 0.00000989  \n","Epoch: [1][800/2464] Elapsed 2m 17s (remain 4m 45s) Loss: 0.0232(0.0786) Grad: 7757.1074  LR: 0.00000986  \n","Epoch: [1][900/2464] Elapsed 2m 34s (remain 4m 27s) Loss: 0.0151(0.0748) Grad: 6137.4067  LR: 0.00000982  \n","Epoch: [1][1000/2464] Elapsed 2m 51s (remain 4m 10s) Loss: 0.0330(0.0709) Grad: 2594.4707  LR: 0.00000977  \n","Epoch: [1][1100/2464] Elapsed 3m 8s (remain 3m 52s) Loss: 0.0237(0.0680) Grad: 2359.9609  LR: 0.00000972  \n","Epoch: [1][1200/2464] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0271(0.0653) Grad: 7986.1875  LR: 0.00000966  \n","Epoch: [1][1300/2464] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0200(0.0635) Grad: 1700.6317  LR: 0.00000960  \n","Epoch: [1][1400/2464] Elapsed 3m 58s (remain 3m 1s) Loss: 0.0214(0.0614) Grad: 6604.8462  LR: 0.00000954  \n","Epoch: [1][1500/2464] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0329(0.0596) Grad: 5674.5381  LR: 0.00000947  \n","Epoch: [1][1600/2464] Elapsed 4m 32s (remain 2m 26s) Loss: 0.0243(0.0578) Grad: 2035.7155  LR: 0.00000940  \n","Epoch: [1][1700/2464] Elapsed 4m 49s (remain 2m 9s) Loss: 0.0327(0.0565) Grad: 13261.2549  LR: 0.00000932  \n","Epoch: [1][1800/2464] Elapsed 5m 6s (remain 1m 52s) Loss: 0.0153(0.0549) Grad: 2939.1191  LR: 0.00000923  \n","Epoch: [1][1900/2464] Elapsed 5m 23s (remain 1m 35s) Loss: 0.0270(0.0537) Grad: 3917.9924  LR: 0.00000915  \n","Epoch: [1][2000/2464] Elapsed 5m 40s (remain 1m 18s) Loss: 0.0154(0.0525) Grad: 3628.4785  LR: 0.00000905  \n","Epoch: [1][2100/2464] Elapsed 5m 57s (remain 1m 1s) Loss: 0.0267(0.0514) Grad: 14196.5420  LR: 0.00000896  \n","Epoch: [1][2200/2464] Elapsed 6m 14s (remain 0m 44s) Loss: 0.0302(0.0504) Grad: 8193.0576  LR: 0.00000886  \n","Epoch: [1][2300/2464] Elapsed 6m 31s (remain 0m 27s) Loss: 0.0131(0.0492) Grad: 8422.9805  LR: 0.00000876  \n","Epoch: [1][2400/2464] Elapsed 6m 48s (remain 0m 10s) Loss: 0.0259(0.0483) Grad: 18865.6855  LR: 0.00000865  \n","Epoch: [1][2463/2464] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0135(0.0477) Grad: 1706.9510  LR: 0.00000858  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 49s) Loss: 0.0580(0.0580) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0911(0.0967) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0477  avg_val_loss: 0.0975  time: 432s\n","Epoch 1 - Score: 0.7841\n","Epoch 1 - Save Best Score: 0.7841 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.2251(0.0975) \n","Epoch: [2][0/2464] Elapsed 0m 0s (remain 19m 25s) Loss: 0.0191(0.0191) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2464] Elapsed 0m 18s (remain 7m 1s) Loss: 0.0450(0.0206) Grad: 32987.9336  LR: 0.00000846  \n","Epoch: [2][200/2464] Elapsed 0m 35s (remain 6m 43s) Loss: 0.0285(0.0198) Grad: 12141.6113  LR: 0.00000835  \n","Epoch: [2][300/2464] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0179(0.0197) Grad: 22615.6035  LR: 0.00000822  \n","Epoch: [2][400/2464] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0326(0.0198) Grad: 67814.5469  LR: 0.00000810  \n","Epoch: [2][500/2464] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0110(0.0197) Grad: 6177.5239  LR: 0.00000797  \n","Epoch: [2][600/2464] Elapsed 1m 43s (remain 5m 20s) Loss: 0.0139(0.0197) Grad: 10810.8584  LR: 0.00000784  \n","Epoch: [2][700/2464] Elapsed 2m 0s (remain 5m 2s) Loss: 0.0075(0.0194) Grad: 6308.5352  LR: 0.00000771  \n","Epoch: [2][800/2464] Elapsed 2m 17s (remain 4m 44s) Loss: 0.0257(0.0194) Grad: 40416.8125  LR: 0.00000757  \n","Epoch: [2][900/2464] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0156(0.0194) Grad: 35796.4805  LR: 0.00000744  \n","Epoch: [2][1000/2464] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0124(0.0194) Grad: 7847.8149  LR: 0.00000729  \n","Epoch: [2][1100/2464] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0045(0.0194) Grad: 19391.0488  LR: 0.00000715  \n","Epoch: [2][1200/2464] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0213(0.0193) Grad: 40653.8008  LR: 0.00000701  \n","Epoch: [2][1300/2464] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0472(0.0192) Grad: 12657.3750  LR: 0.00000686  \n","Epoch: [2][1400/2464] Elapsed 3m 58s (remain 3m 1s) Loss: 0.0311(0.0192) Grad: 22794.4355  LR: 0.00000671  \n","Epoch: [2][1500/2464] Elapsed 4m 15s (remain 2m 44s) Loss: 0.0319(0.0191) Grad: 29433.3867  LR: 0.00000656  \n","Epoch: [2][1600/2464] Elapsed 4m 32s (remain 2m 27s) Loss: 0.0122(0.0192) Grad: 45410.7695  LR: 0.00000640  \n","Epoch: [2][1700/2464] Elapsed 4m 49s (remain 2m 9s) Loss: 0.0322(0.0193) Grad: 62327.5078  LR: 0.00000625  \n","Epoch: [2][1800/2464] Elapsed 5m 6s (remain 1m 52s) Loss: 0.0205(0.0193) Grad: 44433.2305  LR: 0.00000609  \n","Epoch: [2][1900/2464] Elapsed 5m 23s (remain 1m 35s) Loss: 0.0159(0.0194) Grad: 18553.4727  LR: 0.00000594  \n","Epoch: [2][2000/2464] Elapsed 5m 40s (remain 1m 18s) Loss: 0.0128(0.0194) Grad: 39205.4141  LR: 0.00000578  \n","Epoch: [2][2100/2464] Elapsed 5m 57s (remain 1m 1s) Loss: 0.0066(0.0194) Grad: 4731.6118  LR: 0.00000562  \n","Epoch: [2][2200/2464] Elapsed 6m 14s (remain 0m 44s) Loss: 0.0082(0.0193) Grad: 33731.0664  LR: 0.00000546  \n","Epoch: [2][2300/2464] Elapsed 6m 31s (remain 0m 27s) Loss: 0.0236(0.0193) Grad: 10957.8828  LR: 0.00000530  \n","Epoch: [2][2400/2464] Elapsed 6m 48s (remain 0m 10s) Loss: 0.0208(0.0193) Grad: 5477.1660  LR: 0.00000514  \n","Epoch: [2][2463/2464] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0149(0.0192) Grad: 10196.6748  LR: 0.00000504  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 49s) Loss: 0.0604(0.0604) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0956(0.0999) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0192  avg_val_loss: 0.1006  time: 432s\n","Epoch 2 - Score: 0.8073\n","Epoch 2 - Save Best Score: 0.8073 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.2144(0.1006) \n","Epoch: [3][0/2464] Elapsed 0m 0s (remain 20m 33s) Loss: 0.0119(0.0119) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2464] Elapsed 0m 17s (remain 6m 54s) Loss: 0.0040(0.0152) Grad: 34437.1211  LR: 0.00000488  \n","Epoch: [3][200/2464] Elapsed 0m 34s (remain 6m 33s) Loss: 0.0245(0.0146) Grad: 17145.4219  LR: 0.00000472  \n","Epoch: [3][300/2464] Elapsed 0m 51s (remain 6m 12s) Loss: 0.0201(0.0146) Grad: 99388.8828  LR: 0.00000456  \n","Epoch: [3][400/2464] Elapsed 1m 8s (remain 5m 53s) Loss: 0.0047(0.0146) Grad: 26460.2617  LR: 0.00000440  \n","Epoch: [3][500/2464] Elapsed 1m 25s (remain 5m 36s) Loss: 0.0152(0.0146) Grad: 39193.8555  LR: 0.00000424  \n","Epoch: [3][600/2464] Elapsed 1m 42s (remain 5m 18s) Loss: 0.0212(0.0148) Grad: 49620.4688  LR: 0.00000408  \n","Epoch: [3][700/2464] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0080(0.0151) Grad: 14058.9941  LR: 0.00000393  \n","Epoch: [3][800/2464] Elapsed 2m 16s (remain 4m 43s) Loss: 0.0076(0.0150) Grad: 4433.9756  LR: 0.00000377  \n","Epoch: [3][900/2464] Elapsed 2m 33s (remain 4m 26s) Loss: 0.0142(0.0152) Grad: 5663.0322  LR: 0.00000362  \n","Epoch: [3][1000/2464] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0235(0.0152) Grad: 55392.4883  LR: 0.00000346  \n","Epoch: [3][1100/2464] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0045(0.0152) Grad: 16293.4951  LR: 0.00000331  \n","Epoch: [3][1200/2464] Elapsed 3m 24s (remain 3m 34s) Loss: 0.0298(0.0153) Grad: 50077.8984  LR: 0.00000316  \n","Epoch: [3][1300/2464] Elapsed 3m 41s (remain 3m 17s) Loss: 0.0195(0.0153) Grad: 11842.4297  LR: 0.00000301  \n","Epoch: [3][1400/2464] Elapsed 3m 58s (remain 3m 0s) Loss: 0.0118(0.0154) Grad: 15204.0488  LR: 0.00000287  \n","Epoch: [3][1500/2464] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0159(0.0154) Grad: 12092.6162  LR: 0.00000272  \n","Epoch: [3][1600/2464] Elapsed 4m 32s (remain 2m 26s) Loss: 0.0185(0.0154) Grad: 8200.3018  LR: 0.00000258  \n","Epoch: [3][1700/2464] Elapsed 4m 49s (remain 2m 9s) Loss: 0.0044(0.0154) Grad: 4594.1426  LR: 0.00000244  \n","Epoch: [3][1800/2464] Elapsed 5m 5s (remain 1m 52s) Loss: 0.0120(0.0154) Grad: 14391.5508  LR: 0.00000231  \n","Epoch: [3][1900/2464] Elapsed 5m 22s (remain 1m 35s) Loss: 0.0192(0.0154) Grad: 20564.9121  LR: 0.00000217  \n","Epoch: [3][2000/2464] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0138(0.0153) Grad: 9144.0186  LR: 0.00000204  \n","Epoch: [3][2100/2464] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0087(0.0152) Grad: 5589.1392  LR: 0.00000191  \n","Epoch: [3][2200/2464] Elapsed 6m 13s (remain 0m 44s) Loss: 0.0096(0.0151) Grad: 15667.2539  LR: 0.00000179  \n","Epoch: [3][2300/2464] Elapsed 6m 30s (remain 0m 27s) Loss: 0.0167(0.0150) Grad: 7342.4355  LR: 0.00000167  \n","Epoch: [3][2400/2464] Elapsed 6m 47s (remain 0m 10s) Loss: 0.0095(0.0150) Grad: 76853.2734  LR: 0.00000155  \n","Epoch: [3][2463/2464] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0155(0.0150) Grad: 28025.4395  LR: 0.00000148  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 49s) Loss: 0.0594(0.0594) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0905(0.0981) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0150  avg_val_loss: 0.0988  time: 431s\n","Epoch 3 - Score: 0.8116\n","Epoch 3 - Save Best Score: 0.8116 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 13s (remain 0m 0s) Loss: 0.2085(0.0988) \n","Epoch: [4][0/2464] Elapsed 0m 0s (remain 19m 21s) Loss: 0.0058(0.0058) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2464] Elapsed 0m 17s (remain 6m 58s) Loss: 0.0185(0.0114) Grad: 42406.7344  LR: 0.00000137  \n","Epoch: [4][200/2464] Elapsed 0m 35s (remain 6m 38s) Loss: 0.0171(0.0113) Grad: 69650.0156  LR: 0.00000126  \n","Epoch: [4][300/2464] Elapsed 0m 52s (remain 6m 15s) Loss: 0.0070(0.0110) Grad: 19285.1582  LR: 0.00000115  \n","Epoch: [4][400/2464] Elapsed 1m 9s (remain 5m 55s) Loss: 0.0120(0.0113) Grad: 27725.9414  LR: 0.00000105  \n","Epoch: [4][500/2464] Elapsed 1m 26s (remain 5m 37s) Loss: 0.0084(0.0114) Grad: 22870.0176  LR: 0.00000096  \n","Epoch: [4][600/2464] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0156(0.0114) Grad: 5238.3271  LR: 0.00000086  \n","Epoch: [4][700/2464] Elapsed 1m 59s (remain 5m 1s) Loss: 0.0070(0.0114) Grad: 25208.2773  LR: 0.00000078  \n","Epoch: [4][800/2464] Elapsed 2m 16s (remain 4m 43s) Loss: 0.0114(0.0114) Grad: 34474.6680  LR: 0.00000069  \n","Epoch: [4][900/2464] Elapsed 2m 33s (remain 4m 26s) Loss: 0.0132(0.0114) Grad: 10876.8164  LR: 0.00000061  \n","Epoch: [4][1000/2464] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0175(0.0114) Grad: 18231.1289  LR: 0.00000054  \n","Epoch: [4][1100/2464] Elapsed 3m 7s (remain 3m 51s) Loss: 0.0187(0.0114) Grad: 9602.6367  LR: 0.00000047  \n","Epoch: [4][1200/2464] Elapsed 3m 24s (remain 3m 34s) Loss: 0.0095(0.0114) Grad: 3649.2078  LR: 0.00000040  \n","Epoch: [4][1300/2464] Elapsed 3m 41s (remain 3m 17s) Loss: 0.0210(0.0115) Grad: 37642.1289  LR: 0.00000034  \n","Epoch: [4][1400/2464] Elapsed 3m 58s (remain 3m 0s) Loss: 0.0405(0.0116) Grad: 45079.1641  LR: 0.00000029  \n","Epoch: [4][1500/2464] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0052(0.0116) Grad: 8236.5449  LR: 0.00000024  \n","Epoch: [4][1600/2464] Elapsed 4m 31s (remain 2m 26s) Loss: 0.0181(0.0116) Grad: 24247.4316  LR: 0.00000019  \n","Epoch: [4][1700/2464] Elapsed 4m 48s (remain 2m 9s) Loss: 0.0055(0.0115) Grad: 13376.9570  LR: 0.00000015  \n","Epoch: [4][1800/2464] Elapsed 5m 5s (remain 1m 52s) Loss: 0.0310(0.0115) Grad: 14361.0732  LR: 0.00000011  \n","Epoch: [4][1900/2464] Elapsed 5m 22s (remain 1m 35s) Loss: 0.0165(0.0115) Grad: 9668.1348  LR: 0.00000008  \n","Epoch: [4][2000/2464] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0012(0.0115) Grad: 3581.6067  LR: 0.00000005  \n","Epoch: [4][2100/2464] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0145(0.0115) Grad: 29267.6387  LR: 0.00000003  \n","Epoch: [4][2200/2464] Elapsed 6m 14s (remain 0m 44s) Loss: 0.0065(0.0115) Grad: 17904.2695  LR: 0.00000002  \n","Epoch: [4][2300/2464] Elapsed 6m 31s (remain 0m 27s) Loss: 0.0131(0.0114) Grad: 6859.4575  LR: 0.00000001  \n","Epoch: [4][2400/2464] Elapsed 6m 49s (remain 0m 10s) Loss: 0.0053(0.0114) Grad: 9071.0400  LR: 0.00000000  \n","Epoch: [4][2463/2464] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0075(0.0114) Grad: 3029.9707  LR: 0.00000000  \n","EVAL: [0/142] Elapsed 0m 0s (remain 0m 48s) Loss: 0.0584(0.0584) \n","EVAL: [100/142] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0890(0.0965) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0114  avg_val_loss: 0.0971  time: 433s\n","Epoch 4 - Score: 0.8128\n","Epoch 4 - Save Best Score: 0.8128 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [141/142] Elapsed 0m 12s (remain 0m 0s) Loss: 0.2049(0.0971) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 9 result ==========\n","Score: 0.8128\n","========== fold: 10 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2477] Elapsed 0m 0s (remain 18m 13s) Loss: 0.6816(0.6816) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2477] Elapsed 0m 17s (remain 6m 59s) Loss: 0.1788(0.1807) Grad: 58579.1250  LR: 0.00001000  \n","Epoch: [1][200/2477] Elapsed 0m 34s (remain 6m 33s) Loss: 0.0578(0.1307) Grad: 9448.0820  LR: 0.00000999  \n","Epoch: [1][300/2477] Elapsed 0m 51s (remain 6m 12s) Loss: 0.0508(0.1168) Grad: 29797.6016  LR: 0.00000998  \n","Epoch: [1][400/2477] Elapsed 1m 8s (remain 5m 54s) Loss: 0.0249(0.1029) Grad: 11940.6602  LR: 0.00000997  \n","Epoch: [1][500/2477] Elapsed 1m 25s (remain 5m 36s) Loss: 0.1914(0.0935) Grad: 68419.6250  LR: 0.00000995  \n","Epoch: [1][600/2477] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0454(0.0860) Grad: 8189.8521  LR: 0.00000992  \n","Epoch: [1][700/2477] Elapsed 1m 59s (remain 5m 1s) Loss: 0.0183(0.0808) Grad: 7037.7075  LR: 0.00000989  \n","Epoch: [1][800/2477] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0349(0.0754) Grad: 9889.8574  LR: 0.00000986  \n","Epoch: [1][900/2477] Elapsed 2m 32s (remain 4m 27s) Loss: 0.0268(0.0712) Grad: 3646.4705  LR: 0.00000982  \n","Epoch: [1][1000/2477] Elapsed 2m 49s (remain 4m 10s) Loss: 0.0141(0.0690) Grad: 2974.7590  LR: 0.00000977  \n","Epoch: [1][1100/2477] Elapsed 3m 6s (remain 3m 53s) Loss: 0.0270(0.0670) Grad: 4199.8975  LR: 0.00000972  \n","Epoch: [1][1200/2477] Elapsed 3m 23s (remain 3m 36s) Loss: 0.0287(0.0659) Grad: 5869.6899  LR: 0.00000967  \n","Epoch: [1][1300/2477] Elapsed 3m 40s (remain 3m 19s) Loss: 0.0157(0.0640) Grad: 8206.8525  LR: 0.00000961  \n","Epoch: [1][1400/2477] Elapsed 3m 57s (remain 3m 2s) Loss: 0.0614(0.0620) Grad: 26653.7734  LR: 0.00000954  \n","Epoch: [1][1500/2477] Elapsed 4m 14s (remain 2m 45s) Loss: 0.0711(0.0602) Grad: 27998.5371  LR: 0.00000948  \n","Epoch: [1][1600/2477] Elapsed 4m 31s (remain 2m 28s) Loss: 0.0567(0.0586) Grad: 21081.2793  LR: 0.00000940  \n","Epoch: [1][1700/2477] Elapsed 4m 49s (remain 2m 11s) Loss: 0.0721(0.0572) Grad: 20968.8340  LR: 0.00000932  \n","Epoch: [1][1800/2477] Elapsed 5m 6s (remain 1m 54s) Loss: 0.0131(0.0557) Grad: 3291.4731  LR: 0.00000924  \n","Epoch: [1][1900/2477] Elapsed 5m 23s (remain 1m 37s) Loss: 0.0574(0.0543) Grad: 5365.0669  LR: 0.00000916  \n","Epoch: [1][2000/2477] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0232(0.0533) Grad: 1549.7821  LR: 0.00000906  \n","Epoch: [1][2100/2477] Elapsed 5m 57s (remain 1m 3s) Loss: 0.0328(0.0522) Grad: 5456.1357  LR: 0.00000897  \n","Epoch: [1][2200/2477] Elapsed 6m 14s (remain 0m 46s) Loss: 0.0478(0.0510) Grad: 17766.9180  LR: 0.00000887  \n","Epoch: [1][2300/2477] Elapsed 6m 31s (remain 0m 29s) Loss: 0.0171(0.0499) Grad: 13924.4199  LR: 0.00000877  \n","Epoch: [1][2400/2477] Elapsed 6m 47s (remain 0m 12s) Loss: 0.0326(0.0488) Grad: 29121.6191  LR: 0.00000866  \n","Epoch: [1][2476/2477] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0408(0.0481) Grad: 9440.4209  LR: 0.00000858  \n","EVAL: [0/128] Elapsed 0m 0s (remain 0m 44s) Loss: 0.1571(0.1571) \n","EVAL: [100/128] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0320(0.1153) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0481  avg_val_loss: 0.1124  time: 433s\n","Epoch 1 - Score: 0.8283\n","Epoch 1 - Save Best Score: 0.8283 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [127/128] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0089(0.1124) \n","Epoch: [2][0/2477] Elapsed 0m 0s (remain 19m 22s) Loss: 0.0185(0.0185) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2477] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0093(0.0228) Grad: 20379.5918  LR: 0.00000846  \n","Epoch: [2][200/2477] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0096(0.0207) Grad: 16007.8213  LR: 0.00000835  \n","Epoch: [2][300/2477] Elapsed 0m 52s (remain 6m 20s) Loss: 0.0150(0.0196) Grad: 20776.7246  LR: 0.00000823  \n","Epoch: [2][400/2477] Elapsed 1m 9s (remain 6m 1s) Loss: 0.0146(0.0196) Grad: 29500.2578  LR: 0.00000810  \n","Epoch: [2][500/2477] Elapsed 1m 26s (remain 5m 42s) Loss: 0.0167(0.0192) Grad: 40157.7305  LR: 0.00000798  \n","Epoch: [2][600/2477] Elapsed 1m 43s (remain 5m 24s) Loss: 0.0184(0.0193) Grad: 9109.0713  LR: 0.00000785  \n","Epoch: [2][700/2477] Elapsed 2m 1s (remain 5m 6s) Loss: 0.0075(0.0195) Grad: 26374.2207  LR: 0.00000772  \n","Epoch: [2][800/2477] Elapsed 2m 18s (remain 4m 48s) Loss: 0.0223(0.0195) Grad: 51079.6562  LR: 0.00000758  \n","Epoch: [2][900/2477] Elapsed 2m 35s (remain 4m 31s) Loss: 0.0141(0.0195) Grad: 15412.7861  LR: 0.00000744  \n","Epoch: [2][1000/2477] Elapsed 2m 52s (remain 4m 14s) Loss: 0.0269(0.0195) Grad: 38639.5312  LR: 0.00000730  \n","Epoch: [2][1100/2477] Elapsed 3m 9s (remain 3m 56s) Loss: 0.0234(0.0195) Grad: 18334.3691  LR: 0.00000716  \n","Epoch: [2][1200/2477] Elapsed 3m 26s (remain 3m 39s) Loss: 0.0144(0.0194) Grad: 16862.8965  LR: 0.00000702  \n","Epoch: [2][1300/2477] Elapsed 3m 43s (remain 3m 22s) Loss: 0.0260(0.0193) Grad: 56589.8242  LR: 0.00000687  \n","Epoch: [2][1400/2477] Elapsed 4m 0s (remain 3m 4s) Loss: 0.0042(0.0193) Grad: 24458.7480  LR: 0.00000672  \n","Epoch: [2][1500/2477] Elapsed 4m 17s (remain 2m 47s) Loss: 0.0209(0.0192) Grad: 27310.0156  LR: 0.00000657  \n","Epoch: [2][1600/2477] Elapsed 4m 34s (remain 2m 30s) Loss: 0.0137(0.0190) Grad: 5550.9429  LR: 0.00000642  \n","Epoch: [2][1700/2477] Elapsed 4m 51s (remain 2m 13s) Loss: 0.0203(0.0190) Grad: 5989.3301  LR: 0.00000626  \n","Epoch: [2][1800/2477] Elapsed 5m 8s (remain 1m 55s) Loss: 0.0287(0.0189) Grad: 4660.5332  LR: 0.00000611  \n","Epoch: [2][1900/2477] Elapsed 5m 26s (remain 1m 38s) Loss: 0.0411(0.0189) Grad: 22414.9102  LR: 0.00000595  \n","Epoch: [2][2000/2477] Elapsed 5m 43s (remain 1m 21s) Loss: 0.0252(0.0189) Grad: 11589.3691  LR: 0.00000580  \n","Epoch: [2][2100/2477] Elapsed 6m 0s (remain 1m 4s) Loss: 0.0163(0.0188) Grad: 18627.5098  LR: 0.00000564  \n","Epoch: [2][2200/2477] Elapsed 6m 17s (remain 0m 47s) Loss: 0.0195(0.0188) Grad: 50810.0234  LR: 0.00000548  \n","Epoch: [2][2300/2477] Elapsed 6m 34s (remain 0m 30s) Loss: 0.0104(0.0189) Grad: 2863.3843  LR: 0.00000532  \n","Epoch: [2][2400/2477] Elapsed 6m 51s (remain 0m 13s) Loss: 0.0175(0.0189) Grad: 28010.8555  LR: 0.00000516  \n","Epoch: [2][2476/2477] Elapsed 7m 4s (remain 0m 0s) Loss: 0.0174(0.0188) Grad: 4958.9746  LR: 0.00000504  \n","EVAL: [0/128] Elapsed 0m 0s (remain 0m 41s) Loss: 0.1496(0.1496) \n","EVAL: [100/128] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0311(0.1068) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0188  avg_val_loss: 0.1042  time: 436s\n","Epoch 2 - Score: 0.8420\n","Epoch 2 - Save Best Score: 0.8420 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [127/128] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0082(0.1042) \n","Epoch: [3][0/2477] Elapsed 0m 0s (remain 19m 46s) Loss: 0.0082(0.0082) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2477] Elapsed 0m 18s (remain 7m 4s) Loss: 0.0177(0.0147) Grad: 19251.8184  LR: 0.00000488  \n","Epoch: [3][200/2477] Elapsed 0m 36s (remain 6m 48s) Loss: 0.0051(0.0156) Grad: 18109.1973  LR: 0.00000472  \n","Epoch: [3][300/2477] Elapsed 0m 53s (remain 6m 24s) Loss: 0.0312(0.0154) Grad: 38507.9492  LR: 0.00000456  \n","Epoch: [3][400/2477] Elapsed 1m 10s (remain 6m 4s) Loss: 0.0121(0.0155) Grad: 11859.0264  LR: 0.00000440  \n","Epoch: [3][500/2477] Elapsed 1m 27s (remain 5m 44s) Loss: 0.0054(0.0153) Grad: 28668.5430  LR: 0.00000425  \n","Epoch: [3][600/2477] Elapsed 1m 44s (remain 5m 26s) Loss: 0.0117(0.0154) Grad: 36934.0664  LR: 0.00000409  \n","Epoch: [3][700/2477] Elapsed 2m 1s (remain 5m 8s) Loss: 0.0141(0.0154) Grad: 26244.8477  LR: 0.00000393  \n","Epoch: [3][800/2477] Elapsed 2m 18s (remain 4m 50s) Loss: 0.0476(0.0154) Grad: 31928.0566  LR: 0.00000378  \n","Epoch: [3][900/2477] Elapsed 2m 35s (remain 4m 32s) Loss: 0.0036(0.0152) Grad: 21540.5176  LR: 0.00000362  \n","Epoch: [3][1000/2477] Elapsed 2m 52s (remain 4m 14s) Loss: 0.0082(0.0152) Grad: 3922.9414  LR: 0.00000347  \n","Epoch: [3][1100/2477] Elapsed 3m 10s (remain 3m 57s) Loss: 0.0085(0.0151) Grad: 33664.7656  LR: 0.00000332  \n","Epoch: [3][1200/2477] Elapsed 3m 27s (remain 3m 40s) Loss: 0.0167(0.0151) Grad: 9367.8096  LR: 0.00000317  \n","Epoch: [3][1300/2477] Elapsed 3m 44s (remain 3m 22s) Loss: 0.0077(0.0151) Grad: 4533.7119  LR: 0.00000302  \n","Epoch: [3][1400/2477] Elapsed 4m 1s (remain 3m 5s) Loss: 0.0057(0.0150) Grad: 13052.2891  LR: 0.00000288  \n","Epoch: [3][1500/2477] Elapsed 4m 18s (remain 2m 48s) Loss: 0.0073(0.0150) Grad: 22867.2891  LR: 0.00000274  \n","Epoch: [3][1600/2477] Elapsed 4m 35s (remain 2m 30s) Loss: 0.0138(0.0150) Grad: 39768.9102  LR: 0.00000259  \n","Epoch: [3][1700/2477] Elapsed 4m 52s (remain 2m 13s) Loss: 0.0100(0.0149) Grad: 7586.1890  LR: 0.00000246  \n","Epoch: [3][1800/2477] Elapsed 5m 9s (remain 1m 56s) Loss: 0.0079(0.0148) Grad: 6622.9297  LR: 0.00000232  \n","Epoch: [3][1900/2477] Elapsed 5m 26s (remain 1m 39s) Loss: 0.0115(0.0148) Grad: 13655.7383  LR: 0.00000219  \n","Epoch: [3][2000/2477] Elapsed 5m 43s (remain 1m 21s) Loss: 0.0170(0.0147) Grad: 10694.9424  LR: 0.00000206  \n","Epoch: [3][2100/2477] Elapsed 6m 0s (remain 1m 4s) Loss: 0.0176(0.0148) Grad: 38105.0234  LR: 0.00000193  \n","Epoch: [3][2200/2477] Elapsed 6m 17s (remain 0m 47s) Loss: 0.0108(0.0147) Grad: 11897.8672  LR: 0.00000181  \n","Epoch: [3][2300/2477] Elapsed 6m 35s (remain 0m 30s) Loss: 0.0150(0.0146) Grad: 56379.0898  LR: 0.00000168  \n","Epoch: [3][2400/2477] Elapsed 6m 52s (remain 0m 13s) Loss: 0.0073(0.0146) Grad: 10837.3682  LR: 0.00000157  \n","Epoch: [3][2476/2477] Elapsed 7m 5s (remain 0m 0s) Loss: 0.0322(0.0145) Grad: 30402.6797  LR: 0.00000148  \n","EVAL: [0/128] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1430(0.1430) \n","EVAL: [100/128] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0290(0.0995) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0145  avg_val_loss: 0.0970  time: 437s\n","Epoch 3 - Score: 0.8527\n","Epoch 3 - Save Best Score: 0.8527 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [127/128] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0093(0.0970) \n","Epoch: [4][0/2477] Elapsed 0m 0s (remain 19m 44s) Loss: 0.0112(0.0112) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2477] Elapsed 0m 18s (remain 7m 5s) Loss: 0.0122(0.0110) Grad: 45134.1875  LR: 0.00000137  \n","Epoch: [4][200/2477] Elapsed 0m 35s (remain 6m 44s) Loss: 0.0081(0.0111) Grad: 6497.2178  LR: 0.00000126  \n","Epoch: [4][300/2477] Elapsed 0m 52s (remain 6m 21s) Loss: 0.0080(0.0111) Grad: 8653.1279  LR: 0.00000116  \n","Epoch: [4][400/2477] Elapsed 1m 9s (remain 6m 1s) Loss: 0.0067(0.0110) Grad: 11075.3467  LR: 0.00000106  \n","Epoch: [4][500/2477] Elapsed 1m 26s (remain 5m 42s) Loss: 0.0073(0.0110) Grad: 36371.5820  LR: 0.00000096  \n","Epoch: [4][600/2477] Elapsed 1m 43s (remain 5m 24s) Loss: 0.0083(0.0111) Grad: 45263.3203  LR: 0.00000087  \n","Epoch: [4][700/2477] Elapsed 2m 1s (remain 5m 6s) Loss: 0.0079(0.0111) Grad: 9296.9912  LR: 0.00000078  \n","Epoch: [4][800/2477] Elapsed 2m 18s (remain 4m 48s) Loss: 0.0093(0.0111) Grad: 33307.6719  LR: 0.00000070  \n","Epoch: [4][900/2477] Elapsed 2m 35s (remain 4m 31s) Loss: 0.0046(0.0111) Grad: 47167.8203  LR: 0.00000062  \n","Epoch: [4][1000/2477] Elapsed 2m 52s (remain 4m 13s) Loss: 0.0085(0.0112) Grad: 19709.4395  LR: 0.00000054  \n","Epoch: [4][1100/2477] Elapsed 3m 9s (remain 3m 56s) Loss: 0.0088(0.0111) Grad: 28754.6953  LR: 0.00000047  \n","Epoch: [4][1200/2477] Elapsed 3m 26s (remain 3m 39s) Loss: 0.0082(0.0111) Grad: 7615.8076  LR: 0.00000041  \n","Epoch: [4][1300/2477] Elapsed 3m 43s (remain 3m 21s) Loss: 0.0089(0.0111) Grad: 10039.6113  LR: 0.00000035  \n","Epoch: [4][1400/2477] Elapsed 4m 0s (remain 3m 4s) Loss: 0.0048(0.0111) Grad: 43963.6719  LR: 0.00000029  \n","Epoch: [4][1500/2477] Elapsed 4m 17s (remain 2m 47s) Loss: 0.0118(0.0112) Grad: 7658.4663  LR: 0.00000024  \n","Epoch: [4][1600/2477] Elapsed 4m 34s (remain 2m 30s) Loss: 0.0109(0.0112) Grad: 16488.1152  LR: 0.00000019  \n","Epoch: [4][1700/2477] Elapsed 4m 51s (remain 2m 12s) Loss: 0.0105(0.0112) Grad: 39593.9844  LR: 0.00000015  \n","Epoch: [4][1800/2477] Elapsed 5m 8s (remain 1m 55s) Loss: 0.0169(0.0111) Grad: 53584.3008  LR: 0.00000012  \n","Epoch: [4][1900/2477] Elapsed 5m 25s (remain 1m 38s) Loss: 0.0190(0.0111) Grad: 10543.2910  LR: 0.00000008  \n","Epoch: [4][2000/2477] Elapsed 5m 42s (remain 1m 21s) Loss: 0.0156(0.0112) Grad: 10899.7383  LR: 0.00000006  \n","Epoch: [4][2100/2477] Elapsed 5m 59s (remain 1m 4s) Loss: 0.0158(0.0112) Grad: 76465.1328  LR: 0.00000004  \n","Epoch: [4][2200/2477] Elapsed 6m 16s (remain 0m 47s) Loss: 0.0069(0.0111) Grad: 46279.2383  LR: 0.00000002  \n","Epoch: [4][2300/2477] Elapsed 6m 33s (remain 0m 30s) Loss: 0.0143(0.0111) Grad: 62340.3242  LR: 0.00000001  \n","Epoch: [4][2400/2477] Elapsed 6m 50s (remain 0m 12s) Loss: 0.0043(0.0111) Grad: 6978.7490  LR: 0.00000000  \n","Epoch: [4][2476/2477] Elapsed 7m 3s (remain 0m 0s) Loss: 0.0064(0.0111) Grad: 24348.7559  LR: 0.00000000  \n","EVAL: [0/128] Elapsed 0m 0s (remain 0m 42s) Loss: 0.1422(0.1422) \n","EVAL: [100/128] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0290(0.1005) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0111  avg_val_loss: 0.0979  time: 435s\n","Epoch 4 - Score: 0.8527\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [127/128] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0094(0.0979) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 10 result ==========\n","Score: 0.8527\n","========== fold: 11 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2481] Elapsed 0m 0s (remain 18m 19s) Loss: 0.9014(0.9014) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2481] Elapsed 0m 17s (remain 6m 48s) Loss: 0.0827(0.2184) Grad: 8198.5850  LR: 0.00001000  \n","Epoch: [1][200/2481] Elapsed 0m 34s (remain 6m 29s) Loss: 0.0842(0.1473) Grad: 38074.2383  LR: 0.00000999  \n","Epoch: [1][300/2481] Elapsed 0m 51s (remain 6m 12s) Loss: 0.0690(0.1238) Grad: 17250.0547  LR: 0.00000998  \n","Epoch: [1][400/2481] Elapsed 1m 8s (remain 5m 54s) Loss: 0.1122(0.1086) Grad: 49069.8125  LR: 0.00000997  \n","Epoch: [1][500/2481] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0862(0.1000) Grad: 39837.7773  LR: 0.00000995  \n","Epoch: [1][600/2481] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0476(0.0924) Grad: 7914.4424  LR: 0.00000992  \n","Epoch: [1][700/2481] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0500(0.0868) Grad: 28540.1934  LR: 0.00000989  \n","Epoch: [1][800/2481] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0489(0.0822) Grad: 18079.8145  LR: 0.00000986  \n","Epoch: [1][900/2481] Elapsed 2m 32s (remain 4m 28s) Loss: 0.0311(0.0783) Grad: 8667.3408  LR: 0.00000982  \n","Epoch: [1][1000/2481] Elapsed 2m 49s (remain 4m 10s) Loss: 0.0530(0.0742) Grad: 32128.6660  LR: 0.00000977  \n","Epoch: [1][1100/2481] Elapsed 3m 6s (remain 3m 53s) Loss: 0.0513(0.0710) Grad: 22434.1523  LR: 0.00000972  \n","Epoch: [1][1200/2481] Elapsed 3m 23s (remain 3m 36s) Loss: 0.0276(0.0683) Grad: 15182.2461  LR: 0.00000967  \n","Epoch: [1][1300/2481] Elapsed 3m 39s (remain 3m 19s) Loss: 0.0314(0.0657) Grad: 9379.6553  LR: 0.00000961  \n","Epoch: [1][1400/2481] Elapsed 3m 56s (remain 3m 2s) Loss: 0.0851(0.0640) Grad: 38099.1016  LR: 0.00000955  \n","Epoch: [1][1500/2481] Elapsed 4m 13s (remain 2m 45s) Loss: 0.0341(0.0625) Grad: 6812.4458  LR: 0.00000948  \n","Epoch: [1][1600/2481] Elapsed 4m 30s (remain 2m 28s) Loss: 0.0256(0.0609) Grad: 2766.0781  LR: 0.00000940  \n","Epoch: [1][1700/2481] Elapsed 4m 47s (remain 2m 11s) Loss: 0.0320(0.0594) Grad: 10714.2549  LR: 0.00000933  \n","Epoch: [1][1800/2481] Elapsed 5m 3s (remain 1m 54s) Loss: 0.0231(0.0579) Grad: 10578.2812  LR: 0.00000924  \n","Epoch: [1][1900/2481] Elapsed 5m 20s (remain 1m 37s) Loss: 0.0338(0.0565) Grad: 16550.6172  LR: 0.00000916  \n","Epoch: [1][2000/2481] Elapsed 5m 37s (remain 1m 20s) Loss: 0.0171(0.0556) Grad: 4260.8066  LR: 0.00000907  \n","Epoch: [1][2100/2481] Elapsed 5m 54s (remain 1m 4s) Loss: 0.0173(0.0545) Grad: 5856.1050  LR: 0.00000897  \n","Epoch: [1][2200/2481] Elapsed 6m 10s (remain 0m 47s) Loss: 0.0148(0.0532) Grad: 15164.3242  LR: 0.00000887  \n","Epoch: [1][2300/2481] Elapsed 6m 27s (remain 0m 30s) Loss: 0.0297(0.0521) Grad: 21796.5195  LR: 0.00000877  \n","Epoch: [1][2400/2481] Elapsed 6m 44s (remain 0m 13s) Loss: 0.0277(0.0509) Grad: 4062.6206  LR: 0.00000867  \n","Epoch: [1][2480/2481] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0240(0.0502) Grad: 28188.7168  LR: 0.00000858  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1252(0.1252) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0660(0.0889) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0502  avg_val_loss: 0.0894  time: 429s\n","Epoch 1 - Score: 0.8258\n","Epoch 1 - Save Best Score: 0.8258 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1022(0.0894) \n","Epoch: [2][0/2481] Elapsed 0m 0s (remain 20m 4s) Loss: 0.0081(0.0081) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2481] Elapsed 0m 17s (remain 7m 2s) Loss: 0.0098(0.0195) Grad: 11826.4463  LR: 0.00000846  \n","Epoch: [2][200/2481] Elapsed 0m 35s (remain 6m 43s) Loss: 0.0223(0.0203) Grad: 41573.8828  LR: 0.00000835  \n","Epoch: [2][300/2481] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0499(0.0206) Grad: 104910.7266  LR: 0.00000823  \n","Epoch: [2][400/2481] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0224(0.0201) Grad: 12606.3652  LR: 0.00000810  \n","Epoch: [2][500/2481] Elapsed 1m 25s (remain 5m 39s) Loss: 0.0212(0.0198) Grad: 17178.5137  LR: 0.00000798  \n","Epoch: [2][600/2481] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0146(0.0197) Grad: 16350.3691  LR: 0.00000785  \n","Epoch: [2][700/2481] Elapsed 1m 59s (remain 5m 2s) Loss: 0.0544(0.0200) Grad: 48288.4258  LR: 0.00000772  \n","Epoch: [2][800/2481] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0336(0.0198) Grad: 23050.0996  LR: 0.00000758  \n","Epoch: [2][900/2481] Elapsed 2m 32s (remain 4m 28s) Loss: 0.0213(0.0203) Grad: 21121.6992  LR: 0.00000745  \n","Epoch: [2][1000/2481] Elapsed 2m 49s (remain 4m 10s) Loss: 0.0127(0.0201) Grad: 9928.2070  LR: 0.00000731  \n","Epoch: [2][1100/2481] Elapsed 3m 6s (remain 3m 53s) Loss: 0.0174(0.0200) Grad: 23681.1953  LR: 0.00000716  \n","Epoch: [2][1200/2481] Elapsed 3m 23s (remain 3m 36s) Loss: 0.0127(0.0200) Grad: 26283.3574  LR: 0.00000702  \n","Epoch: [2][1300/2481] Elapsed 3m 40s (remain 3m 19s) Loss: 0.0072(0.0199) Grad: 20046.4531  LR: 0.00000687  \n","Epoch: [2][1400/2481] Elapsed 3m 56s (remain 3m 2s) Loss: 0.0208(0.0198) Grad: 29279.6348  LR: 0.00000672  \n","Epoch: [2][1500/2481] Elapsed 4m 13s (remain 2m 45s) Loss: 0.0247(0.0199) Grad: 52457.8359  LR: 0.00000657  \n","Epoch: [2][1600/2481] Elapsed 4m 30s (remain 2m 28s) Loss: 0.0166(0.0198) Grad: 25978.4414  LR: 0.00000642  \n","Epoch: [2][1700/2481] Elapsed 4m 47s (remain 2m 11s) Loss: 0.0399(0.0197) Grad: 59024.1289  LR: 0.00000627  \n","Epoch: [2][1800/2481] Elapsed 5m 4s (remain 1m 54s) Loss: 0.0192(0.0198) Grad: 41394.4141  LR: 0.00000611  \n","Epoch: [2][1900/2481] Elapsed 5m 21s (remain 1m 37s) Loss: 0.0091(0.0198) Grad: 3309.4678  LR: 0.00000596  \n","Epoch: [2][2000/2481] Elapsed 5m 37s (remain 1m 21s) Loss: 0.0395(0.0197) Grad: 59582.0117  LR: 0.00000580  \n","Epoch: [2][2100/2481] Elapsed 5m 54s (remain 1m 4s) Loss: 0.0390(0.0197) Grad: 42809.2070  LR: 0.00000564  \n","Epoch: [2][2200/2481] Elapsed 6m 11s (remain 0m 47s) Loss: 0.0099(0.0195) Grad: 19098.8770  LR: 0.00000549  \n","Epoch: [2][2300/2481] Elapsed 6m 28s (remain 0m 30s) Loss: 0.0102(0.0195) Grad: 6729.2710  LR: 0.00000533  \n","Epoch: [2][2400/2481] Elapsed 6m 45s (remain 0m 13s) Loss: 0.0105(0.0195) Grad: 7148.1909  LR: 0.00000517  \n","Epoch: [2][2480/2481] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0184(0.0195) Grad: 47311.2383  LR: 0.00000504  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 43s) Loss: 0.1460(0.1460) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0765(0.1021) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0195  avg_val_loss: 0.1026  time: 430s\n","Epoch 2 - Score: 0.8425\n","Epoch 2 - Save Best Score: 0.8425 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1151(0.1026) \n","Epoch: [3][0/2481] Elapsed 0m 0s (remain 19m 57s) Loss: 0.0156(0.0156) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2481] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0117(0.0164) Grad: 28345.4746  LR: 0.00000488  \n","Epoch: [3][200/2481] Elapsed 0m 35s (remain 6m 40s) Loss: 0.0153(0.0153) Grad: 26868.7227  LR: 0.00000472  \n","Epoch: [3][300/2481] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0130(0.0153) Grad: 27328.1992  LR: 0.00000456  \n","Epoch: [3][400/2481] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0068(0.0154) Grad: 3353.4949  LR: 0.00000441  \n","Epoch: [3][500/2481] Elapsed 1m 25s (remain 5m 39s) Loss: 0.0189(0.0152) Grad: 36511.6992  LR: 0.00000425  \n","Epoch: [3][600/2481] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0145(0.0154) Grad: 35754.0742  LR: 0.00000409  \n","Epoch: [3][700/2481] Elapsed 1m 59s (remain 5m 4s) Loss: 0.0253(0.0156) Grad: 55370.7383  LR: 0.00000394  \n","Epoch: [3][800/2481] Elapsed 2m 16s (remain 4m 47s) Loss: 0.0304(0.0158) Grad: 20836.0410  LR: 0.00000378  \n","Epoch: [3][900/2481] Elapsed 2m 34s (remain 4m 30s) Loss: 0.0048(0.0157) Grad: 29184.5938  LR: 0.00000363  \n","Epoch: [3][1000/2481] Elapsed 2m 51s (remain 4m 13s) Loss: 0.0194(0.0156) Grad: 39355.6445  LR: 0.00000347  \n","Epoch: [3][1100/2481] Elapsed 3m 8s (remain 3m 55s) Loss: 0.0267(0.0155) Grad: 75478.3359  LR: 0.00000332  \n","Epoch: [3][1200/2481] Elapsed 3m 24s (remain 3m 38s) Loss: 0.0090(0.0155) Grad: 6726.5161  LR: 0.00000318  \n","Epoch: [3][1300/2481] Elapsed 3m 41s (remain 3m 21s) Loss: 0.0161(0.0153) Grad: 23757.5488  LR: 0.00000303  \n","Epoch: [3][1400/2481] Elapsed 3m 58s (remain 3m 4s) Loss: 0.0276(0.0152) Grad: 53749.1602  LR: 0.00000288  \n","Epoch: [3][1500/2481] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0272(0.0152) Grad: 7573.1777  LR: 0.00000274  \n","Epoch: [3][1600/2481] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0129(0.0152) Grad: 28443.2207  LR: 0.00000260  \n","Epoch: [3][1700/2481] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0097(0.0152) Grad: 33836.8477  LR: 0.00000246  \n","Epoch: [3][1800/2481] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0132(0.0151) Grad: 6077.0132  LR: 0.00000233  \n","Epoch: [3][1900/2481] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0110(0.0151) Grad: 8523.9717  LR: 0.00000219  \n","Epoch: [3][2000/2481] Elapsed 5m 39s (remain 1m 21s) Loss: 0.0080(0.0151) Grad: 19479.5703  LR: 0.00000206  \n","Epoch: [3][2100/2481] Elapsed 5m 56s (remain 1m 4s) Loss: 0.0083(0.0150) Grad: 30688.2832  LR: 0.00000194  \n","Epoch: [3][2200/2481] Elapsed 6m 13s (remain 0m 47s) Loss: 0.0082(0.0150) Grad: 35993.8945  LR: 0.00000181  \n","Epoch: [3][2300/2481] Elapsed 6m 30s (remain 0m 30s) Loss: 0.0109(0.0150) Grad: 30137.1953  LR: 0.00000169  \n","Epoch: [3][2400/2481] Elapsed 6m 47s (remain 0m 13s) Loss: 0.0088(0.0149) Grad: 29353.5391  LR: 0.00000157  \n","Epoch: [3][2480/2481] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0104(0.0149) Grad: 8019.9707  LR: 0.00000148  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 47s) Loss: 0.1340(0.1340) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0696(0.0950) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0149  avg_val_loss: 0.0955  time: 432s\n","Epoch 3 - Score: 0.8468\n","Epoch 3 - Save Best Score: 0.8468 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1075(0.0955) \n","Epoch: [4][0/2481] Elapsed 0m 0s (remain 20m 4s) Loss: 0.0115(0.0115) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2481] Elapsed 0m 17s (remain 6m 55s) Loss: 0.0188(0.0103) Grad: 26212.4004  LR: 0.00000137  \n","Epoch: [4][200/2481] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0076(0.0105) Grad: 23464.7383  LR: 0.00000126  \n","Epoch: [4][300/2481] Elapsed 0m 52s (remain 6m 16s) Loss: 0.0116(0.0112) Grad: 23101.4121  LR: 0.00000116  \n","Epoch: [4][400/2481] Elapsed 1m 8s (remain 5m 57s) Loss: 0.0133(0.0114) Grad: 68314.1875  LR: 0.00000106  \n","Epoch: [4][500/2481] Elapsed 1m 25s (remain 5m 39s) Loss: 0.0149(0.0116) Grad: 54242.2852  LR: 0.00000096  \n","Epoch: [4][600/2481] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0197(0.0115) Grad: 56097.7305  LR: 0.00000087  \n","Epoch: [4][700/2481] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0140(0.0115) Grad: 81373.7188  LR: 0.00000078  \n","Epoch: [4][800/2481] Elapsed 2m 16s (remain 4m 46s) Loss: 0.0096(0.0113) Grad: 22074.0332  LR: 0.00000070  \n","Epoch: [4][900/2481] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0127(0.0114) Grad: 8785.2852  LR: 0.00000062  \n","Epoch: [4][1000/2481] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0086(0.0113) Grad: 22929.4922  LR: 0.00000055  \n","Epoch: [4][1100/2481] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0057(0.0113) Grad: 29818.7168  LR: 0.00000048  \n","Epoch: [4][1200/2481] Elapsed 3m 23s (remain 3m 37s) Loss: 0.0112(0.0113) Grad: 37394.9883  LR: 0.00000041  \n","Epoch: [4][1300/2481] Elapsed 3m 40s (remain 3m 20s) Loss: 0.0085(0.0113) Grad: 37874.8359  LR: 0.00000035  \n","Epoch: [4][1400/2481] Elapsed 3m 57s (remain 3m 3s) Loss: 0.0139(0.0113) Grad: 36394.1289  LR: 0.00000029  \n","Epoch: [4][1500/2481] Elapsed 4m 14s (remain 2m 46s) Loss: 0.0137(0.0113) Grad: 23389.2520  LR: 0.00000024  \n","Epoch: [4][1600/2481] Elapsed 4m 31s (remain 2m 29s) Loss: 0.0188(0.0114) Grad: 33241.9492  LR: 0.00000020  \n","Epoch: [4][1700/2481] Elapsed 4m 48s (remain 2m 12s) Loss: 0.0080(0.0114) Grad: 33718.7617  LR: 0.00000015  \n","Epoch: [4][1800/2481] Elapsed 5m 5s (remain 1m 55s) Loss: 0.0046(0.0114) Grad: 24514.8750  LR: 0.00000012  \n","Epoch: [4][1900/2481] Elapsed 5m 21s (remain 1m 38s) Loss: 0.0153(0.0114) Grad: 10278.2285  LR: 0.00000009  \n","Epoch: [4][2000/2481] Elapsed 5m 38s (remain 1m 21s) Loss: 0.0102(0.0114) Grad: 67522.4766  LR: 0.00000006  \n","Epoch: [4][2100/2481] Elapsed 5m 55s (remain 1m 4s) Loss: 0.0070(0.0113) Grad: 5714.3481  LR: 0.00000004  \n","Epoch: [4][2200/2481] Elapsed 6m 12s (remain 0m 47s) Loss: 0.0075(0.0113) Grad: 34217.9180  LR: 0.00000002  \n","Epoch: [4][2300/2481] Elapsed 6m 29s (remain 0m 30s) Loss: 0.0094(0.0113) Grad: 47947.9336  LR: 0.00000001  \n","Epoch: [4][2400/2481] Elapsed 6m 45s (remain 0m 13s) Loss: 0.0175(0.0113) Grad: 18179.4883  LR: 0.00000000  \n","Epoch: [4][2480/2481] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0066(0.0113) Grad: 44289.0781  LR: 0.00000000  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 44s) Loss: 0.1348(0.1348) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0700(0.0940) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0113  avg_val_loss: 0.0946  time: 431s\n","Epoch 4 - Score: 0.8488\n","Epoch 4 - Save Best Score: 0.8488 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1070(0.0946) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 11 result ==========\n","Score: 0.8488\n","========== fold: 12 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2481] Elapsed 0m 0s (remain 18m 38s) Loss: 0.6167(0.6167) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2481] Elapsed 0m 18s (remain 7m 6s) Loss: 0.0615(0.1703) Grad: 21034.5234  LR: 0.00001000  \n","Epoch: [1][200/2481] Elapsed 0m 35s (remain 6m 37s) Loss: 0.1927(0.1289) Grad: 36847.3125  LR: 0.00000999  \n","Epoch: [1][300/2481] Elapsed 0m 51s (remain 6m 15s) Loss: 0.2952(0.1211) Grad: 43051.5352  LR: 0.00000998  \n","Epoch: [1][400/2481] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0643(0.1121) Grad: 15388.9551  LR: 0.00000997  \n","Epoch: [1][500/2481] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0429(0.1014) Grad: 11243.7363  LR: 0.00000995  \n","Epoch: [1][600/2481] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0435(0.0945) Grad: 11302.8799  LR: 0.00000992  \n","Epoch: [1][700/2481] Elapsed 1m 59s (remain 5m 2s) Loss: 0.0331(0.0891) Grad: 6605.2300  LR: 0.00000989  \n","Epoch: [1][800/2481] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0308(0.0827) Grad: 3211.0337  LR: 0.00000986  \n","Epoch: [1][900/2481] Elapsed 2m 32s (remain 4m 28s) Loss: 0.0497(0.0772) Grad: 9211.1875  LR: 0.00000982  \n","Epoch: [1][1000/2481] Elapsed 2m 49s (remain 4m 10s) Loss: 0.0572(0.0732) Grad: 2375.9319  LR: 0.00000977  \n","Epoch: [1][1100/2481] Elapsed 3m 6s (remain 3m 53s) Loss: 0.0345(0.0699) Grad: 1761.4647  LR: 0.00000972  \n","Epoch: [1][1200/2481] Elapsed 3m 23s (remain 3m 36s) Loss: 0.0196(0.0671) Grad: 3892.8074  LR: 0.00000967  \n","Epoch: [1][1300/2481] Elapsed 3m 40s (remain 3m 19s) Loss: 0.0254(0.0645) Grad: 8010.5181  LR: 0.00000961  \n","Epoch: [1][1400/2481] Elapsed 3m 56s (remain 3m 2s) Loss: 0.0488(0.0620) Grad: 11001.8066  LR: 0.00000955  \n","Epoch: [1][1500/2481] Elapsed 4m 13s (remain 2m 45s) Loss: 0.0210(0.0599) Grad: 631.4058  LR: 0.00000948  \n","Epoch: [1][1600/2481] Elapsed 4m 30s (remain 2m 28s) Loss: 0.0269(0.0579) Grad: 7363.5742  LR: 0.00000940  \n","Epoch: [1][1700/2481] Elapsed 4m 47s (remain 2m 11s) Loss: 0.0635(0.0566) Grad: 10149.0273  LR: 0.00000933  \n","Epoch: [1][1800/2481] Elapsed 5m 4s (remain 1m 54s) Loss: 0.0325(0.0552) Grad: 6513.4668  LR: 0.00000924  \n","Epoch: [1][1900/2481] Elapsed 5m 21s (remain 1m 37s) Loss: 0.0263(0.0539) Grad: 7290.9448  LR: 0.00000916  \n","Epoch: [1][2000/2481] Elapsed 5m 37s (remain 1m 21s) Loss: 0.0108(0.0528) Grad: 254.0666  LR: 0.00000907  \n","Epoch: [1][2100/2481] Elapsed 5m 54s (remain 1m 4s) Loss: 0.0132(0.0517) Grad: 1874.2371  LR: 0.00000897  \n","Epoch: [1][2200/2481] Elapsed 6m 11s (remain 0m 47s) Loss: 0.0614(0.0507) Grad: 24668.6816  LR: 0.00000887  \n","Epoch: [1][2300/2481] Elapsed 6m 28s (remain 0m 30s) Loss: 0.0303(0.0496) Grad: 5458.1196  LR: 0.00000877  \n","Epoch: [1][2400/2481] Elapsed 6m 45s (remain 0m 13s) Loss: 0.0073(0.0486) Grad: 4799.0918  LR: 0.00000867  \n","Epoch: [1][2480/2481] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0199(0.0478) Grad: 2752.4697  LR: 0.00000858  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 43s) Loss: 0.0958(0.0958) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0365(0.1006) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0478  avg_val_loss: 0.1015  time: 430s\n","Epoch 1 - Score: 0.8158\n","Epoch 1 - Save Best Score: 0.8158 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1236(0.1015) \n","Epoch: [2][0/2481] Elapsed 0m 0s (remain 20m 17s) Loss: 0.0092(0.0092) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2481] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0159(0.0186) Grad: 24537.1836  LR: 0.00000846  \n","Epoch: [2][200/2481] Elapsed 0m 35s (remain 6m 37s) Loss: 0.0149(0.0172) Grad: 7719.6680  LR: 0.00000835  \n","Epoch: [2][300/2481] Elapsed 0m 51s (remain 6m 15s) Loss: 0.0145(0.0178) Grad: 20176.2246  LR: 0.00000823  \n","Epoch: [2][400/2481] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0126(0.0179) Grad: 6716.4609  LR: 0.00000810  \n","Epoch: [2][500/2481] Elapsed 1m 25s (remain 5m 38s) Loss: 0.0169(0.0179) Grad: 22744.1680  LR: 0.00000798  \n","Epoch: [2][600/2481] Elapsed 1m 42s (remain 5m 20s) Loss: 0.0123(0.0177) Grad: 4289.2749  LR: 0.00000785  \n","Epoch: [2][700/2481] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0387(0.0176) Grad: 66890.5859  LR: 0.00000772  \n","Epoch: [2][800/2481] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0148(0.0177) Grad: 6245.2329  LR: 0.00000758  \n","Epoch: [2][900/2481] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0127(0.0177) Grad: 10218.3174  LR: 0.00000744  \n","Epoch: [2][1000/2481] Elapsed 2m 49s (remain 4m 11s) Loss: 0.0041(0.0177) Grad: 18504.9648  LR: 0.00000730  \n","Epoch: [2][1100/2481] Elapsed 3m 6s (remain 3m 54s) Loss: 0.0134(0.0178) Grad: 33893.0000  LR: 0.00000716  \n","Epoch: [2][1200/2481] Elapsed 3m 23s (remain 3m 37s) Loss: 0.0064(0.0178) Grad: 14563.5283  LR: 0.00000702  \n","Epoch: [2][1300/2481] Elapsed 3m 40s (remain 3m 20s) Loss: 0.0248(0.0178) Grad: 50554.6836  LR: 0.00000687  \n","Epoch: [2][1400/2481] Elapsed 3m 57s (remain 3m 3s) Loss: 0.0173(0.0176) Grad: 14390.6924  LR: 0.00000672  \n","Epoch: [2][1500/2481] Elapsed 4m 14s (remain 2m 46s) Loss: 0.0132(0.0177) Grad: 15834.4795  LR: 0.00000657  \n","Epoch: [2][1600/2481] Elapsed 4m 31s (remain 2m 29s) Loss: 0.0169(0.0176) Grad: 42165.4688  LR: 0.00000642  \n","Epoch: [2][1700/2481] Elapsed 4m 48s (remain 2m 12s) Loss: 0.0136(0.0176) Grad: 41346.6523  LR: 0.00000627  \n","Epoch: [2][1800/2481] Elapsed 5m 5s (remain 1m 55s) Loss: 0.0079(0.0176) Grad: 12694.8662  LR: 0.00000611  \n","Epoch: [2][1900/2481] Elapsed 5m 22s (remain 1m 38s) Loss: 0.0074(0.0176) Grad: 9716.5303  LR: 0.00000596  \n","Epoch: [2][2000/2481] Elapsed 5m 38s (remain 1m 21s) Loss: 0.0077(0.0175) Grad: 15422.4531  LR: 0.00000580  \n","Epoch: [2][2100/2481] Elapsed 5m 55s (remain 1m 4s) Loss: 0.0148(0.0175) Grad: 31095.9688  LR: 0.00000564  \n","Epoch: [2][2200/2481] Elapsed 6m 12s (remain 0m 47s) Loss: 0.0182(0.0174) Grad: 39370.8594  LR: 0.00000549  \n","Epoch: [2][2300/2481] Elapsed 6m 29s (remain 0m 30s) Loss: 0.0068(0.0174) Grad: 29465.9883  LR: 0.00000533  \n","Epoch: [2][2400/2481] Elapsed 6m 46s (remain 0m 13s) Loss: 0.0267(0.0173) Grad: 50008.0156  LR: 0.00000517  \n","Epoch: [2][2480/2481] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0229(0.0173) Grad: 22160.2930  LR: 0.00000504  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 44s) Loss: 0.0946(0.0946) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0347(0.0960) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0173  avg_val_loss: 0.0967  time: 431s\n","Epoch 2 - Score: 0.8321\n","Epoch 2 - Save Best Score: 0.8321 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1218(0.0967) \n","Epoch: [3][0/2481] Elapsed 0m 0s (remain 20m 19s) Loss: 0.0393(0.0393) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2481] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0078(0.0145) Grad: 9657.7959  LR: 0.00000488  \n","Epoch: [3][200/2481] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0188(0.0143) Grad: 62534.3672  LR: 0.00000472  \n","Epoch: [3][300/2481] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0132(0.0146) Grad: 17044.8496  LR: 0.00000456  \n","Epoch: [3][400/2481] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0256(0.0142) Grad: 72950.7812  LR: 0.00000440  \n","Epoch: [3][500/2481] Elapsed 1m 25s (remain 5m 39s) Loss: 0.0041(0.0145) Grad: 26103.9902  LR: 0.00000425  \n","Epoch: [3][600/2481] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0057(0.0145) Grad: 27327.4375  LR: 0.00000409  \n","Epoch: [3][700/2481] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0187(0.0143) Grad: 41654.6797  LR: 0.00000393  \n","Epoch: [3][800/2481] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0090(0.0141) Grad: 11601.4912  LR: 0.00000378  \n","Epoch: [3][900/2481] Elapsed 2m 33s (remain 4m 28s) Loss: 0.0216(0.0141) Grad: 33201.0234  LR: 0.00000363  \n","Epoch: [3][1000/2481] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0126(0.0141) Grad: 11802.4971  LR: 0.00000347  \n","Epoch: [3][1100/2481] Elapsed 3m 6s (remain 3m 54s) Loss: 0.0080(0.0142) Grad: 29858.0820  LR: 0.00000332  \n","Epoch: [3][1200/2481] Elapsed 3m 23s (remain 3m 37s) Loss: 0.0086(0.0142) Grad: 18015.0977  LR: 0.00000317  \n","Epoch: [3][1300/2481] Elapsed 3m 40s (remain 3m 20s) Loss: 0.0130(0.0142) Grad: 19582.1934  LR: 0.00000303  \n","Epoch: [3][1400/2481] Elapsed 3m 57s (remain 3m 3s) Loss: 0.0108(0.0140) Grad: 29638.6914  LR: 0.00000288  \n","Epoch: [3][1500/2481] Elapsed 4m 14s (remain 2m 46s) Loss: 0.0121(0.0140) Grad: 41245.9844  LR: 0.00000274  \n","Epoch: [3][1600/2481] Elapsed 4m 31s (remain 2m 29s) Loss: 0.0044(0.0140) Grad: 16768.3652  LR: 0.00000260  \n","Epoch: [3][1700/2481] Elapsed 4m 48s (remain 2m 12s) Loss: 0.0107(0.0140) Grad: 62898.9766  LR: 0.00000246  \n","Epoch: [3][1800/2481] Elapsed 5m 5s (remain 1m 55s) Loss: 0.0106(0.0139) Grad: 55410.4414  LR: 0.00000232  \n","Epoch: [3][1900/2481] Elapsed 5m 21s (remain 1m 38s) Loss: 0.0317(0.0139) Grad: 60731.4180  LR: 0.00000219  \n","Epoch: [3][2000/2481] Elapsed 5m 38s (remain 1m 21s) Loss: 0.0179(0.0139) Grad: 53766.3477  LR: 0.00000206  \n","Epoch: [3][2100/2481] Elapsed 5m 55s (remain 1m 4s) Loss: 0.0073(0.0138) Grad: 24350.0469  LR: 0.00000193  \n","Epoch: [3][2200/2481] Elapsed 6m 12s (remain 0m 47s) Loss: 0.0294(0.0138) Grad: 60230.5977  LR: 0.00000181  \n","Epoch: [3][2300/2481] Elapsed 6m 29s (remain 0m 30s) Loss: 0.0156(0.0139) Grad: 80663.8281  LR: 0.00000169  \n","Epoch: [3][2400/2481] Elapsed 6m 46s (remain 0m 13s) Loss: 0.0062(0.0140) Grad: 2728.2800  LR: 0.00000157  \n","Epoch: [3][2480/2481] Elapsed 6m 59s (remain 0m 0s) Loss: 0.0188(0.0140) Grad: 11574.1953  LR: 0.00000148  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 46s) Loss: 0.0975(0.0975) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0355(0.0955) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0140  avg_val_loss: 0.0963  time: 431s\n","Epoch 3 - Score: 0.8326\n","Epoch 3 - Save Best Score: 0.8326 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1213(0.0963) \n","Epoch: [4][0/2481] Elapsed 0m 0s (remain 20m 3s) Loss: 0.0101(0.0101) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2481] Elapsed 0m 17s (remain 6m 59s) Loss: 0.0126(0.0111) Grad: 23270.1855  LR: 0.00000137  \n","Epoch: [4][200/2481] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0060(0.0111) Grad: 15500.8418  LR: 0.00000126  \n","Epoch: [4][300/2481] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0096(0.0115) Grad: 20364.2559  LR: 0.00000116  \n","Epoch: [4][400/2481] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0120(0.0116) Grad: 37550.8047  LR: 0.00000106  \n","Epoch: [4][500/2481] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0063(0.0117) Grad: 18342.5000  LR: 0.00000096  \n","Epoch: [4][600/2481] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0089(0.0117) Grad: 44387.3633  LR: 0.00000087  \n","Epoch: [4][700/2481] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0051(0.0118) Grad: 3807.4543  LR: 0.00000078  \n","Epoch: [4][800/2481] Elapsed 2m 16s (remain 4m 46s) Loss: 0.0116(0.0119) Grad: 10927.6973  LR: 0.00000070  \n","Epoch: [4][900/2481] Elapsed 2m 33s (remain 4m 29s) Loss: 0.0134(0.0119) Grad: 40233.7539  LR: 0.00000062  \n","Epoch: [4][1000/2481] Elapsed 2m 50s (remain 4m 11s) Loss: 0.0037(0.0120) Grad: 3108.9917  LR: 0.00000054  \n","Epoch: [4][1100/2481] Elapsed 3m 7s (remain 3m 54s) Loss: 0.0091(0.0121) Grad: 10646.7900  LR: 0.00000047  \n","Epoch: [4][1200/2481] Elapsed 3m 24s (remain 3m 37s) Loss: 0.0080(0.0121) Grad: 8012.5859  LR: 0.00000041  \n","Epoch: [4][1300/2481] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0134(0.0122) Grad: 82921.1172  LR: 0.00000035  \n","Epoch: [4][1400/2481] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0091(0.0121) Grad: 9089.6943  LR: 0.00000029  \n","Epoch: [4][1500/2481] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0062(0.0122) Grad: 19091.7422  LR: 0.00000024  \n","Epoch: [4][1600/2481] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0165(0.0122) Grad: 110855.6250  LR: 0.00000020  \n","Epoch: [4][1700/2481] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0094(0.0122) Grad: 9984.6797  LR: 0.00000015  \n","Epoch: [4][1800/2481] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0176(0.0122) Grad: 60482.2773  LR: 0.00000012  \n","Epoch: [4][1900/2481] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0311(0.0122) Grad: 39576.9727  LR: 0.00000009  \n","Epoch: [4][2000/2481] Elapsed 5m 40s (remain 1m 21s) Loss: 0.0035(0.0122) Grad: 5842.7329  LR: 0.00000006  \n","Epoch: [4][2100/2481] Elapsed 5m 57s (remain 1m 4s) Loss: 0.0203(0.0122) Grad: 11426.0703  LR: 0.00000004  \n","Epoch: [4][2200/2481] Elapsed 6m 14s (remain 0m 47s) Loss: 0.0084(0.0122) Grad: 10023.0605  LR: 0.00000002  \n","Epoch: [4][2300/2481] Elapsed 6m 32s (remain 0m 30s) Loss: 0.0268(0.0122) Grad: 12876.0967  LR: 0.00000001  \n","Epoch: [4][2400/2481] Elapsed 6m 49s (remain 0m 13s) Loss: 0.0119(0.0121) Grad: 7610.3311  LR: 0.00000000  \n","Epoch: [4][2480/2481] Elapsed 7m 3s (remain 0m 0s) Loss: 0.0137(0.0121) Grad: 55977.8750  LR: 0.00000000  \n","EVAL: [0/124] Elapsed 0m 0s (remain 0m 46s) Loss: 0.0965(0.0965) \n","EVAL: [100/124] Elapsed 0m 9s (remain 0m 2s) Loss: 0.0346(0.0945) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0121  avg_val_loss: 0.0953  time: 435s\n","Epoch 4 - Score: 0.8319\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [123/124] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1225(0.0953) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 12 result ==========\n","Score: 0.8326\n","========== fold: 13 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2502] Elapsed 0m 0s (remain 18m 52s) Loss: 1.1240(1.1240) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2502] Elapsed 0m 17s (remain 6m 52s) Loss: 0.1130(0.2243) Grad: 17885.0938  LR: 0.00001000  \n","Epoch: [1][200/2502] Elapsed 0m 34s (remain 6m 33s) Loss: 0.0803(0.1624) Grad: 5063.0410  LR: 0.00000999  \n","Epoch: [1][300/2502] Elapsed 0m 51s (remain 6m 15s) Loss: 0.0455(0.1355) Grad: 5840.8994  LR: 0.00000998  \n","Epoch: [1][400/2502] Elapsed 1m 8s (remain 5m 58s) Loss: 0.0569(0.1173) Grad: 13361.5684  LR: 0.00000997  \n","Epoch: [1][500/2502] Elapsed 1m 25s (remain 5m 41s) Loss: 0.0481(0.1060) Grad: 9158.7412  LR: 0.00000995  \n","Epoch: [1][600/2502] Elapsed 1m 42s (remain 5m 24s) Loss: 0.0599(0.0962) Grad: 9123.0195  LR: 0.00000992  \n","Epoch: [1][700/2502] Elapsed 1m 59s (remain 5m 6s) Loss: 0.0490(0.0893) Grad: 3586.4358  LR: 0.00000989  \n","Epoch: [1][800/2502] Elapsed 2m 16s (remain 4m 49s) Loss: 0.0308(0.0842) Grad: 8797.8125  LR: 0.00000986  \n","Epoch: [1][900/2502] Elapsed 2m 33s (remain 4m 32s) Loss: 0.0742(0.0794) Grad: 16395.2266  LR: 0.00000982  \n","Epoch: [1][1000/2502] Elapsed 2m 50s (remain 4m 15s) Loss: 0.0142(0.0765) Grad: 4212.3447  LR: 0.00000978  \n","Epoch: [1][1100/2502] Elapsed 3m 7s (remain 3m 58s) Loss: 0.0161(0.0736) Grad: 5516.7676  LR: 0.00000973  \n","Epoch: [1][1200/2502] Elapsed 3m 24s (remain 3m 41s) Loss: 0.0654(0.0716) Grad: 13766.0303  LR: 0.00000967  \n","Epoch: [1][1300/2502] Elapsed 3m 41s (remain 3m 24s) Loss: 0.0419(0.0687) Grad: 5400.3765  LR: 0.00000962  \n","Epoch: [1][1400/2502] Elapsed 3m 58s (remain 3m 7s) Loss: 0.0348(0.0661) Grad: 3315.3794  LR: 0.00000955  \n","Epoch: [1][1500/2502] Elapsed 4m 15s (remain 2m 50s) Loss: 0.0224(0.0637) Grad: 862.2470  LR: 0.00000949  \n","Epoch: [1][1600/2502] Elapsed 4m 32s (remain 2m 33s) Loss: 0.0232(0.0618) Grad: 3100.4028  LR: 0.00000941  \n","Epoch: [1][1700/2502] Elapsed 4m 48s (remain 2m 16s) Loss: 0.0314(0.0600) Grad: 8024.9409  LR: 0.00000934  \n","Epoch: [1][1800/2502] Elapsed 5m 5s (remain 1m 59s) Loss: 0.0159(0.0584) Grad: 3641.4250  LR: 0.00000926  \n","Epoch: [1][1900/2502] Elapsed 5m 22s (remain 1m 42s) Loss: 0.0175(0.0569) Grad: 3521.1501  LR: 0.00000917  \n","Epoch: [1][2000/2502] Elapsed 5m 39s (remain 1m 25s) Loss: 0.0099(0.0554) Grad: 684.2062  LR: 0.00000908  \n","Epoch: [1][2100/2502] Elapsed 5m 56s (remain 1m 8s) Loss: 0.0232(0.0540) Grad: 2144.4841  LR: 0.00000899  \n","Epoch: [1][2200/2502] Elapsed 6m 13s (remain 0m 51s) Loss: 0.0280(0.0527) Grad: 2292.4963  LR: 0.00000889  \n","Epoch: [1][2300/2502] Elapsed 6m 30s (remain 0m 34s) Loss: 0.0139(0.0516) Grad: 11057.6738  LR: 0.00000879  \n","Epoch: [1][2400/2502] Elapsed 6m 47s (remain 0m 17s) Loss: 0.0389(0.0505) Grad: 10775.1387  LR: 0.00000869  \n","Epoch: [1][2500/2502] Elapsed 7m 4s (remain 0m 0s) Loss: 0.0120(0.0494) Grad: 4375.9429  LR: 0.00000858  \n","Epoch: [1][2501/2502] Elapsed 7m 4s (remain 0m 0s) Loss: 0.0145(0.0494) Grad: 4558.7441  LR: 0.00000858  \n","EVAL: [0/103] Elapsed 0m 0s (remain 0m 36s) Loss: 0.1000(0.1000) \n","EVAL: [100/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1428(0.1127) \n","EVAL: [102/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.0979(0.1131) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0494  avg_val_loss: 0.1131  time: 435s\n","Epoch 1 - Score: 0.8139\n","Epoch 1 - Save Best Score: 0.8139 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/2502] Elapsed 0m 0s (remain 20m 10s) Loss: 0.0146(0.0146) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2502] Elapsed 0m 17s (remain 7m 5s) Loss: 0.0107(0.0182) Grad: 3584.7017  LR: 0.00000846  \n","Epoch: [2][200/2502] Elapsed 0m 35s (remain 6m 47s) Loss: 0.0209(0.0181) Grad: 46034.8555  LR: 0.00000835  \n","Epoch: [2][300/2502] Elapsed 0m 52s (remain 6m 24s) Loss: 0.0109(0.0182) Grad: 3616.5884  LR: 0.00000823  \n","Epoch: [2][400/2502] Elapsed 1m 9s (remain 6m 3s) Loss: 0.0181(0.0185) Grad: 31875.4531  LR: 0.00000811  \n","Epoch: [2][500/2502] Elapsed 1m 26s (remain 5m 45s) Loss: 0.0143(0.0179) Grad: 10844.1504  LR: 0.00000798  \n","Epoch: [2][600/2502] Elapsed 1m 43s (remain 5m 27s) Loss: 0.0201(0.0179) Grad: 29096.4473  LR: 0.00000785  \n","Epoch: [2][700/2502] Elapsed 2m 0s (remain 5m 9s) Loss: 0.0182(0.0179) Grad: 35343.6875  LR: 0.00000772  \n","Epoch: [2][800/2502] Elapsed 2m 17s (remain 4m 51s) Loss: 0.0307(0.0180) Grad: 17476.8320  LR: 0.00000759  \n","Epoch: [2][900/2502] Elapsed 2m 34s (remain 4m 33s) Loss: 0.0092(0.0180) Grad: 4694.4854  LR: 0.00000745  \n","Epoch: [2][1000/2502] Elapsed 2m 51s (remain 4m 16s) Loss: 0.0399(0.0180) Grad: 86213.0859  LR: 0.00000732  \n","Epoch: [2][1100/2502] Elapsed 3m 7s (remain 3m 59s) Loss: 0.0088(0.0180) Grad: 33520.8555  LR: 0.00000717  \n","Epoch: [2][1200/2502] Elapsed 3m 24s (remain 3m 41s) Loss: 0.0160(0.0180) Grad: 16354.7285  LR: 0.00000703  \n","Epoch: [2][1300/2502] Elapsed 3m 41s (remain 3m 24s) Loss: 0.0201(0.0180) Grad: 39668.2617  LR: 0.00000689  \n","Epoch: [2][1400/2502] Elapsed 3m 58s (remain 3m 7s) Loss: 0.0279(0.0180) Grad: 5411.7095  LR: 0.00000674  \n","Epoch: [2][1500/2502] Elapsed 4m 15s (remain 2m 50s) Loss: 0.0153(0.0178) Grad: 19279.6348  LR: 0.00000659  \n","Epoch: [2][1600/2502] Elapsed 4m 32s (remain 2m 33s) Loss: 0.0311(0.0178) Grad: 27273.2500  LR: 0.00000644  \n","Epoch: [2][1700/2502] Elapsed 4m 49s (remain 2m 16s) Loss: 0.0140(0.0178) Grad: 12682.0654  LR: 0.00000629  \n","Epoch: [2][1800/2502] Elapsed 5m 6s (remain 1m 59s) Loss: 0.0072(0.0178) Grad: 25308.7031  LR: 0.00000614  \n","Epoch: [2][1900/2502] Elapsed 5m 23s (remain 1m 42s) Loss: 0.0083(0.0178) Grad: 19622.0742  LR: 0.00000598  \n","Epoch: [2][2000/2502] Elapsed 5m 40s (remain 1m 25s) Loss: 0.0290(0.0178) Grad: 9435.3633  LR: 0.00000583  \n","Epoch: [2][2100/2502] Elapsed 5m 57s (remain 1m 8s) Loss: 0.0311(0.0178) Grad: 100248.9922  LR: 0.00000567  \n","Epoch: [2][2200/2502] Elapsed 6m 14s (remain 0m 51s) Loss: 0.0180(0.0177) Grad: 37719.1875  LR: 0.00000551  \n","Epoch: [2][2300/2502] Elapsed 6m 31s (remain 0m 34s) Loss: 0.0651(0.0177) Grad: 39514.4258  LR: 0.00000536  \n","Epoch: [2][2400/2502] Elapsed 6m 48s (remain 0m 17s) Loss: 0.0049(0.0175) Grad: 33769.1836  LR: 0.00000520  \n","Epoch: [2][2500/2502] Elapsed 7m 5s (remain 0m 0s) Loss: 0.0245(0.0175) Grad: 30577.0625  LR: 0.00000504  \n","Epoch: [2][2501/2502] Elapsed 7m 5s (remain 0m 0s) Loss: 0.0107(0.0175) Grad: 10704.6367  LR: 0.00000504  \n","EVAL: [0/103] Elapsed 0m 0s (remain 0m 37s) Loss: 0.0930(0.0930) \n","EVAL: [100/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1377(0.1073) \n","EVAL: [102/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1002(0.1077) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0175  avg_val_loss: 0.1077  time: 435s\n","Epoch 2 - Score: 0.8259\n","Epoch 2 - Save Best Score: 0.8259 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/2502] Elapsed 0m 0s (remain 20m 31s) Loss: 0.0172(0.0172) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2502] Elapsed 0m 17s (remain 7m 0s) Loss: 0.0261(0.0142) Grad: 26804.6543  LR: 0.00000488  \n","Epoch: [3][200/2502] Elapsed 0m 35s (remain 6m 44s) Loss: 0.0115(0.0145) Grad: 50575.2695  LR: 0.00000472  \n","Epoch: [3][300/2502] Elapsed 0m 52s (remain 6m 21s) Loss: 0.0135(0.0146) Grad: 17815.9023  LR: 0.00000457  \n","Epoch: [3][400/2502] Elapsed 1m 9s (remain 6m 1s) Loss: 0.0256(0.0147) Grad: 16700.8926  LR: 0.00000441  \n","Epoch: [3][500/2502] Elapsed 1m 26s (remain 5m 43s) Loss: 0.0225(0.0144) Grad: 46578.5430  LR: 0.00000425  \n","Epoch: [3][600/2502] Elapsed 1m 43s (remain 5m 25s) Loss: 0.0094(0.0146) Grad: 13862.2080  LR: 0.00000410  \n","Epoch: [3][700/2502] Elapsed 2m 0s (remain 5m 8s) Loss: 0.0131(0.0146) Grad: 7628.8599  LR: 0.00000394  \n","Epoch: [3][800/2502] Elapsed 2m 16s (remain 4m 50s) Loss: 0.0251(0.0147) Grad: 10551.4697  LR: 0.00000379  \n","Epoch: [3][900/2502] Elapsed 2m 33s (remain 4m 33s) Loss: 0.0131(0.0147) Grad: 25465.1055  LR: 0.00000364  \n","Epoch: [3][1000/2502] Elapsed 2m 50s (remain 4m 16s) Loss: 0.0168(0.0148) Grad: 22787.9316  LR: 0.00000348  \n","Epoch: [3][1100/2502] Elapsed 3m 7s (remain 3m 58s) Loss: 0.0138(0.0149) Grad: 31197.7754  LR: 0.00000334  \n","Epoch: [3][1200/2502] Elapsed 3m 24s (remain 3m 41s) Loss: 0.0072(0.0149) Grad: 34628.1992  LR: 0.00000319  \n","Epoch: [3][1300/2502] Elapsed 3m 41s (remain 3m 24s) Loss: 0.0168(0.0149) Grad: 4116.6440  LR: 0.00000304  \n","Epoch: [3][1400/2502] Elapsed 3m 58s (remain 3m 7s) Loss: 0.0159(0.0149) Grad: 45124.1914  LR: 0.00000290  \n","Epoch: [3][1500/2502] Elapsed 4m 15s (remain 2m 50s) Loss: 0.0111(0.0149) Grad: 16219.6318  LR: 0.00000275  \n","Epoch: [3][1600/2502] Elapsed 4m 32s (remain 2m 33s) Loss: 0.0302(0.0149) Grad: 23794.9082  LR: 0.00000262  \n","Epoch: [3][1700/2502] Elapsed 4m 49s (remain 2m 16s) Loss: 0.0228(0.0149) Grad: 6523.4312  LR: 0.00000248  \n","Epoch: [3][1800/2502] Elapsed 5m 6s (remain 1m 59s) Loss: 0.0132(0.0148) Grad: 25242.5137  LR: 0.00000234  \n","Epoch: [3][1900/2502] Elapsed 5m 23s (remain 1m 42s) Loss: 0.0042(0.0148) Grad: 3121.4517  LR: 0.00000221  \n","Epoch: [3][2000/2502] Elapsed 5m 40s (remain 1m 25s) Loss: 0.0071(0.0148) Grad: 12719.8672  LR: 0.00000208  \n","Epoch: [3][2100/2502] Elapsed 5m 57s (remain 1m 8s) Loss: 0.0139(0.0148) Grad: 7240.5503  LR: 0.00000195  \n","Epoch: [3][2200/2502] Elapsed 6m 14s (remain 0m 51s) Loss: 0.0115(0.0148) Grad: 6336.6484  LR: 0.00000183  \n","Epoch: [3][2300/2502] Elapsed 6m 31s (remain 0m 34s) Loss: 0.0052(0.0148) Grad: 24890.9629  LR: 0.00000171  \n","Epoch: [3][2400/2502] Elapsed 6m 48s (remain 0m 17s) Loss: 0.0166(0.0148) Grad: 27410.1582  LR: 0.00000159  \n","Epoch: [3][2500/2502] Elapsed 7m 5s (remain 0m 0s) Loss: 0.0157(0.0148) Grad: 57900.3242  LR: 0.00000148  \n","Epoch: [3][2501/2502] Elapsed 7m 5s (remain 0m 0s) Loss: 0.0098(0.0148) Grad: 14217.4688  LR: 0.00000148  \n","EVAL: [0/103] Elapsed 0m 0s (remain 0m 36s) Loss: 0.0907(0.0907) \n","EVAL: [100/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1377(0.1057) \n","EVAL: [102/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.0999(0.1061) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0148  avg_val_loss: 0.1061  time: 435s\n","Epoch 3 - Score: 0.8234\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/2502] Elapsed 0m 0s (remain 20m 1s) Loss: 0.0079(0.0079) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2502] Elapsed 0m 17s (remain 6m 51s) Loss: 0.0120(0.0113) Grad: 25106.9883  LR: 0.00000137  \n","Epoch: [4][200/2502] Elapsed 0m 34s (remain 6m 32s) Loss: 0.0067(0.0116) Grad: 54449.8320  LR: 0.00000126  \n","Epoch: [4][300/2502] Elapsed 0m 51s (remain 6m 13s) Loss: 0.0054(0.0118) Grad: 18216.3203  LR: 0.00000116  \n","Epoch: [4][400/2502] Elapsed 1m 8s (remain 5m 56s) Loss: 0.0076(0.0117) Grad: 23049.2969  LR: 0.00000106  \n","Epoch: [4][500/2502] Elapsed 1m 24s (remain 5m 39s) Loss: 0.0119(0.0118) Grad: 22532.4199  LR: 0.00000096  \n","Epoch: [4][600/2502] Elapsed 1m 41s (remain 5m 22s) Loss: 0.0105(0.0120) Grad: 28019.4160  LR: 0.00000087  \n","Epoch: [4][700/2502] Elapsed 1m 58s (remain 5m 5s) Loss: 0.0114(0.0118) Grad: 23445.7188  LR: 0.00000079  \n","Epoch: [4][800/2502] Elapsed 2m 15s (remain 4m 48s) Loss: 0.0086(0.0119) Grad: 10147.7070  LR: 0.00000070  \n","Epoch: [4][900/2502] Elapsed 2m 32s (remain 4m 31s) Loss: 0.0071(0.0119) Grad: 22868.0977  LR: 0.00000062  \n","Epoch: [4][1000/2502] Elapsed 2m 49s (remain 4m 14s) Loss: 0.0084(0.0120) Grad: 7838.7231  LR: 0.00000055  \n","Epoch: [4][1100/2502] Elapsed 3m 6s (remain 3m 57s) Loss: 0.0019(0.0120) Grad: 8294.8682  LR: 0.00000048  \n","Epoch: [4][1200/2502] Elapsed 3m 23s (remain 3m 40s) Loss: 0.0085(0.0120) Grad: 20592.2285  LR: 0.00000042  \n","Epoch: [4][1300/2502] Elapsed 3m 40s (remain 3m 23s) Loss: 0.0185(0.0120) Grad: 55051.7695  LR: 0.00000035  \n","Epoch: [4][1400/2502] Elapsed 3m 57s (remain 3m 6s) Loss: 0.0117(0.0120) Grad: 7556.8027  LR: 0.00000030  \n","Epoch: [4][1500/2502] Elapsed 4m 14s (remain 2m 49s) Loss: 0.0125(0.0119) Grad: 51405.6211  LR: 0.00000025  \n","Epoch: [4][1600/2502] Elapsed 4m 30s (remain 2m 32s) Loss: 0.0072(0.0118) Grad: 7093.1162  LR: 0.00000020  \n","Epoch: [4][1700/2502] Elapsed 4m 47s (remain 2m 15s) Loss: 0.0104(0.0118) Grad: 13193.6943  LR: 0.00000016  \n","Epoch: [4][1800/2502] Elapsed 5m 4s (remain 1m 58s) Loss: 0.0101(0.0118) Grad: 32556.4941  LR: 0.00000012  \n","Epoch: [4][1900/2502] Elapsed 5m 21s (remain 1m 41s) Loss: 0.0065(0.0118) Grad: 21459.5176  LR: 0.00000009  \n","Epoch: [4][2000/2502] Elapsed 5m 38s (remain 1m 24s) Loss: 0.0115(0.0118) Grad: 31596.4922  LR: 0.00000006  \n","Epoch: [4][2100/2502] Elapsed 5m 55s (remain 1m 7s) Loss: 0.0097(0.0118) Grad: 11547.3525  LR: 0.00000004  \n","Epoch: [4][2200/2502] Elapsed 6m 12s (remain 0m 50s) Loss: 0.0095(0.0118) Grad: 15970.2930  LR: 0.00000002  \n","Epoch: [4][2300/2502] Elapsed 6m 28s (remain 0m 33s) Loss: 0.0073(0.0117) Grad: 36905.8867  LR: 0.00000001  \n","Epoch: [4][2400/2502] Elapsed 6m 45s (remain 0m 17s) Loss: 0.0181(0.0117) Grad: 21689.9688  LR: 0.00000000  \n","Epoch: [4][2500/2502] Elapsed 7m 2s (remain 0m 0s) Loss: 0.0044(0.0118) Grad: 4549.9468  LR: 0.00000000  \n","Epoch: [4][2501/2502] Elapsed 7m 2s (remain 0m 0s) Loss: 0.0280(0.0118) Grad: 39725.6211  LR: 0.00000000  \n","EVAL: [0/103] Elapsed 0m 0s (remain 0m 36s) Loss: 0.0908(0.0908) \n","EVAL: [100/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1371(0.1062) \n","EVAL: [102/103] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1000(0.1066) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0118  avg_val_loss: 0.1066  time: 432s\n","Epoch 4 - Score: 0.8249\n","========== fold: 13 result ==========\n","Score: 0.8259\n","========== fold: 14 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2463] Elapsed 0m 0s (remain 18m 23s) Loss: 1.0898(1.0898) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2463] Elapsed 0m 17s (remain 6m 39s) Loss: 0.1320(0.2852) Grad: 4036.6819  LR: 0.00001000  \n","Epoch: [1][200/2463] Elapsed 0m 33s (remain 6m 20s) Loss: 0.0478(0.1895) Grad: 2829.1399  LR: 0.00000999  \n","Epoch: [1][300/2463] Elapsed 0m 50s (remain 6m 3s) Loss: 0.0548(0.1490) Grad: 10550.2998  LR: 0.00000998  \n","Epoch: [1][400/2463] Elapsed 1m 7s (remain 5m 46s) Loss: 0.0373(0.1277) Grad: 7182.1172  LR: 0.00000997  \n","Epoch: [1][500/2463] Elapsed 1m 24s (remain 5m 30s) Loss: 0.0503(0.1131) Grad: 5722.8594  LR: 0.00000995  \n","Epoch: [1][600/2463] Elapsed 1m 41s (remain 5m 13s) Loss: 0.0660(0.1119) Grad: 2025.6595  LR: 0.00000992  \n","Epoch: [1][700/2463] Elapsed 1m 57s (remain 4m 56s) Loss: 0.0938(0.1073) Grad: 13086.4561  LR: 0.00000989  \n","Epoch: [1][800/2463] Elapsed 2m 14s (remain 4m 39s) Loss: 0.0634(0.1053) Grad: 9123.5518  LR: 0.00000986  \n","Epoch: [1][900/2463] Elapsed 2m 31s (remain 4m 22s) Loss: 0.0483(0.1045) Grad: 2165.1453  LR: 0.00000982  \n","Epoch: [1][1000/2463] Elapsed 2m 48s (remain 4m 6s) Loss: 0.0526(0.1029) Grad: 6072.7949  LR: 0.00000977  \n","Epoch: [1][1100/2463] Elapsed 3m 5s (remain 3m 49s) Loss: 0.0568(0.1002) Grad: 7808.7905  LR: 0.00000972  \n","Epoch: [1][1200/2463] Elapsed 3m 22s (remain 3m 32s) Loss: 0.1746(0.0992) Grad: 24963.7988  LR: 0.00000966  \n","Epoch: [1][1300/2463] Elapsed 3m 39s (remain 3m 15s) Loss: 0.0562(0.0977) Grad: 4596.0991  LR: 0.00000960  \n","Epoch: [1][1400/2463] Elapsed 3m 55s (remain 2m 58s) Loss: 0.0631(0.0960) Grad: 13222.3633  LR: 0.00000954  \n","Epoch: [1][1500/2463] Elapsed 4m 12s (remain 2m 42s) Loss: 0.1107(0.0945) Grad: 4659.8408  LR: 0.00000947  \n","Epoch: [1][1600/2463] Elapsed 4m 29s (remain 2m 25s) Loss: 0.0914(0.0935) Grad: 4463.9062  LR: 0.00000939  \n","Epoch: [1][1700/2463] Elapsed 4m 46s (remain 2m 8s) Loss: 0.0515(0.0920) Grad: 1252.7784  LR: 0.00000932  \n","Epoch: [1][1800/2463] Elapsed 5m 3s (remain 1m 51s) Loss: 0.0696(0.0913) Grad: 3038.4060  LR: 0.00000923  \n","Epoch: [1][1900/2463] Elapsed 5m 20s (remain 1m 34s) Loss: 0.0788(0.0904) Grad: 542.8147  LR: 0.00000915  \n","Epoch: [1][2000/2463] Elapsed 5m 37s (remain 1m 17s) Loss: 0.0534(0.0895) Grad: 4056.4995  LR: 0.00000905  \n","Epoch: [1][2100/2463] Elapsed 5m 54s (remain 1m 1s) Loss: 0.0592(0.0885) Grad: 9670.6934  LR: 0.00000896  \n","Epoch: [1][2200/2463] Elapsed 6m 10s (remain 0m 44s) Loss: 0.0392(0.0873) Grad: 8647.0957  LR: 0.00000886  \n","Epoch: [1][2300/2463] Elapsed 6m 27s (remain 0m 27s) Loss: 0.0433(0.0860) Grad: 23391.8477  LR: 0.00000875  \n","Epoch: [1][2400/2463] Elapsed 6m 44s (remain 0m 10s) Loss: 0.0185(0.0845) Grad: 1366.3239  LR: 0.00000865  \n","Epoch: [1][2462/2463] Elapsed 6m 54s (remain 0m 0s) Loss: 0.0261(0.0835) Grad: 15673.0898  LR: 0.00000858  \n","EVAL: [0/143] Elapsed 0m 0s (remain 0m 51s) Loss: 0.1930(0.1930) \n","EVAL: [100/143] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1004(0.1138) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0835  avg_val_loss: 0.1123  time: 428s\n","Epoch 1 - Score: 0.7145\n","Epoch 1 - Save Best Score: 0.7145 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [142/143] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0323(0.1123) \n","Epoch: [2][0/2463] Elapsed 0m 0s (remain 19m 30s) Loss: 0.0651(0.0651) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2463] Elapsed 0m 17s (remain 6m 55s) Loss: 0.0442(0.0359) Grad: 22965.8887  LR: 0.00000846  \n","Epoch: [2][200/2463] Elapsed 0m 35s (remain 6m 37s) Loss: 0.0168(0.0357) Grad: 5850.2798  LR: 0.00000835  \n","Epoch: [2][300/2463] Elapsed 0m 52s (remain 6m 16s) Loss: 0.0345(0.0336) Grad: 38406.4492  LR: 0.00000822  \n","Epoch: [2][400/2463] Elapsed 1m 9s (remain 5m 56s) Loss: 0.0295(0.0335) Grad: 6837.9141  LR: 0.00000810  \n","Epoch: [2][500/2463] Elapsed 1m 26s (remain 5m 37s) Loss: 0.0310(0.0331) Grad: 31100.1836  LR: 0.00000797  \n","Epoch: [2][600/2463] Elapsed 1m 43s (remain 5m 19s) Loss: 0.0354(0.0326) Grad: 6427.8726  LR: 0.00000784  \n","Epoch: [2][700/2463] Elapsed 1m 59s (remain 5m 1s) Loss: 0.0313(0.0321) Grad: 17160.4395  LR: 0.00000771  \n","Epoch: [2][800/2463] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0141(0.0318) Grad: 8081.3062  LR: 0.00000757  \n","Epoch: [2][900/2463] Elapsed 2m 33s (remain 4m 26s) Loss: 0.0301(0.0315) Grad: 23894.6895  LR: 0.00000743  \n","Epoch: [2][1000/2463] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0195(0.0311) Grad: 21028.6484  LR: 0.00000729  \n","Epoch: [2][1100/2463] Elapsed 3m 7s (remain 3m 51s) Loss: 0.0216(0.0308) Grad: 19509.0586  LR: 0.00000715  \n","Epoch: [2][1200/2463] Elapsed 3m 24s (remain 3m 34s) Loss: 0.0177(0.0306) Grad: 4802.8467  LR: 0.00000700  \n","Epoch: [2][1300/2463] Elapsed 3m 41s (remain 3m 17s) Loss: 0.0529(0.0303) Grad: 34830.6914  LR: 0.00000686  \n","Epoch: [2][1400/2463] Elapsed 3m 58s (remain 3m 0s) Loss: 0.0296(0.0301) Grad: 4149.4326  LR: 0.00000671  \n","Epoch: [2][1500/2463] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0883(0.0300) Grad: 6956.3076  LR: 0.00000656  \n","Epoch: [2][1600/2463] Elapsed 4m 31s (remain 2m 26s) Loss: 0.0420(0.0298) Grad: 40396.9570  LR: 0.00000640  \n","Epoch: [2][1700/2463] Elapsed 4m 48s (remain 2m 9s) Loss: 0.0244(0.0294) Grad: 9545.7861  LR: 0.00000625  \n","Epoch: [2][1800/2463] Elapsed 5m 5s (remain 1m 52s) Loss: 0.0217(0.0291) Grad: 14082.9355  LR: 0.00000609  \n","Epoch: [2][1900/2463] Elapsed 5m 22s (remain 1m 35s) Loss: 0.0149(0.0288) Grad: 9353.1426  LR: 0.00000594  \n","Epoch: [2][2000/2463] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0169(0.0286) Grad: 19229.0723  LR: 0.00000578  \n","Epoch: [2][2100/2463] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0413(0.0283) Grad: 12722.7861  LR: 0.00000562  \n","Epoch: [2][2200/2463] Elapsed 6m 13s (remain 0m 44s) Loss: 0.0243(0.0280) Grad: 38645.9375  LR: 0.00000546  \n","Epoch: [2][2300/2463] Elapsed 6m 30s (remain 0m 27s) Loss: 0.0212(0.0278) Grad: 16329.1445  LR: 0.00000530  \n","Epoch: [2][2400/2463] Elapsed 6m 47s (remain 0m 10s) Loss: 0.0324(0.0276) Grad: 38324.7695  LR: 0.00000514  \n","Epoch: [2][2462/2463] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0189(0.0275) Grad: 9405.4395  LR: 0.00000504  \n","EVAL: [0/143] Elapsed 0m 0s (remain 0m 50s) Loss: 0.1392(0.1392) \n","EVAL: [100/143] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0824(0.0968) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0275  avg_val_loss: 0.0953  time: 431s\n","Epoch 2 - Score: 0.8153\n","Epoch 2 - Save Best Score: 0.8153 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [142/143] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0183(0.0953) \n","Epoch: [3][0/2463] Elapsed 0m 0s (remain 20m 21s) Loss: 0.0118(0.0118) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2463] Elapsed 0m 17s (remain 6m 51s) Loss: 0.0244(0.0171) Grad: 7401.3677  LR: 0.00000488  \n","Epoch: [3][200/2463] Elapsed 0m 35s (remain 6m 37s) Loss: 0.0201(0.0185) Grad: 9244.9512  LR: 0.00000472  \n","Epoch: [3][300/2463] Elapsed 0m 52s (remain 6m 15s) Loss: 0.0070(0.0185) Grad: 10781.0957  LR: 0.00000456  \n","Epoch: [3][400/2463] Elapsed 1m 9s (remain 5m 55s) Loss: 0.0164(0.0186) Grad: 23568.9258  LR: 0.00000440  \n","Epoch: [3][500/2463] Elapsed 1m 26s (remain 5m 36s) Loss: 0.0150(0.0183) Grad: 7781.0952  LR: 0.00000424  \n","Epoch: [3][600/2463] Elapsed 1m 42s (remain 5m 18s) Loss: 0.0077(0.0181) Grad: 22150.7871  LR: 0.00000408  \n","Epoch: [3][700/2463] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0331(0.0181) Grad: 20567.4707  LR: 0.00000393  \n","Epoch: [3][800/2463] Elapsed 2m 16s (remain 4m 43s) Loss: 0.0314(0.0182) Grad: 38781.7148  LR: 0.00000377  \n","Epoch: [3][900/2463] Elapsed 2m 33s (remain 4m 25s) Loss: 0.0316(0.0181) Grad: 11973.8164  LR: 0.00000361  \n","Epoch: [3][1000/2463] Elapsed 2m 50s (remain 4m 8s) Loss: 0.0086(0.0183) Grad: 24986.2266  LR: 0.00000346  \n","Epoch: [3][1100/2463] Elapsed 3m 7s (remain 3m 51s) Loss: 0.0226(0.0182) Grad: 26428.7109  LR: 0.00000331  \n","Epoch: [3][1200/2463] Elapsed 3m 23s (remain 3m 34s) Loss: 0.0193(0.0181) Grad: 11838.9365  LR: 0.00000316  \n","Epoch: [3][1300/2463] Elapsed 3m 40s (remain 3m 17s) Loss: 0.0081(0.0180) Grad: 4547.5688  LR: 0.00000301  \n","Epoch: [3][1400/2463] Elapsed 3m 57s (remain 2m 59s) Loss: 0.0371(0.0180) Grad: 10365.3447  LR: 0.00000287  \n","Epoch: [3][1500/2463] Elapsed 4m 14s (remain 2m 42s) Loss: 0.0094(0.0180) Grad: 5394.9028  LR: 0.00000272  \n","Epoch: [3][1600/2463] Elapsed 4m 31s (remain 2m 25s) Loss: 0.0146(0.0179) Grad: 7505.8125  LR: 0.00000258  \n","Epoch: [3][1700/2463] Elapsed 4m 47s (remain 2m 8s) Loss: 0.0167(0.0180) Grad: 32794.2578  LR: 0.00000244  \n","Epoch: [3][1800/2463] Elapsed 5m 4s (remain 1m 51s) Loss: 0.0313(0.0179) Grad: 65999.4688  LR: 0.00000231  \n","Epoch: [3][1900/2463] Elapsed 5m 21s (remain 1m 35s) Loss: 0.0098(0.0178) Grad: 9129.9678  LR: 0.00000217  \n","Epoch: [3][2000/2463] Elapsed 5m 38s (remain 1m 18s) Loss: 0.0289(0.0177) Grad: 46070.7812  LR: 0.00000204  \n","Epoch: [3][2100/2463] Elapsed 5m 54s (remain 1m 1s) Loss: 0.0188(0.0177) Grad: 24105.2246  LR: 0.00000191  \n","Epoch: [3][2200/2463] Elapsed 6m 11s (remain 0m 44s) Loss: 0.0083(0.0177) Grad: 14350.0654  LR: 0.00000179  \n","Epoch: [3][2300/2463] Elapsed 6m 28s (remain 0m 27s) Loss: 0.0161(0.0177) Grad: 16615.8945  LR: 0.00000167  \n","Epoch: [3][2400/2463] Elapsed 6m 45s (remain 0m 10s) Loss: 0.0143(0.0176) Grad: 27660.6973  LR: 0.00000155  \n","Epoch: [3][2462/2463] Elapsed 6m 55s (remain 0m 0s) Loss: 0.0096(0.0176) Grad: 6294.1968  LR: 0.00000148  \n","EVAL: [0/143] Elapsed 0m 0s (remain 0m 52s) Loss: 0.1474(0.1474) \n","EVAL: [100/143] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0942(0.1005) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0176  avg_val_loss: 0.0990  time: 429s\n","Epoch 3 - Score: 0.8247\n","Epoch 3 - Save Best Score: 0.8247 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [142/143] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0189(0.0990) \n","Epoch: [4][0/2463] Elapsed 0m 0s (remain 19m 25s) Loss: 0.0073(0.0073) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2463] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0048(0.0132) Grad: 4300.0225  LR: 0.00000137  \n","Epoch: [4][200/2463] Elapsed 0m 35s (remain 6m 36s) Loss: 0.0089(0.0139) Grad: 21508.6895  LR: 0.00000126  \n","Epoch: [4][300/2463] Elapsed 0m 52s (remain 6m 13s) Loss: 0.0065(0.0141) Grad: 7834.5977  LR: 0.00000115  \n","Epoch: [4][400/2463] Elapsed 1m 8s (remain 5m 54s) Loss: 0.0124(0.0141) Grad: 22329.6777  LR: 0.00000105  \n","Epoch: [4][500/2463] Elapsed 1m 25s (remain 5m 35s) Loss: 0.0161(0.0143) Grad: 15358.2324  LR: 0.00000096  \n","Epoch: [4][600/2463] Elapsed 1m 42s (remain 5m 17s) Loss: 0.0202(0.0141) Grad: 8280.5225  LR: 0.00000086  \n","Epoch: [4][700/2463] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0063(0.0141) Grad: 5787.2710  LR: 0.00000078  \n","Epoch: [4][800/2463] Elapsed 2m 16s (remain 4m 42s) Loss: 0.0191(0.0142) Grad: 7087.5537  LR: 0.00000069  \n","Epoch: [4][900/2463] Elapsed 2m 33s (remain 4m 25s) Loss: 0.0044(0.0142) Grad: 14386.3486  LR: 0.00000061  \n","Epoch: [4][1000/2463] Elapsed 2m 50s (remain 4m 8s) Loss: 0.0032(0.0142) Grad: 3935.1030  LR: 0.00000054  \n","Epoch: [4][1100/2463] Elapsed 3m 6s (remain 3m 51s) Loss: 0.0077(0.0143) Grad: 4879.1948  LR: 0.00000047  \n","Epoch: [4][1200/2463] Elapsed 3m 23s (remain 3m 34s) Loss: 0.0111(0.0143) Grad: 5867.4634  LR: 0.00000040  \n","Epoch: [4][1300/2463] Elapsed 3m 40s (remain 3m 17s) Loss: 0.0148(0.0142) Grad: 16774.1270  LR: 0.00000034  \n","Epoch: [4][1400/2463] Elapsed 3m 57s (remain 3m 0s) Loss: 0.0094(0.0142) Grad: 33237.6836  LR: 0.00000029  \n","Epoch: [4][1500/2463] Elapsed 4m 14s (remain 2m 43s) Loss: 0.0073(0.0141) Grad: 4582.7705  LR: 0.00000024  \n","Epoch: [4][1600/2463] Elapsed 4m 31s (remain 2m 26s) Loss: 0.0224(0.0141) Grad: 35988.7227  LR: 0.00000019  \n","Epoch: [4][1700/2463] Elapsed 4m 48s (remain 2m 9s) Loss: 0.0110(0.0140) Grad: 8187.7222  LR: 0.00000015  \n","Epoch: [4][1800/2463] Elapsed 5m 5s (remain 1m 52s) Loss: 0.0083(0.0140) Grad: 13267.7471  LR: 0.00000011  \n","Epoch: [4][1900/2463] Elapsed 5m 22s (remain 1m 35s) Loss: 0.0270(0.0139) Grad: 38436.3125  LR: 0.00000008  \n","Epoch: [4][2000/2463] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0102(0.0139) Grad: 5010.7339  LR: 0.00000005  \n","Epoch: [4][2100/2463] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0183(0.0139) Grad: 38683.2422  LR: 0.00000003  \n","Epoch: [4][2200/2463] Elapsed 6m 12s (remain 0m 44s) Loss: 0.0075(0.0139) Grad: 21484.8828  LR: 0.00000002  \n","Epoch: [4][2300/2463] Elapsed 6m 29s (remain 0m 27s) Loss: 0.0067(0.0138) Grad: 17865.3105  LR: 0.00000001  \n","Epoch: [4][2400/2463] Elapsed 6m 46s (remain 0m 10s) Loss: 0.0114(0.0138) Grad: 14244.7764  LR: 0.00000000  \n","Epoch: [4][2462/2463] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0568(0.0139) Grad: 51600.0508  LR: 0.00000000  \n","EVAL: [0/143] Elapsed 0m 0s (remain 0m 52s) Loss: 0.1443(0.1443) \n","EVAL: [100/143] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0914(0.0981) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0139  avg_val_loss: 0.0966  time: 430s\n","Epoch 4 - Score: 0.8233\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [142/143] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0171(0.0966) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 14 result ==========\n","Score: 0.8247\n","========== fold: 15 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2461] Elapsed 0m 0s (remain 18m 32s) Loss: 0.5859(0.5859) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2461] Elapsed 0m 17s (remain 6m 41s) Loss: 0.0679(0.1454) Grad: 13719.3633  LR: 0.00001000  \n","Epoch: [1][200/2461] Elapsed 0m 34s (remain 6m 23s) Loss: 0.0490(0.1327) Grad: 14584.9541  LR: 0.00000999  \n","Epoch: [1][300/2461] Elapsed 0m 51s (remain 6m 6s) Loss: 0.0645(0.1182) Grad: 22202.4629  LR: 0.00000998  \n","Epoch: [1][400/2461] Elapsed 1m 8s (remain 5m 49s) Loss: 0.1405(0.1083) Grad: 47845.8555  LR: 0.00000997  \n","Epoch: [1][500/2461] Elapsed 1m 24s (remain 5m 32s) Loss: 0.0258(0.1007) Grad: 9824.3477  LR: 0.00000995  \n","Epoch: [1][600/2461] Elapsed 1m 41s (remain 5m 15s) Loss: 0.0948(0.0934) Grad: 42140.8281  LR: 0.00000992  \n","Epoch: [1][700/2461] Elapsed 1m 58s (remain 4m 58s) Loss: 0.0606(0.0884) Grad: 21159.9121  LR: 0.00000989  \n","Epoch: [1][800/2461] Elapsed 2m 15s (remain 4m 41s) Loss: 0.0585(0.0826) Grad: 6154.7471  LR: 0.00000986  \n","Epoch: [1][900/2461] Elapsed 2m 32s (remain 4m 24s) Loss: 0.0443(0.0808) Grad: 6780.6680  LR: 0.00000981  \n","Epoch: [1][1000/2461] Elapsed 2m 49s (remain 4m 7s) Loss: 0.0236(0.0774) Grad: 1741.5997  LR: 0.00000977  \n","Epoch: [1][1100/2461] Elapsed 3m 6s (remain 3m 50s) Loss: 0.0362(0.0741) Grad: 2670.7424  LR: 0.00000972  \n","Epoch: [1][1200/2461] Elapsed 3m 23s (remain 3m 33s) Loss: 0.0370(0.0713) Grad: 16686.7070  LR: 0.00000966  \n","Epoch: [1][1300/2461] Elapsed 3m 40s (remain 3m 16s) Loss: 0.0450(0.0690) Grad: 20193.6074  LR: 0.00000960  \n","Epoch: [1][1400/2461] Elapsed 3m 57s (remain 2m 59s) Loss: 0.0222(0.0664) Grad: 3678.2959  LR: 0.00000954  \n","Epoch: [1][1500/2461] Elapsed 4m 14s (remain 2m 42s) Loss: 0.0199(0.0643) Grad: 3948.6682  LR: 0.00000947  \n","Epoch: [1][1600/2461] Elapsed 4m 31s (remain 2m 25s) Loss: 0.0102(0.0623) Grad: 1409.6233  LR: 0.00000939  \n","Epoch: [1][1700/2461] Elapsed 4m 48s (remain 2m 8s) Loss: 0.0497(0.0606) Grad: 18548.3809  LR: 0.00000932  \n","Epoch: [1][1800/2461] Elapsed 5m 5s (remain 1m 51s) Loss: 0.0280(0.0588) Grad: 12244.4531  LR: 0.00000923  \n","Epoch: [1][1900/2461] Elapsed 5m 22s (remain 1m 34s) Loss: 0.0273(0.0571) Grad: 8885.2119  LR: 0.00000914  \n","Epoch: [1][2000/2461] Elapsed 5m 39s (remain 1m 17s) Loss: 0.0269(0.0556) Grad: 8566.1553  LR: 0.00000905  \n","Epoch: [1][2100/2461] Elapsed 5m 55s (remain 1m 0s) Loss: 0.0163(0.0542) Grad: 13088.1934  LR: 0.00000896  \n","Epoch: [1][2200/2461] Elapsed 6m 12s (remain 0m 44s) Loss: 0.0292(0.0530) Grad: 4219.1724  LR: 0.00000886  \n","Epoch: [1][2300/2461] Elapsed 6m 29s (remain 0m 27s) Loss: 0.0159(0.0519) Grad: 27056.8965  LR: 0.00000875  \n","Epoch: [1][2400/2461] Elapsed 6m 46s (remain 0m 10s) Loss: 0.0149(0.0509) Grad: 11846.7090  LR: 0.00000865  \n","Epoch: [1][2460/2461] Elapsed 6m 56s (remain 0m 0s) Loss: 0.0238(0.0502) Grad: 13332.0332  LR: 0.00000858  \n","EVAL: [0/144] Elapsed 0m 0s (remain 0m 51s) Loss: 0.1503(0.1503) \n","EVAL: [100/144] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0275(0.0959) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0502  avg_val_loss: 0.0908  time: 430s\n","Epoch 1 - Score: 0.7972\n","Epoch 1 - Save Best Score: 0.7972 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [143/144] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0534(0.0908) \n","Epoch: [2][0/2461] Elapsed 0m 0s (remain 18m 31s) Loss: 0.0178(0.0178) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2461] Elapsed 0m 18s (remain 7m 3s) Loss: 0.0296(0.0210) Grad: 64026.1992  LR: 0.00000846  \n","Epoch: [2][200/2461] Elapsed 0m 35s (remain 6m 40s) Loss: 0.0271(0.0205) Grad: 23810.3809  LR: 0.00000835  \n","Epoch: [2][300/2461] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0119(0.0199) Grad: 13812.1934  LR: 0.00000823  \n","Epoch: [2][400/2461] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0140(0.0196) Grad: 33898.7891  LR: 0.00000810  \n","Epoch: [2][500/2461] Elapsed 1m 26s (remain 5m 37s) Loss: 0.0286(0.0199) Grad: 9424.0391  LR: 0.00000797  \n","Epoch: [2][600/2461] Elapsed 1m 43s (remain 5m 19s) Loss: 0.0306(0.0200) Grad: 58680.9062  LR: 0.00000784  \n","Epoch: [2][700/2461] Elapsed 2m 0s (remain 5m 1s) Loss: 0.0097(0.0200) Grad: 29520.4844  LR: 0.00000771  \n","Epoch: [2][800/2461] Elapsed 2m 17s (remain 4m 43s) Loss: 0.0263(0.0198) Grad: 17650.6836  LR: 0.00000757  \n","Epoch: [2][900/2461] Elapsed 2m 33s (remain 4m 26s) Loss: 0.0130(0.0197) Grad: 29283.1836  LR: 0.00000744  \n","Epoch: [2][1000/2461] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0084(0.0196) Grad: 23285.6992  LR: 0.00000729  \n","Epoch: [2][1100/2461] Elapsed 3m 7s (remain 3m 51s) Loss: 0.0174(0.0194) Grad: 8631.2725  LR: 0.00000715  \n","Epoch: [2][1200/2461] Elapsed 3m 24s (remain 3m 34s) Loss: 0.0126(0.0196) Grad: 12662.4531  LR: 0.00000700  \n","Epoch: [2][1300/2461] Elapsed 3m 41s (remain 3m 17s) Loss: 0.0112(0.0195) Grad: 26680.0977  LR: 0.00000686  \n","Epoch: [2][1400/2461] Elapsed 3m 58s (remain 3m 0s) Loss: 0.0179(0.0195) Grad: 35051.0000  LR: 0.00000671  \n","Epoch: [2][1500/2461] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0197(0.0194) Grad: 56095.6992  LR: 0.00000656  \n","Epoch: [2][1600/2461] Elapsed 4m 31s (remain 2m 26s) Loss: 0.0068(0.0197) Grad: 14662.9688  LR: 0.00000640  \n","Epoch: [2][1700/2461] Elapsed 4m 48s (remain 2m 9s) Loss: 0.0069(0.0195) Grad: 14284.9512  LR: 0.00000625  \n","Epoch: [2][1800/2461] Elapsed 5m 5s (remain 1m 52s) Loss: 0.0239(0.0195) Grad: 43254.8867  LR: 0.00000609  \n","Epoch: [2][1900/2461] Elapsed 5m 22s (remain 1m 35s) Loss: 0.0185(0.0195) Grad: 19176.6523  LR: 0.00000593  \n","Epoch: [2][2000/2461] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0334(0.0196) Grad: 73514.3438  LR: 0.00000578  \n","Epoch: [2][2100/2461] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0166(0.0196) Grad: 11237.5459  LR: 0.00000562  \n","Epoch: [2][2200/2461] Elapsed 6m 13s (remain 0m 44s) Loss: 0.0095(0.0196) Grad: 19771.7988  LR: 0.00000546  \n","Epoch: [2][2300/2461] Elapsed 6m 30s (remain 0m 27s) Loss: 0.0120(0.0195) Grad: 5744.7627  LR: 0.00000530  \n","Epoch: [2][2400/2461] Elapsed 6m 47s (remain 0m 10s) Loss: 0.0114(0.0195) Grad: 4812.2534  LR: 0.00000514  \n","Epoch: [2][2460/2461] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0088(0.0195) Grad: 16914.9863  LR: 0.00000504  \n","EVAL: [0/144] Elapsed 0m 0s (remain 0m 46s) Loss: 0.1475(0.1475) \n","EVAL: [100/144] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0253(0.0963) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0195  avg_val_loss: 0.0907  time: 431s\n","Epoch 2 - Score: 0.8080\n","Epoch 2 - Save Best Score: 0.8080 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [143/144] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0588(0.0907) \n","Epoch: [3][0/2461] Elapsed 0m 0s (remain 18m 40s) Loss: 0.0135(0.0135) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2461] Elapsed 0m 18s (remain 7m 2s) Loss: 0.0133(0.0165) Grad: 39578.3125  LR: 0.00000488  \n","Epoch: [3][200/2461] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0151(0.0164) Grad: 9817.0576  LR: 0.00000472  \n","Epoch: [3][300/2461] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0124(0.0163) Grad: 3999.8191  LR: 0.00000456  \n","Epoch: [3][400/2461] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0036(0.0156) Grad: 5149.5439  LR: 0.00000440  \n","Epoch: [3][500/2461] Elapsed 1m 26s (remain 5m 38s) Loss: 0.0191(0.0156) Grad: 32226.1445  LR: 0.00000424  \n","Epoch: [3][600/2461] Elapsed 1m 43s (remain 5m 20s) Loss: 0.0092(0.0154) Grad: 6029.5674  LR: 0.00000408  \n","Epoch: [3][700/2461] Elapsed 2m 0s (remain 5m 2s) Loss: 0.0213(0.0152) Grad: 24883.5156  LR: 0.00000393  \n","Epoch: [3][800/2461] Elapsed 2m 17s (remain 4m 44s) Loss: 0.0121(0.0152) Grad: 40267.7148  LR: 0.00000377  \n","Epoch: [3][900/2461] Elapsed 2m 34s (remain 4m 26s) Loss: 0.0201(0.0152) Grad: 5183.2505  LR: 0.00000362  \n","Epoch: [3][1000/2461] Elapsed 2m 51s (remain 4m 9s) Loss: 0.0289(0.0151) Grad: 21520.6992  LR: 0.00000346  \n","Epoch: [3][1100/2461] Elapsed 3m 8s (remain 3m 52s) Loss: 0.0167(0.0151) Grad: 24775.6094  LR: 0.00000331  \n","Epoch: [3][1200/2461] Elapsed 3m 24s (remain 3m 34s) Loss: 0.0092(0.0151) Grad: 14771.7529  LR: 0.00000316  \n","Epoch: [3][1300/2461] Elapsed 3m 41s (remain 3m 17s) Loss: 0.0097(0.0151) Grad: 21056.7949  LR: 0.00000301  \n","Epoch: [3][1400/2461] Elapsed 3m 58s (remain 3m 0s) Loss: 0.0173(0.0151) Grad: 45086.8242  LR: 0.00000287  \n","Epoch: [3][1500/2461] Elapsed 4m 15s (remain 2m 43s) Loss: 0.0099(0.0151) Grad: 9097.4307  LR: 0.00000272  \n","Epoch: [3][1600/2461] Elapsed 4m 32s (remain 2m 26s) Loss: 0.0457(0.0152) Grad: 68046.3984  LR: 0.00000258  \n","Epoch: [3][1700/2461] Elapsed 4m 49s (remain 2m 9s) Loss: 0.0130(0.0152) Grad: 5638.0381  LR: 0.00000244  \n","Epoch: [3][1800/2461] Elapsed 5m 6s (remain 1m 52s) Loss: 0.0137(0.0152) Grad: 17277.4004  LR: 0.00000231  \n","Epoch: [3][1900/2461] Elapsed 5m 23s (remain 1m 35s) Loss: 0.0091(0.0152) Grad: 24904.3457  LR: 0.00000217  \n","Epoch: [3][2000/2461] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0351(0.0152) Grad: 11673.7109  LR: 0.00000204  \n","Epoch: [3][2100/2461] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0038(0.0151) Grad: 32555.5449  LR: 0.00000191  \n","Epoch: [3][2200/2461] Elapsed 6m 13s (remain 0m 44s) Loss: 0.0354(0.0150) Grad: 38672.6953  LR: 0.00000179  \n","Epoch: [3][2300/2461] Elapsed 6m 30s (remain 0m 27s) Loss: 0.0120(0.0149) Grad: 45160.6719  LR: 0.00000167  \n","Epoch: [3][2400/2461] Elapsed 6m 47s (remain 0m 10s) Loss: 0.0349(0.0149) Grad: 110636.9453  LR: 0.00000155  \n","Epoch: [3][2460/2461] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0120(0.0149) Grad: 17031.7773  LR: 0.00000148  \n","EVAL: [0/144] Elapsed 0m 0s (remain 0m 46s) Loss: 0.1532(0.1532) \n","EVAL: [100/144] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0268(0.1012) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0149  avg_val_loss: 0.0957  time: 431s\n","Epoch 3 - Score: 0.8102\n","Epoch 3 - Save Best Score: 0.8102 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [143/144] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0607(0.0957) \n","Epoch: [4][0/2461] Elapsed 0m 0s (remain 18m 39s) Loss: 0.0054(0.0054) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2461] Elapsed 0m 17s (remain 6m 51s) Loss: 0.0133(0.0125) Grad: 8043.9580  LR: 0.00000137  \n","Epoch: [4][200/2461] Elapsed 0m 35s (remain 6m 37s) Loss: 0.0203(0.0121) Grad: 16642.5176  LR: 0.00000126  \n","Epoch: [4][300/2461] Elapsed 0m 52s (remain 6m 14s) Loss: 0.0162(0.0123) Grad: 47531.0078  LR: 0.00000116  \n","Epoch: [4][400/2461] Elapsed 1m 9s (remain 5m 54s) Loss: 0.0223(0.0124) Grad: 52958.5508  LR: 0.00000105  \n","Epoch: [4][500/2461] Elapsed 1m 26s (remain 5m 36s) Loss: 0.0198(0.0122) Grad: 32456.1934  LR: 0.00000096  \n","Epoch: [4][600/2461] Elapsed 1m 42s (remain 5m 18s) Loss: 0.0057(0.0121) Grad: 11034.4814  LR: 0.00000087  \n","Epoch: [4][700/2461] Elapsed 1m 59s (remain 5m 0s) Loss: 0.0044(0.0119) Grad: 23909.5430  LR: 0.00000078  \n","Epoch: [4][800/2461] Elapsed 2m 16s (remain 4m 43s) Loss: 0.0109(0.0117) Grad: 62067.2617  LR: 0.00000069  \n","Epoch: [4][900/2461] Elapsed 2m 33s (remain 4m 25s) Loss: 0.0127(0.0118) Grad: 44272.6953  LR: 0.00000061  \n","Epoch: [4][1000/2461] Elapsed 2m 50s (remain 4m 8s) Loss: 0.0096(0.0117) Grad: 11114.2939  LR: 0.00000054  \n","Epoch: [4][1100/2461] Elapsed 3m 7s (remain 3m 51s) Loss: 0.0063(0.0116) Grad: 24324.1543  LR: 0.00000047  \n","Epoch: [4][1200/2461] Elapsed 3m 24s (remain 3m 34s) Loss: 0.0042(0.0116) Grad: 26213.3945  LR: 0.00000040  \n","Epoch: [4][1300/2461] Elapsed 3m 41s (remain 3m 17s) Loss: 0.0129(0.0116) Grad: 57527.5078  LR: 0.00000034  \n","Epoch: [4][1400/2461] Elapsed 3m 57s (remain 2m 59s) Loss: 0.0124(0.0115) Grad: 25484.4160  LR: 0.00000029  \n","Epoch: [4][1500/2461] Elapsed 4m 14s (remain 2m 42s) Loss: 0.0093(0.0115) Grad: 29975.2832  LR: 0.00000024  \n","Epoch: [4][1600/2461] Elapsed 4m 31s (remain 2m 25s) Loss: 0.0181(0.0115) Grad: 15739.1738  LR: 0.00000019  \n","Epoch: [4][1700/2461] Elapsed 4m 48s (remain 2m 8s) Loss: 0.0187(0.0115) Grad: 19934.4277  LR: 0.00000015  \n","Epoch: [4][1800/2461] Elapsed 5m 5s (remain 1m 51s) Loss: 0.0080(0.0114) Grad: 13263.4561  LR: 0.00000011  \n","Epoch: [4][1900/2461] Elapsed 5m 22s (remain 1m 34s) Loss: 0.0048(0.0114) Grad: 12243.7051  LR: 0.00000008  \n","Epoch: [4][2000/2461] Elapsed 5m 39s (remain 1m 18s) Loss: 0.0163(0.0114) Grad: 44949.8555  LR: 0.00000006  \n","Epoch: [4][2100/2461] Elapsed 5m 56s (remain 1m 1s) Loss: 0.0058(0.0114) Grad: 20595.8398  LR: 0.00000003  \n","Epoch: [4][2200/2461] Elapsed 6m 13s (remain 0m 44s) Loss: 0.0174(0.0114) Grad: 38098.1602  LR: 0.00000002  \n","Epoch: [4][2300/2461] Elapsed 6m 30s (remain 0m 27s) Loss: 0.0053(0.0114) Grad: 34720.1953  LR: 0.00000001  \n","Epoch: [4][2400/2461] Elapsed 6m 47s (remain 0m 10s) Loss: 0.0057(0.0113) Grad: 4884.4604  LR: 0.00000000  \n","Epoch: [4][2460/2461] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0059(0.0113) Grad: 7483.3271  LR: 0.00000000  \n","EVAL: [0/144] Elapsed 0m 0s (remain 0m 46s) Loss: 0.1513(0.1513) \n","EVAL: [100/144] Elapsed 0m 9s (remain 0m 3s) Loss: 0.0269(0.1001) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0113  avg_val_loss: 0.0948  time: 430s\n","Epoch 4 - Score: 0.8122\n","Epoch 4 - Save Best Score: 0.8122 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [143/144] Elapsed 0m 13s (remain 0m 0s) Loss: 0.0601(0.0948) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 15 result ==========\n","Score: 0.8122\n","========== fold: 16 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2470] Elapsed 0m 0s (remain 20m 31s) Loss: 1.0713(1.0713) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2470] Elapsed 0m 18s (remain 7m 7s) Loss: 0.1289(0.1757) Grad: 49902.9219  LR: 0.00001000  \n","Epoch: [1][200/2470] Elapsed 0m 35s (remain 6m 38s) Loss: 0.0349(0.1252) Grad: 6754.1777  LR: 0.00000999  \n","Epoch: [1][300/2470] Elapsed 0m 52s (remain 6m 16s) Loss: 0.3206(0.1076) Grad: 97621.3047  LR: 0.00000998  \n","Epoch: [1][400/2470] Elapsed 1m 9s (remain 5m 57s) Loss: 0.0773(0.1004) Grad: 32264.4570  LR: 0.00000997  \n","Epoch: [1][500/2470] Elapsed 1m 26s (remain 5m 39s) Loss: 0.0942(0.0923) Grad: 35857.0000  LR: 0.00000995  \n","Epoch: [1][600/2470] Elapsed 1m 43s (remain 5m 21s) Loss: 0.0623(0.0847) Grad: 27648.5781  LR: 0.00000992  \n","Epoch: [1][700/2470] Elapsed 2m 0s (remain 5m 2s) Loss: 0.0379(0.0781) Grad: 16655.8496  LR: 0.00000989  \n","Epoch: [1][800/2470] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0188(0.0739) Grad: 7165.8447  LR: 0.00000986  \n","Epoch: [1][900/2470] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0342(0.0702) Grad: 10868.4023  LR: 0.00000982  \n","Epoch: [1][1000/2470] Elapsed 2m 50s (remain 4m 10s) Loss: 0.0336(0.0675) Grad: 12417.3662  LR: 0.00000977  \n","Epoch: [1][1100/2470] Elapsed 3m 7s (remain 3m 53s) Loss: 0.0565(0.0648) Grad: 6129.4136  LR: 0.00000972  \n","Epoch: [1][1200/2470] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0514(0.0628) Grad: 2903.3894  LR: 0.00000967  \n","Epoch: [1][1300/2470] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0289(0.0615) Grad: 5179.6782  LR: 0.00000961  \n","Epoch: [1][1400/2470] Elapsed 3m 57s (remain 3m 1s) Loss: 0.0501(0.0595) Grad: 13395.9121  LR: 0.00000954  \n","Epoch: [1][1500/2470] Elapsed 4m 14s (remain 2m 44s) Loss: 0.0253(0.0579) Grad: 5377.9316  LR: 0.00000947  \n","Epoch: [1][1600/2470] Elapsed 4m 31s (remain 2m 27s) Loss: 0.0628(0.0568) Grad: 23935.4980  LR: 0.00000940  \n","Epoch: [1][1700/2470] Elapsed 4m 48s (remain 2m 10s) Loss: 0.0304(0.0555) Grad: 19559.2891  LR: 0.00000932  \n","Epoch: [1][1800/2470] Elapsed 5m 5s (remain 1m 53s) Loss: 0.0796(0.0541) Grad: 29944.4609  LR: 0.00000924  \n","Epoch: [1][1900/2470] Elapsed 5m 22s (remain 1m 36s) Loss: 0.0143(0.0530) Grad: 2228.7268  LR: 0.00000915  \n","Epoch: [1][2000/2470] Elapsed 5m 39s (remain 1m 19s) Loss: 0.0209(0.0519) Grad: 7683.3584  LR: 0.00000906  \n","Epoch: [1][2100/2470] Elapsed 5m 56s (remain 1m 2s) Loss: 0.0145(0.0506) Grad: 2251.3770  LR: 0.00000896  \n","Epoch: [1][2200/2470] Elapsed 6m 13s (remain 0m 45s) Loss: 0.0278(0.0494) Grad: 15960.4443  LR: 0.00000886  \n","Epoch: [1][2300/2470] Elapsed 6m 30s (remain 0m 28s) Loss: 0.0298(0.0483) Grad: 7344.5708  LR: 0.00000876  \n","Epoch: [1][2400/2470] Elapsed 6m 46s (remain 0m 11s) Loss: 0.0149(0.0474) Grad: 13178.8652  LR: 0.00000865  \n","Epoch: [1][2469/2470] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0279(0.0467) Grad: 6607.2915  LR: 0.00000858  \n","EVAL: [0/135] Elapsed 0m 0s (remain 0m 49s) Loss: 0.1677(0.1677) \n","EVAL: [100/135] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1042(0.1087) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0467  avg_val_loss: 0.1074  time: 431s\n","Epoch 1 - Score: 0.8210\n","Epoch 1 - Save Best Score: 0.8210 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [134/135] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0406(0.1074) \n","Epoch: [2][0/2470] Elapsed 0m 0s (remain 20m 1s) Loss: 0.0269(0.0269) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2470] Elapsed 0m 17s (remain 6m 52s) Loss: 0.0118(0.0204) Grad: 44746.8203  LR: 0.00000846  \n","Epoch: [2][200/2470] Elapsed 0m 35s (remain 6m 37s) Loss: 0.0123(0.0198) Grad: 21256.5566  LR: 0.00000835  \n","Epoch: [2][300/2470] Elapsed 0m 51s (remain 6m 14s) Loss: 0.0215(0.0199) Grad: 45480.2695  LR: 0.00000823  \n","Epoch: [2][400/2470] Elapsed 1m 8s (remain 5m 55s) Loss: 0.0217(0.0199) Grad: 25604.8086  LR: 0.00000810  \n","Epoch: [2][500/2470] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0176(0.0201) Grad: 14561.7832  LR: 0.00000798  \n","Epoch: [2][600/2470] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0347(0.0199) Grad: 31931.1758  LR: 0.00000785  \n","Epoch: [2][700/2470] Elapsed 1m 59s (remain 5m 1s) Loss: 0.0182(0.0200) Grad: 25070.3398  LR: 0.00000771  \n","Epoch: [2][800/2470] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0152(0.0199) Grad: 18701.5254  LR: 0.00000758  \n","Epoch: [2][900/2470] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0067(0.0200) Grad: 3007.3789  LR: 0.00000744  \n","Epoch: [2][1000/2470] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0174(0.0201) Grad: 40907.7617  LR: 0.00000730  \n","Epoch: [2][1100/2470] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0213(0.0201) Grad: 13475.9307  LR: 0.00000716  \n","Epoch: [2][1200/2470] Elapsed 3m 23s (remain 3m 35s) Loss: 0.0152(0.0199) Grad: 33317.4219  LR: 0.00000701  \n","Epoch: [2][1300/2470] Elapsed 3m 40s (remain 3m 18s) Loss: 0.0143(0.0198) Grad: 11733.8027  LR: 0.00000686  \n","Epoch: [2][1400/2470] Elapsed 3m 57s (remain 3m 1s) Loss: 0.0029(0.0196) Grad: 7010.2070  LR: 0.00000671  \n","Epoch: [2][1500/2470] Elapsed 4m 14s (remain 2m 44s) Loss: 0.0287(0.0196) Grad: 14620.7334  LR: 0.00000656  \n","Epoch: [2][1600/2470] Elapsed 4m 31s (remain 2m 27s) Loss: 0.0325(0.0196) Grad: 33987.8398  LR: 0.00000641  \n","Epoch: [2][1700/2470] Elapsed 4m 48s (remain 2m 10s) Loss: 0.0288(0.0196) Grad: 49222.5625  LR: 0.00000626  \n","Epoch: [2][1800/2470] Elapsed 5m 5s (remain 1m 53s) Loss: 0.0156(0.0195) Grad: 24034.0801  LR: 0.00000610  \n","Epoch: [2][1900/2470] Elapsed 5m 22s (remain 1m 36s) Loss: 0.0263(0.0195) Grad: 54343.7461  LR: 0.00000594  \n","Epoch: [2][2000/2470] Elapsed 5m 38s (remain 1m 19s) Loss: 0.0241(0.0194) Grad: 45428.3789  LR: 0.00000579  \n","Epoch: [2][2100/2470] Elapsed 5m 55s (remain 1m 2s) Loss: 0.0102(0.0193) Grad: 22095.5391  LR: 0.00000563  \n","Epoch: [2][2200/2470] Elapsed 6m 12s (remain 0m 45s) Loss: 0.0276(0.0192) Grad: 78018.3984  LR: 0.00000547  \n","Epoch: [2][2300/2470] Elapsed 6m 29s (remain 0m 28s) Loss: 0.0113(0.0191) Grad: 15789.5273  LR: 0.00000531  \n","Epoch: [2][2400/2470] Elapsed 6m 46s (remain 0m 11s) Loss: 0.0128(0.0192) Grad: 3072.7144  LR: 0.00000515  \n","Epoch: [2][2469/2470] Elapsed 6m 57s (remain 0m 0s) Loss: 0.0119(0.0192) Grad: 4286.3994  LR: 0.00000504  \n","EVAL: [0/135] Elapsed 0m 0s (remain 0m 51s) Loss: 0.1434(0.1434) \n","EVAL: [100/135] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1019(0.0965) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0192  avg_val_loss: 0.0957  time: 431s\n","Epoch 2 - Score: 0.8287\n","Epoch 2 - Save Best Score: 0.8287 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [134/135] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0364(0.0957) \n","Epoch: [3][0/2470] Elapsed 0m 0s (remain 20m 27s) Loss: 0.0082(0.0082) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2470] Elapsed 0m 17s (remain 7m 0s) Loss: 0.0147(0.0153) Grad: 42759.4219  LR: 0.00000488  \n","Epoch: [3][200/2470] Elapsed 0m 35s (remain 6m 38s) Loss: 0.0059(0.0154) Grad: 7640.3882  LR: 0.00000472  \n","Epoch: [3][300/2470] Elapsed 0m 52s (remain 6m 16s) Loss: 0.0181(0.0155) Grad: 9797.7715  LR: 0.00000456  \n","Epoch: [3][400/2470] Elapsed 1m 9s (remain 5m 56s) Loss: 0.0333(0.0152) Grad: 12293.3369  LR: 0.00000440  \n","Epoch: [3][500/2470] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0138(0.0157) Grad: 14757.7617  LR: 0.00000424  \n","Epoch: [3][600/2470] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0121(0.0156) Grad: 6131.3599  LR: 0.00000409  \n","Epoch: [3][700/2470] Elapsed 1m 59s (remain 5m 1s) Loss: 0.0229(0.0155) Grad: 51743.3789  LR: 0.00000393  \n","Epoch: [3][800/2470] Elapsed 2m 16s (remain 4m 44s) Loss: 0.0328(0.0155) Grad: 62548.6992  LR: 0.00000377  \n","Epoch: [3][900/2470] Elapsed 2m 33s (remain 4m 26s) Loss: 0.0217(0.0156) Grad: 24681.9727  LR: 0.00000362  \n","Epoch: [3][1000/2470] Elapsed 2m 50s (remain 4m 9s) Loss: 0.0179(0.0155) Grad: 8459.2354  LR: 0.00000347  \n","Epoch: [3][1100/2470] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0150(0.0156) Grad: 4940.9629  LR: 0.00000332  \n","Epoch: [3][1200/2470] Elapsed 3m 23s (remain 3m 35s) Loss: 0.0146(0.0156) Grad: 21087.1367  LR: 0.00000317  \n","Epoch: [3][1300/2470] Elapsed 3m 40s (remain 3m 18s) Loss: 0.0141(0.0155) Grad: 24452.1973  LR: 0.00000302  \n","Epoch: [3][1400/2470] Elapsed 3m 57s (remain 3m 1s) Loss: 0.0246(0.0155) Grad: 18884.2910  LR: 0.00000287  \n","Epoch: [3][1500/2470] Elapsed 4m 14s (remain 2m 44s) Loss: 0.0097(0.0155) Grad: 24133.4902  LR: 0.00000273  \n","Epoch: [3][1600/2470] Elapsed 4m 31s (remain 2m 27s) Loss: 0.0133(0.0154) Grad: 23402.9746  LR: 0.00000259  \n","Epoch: [3][1700/2470] Elapsed 4m 48s (remain 2m 10s) Loss: 0.0168(0.0152) Grad: 35416.6211  LR: 0.00000245  \n","Epoch: [3][1800/2470] Elapsed 5m 5s (remain 1m 53s) Loss: 0.0036(0.0151) Grad: 11698.3848  LR: 0.00000231  \n","Epoch: [3][1900/2470] Elapsed 5m 22s (remain 1m 36s) Loss: 0.0223(0.0152) Grad: 16885.1602  LR: 0.00000218  \n","Epoch: [3][2000/2470] Elapsed 5m 39s (remain 1m 19s) Loss: 0.0223(0.0151) Grad: 30751.5625  LR: 0.00000205  \n","Epoch: [3][2100/2470] Elapsed 5m 55s (remain 1m 2s) Loss: 0.0153(0.0150) Grad: 24350.3672  LR: 0.00000192  \n","Epoch: [3][2200/2470] Elapsed 6m 12s (remain 0m 45s) Loss: 0.0133(0.0150) Grad: 17321.8359  LR: 0.00000180  \n","Epoch: [3][2300/2470] Elapsed 6m 29s (remain 0m 28s) Loss: 0.0178(0.0150) Grad: 42668.3555  LR: 0.00000168  \n","Epoch: [3][2400/2470] Elapsed 6m 46s (remain 0m 11s) Loss: 0.0181(0.0149) Grad: 10655.3213  LR: 0.00000156  \n","Epoch: [3][2469/2470] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0085(0.0148) Grad: 10876.6191  LR: 0.00000148  \n","EVAL: [0/135] Elapsed 0m 0s (remain 0m 49s) Loss: 0.1498(0.1498) \n","EVAL: [100/135] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1019(0.0996) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0148  avg_val_loss: 0.0989  time: 431s\n","Epoch 3 - Score: 0.8322\n","Epoch 3 - Save Best Score: 0.8322 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [134/135] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0397(0.0989) \n","Epoch: [4][0/2470] Elapsed 0m 0s (remain 20m 0s) Loss: 0.0057(0.0057) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2470] Elapsed 0m 17s (remain 6m 56s) Loss: 0.0198(0.0114) Grad: 61083.0469  LR: 0.00000137  \n","Epoch: [4][200/2470] Elapsed 0m 35s (remain 6m 38s) Loss: 0.0133(0.0116) Grad: 17660.1406  LR: 0.00000126  \n","Epoch: [4][300/2470] Elapsed 0m 52s (remain 6m 16s) Loss: 0.0068(0.0115) Grad: 6348.6494  LR: 0.00000116  \n","Epoch: [4][400/2470] Elapsed 1m 8s (remain 5m 55s) Loss: 0.0198(0.0117) Grad: 56637.8438  LR: 0.00000106  \n","Epoch: [4][500/2470] Elapsed 1m 25s (remain 5m 37s) Loss: 0.0115(0.0116) Grad: 11370.5654  LR: 0.00000096  \n","Epoch: [4][600/2470] Elapsed 1m 42s (remain 5m 19s) Loss: 0.0069(0.0116) Grad: 7281.0605  LR: 0.00000087  \n","Epoch: [4][700/2470] Elapsed 2m 0s (remain 5m 2s) Loss: 0.0042(0.0114) Grad: 2461.4827  LR: 0.00000078  \n","Epoch: [4][800/2470] Elapsed 2m 16s (remain 4m 45s) Loss: 0.0057(0.0115) Grad: 3941.2239  LR: 0.00000070  \n","Epoch: [4][900/2470] Elapsed 2m 33s (remain 4m 27s) Loss: 0.0128(0.0114) Grad: 6266.8960  LR: 0.00000062  \n","Epoch: [4][1000/2470] Elapsed 2m 50s (remain 4m 10s) Loss: 0.0115(0.0113) Grad: 9996.0215  LR: 0.00000054  \n","Epoch: [4][1100/2470] Elapsed 3m 7s (remain 3m 52s) Loss: 0.0127(0.0113) Grad: 10270.6240  LR: 0.00000047  \n","Epoch: [4][1200/2470] Elapsed 3m 24s (remain 3m 35s) Loss: 0.0117(0.0113) Grad: 9199.4863  LR: 0.00000041  \n","Epoch: [4][1300/2470] Elapsed 3m 41s (remain 3m 18s) Loss: 0.0071(0.0113) Grad: 24271.1621  LR: 0.00000035  \n","Epoch: [4][1400/2470] Elapsed 3m 57s (remain 3m 1s) Loss: 0.0097(0.0112) Grad: 9709.3428  LR: 0.00000029  \n","Epoch: [4][1500/2470] Elapsed 4m 14s (remain 2m 44s) Loss: 0.0108(0.0112) Grad: 21178.2227  LR: 0.00000024  \n","Epoch: [4][1600/2470] Elapsed 4m 31s (remain 2m 27s) Loss: 0.0141(0.0112) Grad: 14412.3584  LR: 0.00000019  \n","Epoch: [4][1700/2470] Elapsed 4m 48s (remain 2m 10s) Loss: 0.0150(0.0112) Grad: 17295.5059  LR: 0.00000015  \n","Epoch: [4][1800/2470] Elapsed 5m 5s (remain 1m 53s) Loss: 0.0103(0.0112) Grad: 4445.2534  LR: 0.00000011  \n","Epoch: [4][1900/2470] Elapsed 5m 22s (remain 1m 36s) Loss: 0.0052(0.0112) Grad: 5849.7524  LR: 0.00000008  \n","Epoch: [4][2000/2470] Elapsed 5m 39s (remain 1m 19s) Loss: 0.0064(0.0112) Grad: 5352.6592  LR: 0.00000006  \n","Epoch: [4][2100/2470] Elapsed 5m 56s (remain 1m 2s) Loss: 0.0040(0.0112) Grad: 7546.8267  LR: 0.00000004  \n","Epoch: [4][2200/2470] Elapsed 6m 12s (remain 0m 45s) Loss: 0.0058(0.0112) Grad: 26223.0801  LR: 0.00000002  \n","Epoch: [4][2300/2470] Elapsed 6m 29s (remain 0m 28s) Loss: 0.0217(0.0111) Grad: 52603.5391  LR: 0.00000001  \n","Epoch: [4][2400/2470] Elapsed 6m 46s (remain 0m 11s) Loss: 0.0038(0.0112) Grad: 34722.9336  LR: 0.00000000  \n","Epoch: [4][2469/2470] Elapsed 6m 58s (remain 0m 0s) Loss: 0.0085(0.0112) Grad: 13829.6670  LR: 0.00000000  \n","EVAL: [0/135] Elapsed 0m 0s (remain 0m 50s) Loss: 0.1481(0.1481) \n","EVAL: [100/135] Elapsed 0m 9s (remain 0m 3s) Loss: 0.1009(0.0982) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0112  avg_val_loss: 0.0974  time: 431s\n","Epoch 4 - Score: 0.8337\n","Epoch 4 - Save Best Score: 0.8337 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [134/135] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0380(0.0974) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 16 result ==========\n","Score: 0.8337\n","========== fold: 17 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2486] Elapsed 0m 0s (remain 19m 38s) Loss: 0.4360(0.4360) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2486] Elapsed 0m 17s (remain 7m 1s) Loss: 0.0432(0.1559) Grad: 20212.2695  LR: 0.00001000  \n","Epoch: [1][200/2486] Elapsed 0m 35s (remain 6m 40s) Loss: 0.0801(0.1174) Grad: 25426.3105  LR: 0.00000999  \n","Epoch: [1][300/2486] Elapsed 0m 52s (remain 6m 18s) Loss: 0.1256(0.1067) Grad: 51746.8633  LR: 0.00000998  \n","Epoch: [1][400/2486] Elapsed 1m 8s (remain 5m 58s) Loss: 0.0606(0.0927) Grad: 19085.5195  LR: 0.00000997  \n","Epoch: [1][500/2486] Elapsed 1m 25s (remain 5m 39s) Loss: 0.0673(0.0852) Grad: 31498.6816  LR: 0.00000995  \n","Epoch: [1][600/2486] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0637(0.0811) Grad: 22136.5195  LR: 0.00000992  \n","Epoch: [1][700/2486] Elapsed 1m 59s (remain 5m 4s) Loss: 0.1584(0.0763) Grad: 52377.6016  LR: 0.00000989  \n","Epoch: [1][800/2486] Elapsed 2m 16s (remain 4m 46s) Loss: 0.0265(0.0722) Grad: 2071.7954  LR: 0.00000986  \n","Epoch: [1][900/2486] Elapsed 2m 33s (remain 4m 29s) Loss: 0.0523(0.0703) Grad: 22730.8789  LR: 0.00000982  \n","Epoch: [1][1000/2486] Elapsed 2m 49s (remain 4m 12s) Loss: 0.0822(0.0696) Grad: 35253.1523  LR: 0.00000977  \n","Epoch: [1][1100/2486] Elapsed 3m 6s (remain 3m 55s) Loss: 0.0306(0.0674) Grad: 10222.6299  LR: 0.00000972  \n","Epoch: [1][1200/2486] Elapsed 3m 23s (remain 3m 37s) Loss: 0.0183(0.0646) Grad: 5306.4341  LR: 0.00000967  \n","Epoch: [1][1300/2486] Elapsed 3m 40s (remain 3m 20s) Loss: 0.0322(0.0623) Grad: 8485.7139  LR: 0.00000961  \n","Epoch: [1][1400/2486] Elapsed 3m 57s (remain 3m 3s) Loss: 0.0270(0.0612) Grad: 18768.8145  LR: 0.00000955  \n","Epoch: [1][1500/2486] Elapsed 4m 14s (remain 2m 46s) Loss: 0.0236(0.0593) Grad: 11279.2891  LR: 0.00000948  \n","Epoch: [1][1600/2486] Elapsed 4m 31s (remain 2m 29s) Loss: 0.0410(0.0577) Grad: 21391.7266  LR: 0.00000941  \n","Epoch: [1][1700/2486] Elapsed 4m 47s (remain 2m 12s) Loss: 0.0410(0.0565) Grad: 15817.5010  LR: 0.00000933  \n","Epoch: [1][1800/2486] Elapsed 5m 4s (remain 1m 55s) Loss: 0.0384(0.0550) Grad: 2887.0129  LR: 0.00000925  \n","Epoch: [1][1900/2486] Elapsed 5m 21s (remain 1m 38s) Loss: 0.0172(0.0538) Grad: 2562.9771  LR: 0.00000916  \n","Epoch: [1][2000/2486] Elapsed 5m 38s (remain 1m 22s) Loss: 0.0350(0.0526) Grad: 3601.5891  LR: 0.00000907  \n","Epoch: [1][2100/2486] Elapsed 5m 55s (remain 1m 5s) Loss: 0.0358(0.0514) Grad: 9227.3848  LR: 0.00000898  \n","Epoch: [1][2200/2486] Elapsed 6m 12s (remain 0m 48s) Loss: 0.0313(0.0504) Grad: 3417.4048  LR: 0.00000888  \n","Epoch: [1][2300/2486] Elapsed 6m 29s (remain 0m 31s) Loss: 0.0416(0.0493) Grad: 7924.5562  LR: 0.00000878  \n","Epoch: [1][2400/2486] Elapsed 6m 46s (remain 0m 14s) Loss: 0.0061(0.0484) Grad: 1292.5663  LR: 0.00000867  \n","Epoch: [1][2485/2486] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0136(0.0476) Grad: 10847.7705  LR: 0.00000858  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 47s) Loss: 0.0699(0.0699) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.1426(0.0949) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0476  avg_val_loss: 0.0943  time: 432s\n","Epoch 1 - Score: 0.7959\n","Epoch 1 - Save Best Score: 0.7959 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0628(0.0943) \n","Epoch: [2][0/2486] Elapsed 0m 0s (remain 21m 2s) Loss: 0.0070(0.0070) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2486] Elapsed 0m 17s (remain 7m 1s) Loss: 0.0120(0.0186) Grad: 28600.1816  LR: 0.00000846  \n","Epoch: [2][200/2486] Elapsed 0m 35s (remain 6m 45s) Loss: 0.0093(0.0196) Grad: 38209.8281  LR: 0.00000835  \n","Epoch: [2][300/2486] Elapsed 0m 52s (remain 6m 21s) Loss: 0.0173(0.0193) Grad: 5525.1074  LR: 0.00000823  \n","Epoch: [2][400/2486] Elapsed 1m 9s (remain 6m 0s) Loss: 0.0159(0.0203) Grad: 3406.3054  LR: 0.00000810  \n","Epoch: [2][500/2486] Elapsed 1m 26s (remain 5m 41s) Loss: 0.0282(0.0203) Grad: 23613.3105  LR: 0.00000798  \n","Epoch: [2][600/2486] Elapsed 1m 43s (remain 5m 23s) Loss: 0.0333(0.0203) Grad: 38062.2031  LR: 0.00000785  \n","Epoch: [2][700/2486] Elapsed 1m 59s (remain 5m 5s) Loss: 0.0097(0.0203) Grad: 34185.7852  LR: 0.00000772  \n","Epoch: [2][800/2486] Elapsed 2m 16s (remain 4m 47s) Loss: 0.0104(0.0200) Grad: 12952.2197  LR: 0.00000758  \n","Epoch: [2][900/2486] Elapsed 2m 33s (remain 4m 30s) Loss: 0.0331(0.0200) Grad: 48710.2500  LR: 0.00000745  \n","Epoch: [2][1000/2486] Elapsed 2m 50s (remain 4m 12s) Loss: 0.0110(0.0199) Grad: 4623.3862  LR: 0.00000731  \n","Epoch: [2][1100/2486] Elapsed 3m 7s (remain 3m 55s) Loss: 0.0148(0.0200) Grad: 3320.6545  LR: 0.00000716  \n","Epoch: [2][1200/2486] Elapsed 3m 24s (remain 3m 38s) Loss: 0.0079(0.0199) Grad: 3600.4658  LR: 0.00000702  \n","Epoch: [2][1300/2486] Elapsed 3m 40s (remain 3m 21s) Loss: 0.0189(0.0199) Grad: 16910.0996  LR: 0.00000687  \n","Epoch: [2][1400/2486] Elapsed 3m 57s (remain 3m 4s) Loss: 0.0116(0.0198) Grad: 3461.2366  LR: 0.00000673  \n","Epoch: [2][1500/2486] Elapsed 4m 14s (remain 2m 46s) Loss: 0.0566(0.0198) Grad: 77061.1016  LR: 0.00000658  \n","Epoch: [2][1600/2486] Elapsed 4m 31s (remain 2m 29s) Loss: 0.0106(0.0198) Grad: 27356.6562  LR: 0.00000642  \n","Epoch: [2][1700/2486] Elapsed 4m 47s (remain 2m 12s) Loss: 0.0242(0.0198) Grad: 25135.9688  LR: 0.00000627  \n","Epoch: [2][1800/2486] Elapsed 5m 4s (remain 1m 55s) Loss: 0.0282(0.0198) Grad: 55193.6445  LR: 0.00000612  \n","Epoch: [2][1900/2486] Elapsed 5m 21s (remain 1m 38s) Loss: 0.0148(0.0197) Grad: 40449.7734  LR: 0.00000596  \n","Epoch: [2][2000/2486] Elapsed 5m 38s (remain 1m 22s) Loss: 0.0117(0.0196) Grad: 39198.7617  LR: 0.00000581  \n","Epoch: [2][2100/2486] Elapsed 5m 55s (remain 1m 5s) Loss: 0.0263(0.0195) Grad: 99161.4141  LR: 0.00000565  \n","Epoch: [2][2200/2486] Elapsed 6m 12s (remain 0m 48s) Loss: 0.0407(0.0194) Grad: inf  LR: 0.00000549  \n","Epoch: [2][2300/2486] Elapsed 6m 29s (remain 0m 31s) Loss: 0.0171(0.0194) Grad: 12192.5938  LR: 0.00000533  \n","Epoch: [2][2400/2486] Elapsed 6m 46s (remain 0m 14s) Loss: 0.0275(0.0193) Grad: 64712.5195  LR: 0.00000517  \n","Epoch: [2][2485/2486] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0108(0.0193) Grad: 14780.9873  LR: 0.00000504  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 44s) Loss: 0.0726(0.0726) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.1448(0.0978) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0193  avg_val_loss: 0.0973  time: 432s\n","Epoch 2 - Score: 0.8055\n","Epoch 2 - Save Best Score: 0.8055 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0657(0.0973) \n","Epoch: [3][0/2486] Elapsed 0m 0s (remain 20m 52s) Loss: 0.0091(0.0091) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2486] Elapsed 0m 17s (remain 7m 1s) Loss: 0.0316(0.0171) Grad: 19703.1270  LR: 0.00000488  \n","Epoch: [3][200/2486] Elapsed 0m 35s (remain 6m 43s) Loss: 0.0237(0.0157) Grad: 37979.6523  LR: 0.00000472  \n","Epoch: [3][300/2486] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0099(0.0163) Grad: 13734.6455  LR: 0.00000456  \n","Epoch: [3][400/2486] Elapsed 1m 9s (remain 6m 1s) Loss: 0.0232(0.0159) Grad: 10360.5039  LR: 0.00000440  \n","Epoch: [3][500/2486] Elapsed 1m 26s (remain 5m 42s) Loss: 0.0258(0.0157) Grad: 12802.2236  LR: 0.00000425  \n","Epoch: [3][600/2486] Elapsed 1m 43s (remain 5m 24s) Loss: 0.0138(0.0160) Grad: 16650.2559  LR: 0.00000409  \n","Epoch: [3][700/2486] Elapsed 2m 0s (remain 5m 6s) Loss: 0.0175(0.0159) Grad: 30875.1641  LR: 0.00000393  \n","Epoch: [3][800/2486] Elapsed 2m 17s (remain 4m 49s) Loss: 0.0078(0.0157) Grad: 5914.8213  LR: 0.00000378  \n","Epoch: [3][900/2486] Elapsed 2m 34s (remain 4m 31s) Loss: 0.0243(0.0156) Grad: 10058.4141  LR: 0.00000363  \n","Epoch: [3][1000/2486] Elapsed 2m 51s (remain 4m 13s) Loss: 0.0094(0.0157) Grad: 35493.3125  LR: 0.00000348  \n","Epoch: [3][1100/2486] Elapsed 3m 8s (remain 3m 56s) Loss: 0.0041(0.0156) Grad: 9264.9521  LR: 0.00000332  \n","Epoch: [3][1200/2486] Elapsed 3m 24s (remain 3m 39s) Loss: 0.0552(0.0156) Grad: 23262.8574  LR: 0.00000318  \n","Epoch: [3][1300/2486] Elapsed 3m 41s (remain 3m 22s) Loss: 0.0327(0.0155) Grad: 10563.7217  LR: 0.00000303  \n","Epoch: [3][1400/2486] Elapsed 3m 58s (remain 3m 4s) Loss: 0.0142(0.0155) Grad: 42135.3008  LR: 0.00000288  \n","Epoch: [3][1500/2486] Elapsed 4m 15s (remain 2m 47s) Loss: 0.0140(0.0156) Grad: 25357.3047  LR: 0.00000274  \n","Epoch: [3][1600/2486] Elapsed 4m 32s (remain 2m 30s) Loss: 0.0169(0.0155) Grad: 36752.5156  LR: 0.00000260  \n","Epoch: [3][1700/2486] Elapsed 4m 49s (remain 2m 13s) Loss: 0.0103(0.0154) Grad: 10080.1289  LR: 0.00000246  \n","Epoch: [3][1800/2486] Elapsed 5m 6s (remain 1m 56s) Loss: 0.0088(0.0155) Grad: 18061.1406  LR: 0.00000233  \n","Epoch: [3][1900/2486] Elapsed 5m 23s (remain 1m 39s) Loss: 0.0108(0.0154) Grad: 10604.5234  LR: 0.00000219  \n","Epoch: [3][2000/2486] Elapsed 5m 40s (remain 1m 22s) Loss: 0.0199(0.0154) Grad: 33053.2617  LR: 0.00000206  \n","Epoch: [3][2100/2486] Elapsed 5m 57s (remain 1m 5s) Loss: 0.0029(0.0152) Grad: 2666.3232  LR: 0.00000194  \n","Epoch: [3][2200/2486] Elapsed 6m 14s (remain 0m 48s) Loss: 0.0100(0.0152) Grad: 15035.6289  LR: 0.00000181  \n","Epoch: [3][2300/2486] Elapsed 6m 31s (remain 0m 31s) Loss: 0.0157(0.0152) Grad: 21858.1406  LR: 0.00000169  \n","Epoch: [3][2400/2486] Elapsed 6m 48s (remain 0m 14s) Loss: 0.0090(0.0152) Grad: 25243.0625  LR: 0.00000158  \n","Epoch: [3][2485/2486] Elapsed 7m 2s (remain 0m 0s) Loss: 0.0147(0.0152) Grad: 31368.0879  LR: 0.00000148  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 44s) Loss: 0.0713(0.0713) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.1414(0.0955) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0152  avg_val_loss: 0.0952  time: 434s\n","Epoch 3 - Score: 0.8068\n","Epoch 3 - Save Best Score: 0.8068 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0636(0.0952) \n","Epoch: [4][0/2486] Elapsed 0m 0s (remain 21m 1s) Loss: 0.0159(0.0159) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2486] Elapsed 0m 18s (remain 7m 8s) Loss: 0.0069(0.0133) Grad: 15929.7109  LR: 0.00000137  \n","Epoch: [4][200/2486] Elapsed 0m 35s (remain 6m 46s) Loss: 0.0164(0.0126) Grad: 29570.4902  LR: 0.00000126  \n","Epoch: [4][300/2486] Elapsed 0m 52s (remain 6m 22s) Loss: 0.0172(0.0123) Grad: 16503.4746  LR: 0.00000116  \n","Epoch: [4][400/2486] Elapsed 1m 9s (remain 6m 2s) Loss: 0.0044(0.0122) Grad: 11250.2070  LR: 0.00000106  \n","Epoch: [4][500/2486] Elapsed 1m 26s (remain 5m 43s) Loss: 0.0093(0.0121) Grad: 8879.2148  LR: 0.00000096  \n","Epoch: [4][600/2486] Elapsed 1m 43s (remain 5m 24s) Loss: 0.0128(0.0120) Grad: 7618.5571  LR: 0.00000087  \n","Epoch: [4][700/2486] Elapsed 2m 0s (remain 5m 6s) Loss: 0.0045(0.0118) Grad: 4569.9663  LR: 0.00000078  \n","Epoch: [4][800/2486] Elapsed 2m 17s (remain 4m 49s) Loss: 0.0050(0.0117) Grad: 3713.3352  LR: 0.00000070  \n","Epoch: [4][900/2486] Elapsed 2m 34s (remain 4m 31s) Loss: 0.0190(0.0118) Grad: 24098.6406  LR: 0.00000062  \n","Epoch: [4][1000/2486] Elapsed 2m 51s (remain 4m 14s) Loss: 0.0064(0.0119) Grad: 2710.6125  LR: 0.00000055  \n","Epoch: [4][1100/2486] Elapsed 3m 8s (remain 3m 56s) Loss: 0.0108(0.0117) Grad: 11170.6094  LR: 0.00000048  \n","Epoch: [4][1200/2486] Elapsed 3m 25s (remain 3m 39s) Loss: 0.0255(0.0117) Grad: 17904.3555  LR: 0.00000041  \n","Epoch: [4][1300/2486] Elapsed 3m 42s (remain 3m 22s) Loss: 0.0123(0.0116) Grad: 15537.6064  LR: 0.00000035  \n","Epoch: [4][1400/2486] Elapsed 3m 59s (remain 3m 5s) Loss: 0.0008(0.0115) Grad: 2759.5730  LR: 0.00000029  \n","Epoch: [4][1500/2486] Elapsed 4m 16s (remain 2m 48s) Loss: 0.0030(0.0115) Grad: 4428.1191  LR: 0.00000024  \n","Epoch: [4][1600/2486] Elapsed 4m 33s (remain 2m 31s) Loss: 0.0097(0.0115) Grad: 7045.0381  LR: 0.00000020  \n","Epoch: [4][1700/2486] Elapsed 4m 50s (remain 2m 14s) Loss: 0.0109(0.0115) Grad: 7978.3218  LR: 0.00000015  \n","Epoch: [4][1800/2486] Elapsed 5m 7s (remain 1m 57s) Loss: 0.0065(0.0115) Grad: 3937.5359  LR: 0.00000012  \n","Epoch: [4][1900/2486] Elapsed 5m 24s (remain 1m 39s) Loss: 0.0109(0.0114) Grad: 33810.9414  LR: 0.00000009  \n","Epoch: [4][2000/2486] Elapsed 5m 41s (remain 1m 22s) Loss: 0.0053(0.0114) Grad: 7685.6162  LR: 0.00000006  \n","Epoch: [4][2100/2486] Elapsed 5m 58s (remain 1m 5s) Loss: 0.0076(0.0115) Grad: 14190.0312  LR: 0.00000004  \n","Epoch: [4][2200/2486] Elapsed 6m 15s (remain 0m 48s) Loss: 0.0034(0.0114) Grad: 28943.7305  LR: 0.00000002  \n","Epoch: [4][2300/2486] Elapsed 6m 32s (remain 0m 31s) Loss: 0.0093(0.0115) Grad: 14169.7832  LR: 0.00000001  \n","Epoch: [4][2400/2486] Elapsed 6m 49s (remain 0m 14s) Loss: 0.0115(0.0114) Grad: 17987.4746  LR: 0.00000000  \n","Epoch: [4][2485/2486] Elapsed 7m 4s (remain 0m 0s) Loss: 0.0065(0.0114) Grad: 13005.7783  LR: 0.00000000  \n","EVAL: [0/119] Elapsed 0m 0s (remain 0m 44s) Loss: 0.0741(0.0741) \n","EVAL: [100/119] Elapsed 0m 9s (remain 0m 1s) Loss: 0.1458(0.0982) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0114  avg_val_loss: 0.0977  time: 436s\n","Epoch 4 - Score: 0.8078\n","Epoch 4 - Save Best Score: 0.8078 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [118/119] Elapsed 0m 10s (remain 0m 0s) Loss: 0.0660(0.0977) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 17 result ==========\n","Score: 0.8078\n","========== fold: 18 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2476] Elapsed 0m 0s (remain 20m 20s) Loss: 1.7021(1.7021) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2476] Elapsed 0m 18s (remain 7m 10s) Loss: 0.3057(0.2772) Grad: 43439.9453  LR: 0.00001000  \n","Epoch: [1][200/2476] Elapsed 0m 35s (remain 6m 42s) Loss: 0.0953(0.1888) Grad: 3318.4761  LR: 0.00000999  \n","Epoch: [1][300/2476] Elapsed 0m 52s (remain 6m 20s) Loss: 0.0508(0.1531) Grad: 4884.3818  LR: 0.00000998  \n","Epoch: [1][400/2476] Elapsed 1m 9s (remain 6m 0s) Loss: 0.0568(0.1340) Grad: 10508.8164  LR: 0.00000997  \n","Epoch: [1][500/2476] Elapsed 1m 26s (remain 5m 42s) Loss: 0.0708(0.1187) Grad: 4818.9585  LR: 0.00000995  \n","Epoch: [1][600/2476] Elapsed 1m 43s (remain 5m 23s) Loss: 0.0625(0.1069) Grad: 2174.1736  LR: 0.00000992  \n","Epoch: [1][700/2476] Elapsed 2m 0s (remain 5m 5s) Loss: 0.0371(0.0976) Grad: 3730.9045  LR: 0.00000989  \n","Epoch: [1][800/2476] Elapsed 2m 17s (remain 4m 48s) Loss: 0.0653(0.0917) Grad: 15563.0205  LR: 0.00000986  \n","Epoch: [1][900/2476] Elapsed 2m 34s (remain 4m 30s) Loss: 0.1256(0.0863) Grad: 22080.8672  LR: 0.00000982  \n","Epoch: [1][1000/2476] Elapsed 2m 51s (remain 4m 13s) Loss: 0.0264(0.0825) Grad: 2678.3064  LR: 0.00000977  \n","Epoch: [1][1100/2476] Elapsed 3m 8s (remain 3m 55s) Loss: 0.0161(0.0786) Grad: 2758.4360  LR: 0.00000972  \n","Epoch: [1][1200/2476] Elapsed 3m 26s (remain 3m 38s) Loss: 0.0275(0.0754) Grad: 7408.7622  LR: 0.00000967  \n","Epoch: [1][1300/2476] Elapsed 3m 43s (remain 3m 21s) Loss: 0.0324(0.0721) Grad: 5506.1709  LR: 0.00000961  \n","Epoch: [1][1400/2476] Elapsed 4m 0s (remain 3m 4s) Loss: 0.0169(0.0693) Grad: 3267.6355  LR: 0.00000954  \n","Epoch: [1][1500/2476] Elapsed 4m 17s (remain 2m 47s) Loss: 0.0439(0.0669) Grad: 2474.7771  LR: 0.00000947  \n","Epoch: [1][1600/2476] Elapsed 4m 34s (remain 2m 29s) Loss: 0.0401(0.0644) Grad: 7546.4976  LR: 0.00000940  \n","Epoch: [1][1700/2476] Elapsed 4m 51s (remain 2m 12s) Loss: 0.0463(0.0624) Grad: 8028.9727  LR: 0.00000932  \n","Epoch: [1][1800/2476] Elapsed 5m 8s (remain 1m 55s) Loss: 0.0120(0.0607) Grad: 1102.7274  LR: 0.00000924  \n","Epoch: [1][1900/2476] Elapsed 5m 25s (remain 1m 38s) Loss: 0.0464(0.0592) Grad: 10444.0537  LR: 0.00000915  \n","Epoch: [1][2000/2476] Elapsed 5m 42s (remain 1m 21s) Loss: 0.0271(0.0578) Grad: 8668.7256  LR: 0.00000906  \n","Epoch: [1][2100/2476] Elapsed 5m 59s (remain 1m 4s) Loss: 0.0457(0.0563) Grad: 6273.7988  LR: 0.00000897  \n","Epoch: [1][2200/2476] Elapsed 6m 15s (remain 0m 46s) Loss: 0.0181(0.0549) Grad: 11047.6738  LR: 0.00000887  \n","Epoch: [1][2300/2476] Elapsed 6m 33s (remain 0m 29s) Loss: 0.0137(0.0537) Grad: 7721.4419  LR: 0.00000877  \n","Epoch: [1][2400/2476] Elapsed 6m 49s (remain 0m 12s) Loss: 0.0151(0.0525) Grad: 2769.9990  LR: 0.00000866  \n","Epoch: [1][2475/2476] Elapsed 7m 2s (remain 0m 0s) Loss: 0.0556(0.0516) Grad: 4161.9619  LR: 0.00000858  \n","EVAL: [0/129] Elapsed 0m 0s (remain 0m 48s) Loss: 0.0633(0.0633) \n","EVAL: [100/129] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1488(0.1071) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0516  avg_val_loss: 0.1075  time: 435s\n","Epoch 1 - Score: 0.8069\n","Epoch 1 - Save Best Score: 0.8069 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [128/129] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0327(0.1075) \n","Epoch: [2][0/2476] Elapsed 0m 0s (remain 21m 44s) Loss: 0.0493(0.0493) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2476] Elapsed 0m 18s (remain 7m 14s) Loss: 0.0218(0.0197) Grad: 43047.1445  LR: 0.00000846  \n","Epoch: [2][200/2476] Elapsed 0m 36s (remain 6m 51s) Loss: 0.0289(0.0194) Grad: 64970.1250  LR: 0.00000835  \n","Epoch: [2][300/2476] Elapsed 0m 53s (remain 6m 25s) Loss: 0.0176(0.0191) Grad: 50462.6719  LR: 0.00000823  \n","Epoch: [2][400/2476] Elapsed 1m 10s (remain 6m 3s) Loss: 0.0094(0.0191) Grad: 17694.8652  LR: 0.00000810  \n","Epoch: [2][500/2476] Elapsed 1m 27s (remain 5m 43s) Loss: 0.0170(0.0187) Grad: 13954.0117  LR: 0.00000798  \n","Epoch: [2][600/2476] Elapsed 1m 44s (remain 5m 24s) Loss: 0.0164(0.0183) Grad: 13948.9678  LR: 0.00000785  \n","Epoch: [2][700/2476] Elapsed 2m 0s (remain 5m 6s) Loss: 0.0200(0.0182) Grad: 66549.1094  LR: 0.00000771  \n","Epoch: [2][800/2476] Elapsed 2m 17s (remain 4m 48s) Loss: 0.0154(0.0182) Grad: 64789.7617  LR: 0.00000758  \n","Epoch: [2][900/2476] Elapsed 2m 34s (remain 4m 30s) Loss: 0.0295(0.0181) Grad: 81482.3750  LR: 0.00000744  \n","Epoch: [2][1000/2476] Elapsed 2m 51s (remain 4m 12s) Loss: 0.0346(0.0180) Grad: 43215.2930  LR: 0.00000730  \n","Epoch: [2][1100/2476] Elapsed 3m 8s (remain 3m 55s) Loss: 0.0141(0.0179) Grad: 11802.9648  LR: 0.00000716  \n","Epoch: [2][1200/2476] Elapsed 3m 25s (remain 3m 38s) Loss: 0.0211(0.0178) Grad: 41997.2891  LR: 0.00000701  \n","Epoch: [2][1300/2476] Elapsed 3m 42s (remain 3m 20s) Loss: 0.0122(0.0178) Grad: 22338.7422  LR: 0.00000687  \n","Epoch: [2][1400/2476] Elapsed 3m 59s (remain 3m 3s) Loss: 0.0240(0.0178) Grad: 60997.8398  LR: 0.00000672  \n","Epoch: [2][1500/2476] Elapsed 4m 16s (remain 2m 46s) Loss: 0.0119(0.0178) Grad: 6337.5259  LR: 0.00000657  \n","Epoch: [2][1600/2476] Elapsed 4m 33s (remain 2m 29s) Loss: 0.0043(0.0178) Grad: 11126.3633  LR: 0.00000642  \n","Epoch: [2][1700/2476] Elapsed 4m 50s (remain 2m 12s) Loss: 0.0111(0.0179) Grad: 22046.4434  LR: 0.00000626  \n","Epoch: [2][1800/2476] Elapsed 5m 7s (remain 1m 55s) Loss: 0.0196(0.0179) Grad: 21687.7500  LR: 0.00000611  \n","Epoch: [2][1900/2476] Elapsed 5m 24s (remain 1m 38s) Loss: 0.0144(0.0178) Grad: 13674.2207  LR: 0.00000595  \n","Epoch: [2][2000/2476] Elapsed 5m 41s (remain 1m 21s) Loss: 0.0143(0.0178) Grad: 31819.4316  LR: 0.00000579  \n","Epoch: [2][2100/2476] Elapsed 5m 58s (remain 1m 3s) Loss: 0.0394(0.0178) Grad: 69837.6641  LR: 0.00000564  \n","Epoch: [2][2200/2476] Elapsed 6m 15s (remain 0m 46s) Loss: 0.0127(0.0178) Grad: 33929.1523  LR: 0.00000548  \n","Epoch: [2][2300/2476] Elapsed 6m 32s (remain 0m 29s) Loss: 0.0085(0.0177) Grad: 7668.1377  LR: 0.00000532  \n","Epoch: [2][2400/2476] Elapsed 6m 49s (remain 0m 12s) Loss: 0.0314(0.0177) Grad: 16839.7480  LR: 0.00000516  \n","Epoch: [2][2475/2476] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0192(0.0178) Grad: 7348.9146  LR: 0.00000504  \n","EVAL: [0/129] Elapsed 0m 0s (remain 0m 47s) Loss: 0.0565(0.0565) \n","EVAL: [100/129] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1329(0.0978) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0178  avg_val_loss: 0.0980  time: 434s\n","Epoch 2 - Score: 0.8177\n","Epoch 2 - Save Best Score: 0.8177 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [128/129] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0326(0.0980) \n","Epoch: [3][0/2476] Elapsed 0m 0s (remain 21m 3s) Loss: 0.0151(0.0151) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2476] Elapsed 0m 17s (remain 7m 0s) Loss: 0.0031(0.0143) Grad: 18174.4121  LR: 0.00000488  \n","Epoch: [3][200/2476] Elapsed 0m 35s (remain 6m 44s) Loss: 0.0067(0.0147) Grad: 4936.2964  LR: 0.00000472  \n","Epoch: [3][300/2476] Elapsed 0m 52s (remain 6m 21s) Loss: 0.0211(0.0148) Grad: 13098.9824  LR: 0.00000456  \n","Epoch: [3][400/2476] Elapsed 1m 9s (remain 6m 1s) Loss: 0.0123(0.0147) Grad: 50262.3320  LR: 0.00000440  \n","Epoch: [3][500/2476] Elapsed 1m 26s (remain 5m 42s) Loss: 0.0153(0.0144) Grad: 27978.7754  LR: 0.00000424  \n","Epoch: [3][600/2476] Elapsed 1m 43s (remain 5m 23s) Loss: 0.0146(0.0145) Grad: 43312.1484  LR: 0.00000409  \n","Epoch: [3][700/2476] Elapsed 2m 0s (remain 5m 5s) Loss: 0.0104(0.0143) Grad: 49591.2930  LR: 0.00000393  \n","Epoch: [3][800/2476] Elapsed 2m 17s (remain 4m 47s) Loss: 0.0178(0.0144) Grad: 96886.1953  LR: 0.00000378  \n","Epoch: [3][900/2476] Elapsed 2m 34s (remain 4m 30s) Loss: 0.0208(0.0145) Grad: 38405.1016  LR: 0.00000362  \n","Epoch: [3][1000/2476] Elapsed 2m 51s (remain 4m 13s) Loss: 0.0240(0.0145) Grad: 68728.6641  LR: 0.00000347  \n","Epoch: [3][1100/2476] Elapsed 3m 8s (remain 3m 55s) Loss: 0.0162(0.0145) Grad: 8837.3896  LR: 0.00000332  \n","Epoch: [3][1200/2476] Elapsed 3m 25s (remain 3m 38s) Loss: 0.0209(0.0145) Grad: 36769.1055  LR: 0.00000317  \n","Epoch: [3][1300/2476] Elapsed 3m 42s (remain 3m 21s) Loss: 0.0075(0.0143) Grad: 15151.5693  LR: 0.00000302  \n","Epoch: [3][1400/2476] Elapsed 4m 0s (remain 3m 4s) Loss: 0.0241(0.0144) Grad: 52198.0977  LR: 0.00000288  \n","Epoch: [3][1500/2476] Elapsed 4m 17s (remain 2m 46s) Loss: 0.0230(0.0145) Grad: 58943.1250  LR: 0.00000273  \n","Epoch: [3][1600/2476] Elapsed 4m 34s (remain 2m 29s) Loss: 0.0220(0.0144) Grad: 55660.7617  LR: 0.00000259  \n","Epoch: [3][1700/2476] Elapsed 4m 50s (remain 2m 12s) Loss: 0.0168(0.0145) Grad: 44527.8008  LR: 0.00000245  \n","Epoch: [3][1800/2476] Elapsed 5m 8s (remain 1m 55s) Loss: 0.0246(0.0145) Grad: 34256.0820  LR: 0.00000232  \n","Epoch: [3][1900/2476] Elapsed 5m 25s (remain 1m 38s) Loss: 0.0325(0.0144) Grad: 67490.2344  LR: 0.00000219  \n","Epoch: [3][2000/2476] Elapsed 5m 42s (remain 1m 21s) Loss: 0.0214(0.0144) Grad: 10776.1035  LR: 0.00000206  \n","Epoch: [3][2100/2476] Elapsed 5m 59s (remain 1m 4s) Loss: 0.0077(0.0144) Grad: 4808.7192  LR: 0.00000193  \n","Epoch: [3][2200/2476] Elapsed 6m 16s (remain 0m 47s) Loss: 0.0109(0.0144) Grad: 6935.4312  LR: 0.00000180  \n","Epoch: [3][2300/2476] Elapsed 6m 33s (remain 0m 29s) Loss: 0.0104(0.0144) Grad: 28438.4727  LR: 0.00000168  \n","Epoch: [3][2400/2476] Elapsed 6m 50s (remain 0m 12s) Loss: 0.0095(0.0144) Grad: 3909.4724  LR: 0.00000157  \n","Epoch: [3][2475/2476] Elapsed 7m 3s (remain 0m 0s) Loss: 0.0098(0.0145) Grad: 6095.8613  LR: 0.00000148  \n","EVAL: [0/129] Elapsed 0m 0s (remain 0m 52s) Loss: 0.0584(0.0584) \n","EVAL: [100/129] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1389(0.0994) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0145  avg_val_loss: 0.0999  time: 435s\n","Epoch 3 - Score: 0.8276\n","Epoch 3 - Save Best Score: 0.8276 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [128/129] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0331(0.0999) \n","Epoch: [4][0/2476] Elapsed 0m 0s (remain 20m 42s) Loss: 0.0096(0.0096) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2476] Elapsed 0m 17s (remain 6m 59s) Loss: 0.0100(0.0139) Grad: 43325.0352  LR: 0.00000137  \n","Epoch: [4][200/2476] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0120(0.0128) Grad: 20522.3184  LR: 0.00000126  \n","Epoch: [4][300/2476] Elapsed 0m 52s (remain 6m 20s) Loss: 0.0131(0.0128) Grad: 12012.0312  LR: 0.00000116  \n","Epoch: [4][400/2476] Elapsed 1m 9s (remain 6m 0s) Loss: 0.0092(0.0126) Grad: 6311.1279  LR: 0.00000106  \n","Epoch: [4][500/2476] Elapsed 1m 26s (remain 5m 41s) Loss: 0.0141(0.0125) Grad: 69331.4141  LR: 0.00000096  \n","Epoch: [4][600/2476] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0053(0.0127) Grad: 38398.3398  LR: 0.00000087  \n","Epoch: [4][700/2476] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0126(0.0124) Grad: 16379.8623  LR: 0.00000078  \n","Epoch: [4][800/2476] Elapsed 2m 17s (remain 4m 47s) Loss: 0.0114(0.0122) Grad: 14518.3506  LR: 0.00000070  \n","Epoch: [4][900/2476] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0072(0.0123) Grad: 11526.2617  LR: 0.00000062  \n","Epoch: [4][1000/2476] Elapsed 2m 51s (remain 4m 12s) Loss: 0.0119(0.0122) Grad: 11176.4385  LR: 0.00000054  \n","Epoch: [4][1100/2476] Elapsed 3m 8s (remain 3m 54s) Loss: 0.0175(0.0121) Grad: 52277.2734  LR: 0.00000047  \n","Epoch: [4][1200/2476] Elapsed 3m 25s (remain 3m 37s) Loss: 0.0173(0.0121) Grad: 36746.3750  LR: 0.00000041  \n","Epoch: [4][1300/2476] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0185(0.0121) Grad: 31430.9609  LR: 0.00000035  \n","Epoch: [4][1400/2476] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0073(0.0120) Grad: 6928.0464  LR: 0.00000029  \n","Epoch: [4][1500/2476] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0164(0.0120) Grad: 21677.8555  LR: 0.00000024  \n","Epoch: [4][1600/2476] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0069(0.0120) Grad: 11023.0234  LR: 0.00000019  \n","Epoch: [4][1700/2476] Elapsed 4m 49s (remain 2m 11s) Loss: 0.0151(0.0120) Grad: 62182.9922  LR: 0.00000015  \n","Epoch: [4][1800/2476] Elapsed 5m 6s (remain 1m 54s) Loss: 0.0346(0.0119) Grad: 27552.1504  LR: 0.00000012  \n","Epoch: [4][1900/2476] Elapsed 5m 23s (remain 1m 37s) Loss: 0.0135(0.0119) Grad: 34015.9844  LR: 0.00000008  \n","Epoch: [4][2000/2476] Elapsed 5m 40s (remain 1m 20s) Loss: 0.0196(0.0120) Grad: 56459.3945  LR: 0.00000006  \n","Epoch: [4][2100/2476] Elapsed 5m 57s (remain 1m 3s) Loss: 0.0206(0.0120) Grad: 28747.9004  LR: 0.00000004  \n","Epoch: [4][2200/2476] Elapsed 6m 14s (remain 0m 46s) Loss: 0.0118(0.0120) Grad: 31420.2305  LR: 0.00000002  \n","Epoch: [4][2300/2476] Elapsed 6m 31s (remain 0m 29s) Loss: 0.0043(0.0120) Grad: 33728.5586  LR: 0.00000001  \n","Epoch: [4][2400/2476] Elapsed 6m 48s (remain 0m 12s) Loss: 0.0101(0.0120) Grad: 37866.0039  LR: 0.00000000  \n","Epoch: [4][2475/2476] Elapsed 7m 0s (remain 0m 0s) Loss: 0.0416(0.0120) Grad: 35209.9297  LR: 0.00000000  \n","EVAL: [0/129] Elapsed 0m 0s (remain 0m 48s) Loss: 0.0580(0.0580) \n","EVAL: [100/129] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1369(0.0986) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0120  avg_val_loss: 0.0989  time: 433s\n","Epoch 4 - Score: 0.8294\n","Epoch 4 - Save Best Score: 0.8294 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [128/129] Elapsed 0m 11s (remain 0m 0s) Loss: 0.0327(0.0989) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 18 result ==========\n","Score: 0.8294\n","========== fold: 19 training ==========\n","Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2480] Elapsed 0m 0s (remain 19m 43s) Loss: 1.5273(1.5273) Grad: nan  LR: 0.00000020  \n","Epoch: [1][100/2480] Elapsed 0m 18s (remain 7m 4s) Loss: 0.0580(0.2297) Grad: 4400.6196  LR: 0.00001000  \n","Epoch: [1][200/2480] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0443(0.1707) Grad: 1537.6082  LR: 0.00000999  \n","Epoch: [1][300/2480] Elapsed 0m 52s (remain 6m 19s) Loss: 0.0995(0.1378) Grad: 19737.4160  LR: 0.00000998  \n","Epoch: [1][400/2480] Elapsed 1m 9s (remain 6m 1s) Loss: 0.0429(0.1259) Grad: 1577.3210  LR: 0.00000997  \n","Epoch: [1][500/2480] Elapsed 1m 26s (remain 5m 43s) Loss: 0.1152(0.1112) Grad: 21302.3164  LR: 0.00000995  \n","Epoch: [1][600/2480] Elapsed 1m 44s (remain 5m 25s) Loss: 0.0279(0.1028) Grad: 10284.1533  LR: 0.00000992  \n","Epoch: [1][700/2480] Elapsed 2m 1s (remain 5m 7s) Loss: 0.0480(0.0947) Grad: 3783.7202  LR: 0.00000989  \n","Epoch: [1][800/2480] Elapsed 2m 18s (remain 4m 49s) Loss: 0.0184(0.0888) Grad: 1712.5676  LR: 0.00000986  \n","Epoch: [1][900/2480] Elapsed 2m 35s (remain 4m 31s) Loss: 0.0254(0.0844) Grad: 5852.0088  LR: 0.00000982  \n","Epoch: [1][1000/2480] Elapsed 2m 52s (remain 4m 14s) Loss: 0.0636(0.0796) Grad: 9541.0176  LR: 0.00000977  \n","Epoch: [1][1100/2480] Elapsed 3m 8s (remain 3m 56s) Loss: 0.0381(0.0755) Grad: 2488.1379  LR: 0.00000972  \n","Epoch: [1][1200/2480] Elapsed 3m 26s (remain 3m 39s) Loss: 0.0342(0.0725) Grad: 1278.6151  LR: 0.00000967  \n","Epoch: [1][1300/2480] Elapsed 3m 42s (remain 3m 21s) Loss: 0.0231(0.0699) Grad: 5093.4355  LR: 0.00000961  \n","Epoch: [1][1400/2480] Elapsed 3m 59s (remain 3m 4s) Loss: 0.0243(0.0670) Grad: 2831.4604  LR: 0.00000954  \n","Epoch: [1][1500/2480] Elapsed 4m 16s (remain 2m 47s) Loss: 0.0283(0.0647) Grad: 6885.2563  LR: 0.00000948  \n","Epoch: [1][1600/2480] Elapsed 4m 33s (remain 2m 30s) Loss: 0.0386(0.0631) Grad: 3386.4858  LR: 0.00000940  \n","Epoch: [1][1700/2480] Elapsed 4m 50s (remain 2m 13s) Loss: 0.0277(0.0618) Grad: 1065.2322  LR: 0.00000933  \n","Epoch: [1][1800/2480] Elapsed 5m 7s (remain 1m 55s) Loss: 0.0479(0.0601) Grad: 1605.2319  LR: 0.00000924  \n","Epoch: [1][1900/2480] Elapsed 5m 24s (remain 1m 38s) Loss: 0.0629(0.0586) Grad: 14492.3262  LR: 0.00000916  \n","Epoch: [1][2000/2480] Elapsed 5m 41s (remain 1m 21s) Loss: 0.0186(0.0572) Grad: 4572.6553  LR: 0.00000907  \n","Epoch: [1][2100/2480] Elapsed 5m 58s (remain 1m 4s) Loss: 0.0394(0.0558) Grad: 18660.7422  LR: 0.00000897  \n","Epoch: [1][2200/2480] Elapsed 6m 15s (remain 0m 47s) Loss: 0.0254(0.0544) Grad: 6889.1978  LR: 0.00000887  \n","Epoch: [1][2300/2480] Elapsed 6m 32s (remain 0m 30s) Loss: 0.0378(0.0531) Grad: 18863.9492  LR: 0.00000877  \n","Epoch: [1][2400/2480] Elapsed 6m 49s (remain 0m 13s) Loss: 0.0456(0.0520) Grad: 15776.7383  LR: 0.00000866  \n","Epoch: [1][2479/2480] Elapsed 7m 3s (remain 0m 0s) Loss: 0.0389(0.0512) Grad: 18913.1094  LR: 0.00000858  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 47s) Loss: 0.0639(0.0639) \n","EVAL: [100/125] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1174(0.0859) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0512  avg_val_loss: 0.0865  time: 435s\n","Epoch 1 - Score: 0.7975\n","Epoch 1 - Save Best Score: 0.7975 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [124/125] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1010(0.0865) \n","Epoch: [2][0/2480] Elapsed 0m 0s (remain 20m 32s) Loss: 0.0226(0.0226) Grad: nan  LR: 0.00000858  \n","Epoch: [2][100/2480] Elapsed 0m 17s (remain 7m 0s) Loss: 0.0194(0.0210) Grad: 20902.2715  LR: 0.00000846  \n","Epoch: [2][200/2480] Elapsed 0m 35s (remain 6m 41s) Loss: 0.0121(0.0194) Grad: 8658.0977  LR: 0.00000835  \n","Epoch: [2][300/2480] Elapsed 0m 52s (remain 6m 18s) Loss: 0.0144(0.0192) Grad: 38175.0234  LR: 0.00000823  \n","Epoch: [2][400/2480] Elapsed 1m 9s (remain 5m 59s) Loss: 0.0153(0.0185) Grad: 13112.2490  LR: 0.00000810  \n","Epoch: [2][500/2480] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0184(0.0185) Grad: 11025.0557  LR: 0.00000798  \n","Epoch: [2][600/2480] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0264(0.0186) Grad: 26935.5898  LR: 0.00000785  \n","Epoch: [2][700/2480] Elapsed 2m 0s (remain 5m 5s) Loss: 0.0183(0.0182) Grad: 10818.2402  LR: 0.00000772  \n","Epoch: [2][800/2480] Elapsed 2m 17s (remain 4m 47s) Loss: 0.0117(0.0180) Grad: 33850.3711  LR: 0.00000758  \n","Epoch: [2][900/2480] Elapsed 2m 34s (remain 4m 29s) Loss: 0.0264(0.0179) Grad: 23477.7012  LR: 0.00000744  \n","Epoch: [2][1000/2480] Elapsed 2m 50s (remain 4m 12s) Loss: 0.0465(0.0179) Grad: 68655.0234  LR: 0.00000730  \n","Epoch: [2][1100/2480] Elapsed 3m 7s (remain 3m 55s) Loss: 0.0151(0.0178) Grad: 6081.5312  LR: 0.00000716  \n","Epoch: [2][1200/2480] Elapsed 3m 24s (remain 3m 38s) Loss: 0.0195(0.0178) Grad: 52088.2734  LR: 0.00000702  \n","Epoch: [2][1300/2480] Elapsed 3m 41s (remain 3m 21s) Loss: 0.0278(0.0177) Grad: 12116.7686  LR: 0.00000687  \n","Epoch: [2][1400/2480] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0303(0.0178) Grad: 21059.5020  LR: 0.00000672  \n","Epoch: [2][1500/2480] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0496(0.0178) Grad: 54699.2617  LR: 0.00000657  \n","Epoch: [2][1600/2480] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0199(0.0177) Grad: 11390.5762  LR: 0.00000642  \n","Epoch: [2][1700/2480] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0244(0.0177) Grad: 46723.2227  LR: 0.00000627  \n","Epoch: [2][1800/2480] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0321(0.0176) Grad: 52089.8203  LR: 0.00000611  \n","Epoch: [2][1900/2480] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0264(0.0176) Grad: 40345.9219  LR: 0.00000596  \n","Epoch: [2][2000/2480] Elapsed 5m 40s (remain 1m 21s) Loss: 0.0169(0.0176) Grad: 19563.3223  LR: 0.00000580  \n","Epoch: [2][2100/2480] Elapsed 5m 57s (remain 1m 4s) Loss: 0.0075(0.0176) Grad: 6924.6777  LR: 0.00000564  \n","Epoch: [2][2200/2480] Elapsed 6m 14s (remain 0m 47s) Loss: 0.0066(0.0175) Grad: 39664.1523  LR: 0.00000548  \n","Epoch: [2][2300/2480] Elapsed 6m 31s (remain 0m 30s) Loss: 0.0106(0.0176) Grad: 52052.0898  LR: 0.00000532  \n","Epoch: [2][2400/2480] Elapsed 6m 48s (remain 0m 13s) Loss: 0.0048(0.0176) Grad: 37243.9023  LR: 0.00000517  \n","Epoch: [2][2479/2480] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0034(0.0175) Grad: 18107.5625  LR: 0.00000504  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 48s) Loss: 0.0737(0.0737) \n","EVAL: [100/125] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1337(0.0999) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0175  avg_val_loss: 0.1006  time: 433s\n","Epoch 2 - Score: 0.8069\n","Epoch 2 - Save Best Score: 0.8069 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [124/125] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1170(0.1006) \n","Epoch: [3][0/2480] Elapsed 0m 0s (remain 20m 52s) Loss: 0.0124(0.0124) Grad: nan  LR: 0.00000504  \n","Epoch: [3][100/2480] Elapsed 0m 17s (remain 6m 59s) Loss: 0.0129(0.0149) Grad: 35748.7930  LR: 0.00000488  \n","Epoch: [3][200/2480] Elapsed 0m 35s (remain 6m 39s) Loss: 0.0053(0.0146) Grad: 9527.0293  LR: 0.00000472  \n","Epoch: [3][300/2480] Elapsed 0m 52s (remain 6m 17s) Loss: 0.0173(0.0149) Grad: 68514.4062  LR: 0.00000456  \n","Epoch: [3][400/2480] Elapsed 1m 9s (remain 5m 58s) Loss: 0.0207(0.0149) Grad: 67367.7422  LR: 0.00000440  \n","Epoch: [3][500/2480] Elapsed 1m 26s (remain 5m 40s) Loss: 0.0202(0.0148) Grad: 66603.2891  LR: 0.00000425  \n","Epoch: [3][600/2480] Elapsed 1m 43s (remain 5m 22s) Loss: 0.0054(0.0149) Grad: 21865.9004  LR: 0.00000409  \n","Epoch: [3][700/2480] Elapsed 2m 0s (remain 5m 4s) Loss: 0.0192(0.0149) Grad: 17327.4316  LR: 0.00000393  \n","Epoch: [3][800/2480] Elapsed 2m 17s (remain 4m 47s) Loss: 0.0057(0.0148) Grad: 34360.2656  LR: 0.00000378  \n","Epoch: [3][900/2480] Elapsed 2m 33s (remain 4m 29s) Loss: 0.0086(0.0148) Grad: 6284.8306  LR: 0.00000362  \n","Epoch: [3][1000/2480] Elapsed 2m 50s (remain 4m 12s) Loss: 0.0035(0.0147) Grad: 12944.3779  LR: 0.00000347  \n","Epoch: [3][1100/2480] Elapsed 3m 7s (remain 3m 55s) Loss: 0.0094(0.0146) Grad: 12573.5273  LR: 0.00000332  \n","Epoch: [3][1200/2480] Elapsed 3m 24s (remain 3m 38s) Loss: 0.0156(0.0147) Grad: 23068.2617  LR: 0.00000317  \n","Epoch: [3][1300/2480] Elapsed 3m 41s (remain 3m 20s) Loss: 0.0268(0.0146) Grad: 13591.9727  LR: 0.00000302  \n","Epoch: [3][1400/2480] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0097(0.0146) Grad: 42392.9688  LR: 0.00000288  \n","Epoch: [3][1500/2480] Elapsed 4m 15s (remain 2m 46s) Loss: 0.0073(0.0145) Grad: 28388.0156  LR: 0.00000274  \n","Epoch: [3][1600/2480] Elapsed 4m 32s (remain 2m 29s) Loss: 0.0175(0.0144) Grad: 37259.1133  LR: 0.00000260  \n","Epoch: [3][1700/2480] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0151(0.0144) Grad: 21943.2227  LR: 0.00000246  \n","Epoch: [3][1800/2480] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0080(0.0143) Grad: 10446.9180  LR: 0.00000232  \n","Epoch: [3][1900/2480] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0131(0.0143) Grad: 29489.9395  LR: 0.00000219  \n","Epoch: [3][2000/2480] Elapsed 5m 40s (remain 1m 21s) Loss: 0.0050(0.0143) Grad: 26405.7852  LR: 0.00000206  \n","Epoch: [3][2100/2480] Elapsed 5m 57s (remain 1m 4s) Loss: 0.0068(0.0143) Grad: 19491.2383  LR: 0.00000193  \n","Epoch: [3][2200/2480] Elapsed 6m 14s (remain 0m 47s) Loss: 0.0153(0.0142) Grad: 30878.5273  LR: 0.00000181  \n","Epoch: [3][2300/2480] Elapsed 6m 31s (remain 0m 30s) Loss: 0.0155(0.0143) Grad: 53793.3906  LR: 0.00000169  \n","Epoch: [3][2400/2480] Elapsed 6m 48s (remain 0m 13s) Loss: 0.0262(0.0142) Grad: 19257.5938  LR: 0.00000157  \n","Epoch: [3][2479/2480] Elapsed 7m 1s (remain 0m 0s) Loss: 0.0172(0.0142) Grad: 30834.7129  LR: 0.00000148  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 45s) Loss: 0.0755(0.0755) \n","EVAL: [100/125] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1362(0.1016) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0142  avg_val_loss: 0.1022  time: 433s\n","Epoch 3 - Score: 0.8049\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [124/125] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1177(0.1022) \n","Epoch: [4][0/2480] Elapsed 0m 0s (remain 21m 42s) Loss: 0.0084(0.0084) Grad: nan  LR: 0.00000148  \n","Epoch: [4][100/2480] Elapsed 0m 17s (remain 6m 51s) Loss: 0.0031(0.0123) Grad: 19371.5488  LR: 0.00000137  \n","Epoch: [4][200/2480] Elapsed 0m 34s (remain 6m 30s) Loss: 0.0196(0.0125) Grad: 21048.7090  LR: 0.00000126  \n","Epoch: [4][300/2480] Elapsed 0m 51s (remain 6m 13s) Loss: 0.0157(0.0125) Grad: 8751.9287  LR: 0.00000116  \n","Epoch: [4][400/2480] Elapsed 1m 8s (remain 5m 55s) Loss: 0.0172(0.0124) Grad: 19257.9336  LR: 0.00000106  \n","Epoch: [4][500/2480] Elapsed 1m 25s (remain 5m 38s) Loss: 0.0188(0.0124) Grad: 28311.3105  LR: 0.00000096  \n","Epoch: [4][600/2480] Elapsed 1m 42s (remain 5m 21s) Loss: 0.0115(0.0123) Grad: 13748.2256  LR: 0.00000087  \n","Epoch: [4][700/2480] Elapsed 1m 59s (remain 5m 3s) Loss: 0.0143(0.0123) Grad: 23912.2266  LR: 0.00000078  \n","Epoch: [4][800/2480] Elapsed 2m 16s (remain 4m 46s) Loss: 0.0063(0.0123) Grad: 11240.6797  LR: 0.00000070  \n","Epoch: [4][900/2480] Elapsed 2m 33s (remain 4m 29s) Loss: 0.0076(0.0122) Grad: 24763.3672  LR: 0.00000062  \n","Epoch: [4][1000/2480] Elapsed 2m 50s (remain 4m 12s) Loss: 0.0116(0.0121) Grad: 6640.5371  LR: 0.00000054  \n","Epoch: [4][1100/2480] Elapsed 3m 7s (remain 3m 55s) Loss: 0.0078(0.0121) Grad: 27755.2207  LR: 0.00000047  \n","Epoch: [4][1200/2480] Elapsed 3m 24s (remain 3m 38s) Loss: 0.0215(0.0122) Grad: 14377.8369  LR: 0.00000041  \n","Epoch: [4][1300/2480] Elapsed 3m 41s (remain 3m 21s) Loss: 0.0107(0.0122) Grad: 17303.6016  LR: 0.00000035  \n","Epoch: [4][1400/2480] Elapsed 3m 58s (remain 3m 3s) Loss: 0.0148(0.0122) Grad: 71661.0469  LR: 0.00000029  \n","Epoch: [4][1500/2480] Elapsed 4m 16s (remain 2m 46s) Loss: 0.0090(0.0122) Grad: 8206.7646  LR: 0.00000024  \n","Epoch: [4][1600/2480] Elapsed 4m 33s (remain 2m 29s) Loss: 0.0226(0.0122) Grad: 14243.5615  LR: 0.00000019  \n","Epoch: [4][1700/2480] Elapsed 4m 49s (remain 2m 12s) Loss: 0.0080(0.0121) Grad: 5286.5015  LR: 0.00000015  \n","Epoch: [4][1800/2480] Elapsed 5m 6s (remain 1m 55s) Loss: 0.0150(0.0121) Grad: 13324.8643  LR: 0.00000012  \n","Epoch: [4][1900/2480] Elapsed 5m 23s (remain 1m 38s) Loss: 0.0071(0.0120) Grad: 10303.3018  LR: 0.00000008  \n","Epoch: [4][2000/2480] Elapsed 5m 40s (remain 1m 21s) Loss: 0.0092(0.0120) Grad: 8800.6709  LR: 0.00000006  \n","Epoch: [4][2100/2480] Elapsed 5m 57s (remain 1m 4s) Loss: 0.0071(0.0120) Grad: 14430.1797  LR: 0.00000004  \n","Epoch: [4][2200/2480] Elapsed 6m 14s (remain 0m 47s) Loss: 0.0044(0.0120) Grad: 34032.3359  LR: 0.00000002  \n","Epoch: [4][2300/2480] Elapsed 6m 32s (remain 0m 30s) Loss: 0.0225(0.0120) Grad: 21461.6152  LR: 0.00000001  \n","Epoch: [4][2400/2480] Elapsed 6m 49s (remain 0m 13s) Loss: 0.0038(0.0120) Grad: 19016.4902  LR: 0.00000000  \n","Epoch: [4][2479/2480] Elapsed 7m 2s (remain 0m 0s) Loss: 0.0059(0.0120) Grad: 27891.6367  LR: 0.00000000  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 46s) Loss: 0.0738(0.0738) \n","EVAL: [100/125] Elapsed 0m 9s (remain 0m 2s) Loss: 0.1331(0.0987) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0120  avg_val_loss: 0.0994  time: 434s\n","Epoch 4 - Score: 0.8055\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [124/125] Elapsed 0m 11s (remain 0m 0s) Loss: 0.1147(0.0994) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 19 result ==========\n","Score: 0.8069\n","========== CV ==========\n","Score: 0.8255\n"]},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0353ec5f989c4255b29ed2aa7176c087","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e▄▁▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e▃█▃▄▂▂▂▂▂▃▂▄▁▂▂▂▂▁▂▁▁▁▁▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e▁▆▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▄▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] loss\u003c/td\u003e\u003ctd\u003e▇█▅▃▇▂▅▂▃▅▂▂▃▂▃▂▂▅▂▁▄▃▁▁▄▁▁▃▄▁▂▁▁▂▁▁▂▂▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] score\u003c/td\u003e\u003ctd\u003e▁▅██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁█▄▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] loss\u003c/td\u003e\u003ctd\u003e▃█▄▂▃▂▅▂▅▂▁▁▂▂▃▂▁▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] score\u003c/td\u003e\u003ctd\u003e▁▆▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] loss\u003c/td\u003e\u003ctd\u003e▃▂█▂▂▂▁▂▁▁▂▁▂▁▁▁▂▁▂▁▁▁▁▂▁▁▂▁▁▂▁▁▁▃▁▁▁▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] score\u003c/td\u003e\u003ctd\u003e▁███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▃▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] loss\u003c/td\u003e\u003ctd\u003e█▃▂▂▂▂▂▃▁▂▁▂▁▁▁▁▂▂▂▁▁▁▂▂▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] score\u003c/td\u003e\u003ctd\u003e▁█▇▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▃▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] loss\u003c/td\u003e\u003ctd\u003e█▃▇▃▄▅▇▆▅▃▃▃▂▃▂▁▁▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▁▂▁▁▁▂▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] score\u003c/td\u003e\u003ctd\u003e▁▇██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] loss\u003c/td\u003e\u003ctd\u003e█▃▂▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▃▂▁▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁▂▂▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] score\u003c/td\u003e\u003ctd\u003e▁▆▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▃▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] loss\u003c/td\u003e\u003ctd\u003e▇█▅▄▅▄▃▃▃▂▂▂▂▃▂▃▁▃▄▃▃▂▂▁▂▃▂▃▁▂▂▁▁▂▂▃▂▂▂▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] score\u003c/td\u003e\u003ctd\u003e▁▅▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▇▃█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] loss\u003c/td\u003e\u003ctd\u003e▄▄▂▂█▄▂▃▂▂▂▂▂▁▂▂▃▁▃▂▂▂▂▂▂▁▁▂▂▁▂▁▁▁▁▂▂▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] score\u003c/td\u003e\u003ctd\u003e▁▇▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▂▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] loss\u003c/td\u003e\u003ctd\u003e▄█▁▂▃▂▂▂▂▂▂▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] score\u003c/td\u003e\u003ctd\u003e▁▄▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▇█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] loss\u003c/td\u003e\u003ctd\u003e█▃▃▄▃▂▃▃▃▄▂▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁▁▂▂▁▂▁▂▂▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] score\u003c/td\u003e\u003ctd\u003e▁█▆▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁█▄▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e█▅▇▃▃▂▃▁▂▁▁▂▁▁▁▁▁▂▂▂▂▁▁▂▁▂▂▂▁▃▁▁▁▁▁▁▂▁▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e▁▄██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e▇▁█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e▂█▂▂▁▂▂▂▁▁▂▁▁▁▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e▁▇█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e▃▁██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e▆▆█▅▃▃▆▃▃▃▁▁▂▁▂▃▂▃▂▂▁▂▃▃▂▁▁▂▂▂▂▂▂▂▁▂▁▂▂▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e▁▄█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e▅██▄▃▅▂▆▃▃▂▁▁▃▂▂▃▂▃▂▁▂▁▂▂▁▂▁▂▁▃▂▃▁▂▁▂▁▃▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e▁▅██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁█▇▅\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] loss\u003c/td\u003e\u003ctd\u003e█▇▆▃▂▅▃▂▃▄▂▃▃▂▁▁▃▂▄▂▃▂▁▂▃▂▂▃▁▄▂▂▂▁▂▁▂▁▄▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] score\u003c/td\u003e\u003ctd\u003e▁▅▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▂█▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] loss\u003c/td\u003e\u003ctd\u003e▅█▅▄▄▅▅▅▅▅▂▂▂▁▂▂▅▂▂▃▂▃▁▂▄▂▂▂▂▂▂▃▁▁▂▁▁▄▂▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] score\u003c/td\u003e\u003ctd\u003e▁▄▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▁▆▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] loss\u003c/td\u003e\u003ctd\u003e█▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▃▂▂▁▂▁▁▂▂▁▁▁▂▂▂▁▁▁▁▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] score\u003c/td\u003e\u003ctd\u003e▁█▇▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_val_loss\u003c/td\u003e\u003ctd\u003e█▂▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] loss\u003c/td\u003e\u003ctd\u003e▄▂█▃▂▄▁▂▂▂▂▁▂▁▂▂▂▂▁▂▂▂▂▁▁▁▂▁▂▂▁▂▁▂▂▁▁▁▃▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] score\u003c/td\u003e\u003ctd\u003e▁███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_val_loss\u003c/td\u003e\u003ctd\u003e▂█▄▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] loss\u003c/td\u003e\u003ctd\u003e█▆▅▅▃▂▅▁▂▃▂▄▂▃▂▁▂▂▃▃▃▂▁▁▂▁▃▂▁▁▂▁▂▂▂▂▁▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] score\u003c/td\u003e\u003ctd\u003e▁▇██\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01109\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09569\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e0.00756\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e0.8271\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01108\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.0979\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] loss\u003c/td\u003e\u003ctd\u003e0.00644\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold10] score\u003c/td\u003e\u003ctd\u003e0.85265\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01125\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09458\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] loss\u003c/td\u003e\u003ctd\u003e0.00663\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold11] score\u003c/td\u003e\u003ctd\u003e0.84876\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01214\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09529\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] loss\u003c/td\u003e\u003ctd\u003e0.01367\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold12] score\u003c/td\u003e\u003ctd\u003e0.83194\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01178\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.1066\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] loss\u003c/td\u003e\u003ctd\u003e0.02797\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold13] score\u003c/td\u003e\u003ctd\u003e0.8249\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01387\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.0966\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] loss\u003c/td\u003e\u003ctd\u003e0.05679\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold14] score\u003c/td\u003e\u003ctd\u003e0.82332\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01131\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09478\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] loss\u003c/td\u003e\u003ctd\u003e0.00593\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold15] score\u003c/td\u003e\u003ctd\u003e0.8122\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01115\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09745\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] loss\u003c/td\u003e\u003ctd\u003e0.00849\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold16] score\u003c/td\u003e\u003ctd\u003e0.83372\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01145\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09766\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] loss\u003c/td\u003e\u003ctd\u003e0.00653\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold17] score\u003c/td\u003e\u003ctd\u003e0.80778\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.012\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09886\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] loss\u003c/td\u003e\u003ctd\u003e0.04163\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold18] score\u003c/td\u003e\u003ctd\u003e0.82941\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01195\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.0994\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] loss\u003c/td\u003e\u003ctd\u003e0.00591\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold19] score\u003c/td\u003e\u003ctd\u003e0.8055\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01151\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09555\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e0.01457\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e0.83605\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01148\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09998\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e0.00695\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e0.83104\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01333\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.0963\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e0.01073\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e0.82943\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01102\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09355\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e0.0343\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e0.81682\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01149\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09807\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] loss\u003c/td\u003e\u003ctd\u003e0.00379\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] score\u003c/td\u003e\u003ctd\u003e0.81841\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.0118\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09594\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] loss\u003c/td\u003e\u003ctd\u003e0.01165\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] score\u003c/td\u003e\u003ctd\u003e0.81774\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01185\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09843\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] loss\u003c/td\u003e\u003ctd\u003e0.02058\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] score\u003c/td\u003e\u003ctd\u003e0.80624\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01191\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09526\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] loss\u003c/td\u003e\u003ctd\u003e0.00691\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] score\u003c/td\u003e\u003ctd\u003e0.84239\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.01138\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.09713\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] loss\u003c/td\u003e\u003ctd\u003e0.00751\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] score\u003c/td\u003e\u003ctd\u003e0.81281\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced \u003cstrong style=\"color:#cdcd00\"\u003eanferico/bert-for-patents\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/bluehills/PPPM-MSE-2/runs/277pe9og\" target=\"_blank\"\u003ehttps://wandb.ai/bluehills/PPPM-MSE-2/runs/277pe9og\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20220610_110906-277pe9og/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:\u003c.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tL7g_rhfN1sr"},"outputs":[{"data":{"text/plain":["308"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EJF7cYLQLW0c"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN2pHH07rWzGPyn0KYaKMXd","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"PPPM MSE 2.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07b9e276c06844b7897aef727f76770c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12df157d00334d0785d191759215ea29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"155b085178f2437c9f78ee74e9011f2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"158491a6825c4035b102915bbc467843":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c3481ada7dc439d9b8842e614a2cf91","IPY_MODEL_59328e03feef46ffb78369940491a22f","IPY_MODEL_a66e4f24fd164439a139d10d74536e3c"],"layout":"IPY_MODEL_709c66f47add4847b463e98e6fc11cbd"}},"184d927c49664777823fc93d6eed5184":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bbdeff5a0424858981e82b0ad2b8486":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bdef5f6b6114dc897a26f3d7376f0d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e37c08b03fc34da2aea9ddedff340e38","max":329241,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aadcfca4a0df40f3b4f81e8fcc8dabba","value":329241}},"202d767567e54f7a991b026c6fb3766f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd309787f60543698c1661d4d0d00b94","placeholder":"​","style":"IPY_MODEL_5f93efe0293647109ffbf5a7e60d9c87","value":"100%"}},"34566a1aba7b41b9b2cbb9c43d572086":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38d2f4ef68904fb29308bb7992c189b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f26e0d2c773465ca7f220d4adf630e1","IPY_MODEL_aee520f32c404b749cbb66954053bff0","IPY_MODEL_9f70e30491b74e169a6bf8f00fda7266"],"layout":"IPY_MODEL_a256fdd8d26f44139884ff9bf5c4e825"}},"38e63e283c924f16bf90bfa69aae083e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d13090cdbf54ccb9caa9d46cf8c2a0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d26ace1c0664b1d98b0f8bf585b37ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55f5ae28e9f54f86b8464cef94423937","IPY_MODEL_ba24ddaf4a2643bd823ba746f4c1ca7c","IPY_MODEL_76e5d6d6c1e946ae9c92939f2b7be386"],"layout":"IPY_MODEL_a88be7492944496ebec524fc0ff9f4a8"}},"4171e6cb2b104c63a5e0d067d3f39a5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_184d927c49664777823fc93d6eed5184","placeholder":"​","style":"IPY_MODEL_d000daac88e74407bb92fae8f7297879","value":"Downloading: 100%"}},"45201dbf868b4a45b8c14f912f2143dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48b512e2c5ca490ca7b86ec86ac0f55a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b13241e2762499b9a19e61898ac4abd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d7d9d82590f47dfa0195c7cc4c5baa9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_202d767567e54f7a991b026c6fb3766f","IPY_MODEL_9f1f052bd3c94c28a439427caae09dd5","IPY_MODEL_c44128aec47e4bf7a4af88e60f1999c5"],"layout":"IPY_MODEL_af9f560382614aeaad28649222040f24"}},"4efc5096aa8443f0972b436a9ca36bda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5471b850654f46d99cac09059c8a6c4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f5ae28e9f54f86b8464cef94423937":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d963954bf87340a0b6fa212f83aea378","placeholder":"​","style":"IPY_MODEL_45201dbf868b4a45b8c14f912f2143dd","value":"100%"}},"59328e03feef46ffb78369940491a22f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48b512e2c5ca490ca7b86ec86ac0f55a","max":327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b13241e2762499b9a19e61898ac4abd","value":327}},"5f93efe0293647109ffbf5a7e60d9c87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"676911edd94a4cf68eaff7c5ffc81b89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709c66f47add4847b463e98e6fc11cbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76e5d6d6c1e946ae9c92939f2b7be386":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b14e6f1b26a54b7185d1f197c724e20f","placeholder":"​","style":"IPY_MODEL_f19f4a5340484c5fbf7cf80a35f74d8d","value":" 36473/36473 [00:03\u0026lt;00:00, 9925.16it/s]"}},"78e8f5ab772044f8b87e2659df5f05a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f26e0d2c773465ca7f220d4adf630e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78e8f5ab772044f8b87e2659df5f05a3","placeholder":"​","style":"IPY_MODEL_92185a38e3a446cfa414b8a6e5daefd5","value":"Downloading: 100%"}},"80868cf0949940559ed7ff6507795e2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"852adb6918d14f48bb7cbc0e3b6da42f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92185a38e3a446cfa414b8a6e5daefd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"951deb4c5074489bbb653374452347bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c3481ada7dc439d9b8842e614a2cf91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e18d8ed27e7a4f71854944cab65588f7","placeholder":"​","style":"IPY_MODEL_80868cf0949940559ed7ff6507795e2c","value":"Downloading: 100%"}},"9e6e649106634c669c952aa34bb5b7e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f1f052bd3c94c28a439427caae09dd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc118c98ad4e4b4fb85d939fbedc1f5f","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_951deb4c5074489bbb653374452347bb","value":36473}},"9f70e30491b74e169a6bf8f00fda7266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_676911edd94a4cf68eaff7c5ffc81b89","placeholder":"​","style":"IPY_MODEL_ccd1e90ac56c4d56a647cdf0115c9e2a","value":" 1.29G/1.29G [00:23\u0026lt;00:00, 59.9MB/s]"}},"a256fdd8d26f44139884ff9bf5c4e825":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27f44eeb5e94932baa0f9f7c3da288d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07b9e276c06844b7897aef727f76770c","placeholder":"​","style":"IPY_MODEL_1bbdeff5a0424858981e82b0ad2b8486","value":" 136/136 [00:00\u0026lt;00:00, 2331.67it/s]"}},"a588bcd5d7144e419605b1bf48cdfd33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea9d85b585af42b3a3b22116d7f7a7dc","IPY_MODEL_f2346ceac6c94c1284c35b8b2eadf28f","IPY_MODEL_a27f44eeb5e94932baa0f9f7c3da288d"],"layout":"IPY_MODEL_5471b850654f46d99cac09059c8a6c4b"}},"a66e4f24fd164439a139d10d74536e3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce127916d10d4af09e6f9697331f91a1","placeholder":"​","style":"IPY_MODEL_12df157d00334d0785d191759215ea29","value":" 327/327 [00:00\u0026lt;00:00, 8.32kB/s]"}},"a88be7492944496ebec524fc0ff9f4a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aadcfca4a0df40f3b4f81e8fcc8dabba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aee520f32c404b749cbb66954053bff0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_852adb6918d14f48bb7cbc0e3b6da42f","max":1383349812,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38e63e283c924f16bf90bfa69aae083e","value":1383349812}},"af9f560382614aeaad28649222040f24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b14e6f1b26a54b7185d1f197c724e20f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b658f2776a99434e90ced031eda5c9c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4171e6cb2b104c63a5e0d067d3f39a5c","IPY_MODEL_1bdef5f6b6114dc897a26f3d7376f0d6","IPY_MODEL_cac381f015e34482b004d308ae3e2f3d"],"layout":"IPY_MODEL_e2edb7db6c8b44a9b09b258333ac5305"}},"b9ffae97bff44838be78ddc3614e78c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba24ddaf4a2643bd823ba746f4c1ca7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d13090cdbf54ccb9caa9d46cf8c2a0b","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_155b085178f2437c9f78ee74e9011f2e","value":36473}},"c44128aec47e4bf7a4af88e60f1999c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8836207ee374efa9da07a2107ecef05","placeholder":"​","style":"IPY_MODEL_34566a1aba7b41b9b2cbb9c43d572086","value":" 36473/36473 [00:03\u0026lt;00:00, 11545.18it/s]"}},"cac381f015e34482b004d308ae3e2f3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e6e649106634c669c952aa34bb5b7e5","placeholder":"​","style":"IPY_MODEL_dcf87b0c90bd475e91bdcf70b7d664b0","value":" 322k/322k [00:00\u0026lt;00:00, 617kB/s]"}},"ccd1e90ac56c4d56a647cdf0115c9e2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce127916d10d4af09e6f9697331f91a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d000daac88e74407bb92fae8f7297879":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d189a809ecf644f491b9e8eead848508":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d963954bf87340a0b6fa212f83aea378":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc118c98ad4e4b4fb85d939fbedc1f5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf87b0c90bd475e91bdcf70b7d664b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e18d8ed27e7a4f71854944cab65588f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e222420044014cfabac3d8459d0c69b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2edb7db6c8b44a9b09b258333ac5305":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e37c08b03fc34da2aea9ddedff340e38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8836207ee374efa9da07a2107ecef05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9d85b585af42b3a3b22116d7f7a7dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9ffae97bff44838be78ddc3614e78c3","placeholder":"​","style":"IPY_MODEL_4efc5096aa8443f0972b436a9ca36bda","value":"100%"}},"f19f4a5340484c5fbf7cf80a35f74d8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2346ceac6c94c1284c35b8b2eadf28f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e222420044014cfabac3d8459d0c69b8","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d189a809ecf644f491b9e8eead848508","value":136}},"fd309787f60543698c1661d4d0d00b94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}