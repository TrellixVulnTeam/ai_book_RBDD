{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4wtXQc5eILks"},"outputs":[],"source":["# !pip install kaggle\n","# from google.colab import files\n","# files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ybT-kPrIRRF"},"outputs":[],"source":["# !ls -1ha kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1902,"status":"ok","timestamp":1652937854801,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ngruL3LzILgG","outputId":"316b4a8d-7bd0-4fb0-cd76-6b4fb23c9e91"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-pSk1HrImpC"},"outputs":[],"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# # Permission Warning 이 일어나지 않도록 \n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 본인이 참가한 모든 대회 보기 \n","# !kaggle competitions list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2975,"status":"ok","timestamp":1652937857768,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"93TLgBfpILdp","outputId":"20fdff48-81c5-4ce2-f362-350453903c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.16)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: shortuuid\u003e=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: sentry-sdk\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.12)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: python-dateutil\u003e=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: protobuf\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: GitPython\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.0.9)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.2.0)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003eGitPython\u003e=1.0.0-\u003ewandb) (5.0.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2021.10.8)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n"]}],"source":["!pip3 install tokenizers wandb sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3586,"status":"ok","timestamp":1652937861348,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"dTDhaP31LevK","outputId":"25d35e04-bc7d-431a-8963-a1e55ef6b708"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABCV5MzcILYt"},"outputs":[],"source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fe14zhChIld4"},"outputs":[],"source":["# !kaggle competitions download -c us-patent-phrase-to-phrase-matching\n","# !unzip us-patent-phrase-to-phrase-matching.zip\n","# !ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enX70dDOIlbH"},"outputs":[],"source":["# debert_v3_tokenizer_path = 'deberta-v2-v3-fast-tokenizer'\n","# %env TOKENIZERS_PARALLELISM=true\n","\n","# import shutil\n","# from pathlib import Path\n","\n","# transformers_path = Path('/usr/local/lib/python3.7/dist-packages/transformers')\n","# input_dir = Path('./deberta-v2-v3-fast-tokenizer')\n","\n","# convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","# conversion_path = transformers_path / convert_file.name\n","\n","# if conversion_path.exists():\n","#     conversion_path.unlink()\n","\n","# shutil.copy(convert_file, transformers_path)\n","# deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","# for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","#     filepath = deberta_v2_path/filename\n","    \n","#     if filepath.exists():\n","#         filepath.unlink()\n","#     shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8uVyeNzILWZ"},"outputs":[],"source":["OUTPUT_DIR = './pppm-mlm/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1652937861356,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"B9XJVEp-ILTm","outputId":"fe2bdb05-e20f-4f73-a88c-16b09075edbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu May 19 05:24:20 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') \u003e= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad4bqKUJILRr"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    competition='PPPM'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=5\n","    encoder_lr=2e-5 #2e-5\n","    decoder_lr=2e-5 #2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=14\n","    fc_dropout=0.1\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    train_all_index=25\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"markdown","metadata":{"id":"g_kIjiCGLHsk"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3514,"status":"ok","timestamp":1652937864847,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"F3Ud6NtXILMj","outputId":"d16bc76e-41d4-4101-b23a-f337ab7f1968"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.19.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","import torch.cuda.amp as amp\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","# from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","# from transformers import AutoTokenizer, AutoConfig, AutoModelForTokenClassification\n","from transformers import AutoModelForMaskedLM, AutoTokenizer, AutoConfig, LineByLineTextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"0N-UkOUGLMTx"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FO_u0OIhILJo"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"DhF4gE3osShB"},"source":["# Generate pretraining data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431},"executionInfo":{"elapsed":1355,"status":"ok","timestamp":1652937866197,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"yDUN0TYbsPOw","outputId":"182d8c9a-9f88-4cd1-c180-7d298e88514f"},"outputs":[{"data":{"text/plain":["(100000, 1)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-a7495588-888e-4881-b19f-be7d28563786\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eabstract\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eThe subject matters of the invention are: a cr...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eThe present invention relates to the treatment...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eThe invention relates to a composition compris...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7495588-888e-4881-b19f-be7d28563786')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-a7495588-888e-4881-b19f-be7d28563786 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a7495588-888e-4881-b19f-be7d28563786');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                                            abstract\n","0  The subject matters of the invention are: a cr...\n","1  The present invention relates to the treatment...\n","2  The invention relates to a composition compris...\n","3                                                NaN\n","4                                                NaN"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(93662, 1)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-fa1c41c4-5c4c-40fd-ab69-5cac2b16f96f\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eabstract\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eThe subject matters of the invention are: a cr...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eThe present invention relates to the treatment...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eThe invention relates to a composition compris...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eThe invention relates to an improved process f...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eThe present invention relates to a new method ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa1c41c4-5c4c-40fd-ab69-5cac2b16f96f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-fa1c41c4-5c4c-40fd-ab69-5cac2b16f96f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fa1c41c4-5c4c-40fd-ab69-5cac2b16f96f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                                            abstract\n","0  The subject matters of the invention are: a cr...\n","1  The present invention relates to the treatment...\n","2  The invention relates to a composition compris...\n","3  The invention relates to an improved process f...\n","4  The present invention relates to a new method ..."]},"metadata":{},"output_type":"display_data"}],"source":["df=pd.read_csv('./pppm_abstract.csv')\n","display(df.shape)\n","display(df.head())\n","\n","df=df.dropna().reset_index(drop=True)\n","display(df.shape)\n","display(df.head())\n","\n","\n","with open('corpus.txt','w',encoding='utf-8') as f:\n","    for ab in df['abstract']:\n","        f.write(ab+'\\n')"]},{"cell_type":"markdown","metadata":{"id":"SOnucxUIs2iC"},"source":["# Training model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11889,"status":"ok","timestamp":1652937878083,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"dNplqK4EsPHa","outputId":"cc5c1434-d918-493b-ea29-d5fe2ae1241c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForMaskedLM: ['mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["('pretrained_models/microsoft/deberta-v3-large/tokenizer_config.json',\n"," 'pretrained_models/microsoft/deberta-v3-large/special_tokens_map.json',\n"," 'pretrained_models/microsoft/deberta-v3-large/spm.model',\n"," 'pretrained_models/microsoft/deberta-v3-large/added_tokens.json',\n"," 'pretrained_models/microsoft/deberta-v3-large/tokenizer.json')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model_name = 'microsoft/deberta-v3-large'\n","\n","model = AutoModelForMaskedLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.save_pretrained('pretrained_models/microsoft/deberta-v3-large')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lS4GPh7atGi1"},"outputs":[],"source":["train_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"./corpus.txt\",  # mention train text file here\n","    block_size=256)\n","\n","valid_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"./corpus.txt\",  # mention valid text file here\n","    block_size=256)\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n","\n","\n","training_args = TrainingArguments(\n","    output_dir=\"pretrained_models/microsoft/deberta-v3-large-pretrain\",  # select model path for checkpoint\n","    overwrite_output_dir=True,\n","    num_train_epochs=8,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    gradient_accumulation_steps=2,\n","    evaluation_strategy='steps',\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    eval_steps=5000,\n","    metric_for_best_model='eval_loss',\n","    greater_is_better=False,\n","    load_best_model_at_end=False,\n","    prediction_loss_only=True,\n","    report_to=\"none\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CmF8TPOv3Ki"},"outputs":[],"source":["# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"u43a_46NsO_A"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 95237\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 95240\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='65715' max='95240' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [65715/95240 23:31:13 \u003c 10:34:03, 0.78 it/s, Epoch 5.52/8]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5000\u003c/td\u003e\n","      \u003ctd\u003e2.224200\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e10000\u003c/td\u003e\n","      \u003ctd\u003e1.841400\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e15000\u003c/td\u003e\n","      \u003ctd\u003e1.661200\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e20000\u003c/td\u003e\n","      \u003ctd\u003e1.540100\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e25000\u003c/td\u003e\n","      \u003ctd\u003e1.469300\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e30000\u003c/td\u003e\n","      \u003ctd\u003e1.432600\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e35000\u003c/td\u003e\n","      \u003ctd\u003e1.397400\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e40000\u003c/td\u003e\n","      \u003ctd\u003e1.358100\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e45000\u003c/td\u003e\n","      \u003ctd\u003e1.305800\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e50000\u003c/td\u003e\n","      \u003ctd\u003e1.291100\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e55000\u003c/td\u003e\n","      \u003ctd\u003e1.278500\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e60000\u003c/td\u003e\n","      \u003ctd\u003e1.255400\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e65000\u003c/td\u003e\n","      \u003ctd\u003e1.249600\u003c/td\u003e\n","      \u003ctd\u003enan\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1000/pytorch_model.bin\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-3500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-20500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-21500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-22500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-23500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-24500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-25500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-26500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-27500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-28500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-29500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-30500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-31500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-32500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-33500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-34500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-35500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-36500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-37500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-38500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-39500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-40500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-41500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-42500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-43500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-44500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-45500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-46500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-47500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-48500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-49500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-50500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-51500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-52500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-53500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-54500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-55500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-56500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-57500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-58500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-59500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-60500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-61500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-62500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63000] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-63500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 95237\n","  Batch size = 4\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65000\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65000/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65000/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-64500] due to args.save_total_limit\n","Saving model checkpoint to pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65500\n","Configuration saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65500/config.json\n","Model weights saved in pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65500/pytorch_model.bin\n","Deleting older checkpoint [pretrained_models/microsoft/deberta-v3-large-pretrain/checkpoint-65000] due to args.save_total_limit\n"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset)\n","\n","trainer.train()\n","trainer.save_model(f'pretrained_models/microsoft/deberta-v3-large')  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lep6zgR-sO1o"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"m1x8L7BQOKr2"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPMtgF_NbjBe"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","            # self.model = AutoModelForSequenceClassification.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","            # self.model = AutoModelForSequenceClassification.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        # self.fc = nn.Linear(self.config.num_labels, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output\n","    \n","    # def forward(self, inputs):\n","    #     return self.model(**inputs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tL7g_rhfN1sr"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNtcZLa3Bu9NIFdbDysFdxd","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"PPPM MLM.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}