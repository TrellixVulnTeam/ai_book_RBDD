{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4wtXQc5eILks"},"outputs":[],"source":["# !pip install kaggle\n","# from google.colab import files\n","# files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ybT-kPrIRRF"},"outputs":[],"source":["# !ls -1ha kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22994,"status":"ok","timestamp":1651750752011,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ngruL3LzILgG","outputId":"98b593a1-ef1c-4773-acb1-334632cfbe3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-pSk1HrImpC"},"outputs":[],"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# # Permission Warning 이 일어나지 않도록 \n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 본인이 참가한 모든 대회 보기 \n","# !kaggle competitions list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7566,"status":"ok","timestamp":1651750759575,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"93TLgBfpILdp","outputId":"348a3fc4-40e9-446c-c479-6f86a92db626"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tokenizers\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 14.8 MB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 71.6 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 61.0 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 83.8 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 84.3 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6c47b78ea6ed9938ff060b33927a03c3c39fe8ad711d9b0a080021350fac8ad2\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb, tokenizers, sentencepiece\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentencepiece-0.1.96 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 tokenizers-0.12.1 wandb-0.12.16\n"]}],"source":["!pip3 install tokenizers wandb sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7104,"status":"ok","timestamp":1651750766662,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"dTDhaP31LevK","outputId":"cf8a9dd3-6148-4187-de9c-b6fcf88bfd4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 14.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 82.2 MB/s \n","\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=38383f166757f162bb30037c1b824326eb4e7b77b224d32cbf69979f56756b4e\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 transformers-4.18.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABCV5MzcILYt"},"outputs":[],"source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fe14zhChIld4"},"outputs":[],"source":["# !kaggle competitions download -c us-patent-phrase-to-phrase-matching\n","# !unzip us-patent-phrase-to-phrase-matching.zip\n","# !ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enX70dDOIlbH"},"outputs":[],"source":["# debert_v3_tokenizer_path = 'deberta-v2-v3-fast-tokenizer'\n","# %env TOKENIZERS_PARALLELISM=true\n","\n","# import shutil\n","# from pathlib import Path\n","\n","# transformers_path = Path('/usr/local/lib/python3.7/dist-packages/transformers')\n","# input_dir = Path('./deberta-v2-v3-fast-tokenizer')\n","\n","# convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","# conversion_path = transformers_path / convert_file.name\n","\n","# if conversion_path.exists():\n","#     conversion_path.unlink()\n","\n","# shutil.copy(convert_file, transformers_path)\n","# deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","# for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","#     filepath = deberta_v2_path/filename\n","    \n","#     if filepath.exists():\n","#         filepath.unlink()\n","#     shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8uVyeNzILWZ"},"outputs":[],"source":["OUTPUT_DIR = './uspppm-deberta-v3-outputs/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651750767170,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"B9XJVEp-ILTm","outputId":"f350d114-1e94-495e-e0de-bb661e89bf4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu May  5 11:39:26 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad4bqKUJILRr"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    competition='PPPM'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=50\n","    epochs=5\n","    encoder_lr=2e-5 #2e-5\n","    decoder_lr=2e-5 #2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=10\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":9995,"status":"ok","timestamp":1651750777161,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qW8but_GILO1","outputId":"1dd5527b-b5c8-444d-f4d3-2b7672da883d"},"outputs":[{"name":"stdout","output_type":"stream","text":["login to wandb\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluehills\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.16"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/drive/My Drive/Kaggle/wandb/run-20220505_113932-3qani33c</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/bluehills/PPPM-focal_loss/runs/3qani33c\" target=\"_blank\">microsoft/deberta-v3-large</a></strong> to <a href=\"https://wandb.ai/bluehills/PPPM-focal_loss\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    import wandb\n","    try:\n","        # from kaggle_secrets import UserSecretsClient\n","        # user_secrets = UserSecretsClient()\n","        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        # wandb.login(key=secret_value_0)\n","        print('login to wandb')\n","        wandb.login()\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='PPPM-focal_loss', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"g_kIjiCGLHsk"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5502,"status":"ok","timestamp":1651750782658,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"F3Ud6NtXILMj","outputId":"14543a12-ac42-4e58-8ad5-7f7fbbf99b8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.18.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","import torch.cuda.amp as amp\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForTokenClassification\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"0N-UkOUGLMTx"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FO_u0OIhILJo"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)\n"]},{"cell_type":"markdown","metadata":{"id":"6epV68-8Lrk7"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":637},"executionInfo":{"elapsed":1915,"status":"ok","timestamp":1651750784569,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"-15eijrbILHp","outputId":"d69c9b7d-5afa-4a1b-e747-3eb7e276a6ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (36473, 5)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"data":{"text/html":["\n","  <div id=\"df-ed91e99f-8408-438a-b416-a0ecfe0e72af\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed91e99f-8408-438a-b416-a0ecfe0e72af')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ed91e99f-8408-438a-b416-a0ecfe0e72af button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ed91e99f-8408-438a-b416-a0ecfe0e72af');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-04ac1a34-9c53-4982-b76a-46de329d7c95\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04ac1a34-9c53-4982-b76a-46de329d7c95')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-04ac1a34-9c53-4982-b76a-46de329d7c95 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-04ac1a34-9c53-4982-b76a-46de329d7c95');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-4c219ce7-75ab-4d14-aa85-9fae5693e0fa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c219ce7-75ab-4d14-aa85-9fae5693e0fa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4c219ce7-75ab-4d14-aa85-9fae5693e0fa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4c219ce7-75ab-4d14-aa85-9fae5693e0fa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","submission = pd.read_csv('sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":4704,"status":"ok","timestamp":1651750789266,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"6T4B0z0yILFW","outputId":"3023e663-f360-45f8-9d80-4618eeeb3e99"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-620c3c9e-3171-4632-b317-e0ab15e884b2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-620c3c9e-3171-4632-b317-e0ab15e884b2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-620c3c9e-3171-4632-b317-e0ab15e884b2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-620c3c9e-3171-4632-b317-e0ab15e884b2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-593795ca-0bb4-45a9-8a15-5449a6268836\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-593795ca-0bb4-45a9-8a15-5449a6268836')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-593795ca-0bb4-45a9-8a15-5449a6268836 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-593795ca-0bb4-45a9-8a15-5449a6268836');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('./CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'./CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651750789267,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"46m7DZuOILDE","outputId":"79247cb3-0623-4c8e-d479-1d94037a35c3"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-6cc68faa-5402-4082-a108-323107201014\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cc68faa-5402-4082-a108-323107201014')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6cc68faa-5402-4082-a108-323107201014 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6cc68faa-5402-4082-a108-323107201014');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text                                               text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]abatement of pollution[SEP]HUMAN...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]act of abating[SEP]HUMAN NECESSI...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]active catalyst[SEP]HUMAN NECESS...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]eliminating process[SEP]HUMAN NE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]forest region[SEP]HUMAN NECESSIT..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-d6da82bb-8d19-4598-a40b-a39ba74a8b90\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","      <td>opc drum[SEP]inorganic photoconductor drum[SEP...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","      <td>adjust gas flow[SEP]altering gas flow[SEP]MECH...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","      <td>lower trunnion[SEP]lower locating[SEP]PERFORMI...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","      <td>cap component[SEP]upper portion[SEP]TEXTILES; ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","      <td>neural stimulation[SEP]artificial neural netwo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6da82bb-8d19-4598-a40b-a39ba74a8b90')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d6da82bb-8d19-4598-a40b-a39ba74a8b90 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d6da82bb-8d19-4598-a40b-a39ba74a8b90');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text                                               text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS  opc drum[SEP]inorganic photoconductor drum[SEP...\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...  adjust gas flow[SEP]altering gas flow[SEP]MECH...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...  lower trunnion[SEP]lower locating[SEP]PERFORMI...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...  cap component[SEP]upper portion[SEP]TEXTILES; ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  neural stimulation[SEP]artificial neural netwo..."]},"metadata":{},"output_type":"display_data"}],"source":["train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"isTSVEuINl2S"},"source":["# EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":559,"status":"ok","timestamp":1651750789822,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"3rsR5QFLILAq","outputId":"baf79d98-c0ca-4372-fbba-1439bacaad5e"},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f05f5aeb850>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651750789822,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qco8TIYeIK-W","outputId":"6913cddc-b142-4ad6-ac3c-ae17a3e77184"},"outputs":[{"data":{"text/plain":["B    8019\n","H    6195\n","G    6013\n","C    5288\n","A    4094\n","F    4054\n","E    1531\n","D    1279\n","Name: context, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"0X9jmLp9NrEE"},"source":["# CV Split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651750789823,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"rnm4sSJdIK73","outputId":"d27f099b-7c01-45e0-8aa5-534d6412eca5"},"outputs":[{"data":{"text/plain":["fold\n","0    7295\n","1    7295\n","2    7295\n","3    7294\n","4    7294\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67wpP1q7IK5L"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"bIqxWfHqNzR2"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["c2ba6397e84a46fea50852917cf717ac","72f8e2a6d041480fb1a4562998abbaed","e4838447dfae4356a9797e2586f7690e","e844688ae13a46168a91d2241b6570da","74e741f14c9444c98fdd26abfb078dd8","2f5ea483442a4b01ba352e9d70143cc3","d3ca43b3e96742bf82c03b29f7fe511d","cd2813defa9449969173c7ebfa74173c","89067053b48a4e17bcd8fdbf564e82c6","dac297841d154eeabe55b48eff97f922","696d1c127d524a3381a9bf309dde7bc3","921dc24c9d7247e2a22b9e9c04eeeb61","fabbfd9f66844756bc1f313f05070d3f","822dd2c2b7bc48dcb5ab38226627c1ac","f748e106a41b48ebb098995b1ca080d3","1012de349be54576bde054bf8aa9d683","e9709e11d8fa4acb9570aa7dbd19c106","856bcfe8302f4d7f9656d3b6eac8c746","6fda01ba8e8a435394d7a099dbaac94e","e7b89f40ae1c4926804d5774d7275342","4e95de29bfef43c3a5296642297a9854","3286928dd88c498db849a668306c0dc5","aac8e190da444ac3a218998ab1f0b32f","74176aaf4e6848d8ad74b486b31cbf2f","8dc718b94f18488e8fa0757f12c6ab58","4584dafed6c04a9c935217db69933959","ef7588eccae94da8b696619a14449ea5","1ef9cbc116cc41c6b029099d625d3854","1d50a6f4347a44d1a062997ef72959d2","e8af80feee5f47e5a747b51dff63a613","c103c92b8a6b42638169478960ed3d39","b74d5ab946c947dd97ce87b7b3c9e741","215f401e97574f5abea2f401fde4b862"]},"executionInfo":{"elapsed":5675,"status":"ok","timestamp":1651750795492,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"0LIvoPmoIFUv","outputId":"691bb98b-a867-45bb-c47f-cfcfdeaff15f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2ba6397e84a46fea50852917cf717ac","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"921dc24c9d7247e2a22b9e9c04eeeb61","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aac8e190da444ac3a218998ab1f0b32f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"BvhCQypyN2nU"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["8f51b00af0c946b8971e8cf447b48d94","c706bb21d46a4752ba214257ac3eea26","d3a3517a6e064e0caaec61c93c1a0806","4159366ecd524e4fa47d613bcd7d5ae8","873dd0bfcfb84bcea41619bf4c271006","1090c75efc8e49ca87eca44850f34430","72793baee4834aaa99a83fde76e685e5","89b7cc5eb1d7455bae0b3da196810e3f","7a99a3dce71d4a8d8efcdd3a4ecc4ef8","b0646d9f26744d92be564153a5dfc0be","4fa26144866943c58accfc901b777444","7318679ec4634d6794085796f242e163","7454b824fc934e16a87c9906ccf1ea35","184d82d6c5be4756868d7f981249d478","c98dd7fd6f69415c9222ff376d4f1008","85893440054f4adc802c17471d763918","b359785ebec64649b24fcffe6166363a","30eb817352dc4faca2d3ca77336f0093","d5e243614e3942e8a87a26fd29d8a317","0595e45ee827428f97a58310a9e7c56b","3c3bbc2770f14a5fba797208427c6d07","59ef73f9d47b4403a159e0debbd898fb","7bcf43b2805445b9952b0fa5258e374c","330ba59431f444e89d8d8a050567b02b","843011e5db384ecfa7ed55244b73ba32","f452d436cc754f5d94745c02e155df20","eb88f4588fd24245a5cc71496d804824","b9af072f7c434858abb95de099757057","439511cc8853446a8e37141e168ac11e","5dbb57fda21647d6ae4142dc6390cc80","8059312702864e949262da6af6a69908","d8bca4927a174b37a716d7ac21c4f2e2","c80f788aced44db7a0c1762f05c38a41"]},"executionInfo":{"elapsed":6022,"status":"ok","timestamp":1651750801511,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"O9KbGQdeN195","outputId":"271f00cb-d07d-43fa-e7bb-ff74228aa257"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f51b00af0c946b8971e8cf447b48d94","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7318679ec4634d6794085796f242e163","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bcf43b2805445b9952b0fa5258e374c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_len: 133\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twc1qFyRN17n"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label"]},{"cell_type":"markdown","metadata":{"id":"m1x8L7BQOKr2"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4Uu80kLN13D"},"outputs":[],"source":["class TransformerHead(nn.Module):\n","    def __init__(self, in_features, max_length, num_layers=1, nhead=8, num_targets=1):\n","        super().__init__()\n","\n","        self.transformer = nn.TransformerEncoder(\n","            encoder_layer=nn.TransformerEncoderLayer(d_model=in_features, nhead=nhead),\n","            num_layers=num_layers)\n","        self.row_fc = nn.Linear(in_features, 1)\n","        self.out_features = max_length\n","\n","    def forward(self, x):\n","        out = self.transformer(x)\n","        out = self.row_fc(out).squeeze(-1)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYUMhMGIOL4z"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        \n","        self.feature_extractor = AutoModelForTokenClassification.from_pretrained(cfg.model)\n","        in_features = self.feature_extractor.classifier.in_features\n","        self.attention = TransformerHead(in_features=in_features, max_length=133, num_layers=1, nhead=8, num_targets=1)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.attention.out_features, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        feature = self.attention(last_hidden_states)\n","        \n","        return feature\n","\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        #print(feature.shape)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPMtgF_NbjBe"},"outputs":[],"source":["# # ====================================================\n","# # Model\n","# # ====================================================\n","# class CustomModel(nn.Module):\n","#     def __init__(self, cfg, config_path=None, pretrained=False):\n","#         super().__init__()\n","#         self.cfg = cfg\n","#         if config_path is None:\n","#             self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","#         else:\n","#             self.config = torch.load(config_path)\n","#         if pretrained:\n","#             self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","#         else:\n","#             self.model = AutoModel.from_config(self.config)\n","#         self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","#         self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","#         self._init_weights(self.fc)\n","#         self.attention = nn.Sequential(\n","#             nn.Linear(self.config.hidden_size, 512),\n","#             nn.Tanh(),\n","#             nn.Linear(512, 1),\n","#             nn.Softmax(dim=1)\n","#         )\n","#         self._init_weights(self.attention)\n","        \n","#     def _init_weights(self, module):\n","#         if isinstance(module, nn.Linear):\n","#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","#             if module.bias is not None:\n","#                 module.bias.data.zero_()\n","#         elif isinstance(module, nn.Embedding):\n","#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","#             if module.padding_idx is not None:\n","#                 module.weight.data[module.padding_idx].zero_()\n","#         elif isinstance(module, nn.LayerNorm):\n","#             module.bias.data.zero_()\n","#             module.weight.data.fill_(1.0)\n","        \n","#     def feature(self, inputs):\n","#         outputs = self.model(**inputs)\n","#         last_hidden_states = outputs[0]\n","#         # feature = torch.mean(last_hidden_states, 1)\n","#         weights = self.attention(last_hidden_states)\n","#         feature = torch.sum(weights * last_hidden_states, dim=1)\n","#         return feature\n","\n","#     def forward(self, inputs):\n","#         feature = self.feature(inputs)\n","#         output = self.fc(self.fc_dropout(feature))\n","#         return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmtpzWxmRGwb"},"outputs":[],"source":["class FocalLossV1(nn.Module):\n","    def __init__(self,\n","                 alpha=0.25,\n","                 gamma=2,\n","                 reduction='mean',):\n","        super(FocalLossV1, self).__init__()\n","        self.alpha = alpha\n","        # self.alpha = torch.tensor([alpha, 1-alpha]).cuda()\n","        self.gamma = gamma\n","        self.reduction = reduction\n","        self.crit = nn.BCEWithLogitsLoss(reduction='none')\n","\n","    def forward(self, logits, label):\n","        '''\n","        Usage is same as nn.BCEWithLogits:\n","            >>> criteria = FocalLossV1()\n","            >>> logits = torch.randn(8, 19, 384, 384)\n","            >>> lbs = torch.randint(0, 2, (8, 19, 384, 384)).float()\n","            >>> loss = criteria(logits, lbs)\n","        '''\n","        probs = torch.sigmoid(logits)\n","        coeff = torch.abs(label - probs).pow(self.gamma).neg()\n","        log_probs = torch.where(logits >= 0,\n","                F.softplus(logits, -1, 50),\n","                logits - F.softplus(logits, 1, 50))\n","        log_1_probs = torch.where(logits >= 0,\n","                -logits + F.softplus(logits, -1, 50),\n","                -F.softplus(logits, 1, 50))\n","        loss = label * self.alpha * log_probs + (1. - label) * (1. - self.alpha) * log_1_probs\n","        loss = loss * coeff\n","\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        if self.reduction == 'sum':\n","            loss = loss.sum()\n","        return loss\n","        # BCE_loss = F.binary_cross_entropy_with_logits(logits, label, reduction='none')\n","        # targets = label.type(torch.long)\n","        # at = self.alpha.gather(0, targets.data.view(-1))\n","        # pt = torch.exp(-BCE_loss)\n","        # F_loss = at*(1-pt)**self.gamma * BCE_loss\n","        # return F_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"N80Z0ZF9OcjW"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjzXaGwxN10f"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        # loss = criterion(y_preds.sigmoid().view(-1, 1), labels.view(-1, 1))\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        # preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9fNekOSN1yT"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    # criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    criterion = FocalLossV1().cuda()\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["42dbe699f48d408db53cdfb37eb70271","41ff7814d98b4890b8ae497fe46b1e74","053622ad6b62496d9918efd68e086b70","e4f39d2a23034b9d9ae048a525c64f4b","ad4c3b4a38494c7db66148c71ac06460","b76859dd3da0471db7ac35fa116478f1","95f3684adc374590bcf8631f9990d73f","87fc94aa16e0457d954d6448e8634d21","0833bb9884c545a18ad187dbb1ecb76c","e24f1cc8f7b34cd7bed2538447e70006","07c27ab4282940fb90ef6291653f2cd6","64ea357fd2b34a66ad2a8e2e2e5174dd"]},"id":"GIQnVGWmN1vf","outputId":"4f1428a8-970b-4c0d-80f9-349a907b417e"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42dbe699f48d408db53cdfb37eb70271","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['lm_predictions.lm_head.dense.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2917] Elapsed 0m 0s (remain 41m 3s) Loss: 0.0395(0.0395) Grad: 57540.9570  LR: 0.00000040  \n","Epoch: [1][100/2917] Elapsed 0m 26s (remain 12m 16s) Loss: 0.0206(0.0260) Grad: 33961.5234  LR: 0.00002000  \n","Epoch: [1][200/2917] Elapsed 0m 52s (remain 11m 44s) Loss: 0.0212(0.0214) Grad: 60270.8789  LR: 0.00001999  \n","Epoch: [1][300/2917] Elapsed 1m 17s (remain 11m 14s) Loss: 0.0092(0.0186) Grad: 18792.7695  LR: 0.00001999  \n","Epoch: [1][400/2917] Elapsed 1m 43s (remain 10m 47s) Loss: 0.0083(0.0169) Grad: 18679.0488  LR: 0.00001997  \n","Epoch: [1][500/2917] Elapsed 2m 8s (remain 10m 21s) Loss: 0.0158(0.0156) Grad: 30010.2090  LR: 0.00001995  \n","Epoch: [1][600/2917] Elapsed 2m 34s (remain 9m 54s) Loss: 0.0164(0.0146) Grad: 34942.2422  LR: 0.00001993  \n","Epoch: [1][700/2917] Elapsed 3m 0s (remain 9m 31s) Loss: 0.0082(0.0138) Grad: 11473.5996  LR: 0.00001990  \n","Epoch: [1][800/2917] Elapsed 3m 26s (remain 9m 5s) Loss: 0.0117(0.0133) Grad: 59560.9805  LR: 0.00001987  \n","Epoch: [1][900/2917] Elapsed 3m 52s (remain 8m 39s) Loss: 0.0070(0.0129) Grad: 13183.1963  LR: 0.00001983  \n","Epoch: [1][1000/2917] Elapsed 4m 18s (remain 8m 13s) Loss: 0.0133(0.0124) Grad: 16073.6240  LR: 0.00001979  \n","Epoch: [1][1100/2917] Elapsed 4m 43s (remain 7m 47s) Loss: 0.0042(0.0121) Grad: 6298.3403  LR: 0.00001974  \n","Epoch: [1][1200/2917] Elapsed 5m 9s (remain 7m 21s) Loss: 0.0105(0.0118) Grad: 25862.0527  LR: 0.00001969  \n","Epoch: [1][1300/2917] Elapsed 5m 34s (remain 6m 55s) Loss: 0.0025(0.0115) Grad: 12694.9463  LR: 0.00001964  \n","Epoch: [1][1400/2917] Elapsed 6m 0s (remain 6m 29s) Loss: 0.0041(0.0113) Grad: 14052.2822  LR: 0.00001958  \n","Epoch: [1][1500/2917] Elapsed 6m 26s (remain 6m 4s) Loss: 0.0035(0.0110) Grad: 12046.5527  LR: 0.00001951  \n","Epoch: [1][1600/2917] Elapsed 6m 52s (remain 5m 38s) Loss: 0.0072(0.0109) Grad: 39372.4883  LR: 0.00001944  \n","Epoch: [1][1700/2917] Elapsed 7m 17s (remain 5m 12s) Loss: 0.0172(0.0107) Grad: 33227.6211  LR: 0.00001937  \n","Epoch: [1][1800/2917] Elapsed 7m 43s (remain 4m 46s) Loss: 0.0063(0.0105) Grad: 9390.2471  LR: 0.00001929  \n","Epoch: [1][1900/2917] Elapsed 8m 9s (remain 4m 21s) Loss: 0.0073(0.0103) Grad: 14299.6113  LR: 0.00001921  \n","Epoch: [1][2000/2917] Elapsed 8m 34s (remain 3m 55s) Loss: 0.0070(0.0102) Grad: 27540.9863  LR: 0.00001912  \n","Epoch: [1][2100/2917] Elapsed 9m 0s (remain 3m 29s) Loss: 0.0225(0.0101) Grad: 35190.4023  LR: 0.00001903  \n","Epoch: [1][2200/2917] Elapsed 9m 26s (remain 3m 4s) Loss: 0.0006(0.0100) Grad: 2280.6575  LR: 0.00001894  \n","Epoch: [1][2300/2917] Elapsed 9m 52s (remain 2m 38s) Loss: 0.0047(0.0098) Grad: 11624.5625  LR: 0.00001884  \n","Epoch: [1][2400/2917] Elapsed 10m 18s (remain 2m 12s) Loss: 0.0084(0.0097) Grad: 24807.5996  LR: 0.00001874  \n","Epoch: [1][2500/2917] Elapsed 10m 44s (remain 1m 47s) Loss: 0.0071(0.0096) Grad: 16840.6758  LR: 0.00001863  \n","Epoch: [1][2600/2917] Elapsed 11m 10s (remain 1m 21s) Loss: 0.0024(0.0095) Grad: 7907.3462  LR: 0.00001852  \n","Epoch: [1][2700/2917] Elapsed 11m 35s (remain 0m 55s) Loss: 0.0025(0.0094) Grad: 3559.5093  LR: 0.00001840  \n","Epoch: [1][2800/2917] Elapsed 12m 1s (remain 0m 29s) Loss: 0.0033(0.0093) Grad: 6186.9106  LR: 0.00001828  \n","Epoch: [1][2900/2917] Elapsed 12m 27s (remain 0m 4s) Loss: 0.0039(0.0093) Grad: 9396.0166  LR: 0.00001816  \n","Epoch: [1][2916/2917] Elapsed 12m 31s (remain 0m 0s) Loss: 0.0042(0.0092) Grad: 16009.9395  LR: 0.00001814  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 39s) Loss: 0.0009(0.0009) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0042(0.0072) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 57s) Loss: 0.0049(0.0068) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0090(0.0064) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0089(0.0063) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0018(0.0064) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0040(0.0064) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0129(0.0065) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0092  avg_val_loss: 0.0065  time: 831s\n","Epoch 1 - Score: 0.8331\n","Epoch 1 - Save Best Score: 0.8331 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0009(0.0065) \n","Epoch: [2][0/2917] Elapsed 0m 0s (remain 29m 55s) Loss: 0.0051(0.0051) Grad: 11674.1807  LR: 0.00001814  \n","Epoch: [2][100/2917] Elapsed 0m 27s (remain 12m 40s) Loss: 0.0026(0.0047) Grad: 20088.9844  LR: 0.00001801  \n","Epoch: [2][200/2917] Elapsed 0m 53s (remain 12m 7s) Loss: 0.0050(0.0051) Grad: 11132.5000  LR: 0.00001788  \n","Epoch: [2][300/2917] Elapsed 1m 20s (remain 11m 36s) Loss: 0.0035(0.0048) Grad: 29348.0195  LR: 0.00001775  \n","Epoch: [2][400/2917] Elapsed 1m 45s (remain 11m 4s) Loss: 0.0049(0.0049) Grad: 16333.0059  LR: 0.00001761  \n","Epoch: [2][500/2917] Elapsed 2m 11s (remain 10m 33s) Loss: 0.0040(0.0049) Grad: 10002.2041  LR: 0.00001747  \n","Epoch: [2][600/2917] Elapsed 2m 37s (remain 10m 5s) Loss: 0.0065(0.0050) Grad: 8701.7305  LR: 0.00001732  \n","Epoch: [2][700/2917] Elapsed 3m 2s (remain 9m 38s) Loss: 0.0043(0.0050) Grad: 7229.6401  LR: 0.00001717  \n","Epoch: [2][800/2917] Elapsed 3m 28s (remain 9m 11s) Loss: 0.0030(0.0050) Grad: 38005.0781  LR: 0.00001702  \n","Epoch: [2][900/2917] Elapsed 3m 55s (remain 8m 46s) Loss: 0.0018(0.0050) Grad: 8417.6309  LR: 0.00001686  \n","Epoch: [2][1000/2917] Elapsed 4m 20s (remain 8m 19s) Loss: 0.0038(0.0049) Grad: 11772.5127  LR: 0.00001671  \n","Epoch: [2][1100/2917] Elapsed 4m 46s (remain 7m 52s) Loss: 0.0177(0.0050) Grad: 47909.0195  LR: 0.00001654  \n","Epoch: [2][1200/2917] Elapsed 5m 12s (remain 7m 26s) Loss: 0.0119(0.0051) Grad: 13802.8574  LR: 0.00001638  \n","Epoch: [2][1300/2917] Elapsed 5m 38s (remain 7m 0s) Loss: 0.0049(0.0050) Grad: 10891.0830  LR: 0.00001621  \n","Epoch: [2][1400/2917] Elapsed 6m 4s (remain 6m 34s) Loss: 0.0079(0.0050) Grad: 22867.6602  LR: 0.00001604  \n","Epoch: [2][1500/2917] Elapsed 6m 30s (remain 6m 8s) Loss: 0.0073(0.0050) Grad: 28994.4395  LR: 0.00001587  \n","Epoch: [2][1600/2917] Elapsed 6m 56s (remain 5m 41s) Loss: 0.0041(0.0050) Grad: 4855.0356  LR: 0.00001569  \n","Epoch: [2][1700/2917] Elapsed 7m 21s (remain 5m 15s) Loss: 0.0028(0.0050) Grad: 5613.4263  LR: 0.00001551  \n","Epoch: [2][1800/2917] Elapsed 7m 47s (remain 4m 49s) Loss: 0.0034(0.0050) Grad: 8704.3369  LR: 0.00001533  \n","Epoch: [2][1900/2917] Elapsed 8m 13s (remain 4m 23s) Loss: 0.0013(0.0050) Grad: 4277.2915  LR: 0.00001515  \n","Epoch: [2][2000/2917] Elapsed 8m 38s (remain 3m 57s) Loss: 0.0062(0.0050) Grad: 32339.7754  LR: 0.00001496  \n","Epoch: [2][2100/2917] Elapsed 9m 4s (remain 3m 31s) Loss: 0.0038(0.0049) Grad: 17054.1094  LR: 0.00001477  \n","Epoch: [2][2200/2917] Elapsed 9m 30s (remain 3m 5s) Loss: 0.0022(0.0049) Grad: 23522.7246  LR: 0.00001458  \n","Epoch: [2][2300/2917] Elapsed 9m 56s (remain 2m 39s) Loss: 0.0026(0.0049) Grad: 15829.7383  LR: 0.00001439  \n","Epoch: [2][2400/2917] Elapsed 10m 21s (remain 2m 13s) Loss: 0.0055(0.0049) Grad: 36758.6992  LR: 0.00001419  \n","Epoch: [2][2500/2917] Elapsed 10m 47s (remain 1m 47s) Loss: 0.0131(0.0049) Grad: 63107.8906  LR: 0.00001399  \n","Epoch: [2][2600/2917] Elapsed 11m 13s (remain 1m 21s) Loss: 0.0008(0.0049) Grad: 6821.2539  LR: 0.00001380  \n","Epoch: [2][2700/2917] Elapsed 11m 39s (remain 0m 55s) Loss: 0.0030(0.0048) Grad: 17741.9082  LR: 0.00001359  \n","Epoch: [2][2800/2917] Elapsed 12m 4s (remain 0m 30s) Loss: 0.0044(0.0048) Grad: 17594.5957  LR: 0.00001339  \n","Epoch: [2][2900/2917] Elapsed 12m 30s (remain 0m 4s) Loss: 0.0004(0.0048) Grad: 5241.9961  LR: 0.00001319  \n","Epoch: [2][2916/2917] Elapsed 12m 34s (remain 0m 0s) Loss: 0.0024(0.0048) Grad: 17144.3184  LR: 0.00001316  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 19s) Loss: 0.0064(0.0064) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0036(0.0069) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0042(0.0063) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0068(0.0058) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0050(0.0057) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0014(0.0059) \n","EVAL: [600/730] Elapsed 1m 4s (remain 0m 13s) Loss: 0.0062(0.0058) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0127(0.0059) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0048  avg_val_loss: 0.0059  time: 833s\n","Epoch 2 - Score: 0.8386\n","Epoch 2 - Save Best Score: 0.8386 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0007(0.0059) \n","Epoch: [3][0/2917] Elapsed 0m 0s (remain 30m 54s) Loss: 0.0028(0.0028) Grad: 5974.9116  LR: 0.00001315  \n","Epoch: [3][100/2917] Elapsed 0m 27s (remain 12m 40s) Loss: 0.0007(0.0031) Grad: 2791.5486  LR: 0.00001295  \n","Epoch: [3][200/2917] Elapsed 0m 53s (remain 12m 8s) Loss: 0.0032(0.0033) Grad: 8959.9336  LR: 0.00001274  \n","Epoch: [3][300/2917] Elapsed 1m 20s (remain 11m 37s) Loss: 0.0024(0.0034) Grad: 5413.5449  LR: 0.00001253  \n","Epoch: [3][400/2917] Elapsed 1m 45s (remain 11m 1s) Loss: 0.0019(0.0034) Grad: 5982.5967  LR: 0.00001232  \n","Epoch: [3][500/2917] Elapsed 2m 10s (remain 10m 31s) Loss: 0.0063(0.0034) Grad: 21289.3809  LR: 0.00001211  \n","Epoch: [3][600/2917] Elapsed 2m 36s (remain 10m 2s) Loss: 0.0014(0.0035) Grad: 9189.3115  LR: 0.00001190  \n","Epoch: [3][700/2917] Elapsed 3m 1s (remain 9m 34s) Loss: 0.0018(0.0034) Grad: 4527.1172  LR: 0.00001169  \n","Epoch: [3][800/2917] Elapsed 3m 27s (remain 9m 8s) Loss: 0.0024(0.0034) Grad: 7015.3228  LR: 0.00001147  \n","Epoch: [3][900/2917] Elapsed 3m 53s (remain 8m 41s) Loss: 0.0019(0.0034) Grad: 5505.3140  LR: 0.00001126  \n","Epoch: [3][1000/2917] Elapsed 4m 19s (remain 8m 16s) Loss: 0.0049(0.0034) Grad: 10749.1436  LR: 0.00001104  \n","Epoch: [3][1100/2917] Elapsed 4m 45s (remain 7m 50s) Loss: 0.0037(0.0034) Grad: 14871.4189  LR: 0.00001083  \n","Epoch: [3][1200/2917] Elapsed 5m 11s (remain 7m 24s) Loss: 0.0024(0.0034) Grad: 7606.9878  LR: 0.00001061  \n","Epoch: [3][1300/2917] Elapsed 5m 37s (remain 6m 59s) Loss: 0.0011(0.0034) Grad: 11663.5283  LR: 0.00001040  \n","Epoch: [3][1400/2917] Elapsed 6m 2s (remain 6m 32s) Loss: 0.0022(0.0034) Grad: 6178.6460  LR: 0.00001018  \n","Epoch: [3][1500/2917] Elapsed 6m 29s (remain 6m 7s) Loss: 0.0014(0.0034) Grad: 6916.7925  LR: 0.00000997  \n","Epoch: [3][1600/2917] Elapsed 6m 54s (remain 5m 41s) Loss: 0.0026(0.0034) Grad: 5849.2119  LR: 0.00000975  \n","Epoch: [3][1700/2917] Elapsed 7m 20s (remain 5m 14s) Loss: 0.0031(0.0034) Grad: 9958.9434  LR: 0.00000953  \n","Epoch: [3][1800/2917] Elapsed 7m 45s (remain 4m 48s) Loss: 0.0036(0.0034) Grad: 8258.2422  LR: 0.00000932  \n","Epoch: [3][1900/2917] Elapsed 8m 10s (remain 4m 22s) Loss: 0.0015(0.0034) Grad: 7098.4863  LR: 0.00000910  \n","Epoch: [3][2000/2917] Elapsed 8m 36s (remain 3m 56s) Loss: 0.0014(0.0034) Grad: 12465.6406  LR: 0.00000889  \n","Epoch: [3][2100/2917] Elapsed 9m 1s (remain 3m 30s) Loss: 0.0014(0.0034) Grad: 8063.4136  LR: 0.00000867  \n","Epoch: [3][2200/2917] Elapsed 9m 27s (remain 3m 4s) Loss: 0.0019(0.0034) Grad: 17737.3379  LR: 0.00000846  \n","Epoch: [3][2300/2917] Elapsed 9m 52s (remain 2m 38s) Loss: 0.0048(0.0034) Grad: 21314.9531  LR: 0.00000825  \n","Epoch: [3][2400/2917] Elapsed 10m 17s (remain 2m 12s) Loss: 0.0032(0.0034) Grad: 13474.3203  LR: 0.00000803  \n","Epoch: [3][2500/2917] Elapsed 10m 43s (remain 1m 47s) Loss: 0.0005(0.0034) Grad: 5075.8906  LR: 0.00000782  \n","Epoch: [3][2600/2917] Elapsed 11m 9s (remain 1m 21s) Loss: 0.0058(0.0034) Grad: 28342.0586  LR: 0.00000761  \n","Epoch: [3][2700/2917] Elapsed 11m 34s (remain 0m 55s) Loss: 0.0154(0.0034) Grad: 53130.7305  LR: 0.00000740  \n","Epoch: [3][2800/2917] Elapsed 12m 0s (remain 0m 29s) Loss: 0.0100(0.0034) Grad: 69232.5312  LR: 0.00000720  \n","Epoch: [3][2900/2917] Elapsed 12m 25s (remain 0m 4s) Loss: 0.0050(0.0034) Grad: 22679.6250  LR: 0.00000699  \n","Epoch: [3][2916/2917] Elapsed 12m 29s (remain 0m 0s) Loss: 0.0027(0.0034) Grad: 20591.4141  LR: 0.00000696  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 28s) Loss: 0.0136(0.0136) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0037(0.0068) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0045(0.0065) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0073(0.0060) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0074(0.0058) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0005(0.0059) \n","EVAL: [600/730] Elapsed 1m 4s (remain 0m 13s) Loss: 0.0058(0.0057) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0144(0.0057) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0034  avg_val_loss: 0.0058  time: 829s\n","Epoch 3 - Score: 0.8330\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0003(0.0058) \n","Epoch: [4][0/2917] Elapsed 0m 0s (remain 30m 7s) Loss: 0.0014(0.0014) Grad: 7326.5244  LR: 0.00000695  \n","Epoch: [4][100/2917] Elapsed 0m 26s (remain 12m 13s) Loss: 0.0009(0.0021) Grad: 5445.2168  LR: 0.00000675  \n","Epoch: [4][200/2917] Elapsed 0m 52s (remain 11m 47s) Loss: 0.0016(0.0024) Grad: 10977.6445  LR: 0.00000655  \n","Epoch: [4][300/2917] Elapsed 1m 18s (remain 11m 18s) Loss: 0.0020(0.0025) Grad: 11710.8389  LR: 0.00000634  \n","Epoch: [4][400/2917] Elapsed 1m 43s (remain 10m 49s) Loss: 0.0008(0.0024) Grad: 4902.9463  LR: 0.00000614  \n","Epoch: [4][500/2917] Elapsed 2m 9s (remain 10m 23s) Loss: 0.0032(0.0024) Grad: 9508.8594  LR: 0.00000594  \n","Epoch: [4][600/2917] Elapsed 2m 35s (remain 9m 57s) Loss: 0.0027(0.0024) Grad: 12313.7207  LR: 0.00000575  \n","Epoch: [4][700/2917] Elapsed 3m 0s (remain 9m 31s) Loss: 0.0024(0.0024) Grad: 5699.3213  LR: 0.00000555  \n","Epoch: [4][800/2917] Elapsed 3m 26s (remain 9m 5s) Loss: 0.0047(0.0024) Grad: 8010.1792  LR: 0.00000536  \n","Epoch: [4][900/2917] Elapsed 3m 51s (remain 8m 38s) Loss: 0.0014(0.0023) Grad: 6575.3672  LR: 0.00000517  \n","Epoch: [4][1000/2917] Elapsed 4m 17s (remain 8m 12s) Loss: 0.0015(0.0023) Grad: 3556.3416  LR: 0.00000498  \n","Epoch: [4][1100/2917] Elapsed 4m 42s (remain 7m 46s) Loss: 0.0048(0.0023) Grad: 9937.5381  LR: 0.00000480  \n","Epoch: [4][1200/2917] Elapsed 5m 8s (remain 7m 20s) Loss: 0.0028(0.0023) Grad: 5313.3618  LR: 0.00000461  \n","Epoch: [4][1300/2917] Elapsed 5m 33s (remain 6m 54s) Loss: 0.0012(0.0023) Grad: 6332.9619  LR: 0.00000443  \n","Epoch: [4][1400/2917] Elapsed 5m 59s (remain 6m 29s) Loss: 0.0043(0.0024) Grad: 8464.4756  LR: 0.00000425  \n","Epoch: [4][1500/2917] Elapsed 6m 24s (remain 6m 2s) Loss: 0.0006(0.0023) Grad: 3586.4241  LR: 0.00000408  \n","Epoch: [4][1600/2917] Elapsed 6m 50s (remain 5m 37s) Loss: 0.0003(0.0023) Grad: 2134.7834  LR: 0.00000391  \n","Epoch: [4][1700/2917] Elapsed 7m 16s (remain 5m 11s) Loss: 0.0003(0.0024) Grad: 2555.8254  LR: 0.00000374  \n","Epoch: [4][1800/2917] Elapsed 7m 42s (remain 4m 46s) Loss: 0.0040(0.0024) Grad: 16829.2188  LR: 0.00000357  \n","Epoch: [4][1900/2917] Elapsed 8m 7s (remain 4m 20s) Loss: 0.0015(0.0024) Grad: 4387.9253  LR: 0.00000341  \n","Epoch: [4][2000/2917] Elapsed 8m 33s (remain 3m 54s) Loss: 0.0025(0.0024) Grad: 13364.2686  LR: 0.00000324  \n","Epoch: [4][2100/2917] Elapsed 8m 58s (remain 3m 29s) Loss: 0.0015(0.0023) Grad: 24632.9316  LR: 0.00000309  \n","Epoch: [4][2200/2917] Elapsed 9m 24s (remain 3m 3s) Loss: 0.0026(0.0023) Grad: 14032.4883  LR: 0.00000293  \n","Epoch: [4][2300/2917] Elapsed 9m 50s (remain 2m 37s) Loss: 0.0014(0.0023) Grad: 14141.4521  LR: 0.00000278  \n","Epoch: [4][2400/2917] Elapsed 10m 15s (remain 2m 12s) Loss: 0.0007(0.0024) Grad: 7884.6909  LR: 0.00000263  \n","Epoch: [4][2500/2917] Elapsed 10m 40s (remain 1m 46s) Loss: 0.0012(0.0024) Grad: 9897.7109  LR: 0.00000249  \n","Epoch: [4][2600/2917] Elapsed 11m 6s (remain 1m 21s) Loss: 0.0005(0.0023) Grad: 7590.9370  LR: 0.00000235  \n","Epoch: [4][2700/2917] Elapsed 11m 32s (remain 0m 55s) Loss: 0.0042(0.0023) Grad: 35258.0742  LR: 0.00000221  \n","Epoch: [4][2800/2917] Elapsed 11m 58s (remain 0m 29s) Loss: 0.0082(0.0023) Grad: 51827.0039  LR: 0.00000208  \n","Epoch: [4][2900/2917] Elapsed 12m 23s (remain 0m 4s) Loss: 0.0073(0.0023) Grad: 31026.9199  LR: 0.00000195  \n","Epoch: [4][2916/2917] Elapsed 12m 27s (remain 0m 0s) Loss: 0.0031(0.0023) Grad: 17680.1172  LR: 0.00000193  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 27s) Loss: 0.0159(0.0159) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0034(0.0069) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0049(0.0067) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0081(0.0062) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0067(0.0059) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0004(0.0061) \n","EVAL: [600/730] Elapsed 1m 4s (remain 0m 13s) Loss: 0.0072(0.0059) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0112(0.0059) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0060  time: 827s\n","Epoch 4 - Score: 0.8258\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0001(0.0060) \n","Epoch: [5][0/2917] Elapsed 0m 0s (remain 29m 52s) Loss: 0.0021(0.0021) Grad: 9361.0479  LR: 0.00000193  \n","Epoch: [5][100/2917] Elapsed 0m 26s (remain 12m 21s) Loss: 0.0019(0.0017) Grad: 18831.6309  LR: 0.00000180  \n","Epoch: [5][200/2917] Elapsed 0m 52s (remain 11m 47s) Loss: 0.0026(0.0018) Grad: 10160.2363  LR: 0.00000168  \n","Epoch: [5][300/2917] Elapsed 1m 17s (remain 11m 17s) Loss: 0.0004(0.0017) Grad: 2805.7529  LR: 0.00000156  \n","Epoch: [5][400/2917] Elapsed 1m 43s (remain 10m 49s) Loss: 0.0014(0.0017) Grad: 3249.1182  LR: 0.00000145  \n","Epoch: [5][500/2917] Elapsed 2m 9s (remain 10m 24s) Loss: 0.0043(0.0018) Grad: 8334.4326  LR: 0.00000134  \n","Epoch: [5][600/2917] Elapsed 2m 35s (remain 9m 58s) Loss: 0.0010(0.0019) Grad: 5579.1426  LR: 0.00000123  \n","Epoch: [5][700/2917] Elapsed 3m 0s (remain 9m 31s) Loss: 0.0031(0.0019) Grad: 8794.4160  LR: 0.00000113  \n","Epoch: [5][800/2917] Elapsed 3m 26s (remain 9m 6s) Loss: 0.0034(0.0018) Grad: 8993.4775  LR: 0.00000103  \n","Epoch: [5][900/2917] Elapsed 3m 52s (remain 8m 40s) Loss: 0.0013(0.0018) Grad: 8332.2207  LR: 0.00000094  \n","Epoch: [5][1000/2917] Elapsed 4m 18s (remain 8m 15s) Loss: 0.0046(0.0019) Grad: 23029.4629  LR: 0.00000085  \n","Epoch: [5][1100/2917] Elapsed 4m 44s (remain 7m 49s) Loss: 0.0025(0.0019) Grad: 9495.0713  LR: 0.00000076  \n","Epoch: [5][1200/2917] Elapsed 5m 10s (remain 7m 23s) Loss: 0.0024(0.0019) Grad: 17373.0938  LR: 0.00000068  \n","Epoch: [5][1300/2917] Elapsed 5m 36s (remain 6m 57s) Loss: 0.0005(0.0019) Grad: 6126.8950  LR: 0.00000061  \n","Epoch: [5][1400/2917] Elapsed 6m 2s (remain 6m 32s) Loss: 0.0012(0.0019) Grad: 6758.4453  LR: 0.00000053  \n","Epoch: [5][1500/2917] Elapsed 6m 28s (remain 6m 6s) Loss: 0.0004(0.0019) Grad: 3620.7910  LR: 0.00000047  \n","Epoch: [5][1600/2917] Elapsed 6m 53s (remain 5m 40s) Loss: 0.0003(0.0019) Grad: 2500.5979  LR: 0.00000040  \n","Epoch: [5][1700/2917] Elapsed 7m 20s (remain 5m 14s) Loss: 0.0039(0.0019) Grad: 15204.5195  LR: 0.00000035  \n","Epoch: [5][1800/2917] Elapsed 7m 46s (remain 4m 48s) Loss: 0.0013(0.0019) Grad: 9355.2607  LR: 0.00000029  \n","Epoch: [5][1900/2917] Elapsed 8m 12s (remain 4m 23s) Loss: 0.0052(0.0019) Grad: 10026.9385  LR: 0.00000024  \n","Epoch: [5][2000/2917] Elapsed 8m 38s (remain 3m 57s) Loss: 0.0027(0.0019) Grad: 10049.7432  LR: 0.00000020  \n","Epoch: [5][2100/2917] Elapsed 9m 4s (remain 3m 31s) Loss: 0.0007(0.0019) Grad: 13223.6396  LR: 0.00000016  \n","Epoch: [5][2200/2917] Elapsed 9m 31s (remain 3m 5s) Loss: 0.0013(0.0019) Grad: 14546.0371  LR: 0.00000012  \n","Epoch: [5][2300/2917] Elapsed 9m 57s (remain 2m 39s) Loss: 0.0009(0.0019) Grad: 7988.0181  LR: 0.00000009  \n","Epoch: [5][2400/2917] Elapsed 10m 23s (remain 2m 14s) Loss: 0.0017(0.0019) Grad: 10632.5898  LR: 0.00000006  \n","Epoch: [5][2500/2917] Elapsed 10m 50s (remain 1m 48s) Loss: 0.0023(0.0019) Grad: 14970.5254  LR: 0.00000004  \n","Epoch: [5][2600/2917] Elapsed 11m 16s (remain 1m 22s) Loss: 0.0038(0.0019) Grad: 21090.1484  LR: 0.00000002  \n","Epoch: [5][2700/2917] Elapsed 11m 43s (remain 0m 56s) Loss: 0.0008(0.0019) Grad: 23343.6230  LR: 0.00000001  \n","Epoch: [5][2800/2917] Elapsed 12m 9s (remain 0m 30s) Loss: 0.0030(0.0019) Grad: 16876.2617  LR: 0.00000000  \n","Epoch: [5][2900/2917] Elapsed 12m 35s (remain 0m 4s) Loss: 0.0004(0.0019) Grad: 10596.9883  LR: 0.00000000  \n","Epoch: [5][2916/2917] Elapsed 12m 39s (remain 0m 0s) Loss: 0.0010(0.0019) Grad: 8107.1748  LR: 0.00000000  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 32s) Loss: 0.0161(0.0161) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0037(0.0070) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0050(0.0068) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0088(0.0063) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0073(0.0060) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0003(0.0062) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0077(0.0060) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0119(0.0061) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0019  avg_val_loss: 0.0061  time: 838s\n","Epoch 5 - Score: 0.8254\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0001(0.0061) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.8386\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['lm_predictions.lm_head.dense.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2917] Elapsed 0m 0s (remain 30m 48s) Loss: 0.0397(0.0397) Grad: 64993.8320  LR: 0.00000040  \n","Epoch: [1][100/2917] Elapsed 0m 26s (remain 12m 20s) Loss: 0.0082(0.0229) Grad: 13460.7891  LR: 0.00002000  \n","Epoch: [1][200/2917] Elapsed 0m 52s (remain 11m 47s) Loss: 0.0180(0.0214) Grad: 13687.8799  LR: 0.00001999  \n","Epoch: [1][300/2917] Elapsed 1m 17s (remain 11m 17s) Loss: 0.0121(0.0207) Grad: 20043.2168  LR: 0.00001999  \n","Epoch: [1][400/2917] Elapsed 1m 43s (remain 10m 48s) Loss: 0.0186(0.0196) Grad: 40200.6797  LR: 0.00001997  \n","Epoch: [1][500/2917] Elapsed 2m 8s (remain 10m 20s) Loss: 0.0075(0.0186) Grad: 19787.4453  LR: 0.00001995  \n","Epoch: [1][600/2917] Elapsed 2m 34s (remain 9m 53s) Loss: 0.0136(0.0176) Grad: 51605.5273  LR: 0.00001993  \n","Epoch: [1][700/2917] Elapsed 2m 59s (remain 9m 26s) Loss: 0.0097(0.0166) Grad: 20879.4258  LR: 0.00001990  \n","Epoch: [1][800/2917] Elapsed 3m 24s (remain 9m 1s) Loss: 0.0090(0.0159) Grad: 22007.5605  LR: 0.00001987  \n","Epoch: [1][900/2917] Elapsed 3m 50s (remain 8m 34s) Loss: 0.0114(0.0152) Grad: 24973.3594  LR: 0.00001983  \n","Epoch: [1][1000/2917] Elapsed 4m 15s (remain 8m 9s) Loss: 0.0038(0.0146) Grad: 8790.6621  LR: 0.00001979  \n","Epoch: [1][1100/2917] Elapsed 4m 41s (remain 7m 44s) Loss: 0.0044(0.0142) Grad: 9122.5244  LR: 0.00001974  \n","Epoch: [1][1200/2917] Elapsed 5m 7s (remain 7m 19s) Loss: 0.0040(0.0138) Grad: 11715.0723  LR: 0.00001969  \n","Epoch: [1][1300/2917] Elapsed 5m 33s (remain 6m 54s) Loss: 0.0030(0.0134) Grad: 10082.6191  LR: 0.00001964  \n","Epoch: [1][1400/2917] Elapsed 5m 59s (remain 6m 28s) Loss: 0.0064(0.0130) Grad: 19273.9922  LR: 0.00001958  \n","Epoch: [1][1500/2917] Elapsed 6m 25s (remain 6m 3s) Loss: 0.0054(0.0127) Grad: 11024.7197  LR: 0.00001951  \n","Epoch: [1][1600/2917] Elapsed 6m 50s (remain 5m 37s) Loss: 0.0111(0.0125) Grad: 17770.7324  LR: 0.00001944  \n","Epoch: [1][1700/2917] Elapsed 7m 16s (remain 5m 12s) Loss: 0.0033(0.0123) Grad: 7655.0869  LR: 0.00001937  \n","Epoch: [1][1800/2917] Elapsed 7m 42s (remain 4m 46s) Loss: 0.0066(0.0120) Grad: 10153.7559  LR: 0.00001929  \n","Epoch: [1][1900/2917] Elapsed 8m 8s (remain 4m 21s) Loss: 0.0034(0.0117) Grad: 11834.5000  LR: 0.00001921  \n","Epoch: [1][2000/2917] Elapsed 8m 34s (remain 3m 55s) Loss: 0.0058(0.0116) Grad: 24865.7520  LR: 0.00001912  \n","Epoch: [1][2100/2917] Elapsed 9m 0s (remain 3m 29s) Loss: 0.0021(0.0114) Grad: 29220.7422  LR: 0.00001903  \n","Epoch: [1][2200/2917] Elapsed 9m 26s (remain 3m 4s) Loss: 0.0121(0.0112) Grad: 57763.0664  LR: 0.00001894  \n","Epoch: [1][2300/2917] Elapsed 9m 52s (remain 2m 38s) Loss: 0.0016(0.0110) Grad: 14874.7695  LR: 0.00001884  \n","Epoch: [1][2400/2917] Elapsed 10m 18s (remain 2m 12s) Loss: 0.0103(0.0108) Grad: 36956.0469  LR: 0.00001874  \n","Epoch: [1][2500/2917] Elapsed 10m 44s (remain 1m 47s) Loss: 0.0060(0.0107) Grad: 20896.3594  LR: 0.00001863  \n","Epoch: [1][2600/2917] Elapsed 11m 9s (remain 1m 21s) Loss: 0.0073(0.0105) Grad: 88783.4141  LR: 0.00001852  \n","Epoch: [1][2700/2917] Elapsed 11m 35s (remain 0m 55s) Loss: 0.0073(0.0104) Grad: 23009.2344  LR: 0.00001840  \n","Epoch: [1][2800/2917] Elapsed 12m 1s (remain 0m 29s) Loss: 0.0073(0.0103) Grad: 14672.5068  LR: 0.00001828  \n","Epoch: [1][2900/2917] Elapsed 12m 26s (remain 0m 4s) Loss: 0.0114(0.0102) Grad: 34003.9844  LR: 0.00001816  \n","Epoch: [1][2916/2917] Elapsed 12m 30s (remain 0m 0s) Loss: 0.0252(0.0102) Grad: 55668.6406  LR: 0.00001814  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 40s) Loss: 0.0026(0.0026) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0095(0.0074) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 57s) Loss: 0.0061(0.0074) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0049(0.0069) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0062(0.0076) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0017(0.0079) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0285(0.0080) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0136(0.0078) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0102  avg_val_loss: 0.0078  time: 830s\n","Epoch 1 - Score: 0.8198\n","Epoch 1 - Save Best Score: 0.8198 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0092(0.0078) \n","Epoch: [2][0/2917] Elapsed 0m 0s (remain 34m 14s) Loss: 0.0036(0.0036) Grad: 11079.6572  LR: 0.00001814  \n","Epoch: [2][100/2917] Elapsed 0m 27s (remain 12m 48s) Loss: 0.0013(0.0056) Grad: 4679.3271  LR: 0.00001801  \n","Epoch: [2][200/2917] Elapsed 0m 54s (remain 12m 18s) Loss: 0.0070(0.0057) Grad: 20496.6074  LR: 0.00001788  \n","Epoch: [2][300/2917] Elapsed 1m 20s (remain 11m 43s) Loss: 0.0083(0.0056) Grad: 20545.0176  LR: 0.00001775  \n","Epoch: [2][400/2917] Elapsed 1m 46s (remain 11m 9s) Loss: 0.0083(0.0055) Grad: 21726.8203  LR: 0.00001761  \n","Epoch: [2][500/2917] Elapsed 2m 12s (remain 10m 39s) Loss: 0.0067(0.0055) Grad: 13559.1338  LR: 0.00001747  \n","Epoch: [2][600/2917] Elapsed 2m 38s (remain 10m 9s) Loss: 0.0022(0.0055) Grad: 11921.6895  LR: 0.00001732  \n","Epoch: [2][700/2917] Elapsed 3m 3s (remain 9m 40s) Loss: 0.0042(0.0056) Grad: 9961.3496  LR: 0.00001717  \n","Epoch: [2][800/2917] Elapsed 3m 29s (remain 9m 12s) Loss: 0.0026(0.0056) Grad: 7505.0317  LR: 0.00001702  \n","Epoch: [2][900/2917] Elapsed 3m 54s (remain 8m 45s) Loss: 0.0051(0.0056) Grad: 9321.6494  LR: 0.00001686  \n","Epoch: [2][1000/2917] Elapsed 4m 20s (remain 8m 18s) Loss: 0.0072(0.0056) Grad: 21747.0215  LR: 0.00001671  \n","Epoch: [2][1100/2917] Elapsed 4m 46s (remain 7m 52s) Loss: 0.0073(0.0056) Grad: 26553.4941  LR: 0.00001654  \n","Epoch: [2][1200/2917] Elapsed 5m 11s (remain 7m 25s) Loss: 0.0048(0.0056) Grad: 9107.3867  LR: 0.00001638  \n","Epoch: [2][1300/2917] Elapsed 5m 37s (remain 6m 59s) Loss: 0.0047(0.0055) Grad: 19882.5781  LR: 0.00001621  \n","Epoch: [2][1400/2917] Elapsed 6m 2s (remain 6m 32s) Loss: 0.0042(0.0055) Grad: 23872.8047  LR: 0.00001604  \n","Epoch: [2][1500/2917] Elapsed 6m 28s (remain 6m 6s) Loss: 0.0024(0.0055) Grad: 13028.8848  LR: 0.00001587  \n","Epoch: [2][1600/2917] Elapsed 6m 54s (remain 5m 40s) Loss: 0.0041(0.0054) Grad: 24023.9492  LR: 0.00001569  \n","Epoch: [2][1700/2917] Elapsed 7m 20s (remain 5m 14s) Loss: 0.0029(0.0054) Grad: 34527.3828  LR: 0.00001551  \n","Epoch: [2][1800/2917] Elapsed 7m 45s (remain 4m 48s) Loss: 0.0026(0.0054) Grad: 8169.0830  LR: 0.00001533  \n","Epoch: [2][1900/2917] Elapsed 8m 11s (remain 4m 22s) Loss: 0.0048(0.0054) Grad: 8369.0547  LR: 0.00001515  \n","Epoch: [2][2000/2917] Elapsed 8m 36s (remain 3m 56s) Loss: 0.0046(0.0053) Grad: 18195.1738  LR: 0.00001496  \n","Epoch: [2][2100/2917] Elapsed 9m 1s (remain 3m 30s) Loss: 0.0024(0.0054) Grad: 14758.6494  LR: 0.00001477  \n","Epoch: [2][2200/2917] Elapsed 9m 27s (remain 3m 4s) Loss: 0.0053(0.0054) Grad: 24200.5195  LR: 0.00001458  \n","Epoch: [2][2300/2917] Elapsed 9m 53s (remain 2m 38s) Loss: 0.0046(0.0053) Grad: 21269.9004  LR: 0.00001439  \n","Epoch: [2][2400/2917] Elapsed 10m 18s (remain 2m 12s) Loss: 0.0027(0.0053) Grad: 17476.3125  LR: 0.00001419  \n","Epoch: [2][2500/2917] Elapsed 10m 44s (remain 1m 47s) Loss: 0.0053(0.0053) Grad: 20575.5020  LR: 0.00001399  \n","Epoch: [2][2600/2917] Elapsed 11m 9s (remain 1m 21s) Loss: 0.0022(0.0053) Grad: 21301.7793  LR: 0.00001380  \n","Epoch: [2][2700/2917] Elapsed 11m 35s (remain 0m 55s) Loss: 0.0027(0.0054) Grad: 17912.5332  LR: 0.00001359  \n","Epoch: [2][2800/2917] Elapsed 12m 2s (remain 0m 29s) Loss: 0.0022(0.0054) Grad: 10949.1494  LR: 0.00001339  \n","Epoch: [2][2900/2917] Elapsed 12m 28s (remain 0m 4s) Loss: 0.0024(0.0053) Grad: 8835.8027  LR: 0.00001319  \n","Epoch: [2][2916/2917] Elapsed 12m 32s (remain 0m 0s) Loss: 0.0021(0.0054) Grad: 12882.8721  LR: 0.00001316  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 58s) Loss: 0.0027(0.0027) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0088(0.0068) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0065(0.0068) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0058(0.0061) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0030(0.0067) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0017(0.0070) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0136(0.0069) \n","EVAL: [700/730] Elapsed 1m 16s (remain 0m 3s) Loss: 0.0051(0.0066) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0054  avg_val_loss: 0.0066  time: 832s\n","Epoch 2 - Score: 0.8179\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0034(0.0066) \n","Epoch: [3][0/2917] Elapsed 0m 0s (remain 31m 22s) Loss: 0.0031(0.0031) Grad: 8830.9590  LR: 0.00001315  \n","Epoch: [3][100/2917] Elapsed 0m 26s (remain 12m 31s) Loss: 0.0030(0.0034) Grad: 21011.7520  LR: 0.00001295  \n","Epoch: [3][200/2917] Elapsed 0m 53s (remain 12m 7s) Loss: 0.0031(0.0035) Grad: 8150.0752  LR: 0.00001274  \n","Epoch: [3][300/2917] Elapsed 1m 20s (remain 11m 40s) Loss: 0.0021(0.0036) Grad: 9230.5645  LR: 0.00001253  \n","Epoch: [3][400/2917] Elapsed 1m 47s (remain 11m 12s) Loss: 0.0024(0.0036) Grad: 4896.7812  LR: 0.00001232  \n","Epoch: [3][500/2917] Elapsed 2m 13s (remain 10m 45s) Loss: 0.0004(0.0037) Grad: 2977.3845  LR: 0.00001211  \n","Epoch: [3][600/2917] Elapsed 2m 40s (remain 10m 17s) Loss: 0.0081(0.0037) Grad: 23952.2695  LR: 0.00001190  \n","Epoch: [3][700/2917] Elapsed 3m 6s (remain 9m 49s) Loss: 0.0024(0.0037) Grad: 7509.4492  LR: 0.00001169  \n","Epoch: [3][800/2917] Elapsed 3m 32s (remain 9m 22s) Loss: 0.0021(0.0037) Grad: 4788.8071  LR: 0.00001147  \n","Epoch: [3][900/2917] Elapsed 3m 59s (remain 8m 55s) Loss: 0.0028(0.0037) Grad: 8188.5796  LR: 0.00001126  \n","Epoch: [3][1000/2917] Elapsed 4m 26s (remain 8m 29s) Loss: 0.0038(0.0037) Grad: 13904.4316  LR: 0.00001104  \n","Epoch: [3][1100/2917] Elapsed 4m 52s (remain 8m 2s) Loss: 0.0051(0.0037) Grad: 15841.8184  LR: 0.00001083  \n","Epoch: [3][1200/2917] Elapsed 5m 18s (remain 7m 35s) Loss: 0.0033(0.0036) Grad: 10756.5391  LR: 0.00001061  \n","Epoch: [3][1300/2917] Elapsed 5m 45s (remain 7m 9s) Loss: 0.0044(0.0037) Grad: 10043.4971  LR: 0.00001040  \n","Epoch: [3][1400/2917] Elapsed 6m 11s (remain 6m 42s) Loss: 0.0007(0.0037) Grad: 3748.4702  LR: 0.00001018  \n","Epoch: [3][1500/2917] Elapsed 6m 38s (remain 6m 15s) Loss: 0.0025(0.0036) Grad: 7040.2944  LR: 0.00000997  \n","Epoch: [3][1600/2917] Elapsed 7m 5s (remain 5m 49s) Loss: 0.0032(0.0036) Grad: 10157.4189  LR: 0.00000975  \n","Epoch: [3][1700/2917] Elapsed 7m 31s (remain 5m 22s) Loss: 0.0039(0.0036) Grad: 7404.8315  LR: 0.00000953  \n","Epoch: [3][1800/2917] Elapsed 7m 57s (remain 4m 56s) Loss: 0.0064(0.0036) Grad: 23362.9824  LR: 0.00000932  \n","Epoch: [3][1900/2917] Elapsed 8m 24s (remain 4m 29s) Loss: 0.0023(0.0036) Grad: 7310.5317  LR: 0.00000910  \n","Epoch: [3][2000/2917] Elapsed 8m 50s (remain 4m 2s) Loss: 0.0024(0.0036) Grad: 20585.0703  LR: 0.00000889  \n","Epoch: [3][2100/2917] Elapsed 9m 16s (remain 3m 36s) Loss: 0.0040(0.0036) Grad: 32018.6699  LR: 0.00000867  \n","Epoch: [3][2200/2917] Elapsed 9m 43s (remain 3m 9s) Loss: 0.0045(0.0036) Grad: 16866.6758  LR: 0.00000846  \n","Epoch: [3][2300/2917] Elapsed 10m 9s (remain 2m 43s) Loss: 0.0092(0.0036) Grad: 82625.6953  LR: 0.00000825  \n","Epoch: [3][2400/2917] Elapsed 10m 36s (remain 2m 16s) Loss: 0.0033(0.0035) Grad: 33266.5820  LR: 0.00000803  \n","Epoch: [3][2500/2917] Elapsed 11m 2s (remain 1m 50s) Loss: 0.0024(0.0035) Grad: 15649.2607  LR: 0.00000782  \n","Epoch: [3][2600/2917] Elapsed 11m 29s (remain 1m 23s) Loss: 0.0049(0.0035) Grad: 47603.7070  LR: 0.00000761  \n","Epoch: [3][2700/2917] Elapsed 11m 55s (remain 0m 57s) Loss: 0.0049(0.0035) Grad: 16460.7773  LR: 0.00000740  \n","Epoch: [3][2800/2917] Elapsed 12m 22s (remain 0m 30s) Loss: 0.0031(0.0036) Grad: 17091.4395  LR: 0.00000720  \n","Epoch: [3][2900/2917] Elapsed 12m 48s (remain 0m 4s) Loss: 0.0023(0.0035) Grad: 16339.8418  LR: 0.00000699  \n","Epoch: [3][2916/2917] Elapsed 12m 53s (remain 0m 0s) Loss: 0.0108(0.0036) Grad: 77172.4609  LR: 0.00000696  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 51s) Loss: 0.0013(0.0013) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0109(0.0066) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 57s) Loss: 0.0064(0.0065) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0060(0.0059) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0021(0.0066) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0014(0.0070) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0061(0.0069) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0058(0.0067) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0036  avg_val_loss: 0.0067  time: 852s\n","Epoch 3 - Score: 0.8250\n","Epoch 3 - Save Best Score: 0.8250 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0029(0.0067) \n","Epoch: [4][0/2917] Elapsed 0m 0s (remain 33m 15s) Loss: 0.0007(0.0007) Grad: 5573.6895  LR: 0.00000695  \n","Epoch: [4][100/2917] Elapsed 0m 27s (remain 12m 54s) Loss: 0.0025(0.0028) Grad: 4854.0278  LR: 0.00000675  \n","Epoch: [4][200/2917] Elapsed 0m 55s (remain 12m 25s) Loss: 0.0009(0.0026) Grad: 6178.6367  LR: 0.00000655  \n","Epoch: [4][300/2917] Elapsed 1m 22s (remain 11m 53s) Loss: 0.0044(0.0027) Grad: 7660.7231  LR: 0.00000634  \n","Epoch: [4][400/2917] Elapsed 1m 48s (remain 11m 18s) Loss: 0.0023(0.0026) Grad: 21035.8770  LR: 0.00000614  \n","Epoch: [4][500/2917] Elapsed 2m 13s (remain 10m 45s) Loss: 0.0022(0.0028) Grad: 6107.9927  LR: 0.00000594  \n","Epoch: [4][600/2917] Elapsed 2m 39s (remain 10m 16s) Loss: 0.0009(0.0027) Grad: 7040.0264  LR: 0.00000575  \n","Epoch: [4][700/2917] Elapsed 3m 5s (remain 9m 47s) Loss: 0.0020(0.0027) Grad: 5209.6968  LR: 0.00000555  \n","Epoch: [4][800/2917] Elapsed 3m 31s (remain 9m 18s) Loss: 0.0060(0.0027) Grad: 9070.6787  LR: 0.00000536  \n","Epoch: [4][900/2917] Elapsed 3m 57s (remain 8m 50s) Loss: 0.0014(0.0027) Grad: 4593.5361  LR: 0.00000517  \n","Epoch: [4][1000/2917] Elapsed 4m 23s (remain 8m 24s) Loss: 0.0027(0.0027) Grad: 6425.2056  LR: 0.00000498  \n","Epoch: [4][1100/2917] Elapsed 4m 50s (remain 7m 58s) Loss: 0.0005(0.0027) Grad: 2739.8308  LR: 0.00000480  \n","Epoch: [4][1200/2917] Elapsed 5m 16s (remain 7m 32s) Loss: 0.0003(0.0027) Grad: 2136.4148  LR: 0.00000461  \n","Epoch: [4][1300/2917] Elapsed 5m 43s (remain 7m 7s) Loss: 0.0036(0.0027) Grad: 9388.2207  LR: 0.00000443  \n","Epoch: [4][1400/2917] Elapsed 6m 10s (remain 6m 40s) Loss: 0.0007(0.0026) Grad: 2743.0686  LR: 0.00000425  \n","Epoch: [4][1500/2917] Elapsed 6m 36s (remain 6m 14s) Loss: 0.0044(0.0026) Grad: 12209.5410  LR: 0.00000408  \n","Epoch: [4][1600/2917] Elapsed 7m 2s (remain 5m 47s) Loss: 0.0006(0.0026) Grad: 2856.2976  LR: 0.00000391  \n","Epoch: [4][1700/2917] Elapsed 7m 29s (remain 5m 21s) Loss: 0.0019(0.0027) Grad: 8465.0078  LR: 0.00000374  \n","Epoch: [4][1800/2917] Elapsed 7m 55s (remain 4m 54s) Loss: 0.0014(0.0026) Grad: 5884.6670  LR: 0.00000357  \n","Epoch: [4][1900/2917] Elapsed 8m 22s (remain 4m 28s) Loss: 0.0026(0.0026) Grad: 6893.4326  LR: 0.00000341  \n","Epoch: [4][2000/2917] Elapsed 8m 48s (remain 4m 2s) Loss: 0.0027(0.0026) Grad: 14442.9883  LR: 0.00000324  \n","Epoch: [4][2100/2917] Elapsed 9m 14s (remain 3m 35s) Loss: 0.0005(0.0026) Grad: 5218.2095  LR: 0.00000309  \n","Epoch: [4][2200/2917] Elapsed 9m 40s (remain 3m 8s) Loss: 0.0009(0.0026) Grad: 7387.8242  LR: 0.00000293  \n","Epoch: [4][2300/2917] Elapsed 10m 7s (remain 2m 42s) Loss: 0.0003(0.0026) Grad: 4809.8101  LR: 0.00000278  \n","Epoch: [4][2400/2917] Elapsed 10m 33s (remain 2m 16s) Loss: 0.0026(0.0026) Grad: 19388.5586  LR: 0.00000263  \n","Epoch: [4][2500/2917] Elapsed 11m 0s (remain 1m 49s) Loss: 0.0009(0.0026) Grad: 9040.7773  LR: 0.00000249  \n","Epoch: [4][2600/2917] Elapsed 11m 27s (remain 1m 23s) Loss: 0.0007(0.0026) Grad: 7999.8867  LR: 0.00000235  \n","Epoch: [4][2700/2917] Elapsed 11m 53s (remain 0m 57s) Loss: 0.0004(0.0026) Grad: 5236.1528  LR: 0.00000221  \n","Epoch: [4][2800/2917] Elapsed 12m 20s (remain 0m 30s) Loss: 0.0038(0.0026) Grad: 22464.5273  LR: 0.00000208  \n","Epoch: [4][2900/2917] Elapsed 12m 46s (remain 0m 4s) Loss: 0.0017(0.0025) Grad: 11535.4404  LR: 0.00000195  \n","Epoch: [4][2916/2917] Elapsed 12m 50s (remain 0m 0s) Loss: 0.0028(0.0025) Grad: 32277.0117  LR: 0.00000193  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 47s) Loss: 0.0016(0.0016) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0132(0.0061) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0054(0.0062) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0030(0.0056) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0022(0.0063) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0014(0.0066) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0070(0.0065) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0045(0.0063) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0025  avg_val_loss: 0.0063  time: 850s\n","Epoch 4 - Score: 0.8166\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0002(0.0063) \n","Epoch: [5][0/2917] Elapsed 0m 0s (remain 31m 9s) Loss: 0.0021(0.0021) Grad: 5777.3311  LR: 0.00000193  \n","Epoch: [5][100/2917] Elapsed 0m 26s (remain 12m 30s) Loss: 0.0004(0.0019) Grad: 3157.3630  LR: 0.00000180  \n","Epoch: [5][200/2917] Elapsed 0m 53s (remain 12m 2s) Loss: 0.0042(0.0020) Grad: 6433.5850  LR: 0.00000168  \n","Epoch: [5][300/2917] Elapsed 1m 20s (remain 11m 37s) Loss: 0.0007(0.0020) Grad: 6042.2969  LR: 0.00000156  \n","Epoch: [5][400/2917] Elapsed 1m 46s (remain 11m 11s) Loss: 0.0018(0.0021) Grad: 4738.5425  LR: 0.00000145  \n","Epoch: [5][500/2917] Elapsed 2m 13s (remain 10m 45s) Loss: 0.0012(0.0021) Grad: 5766.0293  LR: 0.00000134  \n","Epoch: [5][600/2917] Elapsed 2m 40s (remain 10m 18s) Loss: 0.0023(0.0021) Grad: 11225.4434  LR: 0.00000123  \n","Epoch: [5][700/2917] Elapsed 3m 7s (remain 9m 52s) Loss: 0.0026(0.0021) Grad: 6517.3438  LR: 0.00000113  \n","Epoch: [5][800/2917] Elapsed 3m 34s (remain 9m 25s) Loss: 0.0044(0.0021) Grad: 20510.9414  LR: 0.00000103  \n","Epoch: [5][900/2917] Elapsed 4m 1s (remain 8m 59s) Loss: 0.0010(0.0021) Grad: 6641.7104  LR: 0.00000094  \n","Epoch: [5][1000/2917] Elapsed 4m 27s (remain 8m 32s) Loss: 0.0002(0.0021) Grad: 1335.0540  LR: 0.00000085  \n","Epoch: [5][1100/2917] Elapsed 4m 54s (remain 8m 6s) Loss: 0.0013(0.0021) Grad: 4830.8906  LR: 0.00000076  \n","Epoch: [5][1200/2917] Elapsed 5m 21s (remain 7m 39s) Loss: 0.0007(0.0021) Grad: 3328.9021  LR: 0.00000068  \n","Epoch: [5][1300/2917] Elapsed 5m 48s (remain 7m 13s) Loss: 0.0013(0.0020) Grad: 8615.8115  LR: 0.00000061  \n","Epoch: [5][1400/2917] Elapsed 6m 15s (remain 6m 46s) Loss: 0.0023(0.0020) Grad: 6693.6982  LR: 0.00000053  \n","Epoch: [5][1500/2917] Elapsed 6m 42s (remain 6m 19s) Loss: 0.0009(0.0020) Grad: 2875.4919  LR: 0.00000047  \n","Epoch: [5][1600/2917] Elapsed 7m 9s (remain 5m 53s) Loss: 0.0006(0.0020) Grad: 4948.3472  LR: 0.00000040  \n","Epoch: [5][1700/2917] Elapsed 7m 36s (remain 5m 26s) Loss: 0.0017(0.0020) Grad: 15716.2803  LR: 0.00000035  \n","Epoch: [5][1800/2917] Elapsed 8m 2s (remain 4m 59s) Loss: 0.0026(0.0020) Grad: 7281.5464  LR: 0.00000029  \n","Epoch: [5][1900/2917] Elapsed 8m 29s (remain 4m 32s) Loss: 0.0004(0.0020) Grad: 2307.7637  LR: 0.00000024  \n","Epoch: [5][2000/2917] Elapsed 8m 56s (remain 4m 5s) Loss: 0.0025(0.0020) Grad: 21432.5488  LR: 0.00000020  \n","Epoch: [5][2100/2917] Elapsed 9m 22s (remain 3m 38s) Loss: 0.0021(0.0020) Grad: 23043.2559  LR: 0.00000016  \n","Epoch: [5][2200/2917] Elapsed 9m 49s (remain 3m 11s) Loss: 0.0022(0.0020) Grad: 15940.1738  LR: 0.00000012  \n","Epoch: [5][2300/2917] Elapsed 10m 16s (remain 2m 44s) Loss: 0.0004(0.0020) Grad: 5484.0283  LR: 0.00000009  \n","Epoch: [5][2400/2917] Elapsed 10m 42s (remain 2m 18s) Loss: 0.0025(0.0020) Grad: 13335.1973  LR: 0.00000006  \n","Epoch: [5][2500/2917] Elapsed 11m 9s (remain 1m 51s) Loss: 0.0023(0.0020) Grad: 12985.7549  LR: 0.00000004  \n","Epoch: [5][2600/2917] Elapsed 11m 36s (remain 1m 24s) Loss: 0.0016(0.0020) Grad: 11910.2568  LR: 0.00000002  \n","Epoch: [5][2700/2917] Elapsed 12m 3s (remain 0m 57s) Loss: 0.0006(0.0020) Grad: 7617.1616  LR: 0.00000001  \n","Epoch: [5][2800/2917] Elapsed 12m 30s (remain 0m 31s) Loss: 0.0037(0.0020) Grad: 46332.5391  LR: 0.00000000  \n","Epoch: [5][2900/2917] Elapsed 12m 57s (remain 0m 4s) Loss: 0.0013(0.0020) Grad: 7231.0229  LR: 0.00000000  \n","Epoch: [5][2916/2917] Elapsed 13m 1s (remain 0m 0s) Loss: 0.0027(0.0020) Grad: 16931.0020  LR: 0.00000000  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 46s) Loss: 0.0017(0.0017) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0148(0.0064) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0057(0.0065) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0043(0.0059) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0023(0.0066) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0013(0.0070) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0074(0.0068) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0042(0.0066) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0020  avg_val_loss: 0.0066  time: 861s\n","Epoch 5 - Score: 0.8165\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0003(0.0066) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Score: 0.8250\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['lm_predictions.lm_head.dense.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2917] Elapsed 0m 0s (remain 28m 47s) Loss: 0.0620(0.0620) Grad: 29695.9980  LR: 0.00000040  \n","Epoch: [1][100/2917] Elapsed 0m 27s (remain 12m 44s) Loss: 0.0297(0.0286) Grad: 49957.9844  LR: 0.00002000  \n","Epoch: [1][200/2917] Elapsed 0m 53s (remain 12m 6s) Loss: 0.0402(0.0242) Grad: 24375.2051  LR: 0.00001999  \n","Epoch: [1][300/2917] Elapsed 1m 20s (remain 11m 38s) Loss: 0.0081(0.0230) Grad: 22820.4727  LR: 0.00001999  \n","Epoch: [1][400/2917] Elapsed 1m 46s (remain 11m 10s) Loss: 0.0286(0.0221) Grad: 71129.2031  LR: 0.00001997  \n","Epoch: [1][500/2917] Elapsed 2m 13s (remain 10m 43s) Loss: 0.0140(0.0206) Grad: 35975.9375  LR: 0.00001995  \n","Epoch: [1][600/2917] Elapsed 2m 40s (remain 10m 16s) Loss: 0.0051(0.0191) Grad: 13325.4912  LR: 0.00001993  \n","Epoch: [1][700/2917] Elapsed 3m 6s (remain 9m 49s) Loss: 0.0121(0.0181) Grad: 40465.4805  LR: 0.00001990  \n","Epoch: [1][800/2917] Elapsed 3m 33s (remain 9m 22s) Loss: 0.0093(0.0172) Grad: 32831.9922  LR: 0.00001987  \n","Epoch: [1][900/2917] Elapsed 3m 59s (remain 8m 55s) Loss: 0.0064(0.0165) Grad: 11945.5215  LR: 0.00001983  \n","Epoch: [1][1000/2917] Elapsed 4m 25s (remain 8m 28s) Loss: 0.0056(0.0158) Grad: 19319.7422  LR: 0.00001979  \n","Epoch: [1][1100/2917] Elapsed 4m 52s (remain 8m 1s) Loss: 0.0063(0.0153) Grad: 12498.5020  LR: 0.00001974  \n","Epoch: [1][1200/2917] Elapsed 5m 18s (remain 7m 34s) Loss: 0.0031(0.0147) Grad: 18058.5547  LR: 0.00001969  \n","Epoch: [1][1300/2917] Elapsed 5m 44s (remain 7m 8s) Loss: 0.0084(0.0143) Grad: 14483.6152  LR: 0.00001964  \n","Epoch: [1][1400/2917] Elapsed 6m 11s (remain 6m 41s) Loss: 0.0151(0.0139) Grad: 43263.9531  LR: 0.00001958  \n","Epoch: [1][1500/2917] Elapsed 6m 37s (remain 6m 15s) Loss: 0.0087(0.0135) Grad: 44769.4414  LR: 0.00001951  \n","Epoch: [1][1600/2917] Elapsed 7m 4s (remain 5m 48s) Loss: 0.0047(0.0133) Grad: 16671.6777  LR: 0.00001944  \n","Epoch: [1][1700/2917] Elapsed 7m 30s (remain 5m 22s) Loss: 0.0033(0.0129) Grad: 8231.8115  LR: 0.00001937  \n","Epoch: [1][1800/2917] Elapsed 7m 56s (remain 4m 55s) Loss: 0.0065(0.0127) Grad: 39450.2539  LR: 0.00001929  \n","Epoch: [1][1900/2917] Elapsed 8m 23s (remain 4m 28s) Loss: 0.0040(0.0125) Grad: 11583.1846  LR: 0.00001921  \n","Epoch: [1][2000/2917] Elapsed 8m 49s (remain 4m 2s) Loss: 0.0028(0.0122) Grad: 20864.6426  LR: 0.00001912  \n","Epoch: [1][2100/2917] Elapsed 9m 15s (remain 3m 35s) Loss: 0.0054(0.0120) Grad: 26518.7695  LR: 0.00001903  \n","Epoch: [1][2200/2917] Elapsed 9m 42s (remain 3m 9s) Loss: 0.0077(0.0118) Grad: 35778.1250  LR: 0.00001894  \n","Epoch: [1][2300/2917] Elapsed 10m 8s (remain 2m 42s) Loss: 0.0036(0.0116) Grad: 22948.1289  LR: 0.00001884  \n","Epoch: [1][2400/2917] Elapsed 10m 34s (remain 2m 16s) Loss: 0.0033(0.0114) Grad: 23299.2344  LR: 0.00001874  \n","Epoch: [1][2500/2917] Elapsed 11m 1s (remain 1m 49s) Loss: 0.0025(0.0113) Grad: 12229.3594  LR: 0.00001863  \n","Epoch: [1][2600/2917] Elapsed 11m 27s (remain 1m 23s) Loss: 0.0072(0.0111) Grad: 32949.7891  LR: 0.00001852  \n","Epoch: [1][2700/2917] Elapsed 11m 53s (remain 0m 57s) Loss: 0.0065(0.0109) Grad: 76691.3672  LR: 0.00001840  \n","Epoch: [1][2800/2917] Elapsed 12m 20s (remain 0m 30s) Loss: 0.0049(0.0108) Grad: 19457.4121  LR: 0.00001828  \n","Epoch: [1][2900/2917] Elapsed 12m 46s (remain 0m 4s) Loss: 0.0048(0.0106) Grad: 17436.6641  LR: 0.00001816  \n","Epoch: [1][2916/2917] Elapsed 12m 50s (remain 0m 0s) Loss: 0.0025(0.0106) Grad: 38313.5547  LR: 0.00001814  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 41s) Loss: 0.0079(0.0079) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0069(0.0072) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0039(0.0078) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0134(0.0080) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0010(0.0078) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0039(0.0078) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0079(0.0077) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0013(0.0077) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0106  avg_val_loss: 0.0077  time: 850s\n","Epoch 1 - Score: 0.8022\n","Epoch 1 - Save Best Score: 0.8022 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0197(0.0077) \n","Epoch: [2][0/2917] Elapsed 0m 3s (remain 171m 13s) Loss: 0.0221(0.0221) Grad: 29713.1055  LR: 0.00001814  \n","Epoch: [2][100/2917] Elapsed 0m 30s (remain 14m 18s) Loss: 0.0030(0.0053) Grad: 6935.9580  LR: 0.00001801  \n","Epoch: [2][200/2917] Elapsed 0m 58s (remain 13m 6s) Loss: 0.0034(0.0054) Grad: 21807.8145  LR: 0.00001788  \n","Epoch: [2][300/2917] Elapsed 1m 25s (remain 12m 22s) Loss: 0.0078(0.0053) Grad: 30751.7695  LR: 0.00001775  \n","Epoch: [2][400/2917] Elapsed 1m 51s (remain 11m 39s) Loss: 0.0040(0.0056) Grad: 11034.3623  LR: 0.00001761  \n","Epoch: [2][500/2917] Elapsed 2m 17s (remain 11m 4s) Loss: 0.0096(0.0055) Grad: 20636.2383  LR: 0.00001747  \n","Epoch: [2][600/2917] Elapsed 2m 44s (remain 10m 32s) Loss: 0.0187(0.0056) Grad: 138420.2031  LR: 0.00001732  \n","Epoch: [2][700/2917] Elapsed 3m 10s (remain 10m 3s) Loss: 0.0048(0.0055) Grad: 10042.6738  LR: 0.00001717  \n","Epoch: [2][800/2917] Elapsed 3m 36s (remain 9m 33s) Loss: 0.0055(0.0055) Grad: 12689.8496  LR: 0.00001702  \n","Epoch: [2][900/2917] Elapsed 4m 3s (remain 9m 4s) Loss: 0.0023(0.0054) Grad: 6101.6523  LR: 0.00001686  \n","Epoch: [2][1000/2917] Elapsed 4m 29s (remain 8m 36s) Loss: 0.0047(0.0055) Grad: 8745.8408  LR: 0.00001671  \n","Epoch: [2][1100/2917] Elapsed 4m 55s (remain 8m 7s) Loss: 0.0082(0.0055) Grad: 12803.3359  LR: 0.00001654  \n","Epoch: [2][1200/2917] Elapsed 5m 22s (remain 7m 40s) Loss: 0.0021(0.0056) Grad: 5808.3301  LR: 0.00001638  \n","Epoch: [2][1300/2917] Elapsed 5m 49s (remain 7m 13s) Loss: 0.0065(0.0056) Grad: 12680.4004  LR: 0.00001621  \n","Epoch: [2][1400/2917] Elapsed 6m 15s (remain 6m 46s) Loss: 0.0101(0.0056) Grad: 13047.3486  LR: 0.00001604  \n","Epoch: [2][1500/2917] Elapsed 6m 41s (remain 6m 18s) Loss: 0.0050(0.0056) Grad: 8489.4834  LR: 0.00001587  \n","Epoch: [2][1600/2917] Elapsed 7m 7s (remain 5m 51s) Loss: 0.0055(0.0056) Grad: 16135.1797  LR: 0.00001569  \n","Epoch: [2][1700/2917] Elapsed 7m 34s (remain 5m 24s) Loss: 0.0061(0.0056) Grad: 13595.3467  LR: 0.00001551  \n","Epoch: [2][1800/2917] Elapsed 7m 59s (remain 4m 57s) Loss: 0.0043(0.0056) Grad: 13566.8545  LR: 0.00001533  \n","Epoch: [2][1900/2917] Elapsed 8m 26s (remain 4m 30s) Loss: 0.0022(0.0056) Grad: 7655.7183  LR: 0.00001515  \n","Epoch: [2][2000/2917] Elapsed 8m 53s (remain 4m 4s) Loss: 0.0007(0.0055) Grad: 5189.7412  LR: 0.00001496  \n","Epoch: [2][2100/2917] Elapsed 9m 20s (remain 3m 37s) Loss: 0.0093(0.0055) Grad: 23431.9219  LR: 0.00001477  \n","Epoch: [2][2200/2917] Elapsed 9m 47s (remain 3m 11s) Loss: 0.0074(0.0055) Grad: 27850.5547  LR: 0.00001458  \n","Epoch: [2][2300/2917] Elapsed 10m 13s (remain 2m 44s) Loss: 0.0052(0.0055) Grad: 29690.6016  LR: 0.00001439  \n","Epoch: [2][2400/2917] Elapsed 10m 40s (remain 2m 17s) Loss: 0.0021(0.0055) Grad: 11602.9854  LR: 0.00001419  \n","Epoch: [2][2500/2917] Elapsed 11m 6s (remain 1m 50s) Loss: 0.0033(0.0055) Grad: 14043.1104  LR: 0.00001399  \n","Epoch: [2][2600/2917] Elapsed 11m 33s (remain 1m 24s) Loss: 0.0022(0.0055) Grad: 11846.8604  LR: 0.00001380  \n","Epoch: [2][2700/2917] Elapsed 12m 0s (remain 0m 57s) Loss: 0.0035(0.0055) Grad: 15132.4521  LR: 0.00001359  \n","Epoch: [2][2800/2917] Elapsed 12m 26s (remain 0m 30s) Loss: 0.0036(0.0055) Grad: 20480.4961  LR: 0.00001339  \n","Epoch: [2][2900/2917] Elapsed 12m 52s (remain 0m 4s) Loss: 0.0172(0.0055) Grad: 13450.1309  LR: 0.00001319  \n","Epoch: [2][2916/2917] Elapsed 12m 56s (remain 0m 0s) Loss: 0.0055(0.0055) Grad: 9717.1221  LR: 0.00001316  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 46s) Loss: 0.0045(0.0045) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0016(0.0064) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0043(0.0063) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0047(0.0064) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0006(0.0064) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0041(0.0064) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0079(0.0063) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0012(0.0061) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0061  time: 856s\n","Epoch 2 - Score: 0.8195\n","Epoch 2 - Save Best Score: 0.8195 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0081(0.0061) \n","Epoch: [3][0/2917] Elapsed 0m 0s (remain 32m 58s) Loss: 0.0024(0.0024) Grad: 5493.8076  LR: 0.00001315  \n","Epoch: [3][100/2917] Elapsed 0m 27s (remain 12m 52s) Loss: 0.0053(0.0034) Grad: 13994.2461  LR: 0.00001295  \n","Epoch: [3][200/2917] Elapsed 0m 55s (remain 12m 26s) Loss: 0.0075(0.0037) Grad: 31011.6309  LR: 0.00001274  \n","Epoch: [3][300/2917] Elapsed 1m 22s (remain 11m 56s) Loss: 0.0018(0.0036) Grad: 6452.3687  LR: 0.00001253  \n","Epoch: [3][400/2917] Elapsed 1m 49s (remain 11m 24s) Loss: 0.0009(0.0038) Grad: 5809.6377  LR: 0.00001232  \n","Epoch: [3][500/2917] Elapsed 2m 15s (remain 10m 52s) Loss: 0.0009(0.0038) Grad: 5954.0293  LR: 0.00001211  \n","Epoch: [3][600/2917] Elapsed 2m 41s (remain 10m 24s) Loss: 0.0091(0.0039) Grad: 25011.5703  LR: 0.00001190  \n","Epoch: [3][700/2917] Elapsed 3m 8s (remain 9m 56s) Loss: 0.0010(0.0038) Grad: 5463.0874  LR: 0.00001169  \n","Epoch: [3][800/2917] Elapsed 3m 35s (remain 9m 27s) Loss: 0.0030(0.0038) Grad: 8295.7607  LR: 0.00001147  \n","Epoch: [3][900/2917] Elapsed 4m 1s (remain 9m 0s) Loss: 0.0074(0.0039) Grad: 33538.7578  LR: 0.00001126  \n","Epoch: [3][1000/2917] Elapsed 4m 27s (remain 8m 32s) Loss: 0.0014(0.0038) Grad: 4463.9062  LR: 0.00001104  \n","Epoch: [3][1100/2917] Elapsed 4m 54s (remain 8m 6s) Loss: 0.0026(0.0038) Grad: 10441.8252  LR: 0.00001083  \n","Epoch: [3][1200/2917] Elapsed 5m 21s (remain 7m 38s) Loss: 0.0007(0.0038) Grad: 3232.0908  LR: 0.00001061  \n","Epoch: [3][1300/2917] Elapsed 5m 47s (remain 7m 12s) Loss: 0.0008(0.0038) Grad: 4645.9878  LR: 0.00001040  \n","Epoch: [3][1400/2917] Elapsed 6m 14s (remain 6m 45s) Loss: 0.0020(0.0038) Grad: 9310.4043  LR: 0.00001018  \n","Epoch: [3][1500/2917] Elapsed 6m 41s (remain 6m 18s) Loss: 0.0035(0.0038) Grad: 8096.4771  LR: 0.00000997  \n","Epoch: [3][1600/2917] Elapsed 7m 7s (remain 5m 51s) Loss: 0.0025(0.0039) Grad: 7537.8750  LR: 0.00000975  \n","Epoch: [3][1700/2917] Elapsed 7m 34s (remain 5m 24s) Loss: 0.0024(0.0038) Grad: 12558.8857  LR: 0.00000953  \n","Epoch: [3][1800/2917] Elapsed 8m 0s (remain 4m 57s) Loss: 0.0022(0.0038) Grad: 8211.4316  LR: 0.00000932  \n","Epoch: [3][1900/2917] Elapsed 8m 26s (remain 4m 30s) Loss: 0.0030(0.0038) Grad: 7803.8628  LR: 0.00000910  \n","Epoch: [3][2000/2917] Elapsed 8m 53s (remain 4m 4s) Loss: 0.0084(0.0038) Grad: 48643.2852  LR: 0.00000889  \n","Epoch: [3][2100/2917] Elapsed 9m 19s (remain 3m 37s) Loss: 0.0024(0.0038) Grad: 8390.1191  LR: 0.00000867  \n","Epoch: [3][2200/2917] Elapsed 9m 46s (remain 3m 10s) Loss: 0.0004(0.0037) Grad: 7418.6299  LR: 0.00000846  \n","Epoch: [3][2300/2917] Elapsed 10m 12s (remain 2m 44s) Loss: 0.0120(0.0037) Grad: 67633.2109  LR: 0.00000825  \n","Epoch: [3][2400/2917] Elapsed 10m 39s (remain 2m 17s) Loss: 0.0022(0.0037) Grad: 16476.0801  LR: 0.00000803  \n","Epoch: [3][2500/2917] Elapsed 11m 6s (remain 1m 50s) Loss: 0.0044(0.0037) Grad: 14973.1250  LR: 0.00000782  \n","Epoch: [3][2600/2917] Elapsed 11m 32s (remain 1m 24s) Loss: 0.0054(0.0037) Grad: 20151.6426  LR: 0.00000761  \n","Epoch: [3][2700/2917] Elapsed 11m 59s (remain 0m 57s) Loss: 0.0051(0.0037) Grad: 16441.1328  LR: 0.00000740  \n","Epoch: [3][2800/2917] Elapsed 12m 25s (remain 0m 30s) Loss: 0.0123(0.0037) Grad: 41304.7578  LR: 0.00000720  \n","Epoch: [3][2900/2917] Elapsed 12m 52s (remain 0m 4s) Loss: 0.0017(0.0036) Grad: 13668.0576  LR: 0.00000699  \n","Epoch: [3][2916/2917] Elapsed 12m 56s (remain 0m 0s) Loss: 0.0049(0.0037) Grad: 16797.0195  LR: 0.00000696  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 51s) Loss: 0.0057(0.0057) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0028(0.0057) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0044(0.0062) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0042(0.0066) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0002(0.0066) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0039(0.0066) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 14s) Loss: 0.0075(0.0066) \n","EVAL: [700/730] Elapsed 1m 16s (remain 0m 3s) Loss: 0.0010(0.0065) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0037  avg_val_loss: 0.0065  time: 856s\n","Epoch 3 - Score: 0.8249\n","Epoch 3 - Save Best Score: 0.8249 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0086(0.0065) \n","Epoch: [4][0/2917] Elapsed 0m 0s (remain 34m 47s) Loss: 0.0035(0.0035) Grad: 7696.7773  LR: 0.00000695  \n","Epoch: [4][100/2917] Elapsed 0m 28s (remain 13m 17s) Loss: 0.0025(0.0029) Grad: 7795.3232  LR: 0.00000675  \n","Epoch: [4][200/2917] Elapsed 0m 56s (remain 12m 42s) Loss: 0.0024(0.0027) Grad: 5420.3188  LR: 0.00000655  \n","Epoch: [4][300/2917] Elapsed 1m 23s (remain 12m 5s) Loss: 0.0019(0.0029) Grad: 12628.9941  LR: 0.00000634  \n","Epoch: [4][400/2917] Elapsed 1m 49s (remain 11m 29s) Loss: 0.0023(0.0029) Grad: 8735.5479  LR: 0.00000614  \n","Epoch: [4][500/2917] Elapsed 2m 16s (remain 10m 57s) Loss: 0.0041(0.0028) Grad: 6712.5586  LR: 0.00000594  \n","Epoch: [4][600/2917] Elapsed 2m 43s (remain 10m 28s) Loss: 0.0012(0.0027) Grad: 11313.8076  LR: 0.00000575  \n","Epoch: [4][700/2917] Elapsed 3m 9s (remain 9m 59s) Loss: 0.0003(0.0028) Grad: 3036.6038  LR: 0.00000555  \n","Epoch: [4][800/2917] Elapsed 3m 36s (remain 9m 31s) Loss: 0.0016(0.0027) Grad: 13564.0615  LR: 0.00000536  \n","Epoch: [4][900/2917] Elapsed 4m 2s (remain 9m 3s) Loss: 0.0023(0.0026) Grad: 6458.6421  LR: 0.00000517  \n","Epoch: [4][1000/2917] Elapsed 4m 29s (remain 8m 35s) Loss: 0.0014(0.0026) Grad: 13833.0449  LR: 0.00000498  \n","Epoch: [4][1100/2917] Elapsed 4m 55s (remain 8m 7s) Loss: 0.0005(0.0026) Grad: 5582.3779  LR: 0.00000480  \n","Epoch: [4][1200/2917] Elapsed 5m 22s (remain 7m 40s) Loss: 0.0043(0.0026) Grad: 10074.0635  LR: 0.00000461  \n","Epoch: [4][1300/2917] Elapsed 5m 48s (remain 7m 13s) Loss: 0.0023(0.0026) Grad: 10942.5176  LR: 0.00000443  \n","Epoch: [4][1400/2917] Elapsed 6m 15s (remain 6m 46s) Loss: 0.0022(0.0026) Grad: 9793.0117  LR: 0.00000425  \n","Epoch: [4][1500/2917] Elapsed 6m 42s (remain 6m 19s) Loss: 0.0024(0.0026) Grad: 8774.8467  LR: 0.00000408  \n","Epoch: [4][1600/2917] Elapsed 7m 8s (remain 5m 52s) Loss: 0.0026(0.0027) Grad: 21325.1230  LR: 0.00000391  \n","Epoch: [4][1700/2917] Elapsed 7m 34s (remain 5m 24s) Loss: 0.0013(0.0027) Grad: 6842.7432  LR: 0.00000374  \n","Epoch: [4][1800/2917] Elapsed 8m 0s (remain 4m 57s) Loss: 0.0063(0.0027) Grad: 12533.4551  LR: 0.00000357  \n","Epoch: [4][1900/2917] Elapsed 8m 27s (remain 4m 31s) Loss: 0.0040(0.0027) Grad: 11783.9014  LR: 0.00000341  \n","Epoch: [4][2000/2917] Elapsed 8m 53s (remain 4m 4s) Loss: 0.0020(0.0027) Grad: 15305.0352  LR: 0.00000324  \n","Epoch: [4][2100/2917] Elapsed 9m 19s (remain 3m 37s) Loss: 0.0021(0.0027) Grad: 22601.2559  LR: 0.00000309  \n","Epoch: [4][2200/2917] Elapsed 9m 46s (remain 3m 10s) Loss: 0.0024(0.0026) Grad: 10866.5762  LR: 0.00000293  \n","Epoch: [4][2300/2917] Elapsed 10m 13s (remain 2m 44s) Loss: 0.0037(0.0026) Grad: 12253.9004  LR: 0.00000278  \n","Epoch: [4][2400/2917] Elapsed 10m 39s (remain 2m 17s) Loss: 0.0012(0.0026) Grad: 13112.9609  LR: 0.00000263  \n","Epoch: [4][2500/2917] Elapsed 11m 5s (remain 1m 50s) Loss: 0.0010(0.0026) Grad: 15765.2871  LR: 0.00000249  \n","Epoch: [4][2600/2917] Elapsed 11m 32s (remain 1m 24s) Loss: 0.0089(0.0026) Grad: 65101.6367  LR: 0.00000235  \n","Epoch: [4][2700/2917] Elapsed 11m 58s (remain 0m 57s) Loss: 0.0029(0.0026) Grad: 21631.2793  LR: 0.00000221  \n","Epoch: [4][2800/2917] Elapsed 12m 24s (remain 0m 30s) Loss: 0.0006(0.0026) Grad: 8554.7256  LR: 0.00000208  \n","Epoch: [4][2900/2917] Elapsed 12m 51s (remain 0m 4s) Loss: 0.0002(0.0026) Grad: 5898.2549  LR: 0.00000195  \n","Epoch: [4][2916/2917] Elapsed 12m 55s (remain 0m 0s) Loss: 0.0027(0.0026) Grad: 16142.1719  LR: 0.00000193  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 22s) Loss: 0.0055(0.0055) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0018(0.0063) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0043(0.0065) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0020(0.0068) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0001(0.0069) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0062(0.0068) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0083(0.0068) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0005(0.0067) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0026  avg_val_loss: 0.0066  time: 855s\n","Epoch 4 - Score: 0.8178\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0050(0.0066) \n","Epoch: [5][0/2917] Elapsed 0m 0s (remain 30m 19s) Loss: 0.0094(0.0094) Grad: 14172.2666  LR: 0.00000193  \n","Epoch: [5][100/2917] Elapsed 0m 27s (remain 12m 37s) Loss: 0.0001(0.0021) Grad: 1991.9622  LR: 0.00000180  \n","Epoch: [5][200/2917] Elapsed 0m 53s (remain 12m 0s) Loss: 0.0015(0.0021) Grad: 6348.5396  LR: 0.00000168  \n","Epoch: [5][300/2917] Elapsed 1m 19s (remain 11m 30s) Loss: 0.0011(0.0020) Grad: 8697.1768  LR: 0.00000156  \n","Epoch: [5][400/2917] Elapsed 1m 46s (remain 11m 5s) Loss: 0.0024(0.0021) Grad: 11386.2734  LR: 0.00000145  \n","Epoch: [5][500/2917] Elapsed 2m 13s (remain 10m 42s) Loss: 0.0011(0.0020) Grad: 5098.9624  LR: 0.00000134  \n","Epoch: [5][600/2917] Elapsed 2m 40s (remain 10m 17s) Loss: 0.0003(0.0021) Grad: 1621.7648  LR: 0.00000123  \n","Epoch: [5][700/2917] Elapsed 3m 7s (remain 9m 51s) Loss: 0.0074(0.0021) Grad: 45829.5312  LR: 0.00000113  \n","Epoch: [5][800/2917] Elapsed 3m 33s (remain 9m 24s) Loss: 0.0041(0.0021) Grad: 9435.7549  LR: 0.00000103  \n","Epoch: [5][900/2917] Elapsed 4m 0s (remain 8m 57s) Loss: 0.0034(0.0021) Grad: 14867.1748  LR: 0.00000094  \n","Epoch: [5][1000/2917] Elapsed 4m 26s (remain 8m 29s) Loss: 0.0028(0.0021) Grad: 9477.7441  LR: 0.00000085  \n","Epoch: [5][1100/2917] Elapsed 4m 52s (remain 8m 2s) Loss: 0.0025(0.0021) Grad: 7973.5503  LR: 0.00000076  \n","Epoch: [5][1200/2917] Elapsed 5m 19s (remain 7m 36s) Loss: 0.0003(0.0021) Grad: 10349.2363  LR: 0.00000068  \n","Epoch: [5][1300/2917] Elapsed 5m 46s (remain 7m 10s) Loss: 0.0027(0.0021) Grad: 10674.5371  LR: 0.00000061  \n","Epoch: [5][1400/2917] Elapsed 6m 12s (remain 6m 43s) Loss: 0.0017(0.0021) Grad: 8345.0039  LR: 0.00000053  \n","Epoch: [5][1500/2917] Elapsed 6m 39s (remain 6m 16s) Loss: 0.0006(0.0021) Grad: 2648.2095  LR: 0.00000047  \n","Epoch: [5][1600/2917] Elapsed 7m 5s (remain 5m 50s) Loss: 0.0004(0.0021) Grad: 2744.9092  LR: 0.00000040  \n","Epoch: [5][1700/2917] Elapsed 7m 32s (remain 5m 23s) Loss: 0.0018(0.0021) Grad: 10632.1592  LR: 0.00000035  \n","Epoch: [5][1800/2917] Elapsed 7m 58s (remain 4m 56s) Loss: 0.0031(0.0020) Grad: 6974.1826  LR: 0.00000029  \n","Epoch: [5][1900/2917] Elapsed 8m 25s (remain 4m 30s) Loss: 0.0005(0.0020) Grad: 3919.7334  LR: 0.00000024  \n","Epoch: [5][2000/2917] Elapsed 8m 52s (remain 4m 3s) Loss: 0.0037(0.0021) Grad: 30869.1191  LR: 0.00000020  \n","Epoch: [5][2100/2917] Elapsed 9m 18s (remain 3m 37s) Loss: 0.0004(0.0021) Grad: 8637.6299  LR: 0.00000016  \n","Epoch: [5][2200/2917] Elapsed 9m 45s (remain 3m 10s) Loss: 0.0001(0.0021) Grad: 3021.1997  LR: 0.00000012  \n","Epoch: [5][2300/2917] Elapsed 10m 11s (remain 2m 43s) Loss: 0.0022(0.0021) Grad: 12502.1367  LR: 0.00000009  \n","Epoch: [5][2400/2917] Elapsed 10m 38s (remain 2m 17s) Loss: 0.0025(0.0021) Grad: 16538.8711  LR: 0.00000006  \n","Epoch: [5][2500/2917] Elapsed 11m 4s (remain 1m 50s) Loss: 0.0034(0.0021) Grad: 20557.7500  LR: 0.00000004  \n","Epoch: [5][2600/2917] Elapsed 11m 31s (remain 1m 24s) Loss: 0.0003(0.0021) Grad: 5391.3433  LR: 0.00000002  \n","Epoch: [5][2700/2917] Elapsed 11m 57s (remain 0m 57s) Loss: 0.0035(0.0021) Grad: 13681.2617  LR: 0.00000001  \n","Epoch: [5][2800/2917] Elapsed 12m 24s (remain 0m 30s) Loss: 0.0022(0.0021) Grad: 65689.6562  LR: 0.00000000  \n","Epoch: [5][2900/2917] Elapsed 12m 50s (remain 0m 4s) Loss: 0.0010(0.0021) Grad: 10544.2178  LR: 0.00000000  \n","Epoch: [5][2916/2917] Elapsed 12m 54s (remain 0m 0s) Loss: 0.0005(0.0021) Grad: 5651.2144  LR: 0.00000000  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 25s) Loss: 0.0069(0.0069) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0023(0.0065) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 57s) Loss: 0.0044(0.0067) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0019(0.0071) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0001(0.0071) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0065(0.0071) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0089(0.0071) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0005(0.0070) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0021  avg_val_loss: 0.0069  time: 854s\n","Epoch 5 - Score: 0.8176\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0047(0.0069) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","Score: 0.8249\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['lm_predictions.lm_head.dense.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2917] Elapsed 0m 0s (remain 29m 50s) Loss: 0.0643(0.0643) Grad: 74131.9141  LR: 0.00000040  \n","Epoch: [1][100/2917] Elapsed 0m 26s (remain 12m 21s) Loss: 0.0186(0.0245) Grad: 21126.9766  LR: 0.00002000  \n","Epoch: [1][200/2917] Elapsed 0m 52s (remain 11m 48s) Loss: 0.0101(0.0213) Grad: 12931.5459  LR: 0.00001999  \n","Epoch: [1][300/2917] Elapsed 1m 17s (remain 11m 17s) Loss: 0.0171(0.0188) Grad: 32500.3340  LR: 0.00001999  \n","Epoch: [1][400/2917] Elapsed 1m 43s (remain 10m 49s) Loss: 0.0154(0.0171) Grad: 47811.1680  LR: 0.00001997  \n","Epoch: [1][500/2917] Elapsed 2m 9s (remain 10m 24s) Loss: 0.0027(0.0158) Grad: 4176.0132  LR: 0.00001995  \n","Epoch: [1][600/2917] Elapsed 2m 35s (remain 9m 58s) Loss: 0.0156(0.0151) Grad: 12159.0039  LR: 0.00001993  \n","Epoch: [1][700/2917] Elapsed 3m 1s (remain 9m 33s) Loss: 0.0167(0.0145) Grad: 26502.7246  LR: 0.00001990  \n","Epoch: [1][800/2917] Elapsed 3m 27s (remain 9m 6s) Loss: 0.0217(0.0139) Grad: 33063.4570  LR: 0.00001987  \n","Epoch: [1][900/2917] Elapsed 3m 53s (remain 8m 41s) Loss: 0.0120(0.0134) Grad: 16228.7949  LR: 0.00001983  \n","Epoch: [1][1000/2917] Elapsed 4m 18s (remain 8m 15s) Loss: 0.0099(0.0129) Grad: 6709.1914  LR: 0.00001979  \n","Epoch: [1][1100/2917] Elapsed 4m 44s (remain 7m 49s) Loss: 0.0126(0.0126) Grad: 13349.0283  LR: 0.00001974  \n","Epoch: [1][1200/2917] Elapsed 5m 10s (remain 7m 23s) Loss: 0.0135(0.0124) Grad: 9701.8945  LR: 0.00001969  \n","Epoch: [1][1300/2917] Elapsed 5m 36s (remain 6m 57s) Loss: 0.0139(0.0121) Grad: 7920.8882  LR: 0.00001964  \n","Epoch: [1][1400/2917] Elapsed 6m 2s (remain 6m 31s) Loss: 0.0051(0.0118) Grad: 6255.4199  LR: 0.00001958  \n","Epoch: [1][1500/2917] Elapsed 6m 28s (remain 6m 6s) Loss: 0.0051(0.0115) Grad: 7062.9072  LR: 0.00001951  \n","Epoch: [1][1600/2917] Elapsed 6m 54s (remain 5m 40s) Loss: 0.0058(0.0113) Grad: 5537.3535  LR: 0.00001944  \n","Epoch: [1][1700/2917] Elapsed 7m 20s (remain 5m 14s) Loss: 0.0038(0.0110) Grad: 4584.5854  LR: 0.00001937  \n","Epoch: [1][1800/2917] Elapsed 7m 45s (remain 4m 48s) Loss: 0.0215(0.0109) Grad: 12885.7383  LR: 0.00001929  \n","Epoch: [1][1900/2917] Elapsed 8m 12s (remain 4m 23s) Loss: 0.0028(0.0107) Grad: 3089.4890  LR: 0.00001921  \n","Epoch: [1][2000/2917] Elapsed 8m 39s (remain 3m 57s) Loss: 0.0022(0.0106) Grad: 2042.9858  LR: 0.00001912  \n","Epoch: [1][2100/2917] Elapsed 9m 5s (remain 3m 31s) Loss: 0.0032(0.0104) Grad: 5336.5000  LR: 0.00001903  \n","Epoch: [1][2200/2917] Elapsed 9m 31s (remain 3m 5s) Loss: 0.0061(0.0103) Grad: 3570.0359  LR: 0.00001894  \n","Epoch: [1][2300/2917] Elapsed 9m 57s (remain 2m 39s) Loss: 0.0140(0.0102) Grad: 9349.3623  LR: 0.00001884  \n","Epoch: [1][2400/2917] Elapsed 10m 23s (remain 2m 13s) Loss: 0.0098(0.0101) Grad: 8572.3145  LR: 0.00001874  \n","Epoch: [1][2500/2917] Elapsed 10m 49s (remain 1m 48s) Loss: 0.0135(0.0099) Grad: 20336.2500  LR: 0.00001863  \n","Epoch: [1][2600/2917] Elapsed 11m 16s (remain 1m 22s) Loss: 0.0032(0.0098) Grad: 9509.0762  LR: 0.00001852  \n","Epoch: [1][2700/2917] Elapsed 11m 42s (remain 0m 56s) Loss: 0.0085(0.0097) Grad: 13340.8643  LR: 0.00001840  \n","Epoch: [1][2800/2917] Elapsed 12m 8s (remain 0m 30s) Loss: 0.0089(0.0096) Grad: 15220.6055  LR: 0.00001828  \n","Epoch: [1][2900/2917] Elapsed 12m 34s (remain 0m 4s) Loss: 0.0058(0.0095) Grad: 7610.5947  LR: 0.00001816  \n","Epoch: [1][2916/2917] Elapsed 12m 38s (remain 0m 0s) Loss: 0.0105(0.0095) Grad: 23415.3066  LR: 0.00001814  \n","EVAL: [0/730] Elapsed 0m 0s (remain 5m 6s) Loss: 0.0045(0.0045) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0085(0.0054) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0034(0.0065) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0117(0.0064) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0113(0.0065) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0117(0.0067) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0048(0.0067) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0042(0.0065) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0095  avg_val_loss: 0.0065  time: 838s\n","Epoch 1 - Score: 0.8172\n","Epoch 1 - Save Best Score: 0.8172 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0002(0.0065) \n","Epoch: [2][0/2917] Elapsed 0m 0s (remain 32m 50s) Loss: 0.0120(0.0120) Grad: 14418.2275  LR: 0.00001814  \n","Epoch: [2][100/2917] Elapsed 0m 28s (remain 13m 15s) Loss: 0.0012(0.0047) Grad: 2497.4514  LR: 0.00001801  \n","Epoch: [2][200/2917] Elapsed 0m 56s (remain 12m 47s) Loss: 0.0032(0.0047) Grad: 8373.4902  LR: 0.00001788  \n","Epoch: [2][300/2917] Elapsed 1m 23s (remain 12m 8s) Loss: 0.0048(0.0047) Grad: 9306.7773  LR: 0.00001775  \n","Epoch: [2][400/2917] Elapsed 1m 50s (remain 11m 35s) Loss: 0.0025(0.0045) Grad: 7976.9443  LR: 0.00001761  \n","Epoch: [2][500/2917] Elapsed 2m 17s (remain 11m 5s) Loss: 0.0100(0.0046) Grad: 14707.2930  LR: 0.00001747  \n","Epoch: [2][600/2917] Elapsed 2m 44s (remain 10m 35s) Loss: 0.0066(0.0045) Grad: 8287.5176  LR: 0.00001732  \n","Epoch: [2][700/2917] Elapsed 3m 12s (remain 10m 7s) Loss: 0.0061(0.0045) Grad: 36722.6797  LR: 0.00001717  \n","Epoch: [2][800/2917] Elapsed 3m 39s (remain 9m 38s) Loss: 0.0071(0.0045) Grad: 18653.1816  LR: 0.00001702  \n","Epoch: [2][900/2917] Elapsed 4m 6s (remain 9m 10s) Loss: 0.0033(0.0045) Grad: 6201.2939  LR: 0.00001686  \n","Epoch: [2][1000/2917] Elapsed 4m 33s (remain 8m 43s) Loss: 0.0053(0.0045) Grad: 9935.6924  LR: 0.00001671  \n","Epoch: [2][1100/2917] Elapsed 5m 0s (remain 8m 15s) Loss: 0.0041(0.0045) Grad: 7887.7983  LR: 0.00001654  \n","Epoch: [2][1200/2917] Elapsed 5m 27s (remain 7m 47s) Loss: 0.0103(0.0045) Grad: 19704.1211  LR: 0.00001638  \n","Epoch: [2][1300/2917] Elapsed 5m 54s (remain 7m 20s) Loss: 0.0040(0.0046) Grad: 5457.5903  LR: 0.00001621  \n","Epoch: [2][1400/2917] Elapsed 6m 21s (remain 6m 52s) Loss: 0.0079(0.0046) Grad: 11340.4355  LR: 0.00001604  \n","Epoch: [2][1500/2917] Elapsed 6m 48s (remain 6m 25s) Loss: 0.0020(0.0046) Grad: 5591.9526  LR: 0.00001587  \n","Epoch: [2][1600/2917] Elapsed 7m 15s (remain 5m 57s) Loss: 0.0049(0.0046) Grad: 8945.6650  LR: 0.00001569  \n","Epoch: [2][1700/2917] Elapsed 7m 42s (remain 5m 30s) Loss: 0.0010(0.0046) Grad: 3805.7654  LR: 0.00001551  \n","Epoch: [2][1800/2917] Elapsed 8m 8s (remain 5m 2s) Loss: 0.0020(0.0047) Grad: 5651.9531  LR: 0.00001533  \n","Epoch: [2][1900/2917] Elapsed 8m 35s (remain 4m 35s) Loss: 0.0116(0.0047) Grad: 22839.1816  LR: 0.00001515  \n","Epoch: [2][2000/2917] Elapsed 9m 2s (remain 4m 8s) Loss: 0.0021(0.0047) Grad: 11349.0684  LR: 0.00001496  \n","Epoch: [2][2100/2917] Elapsed 9m 29s (remain 3m 41s) Loss: 0.0015(0.0047) Grad: 7467.5415  LR: 0.00001477  \n","Epoch: [2][2200/2917] Elapsed 9m 56s (remain 3m 14s) Loss: 0.0066(0.0047) Grad: 49372.9570  LR: 0.00001458  \n","Epoch: [2][2300/2917] Elapsed 10m 23s (remain 2m 46s) Loss: 0.0044(0.0047) Grad: 18778.1191  LR: 0.00001439  \n","Epoch: [2][2400/2917] Elapsed 10m 50s (remain 2m 19s) Loss: 0.0023(0.0046) Grad: 12719.9854  LR: 0.00001419  \n","Epoch: [2][2500/2917] Elapsed 11m 17s (remain 1m 52s) Loss: 0.0054(0.0046) Grad: 70737.9688  LR: 0.00001399  \n","Epoch: [2][2600/2917] Elapsed 11m 43s (remain 1m 25s) Loss: 0.0036(0.0046) Grad: 16665.2168  LR: 0.00001380  \n","Epoch: [2][2700/2917] Elapsed 12m 10s (remain 0m 58s) Loss: 0.0021(0.0046) Grad: 16135.7383  LR: 0.00001359  \n","Epoch: [2][2800/2917] Elapsed 12m 37s (remain 0m 31s) Loss: 0.0030(0.0046) Grad: 38561.5586  LR: 0.00001339  \n","Epoch: [2][2900/2917] Elapsed 13m 4s (remain 0m 4s) Loss: 0.0014(0.0046) Grad: 9375.8145  LR: 0.00001319  \n","Epoch: [2][2916/2917] Elapsed 13m 8s (remain 0m 0s) Loss: 0.0018(0.0046) Grad: 11197.8750  LR: 0.00001316  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 33s) Loss: 0.0049(0.0049) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0080(0.0054) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0025(0.0061) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0123(0.0059) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0078(0.0060) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0084(0.0062) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0038(0.0062) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0039(0.0060) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0046  avg_val_loss: 0.0060  time: 868s\n","Epoch 2 - Score: 0.8072\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0012(0.0060) \n","Epoch: [3][0/2917] Elapsed 0m 0s (remain 30m 41s) Loss: 0.0032(0.0032) Grad: 7231.1577  LR: 0.00001315  \n","Epoch: [3][100/2917] Elapsed 0m 27s (remain 12m 41s) Loss: 0.0039(0.0032) Grad: 8898.3018  LR: 0.00001295  \n","Epoch: [3][200/2917] Elapsed 0m 54s (remain 12m 12s) Loss: 0.0021(0.0030) Grad: 5060.3232  LR: 0.00001274  \n","Epoch: [3][300/2917] Elapsed 1m 21s (remain 11m 45s) Loss: 0.0037(0.0031) Grad: 9777.0391  LR: 0.00001253  \n","Epoch: [3][400/2917] Elapsed 1m 47s (remain 11m 16s) Loss: 0.0009(0.0032) Grad: 4377.8242  LR: 0.00001232  \n","Epoch: [3][500/2917] Elapsed 2m 14s (remain 10m 49s) Loss: 0.0015(0.0032) Grad: 6338.6382  LR: 0.00001211  \n","Epoch: [3][600/2917] Elapsed 2m 41s (remain 10m 21s) Loss: 0.0031(0.0032) Grad: 9826.5840  LR: 0.00001190  \n","Epoch: [3][700/2917] Elapsed 3m 8s (remain 9m 55s) Loss: 0.0024(0.0032) Grad: 6377.3833  LR: 0.00001169  \n","Epoch: [3][800/2917] Elapsed 3m 35s (remain 9m 28s) Loss: 0.0030(0.0032) Grad: 7779.8052  LR: 0.00001147  \n","Epoch: [3][900/2917] Elapsed 4m 1s (remain 9m 1s) Loss: 0.0014(0.0032) Grad: 4695.1045  LR: 0.00001126  \n","Epoch: [3][1000/2917] Elapsed 4m 28s (remain 8m 34s) Loss: 0.0040(0.0032) Grad: 8882.6855  LR: 0.00001104  \n","Epoch: [3][1100/2917] Elapsed 4m 55s (remain 8m 7s) Loss: 0.0032(0.0032) Grad: 5245.7554  LR: 0.00001083  \n","Epoch: [3][1200/2917] Elapsed 5m 22s (remain 7m 41s) Loss: 0.0019(0.0031) Grad: 7818.9805  LR: 0.00001061  \n","Epoch: [3][1300/2917] Elapsed 5m 49s (remain 7m 14s) Loss: 0.0010(0.0031) Grad: 5438.3081  LR: 0.00001040  \n","Epoch: [3][1400/2917] Elapsed 6m 16s (remain 6m 47s) Loss: 0.0035(0.0031) Grad: 6351.6582  LR: 0.00001018  \n","Epoch: [3][1500/2917] Elapsed 6m 43s (remain 6m 20s) Loss: 0.0038(0.0032) Grad: 6841.0693  LR: 0.00000997  \n","Epoch: [3][1600/2917] Elapsed 7m 10s (remain 5m 53s) Loss: 0.0043(0.0032) Grad: 11370.3926  LR: 0.00000975  \n","Epoch: [3][1700/2917] Elapsed 7m 37s (remain 5m 26s) Loss: 0.0045(0.0032) Grad: 12291.7793  LR: 0.00000953  \n","Epoch: [3][1800/2917] Elapsed 8m 3s (remain 4m 59s) Loss: 0.0054(0.0032) Grad: 10699.8672  LR: 0.00000932  \n","Epoch: [3][1900/2917] Elapsed 8m 30s (remain 4m 32s) Loss: 0.0040(0.0032) Grad: 15623.6641  LR: 0.00000910  \n","Epoch: [3][2000/2917] Elapsed 8m 56s (remain 4m 5s) Loss: 0.0011(0.0032) Grad: 7885.8447  LR: 0.00000889  \n","Epoch: [3][2100/2917] Elapsed 9m 23s (remain 3m 38s) Loss: 0.0017(0.0032) Grad: 19096.0605  LR: 0.00000867  \n","Epoch: [3][2200/2917] Elapsed 9m 49s (remain 3m 11s) Loss: 0.0021(0.0032) Grad: 29607.3789  LR: 0.00000846  \n","Epoch: [3][2300/2917] Elapsed 10m 16s (remain 2m 44s) Loss: 0.0035(0.0032) Grad: 20682.6504  LR: 0.00000825  \n","Epoch: [3][2400/2917] Elapsed 10m 43s (remain 2m 18s) Loss: 0.0007(0.0032) Grad: 8548.4932  LR: 0.00000803  \n","Epoch: [3][2500/2917] Elapsed 11m 9s (remain 1m 51s) Loss: 0.0053(0.0032) Grad: 30520.9473  LR: 0.00000782  \n","Epoch: [3][2600/2917] Elapsed 11m 36s (remain 1m 24s) Loss: 0.0020(0.0032) Grad: 11634.6074  LR: 0.00000761  \n","Epoch: [3][2700/2917] Elapsed 12m 3s (remain 0m 57s) Loss: 0.0001(0.0032) Grad: 2011.5895  LR: 0.00000740  \n","Epoch: [3][2800/2917] Elapsed 12m 30s (remain 0m 31s) Loss: 0.0041(0.0032) Grad: 25180.4551  LR: 0.00000720  \n","Epoch: [3][2900/2917] Elapsed 12m 57s (remain 0m 4s) Loss: 0.0022(0.0032) Grad: 13706.9346  LR: 0.00000699  \n","Epoch: [3][2916/2917] Elapsed 13m 1s (remain 0m 0s) Loss: 0.0045(0.0032) Grad: 34800.6289  LR: 0.00000696  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 39s) Loss: 0.0042(0.0042) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0118(0.0057) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0041(0.0066) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0118(0.0063) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0117(0.0064) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0110(0.0065) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 14s) Loss: 0.0037(0.0066) \n","EVAL: [700/730] Elapsed 1m 16s (remain 0m 3s) Loss: 0.0029(0.0065) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0032  avg_val_loss: 0.0065  time: 861s\n","Epoch 3 - Score: 0.8171\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0002(0.0065) \n","Epoch: [4][0/2917] Elapsed 0m 0s (remain 31m 0s) Loss: 0.0005(0.0005) Grad: 3609.1309  LR: 0.00000695  \n","Epoch: [4][100/2917] Elapsed 0m 27s (remain 12m 38s) Loss: 0.0012(0.0024) Grad: 5244.5781  LR: 0.00000675  \n","Epoch: [4][200/2917] Elapsed 0m 53s (remain 12m 7s) Loss: 0.0006(0.0022) Grad: 4743.7910  LR: 0.00000655  \n","Epoch: [4][300/2917] Elapsed 1m 20s (remain 11m 41s) Loss: 0.0014(0.0022) Grad: 8630.4756  LR: 0.00000634  \n","Epoch: [4][400/2917] Elapsed 1m 47s (remain 11m 13s) Loss: 0.0011(0.0023) Grad: 5044.1152  LR: 0.00000614  \n","Epoch: [4][500/2917] Elapsed 2m 14s (remain 10m 46s) Loss: 0.0010(0.0023) Grad: 5491.7578  LR: 0.00000594  \n","Epoch: [4][600/2917] Elapsed 2m 40s (remain 10m 18s) Loss: 0.0057(0.0023) Grad: 11803.8018  LR: 0.00000575  \n","Epoch: [4][700/2917] Elapsed 3m 7s (remain 9m 52s) Loss: 0.0035(0.0024) Grad: 21328.8730  LR: 0.00000555  \n","Epoch: [4][800/2917] Elapsed 3m 34s (remain 9m 25s) Loss: 0.0006(0.0023) Grad: 3781.1748  LR: 0.00000536  \n","Epoch: [4][900/2917] Elapsed 4m 0s (remain 8m 58s) Loss: 0.0014(0.0023) Grad: 5149.0903  LR: 0.00000517  \n","Epoch: [4][1000/2917] Elapsed 4m 27s (remain 8m 31s) Loss: 0.0008(0.0023) Grad: 4817.3213  LR: 0.00000498  \n","Epoch: [4][1100/2917] Elapsed 4m 54s (remain 8m 5s) Loss: 0.0006(0.0024) Grad: 3239.7324  LR: 0.00000480  \n","Epoch: [4][1200/2917] Elapsed 5m 21s (remain 7m 39s) Loss: 0.0027(0.0024) Grad: 6774.0874  LR: 0.00000461  \n","Epoch: [4][1300/2917] Elapsed 5m 48s (remain 7m 12s) Loss: 0.0026(0.0024) Grad: 21051.1621  LR: 0.00000443  \n","Epoch: [4][1400/2917] Elapsed 6m 15s (remain 6m 46s) Loss: 0.0048(0.0023) Grad: 11117.5439  LR: 0.00000425  \n","Epoch: [4][1500/2917] Elapsed 6m 42s (remain 6m 19s) Loss: 0.0014(0.0023) Grad: 5509.7939  LR: 0.00000408  \n","Epoch: [4][1600/2917] Elapsed 7m 9s (remain 5m 52s) Loss: 0.0014(0.0023) Grad: 12782.9863  LR: 0.00000391  \n","Epoch: [4][1700/2917] Elapsed 7m 35s (remain 5m 25s) Loss: 0.0033(0.0023) Grad: 14024.6699  LR: 0.00000374  \n","Epoch: [4][1800/2917] Elapsed 8m 2s (remain 4m 58s) Loss: 0.0034(0.0023) Grad: 5360.6040  LR: 0.00000357  \n","Epoch: [4][1900/2917] Elapsed 8m 29s (remain 4m 32s) Loss: 0.0006(0.0023) Grad: 4620.1040  LR: 0.00000341  \n","Epoch: [4][2000/2917] Elapsed 8m 56s (remain 4m 5s) Loss: 0.0024(0.0023) Grad: 14287.5205  LR: 0.00000324  \n","Epoch: [4][2100/2917] Elapsed 9m 23s (remain 3m 38s) Loss: 0.0022(0.0023) Grad: 22481.0371  LR: 0.00000309  \n","Epoch: [4][2200/2917] Elapsed 9m 49s (remain 3m 11s) Loss: 0.0020(0.0023) Grad: 20320.6992  LR: 0.00000293  \n","Epoch: [4][2300/2917] Elapsed 10m 16s (remain 2m 45s) Loss: 0.0015(0.0023) Grad: 8360.6865  LR: 0.00000278  \n","Epoch: [4][2400/2917] Elapsed 10m 43s (remain 2m 18s) Loss: 0.0064(0.0023) Grad: 18392.8516  LR: 0.00000263  \n","Epoch: [4][2500/2917] Elapsed 11m 10s (remain 1m 51s) Loss: 0.0011(0.0023) Grad: 15787.1299  LR: 0.00000249  \n","Epoch: [4][2600/2917] Elapsed 11m 37s (remain 1m 24s) Loss: 0.0014(0.0023) Grad: 12884.0811  LR: 0.00000235  \n","Epoch: [4][2700/2917] Elapsed 12m 4s (remain 0m 57s) Loss: 0.0003(0.0023) Grad: 4278.3594  LR: 0.00000221  \n","Epoch: [4][2800/2917] Elapsed 12m 30s (remain 0m 31s) Loss: 0.0010(0.0023) Grad: 8707.1250  LR: 0.00000208  \n","Epoch: [4][2900/2917] Elapsed 12m 57s (remain 0m 4s) Loss: 0.0031(0.0023) Grad: 14339.1104  LR: 0.00000195  \n","Epoch: [4][2916/2917] Elapsed 13m 2s (remain 0m 0s) Loss: 0.0028(0.0023) Grad: 18394.1855  LR: 0.00000193  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 29s) Loss: 0.0044(0.0044) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0056(0.0055) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0050(0.0064) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0132(0.0063) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0090(0.0064) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0090(0.0066) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0042(0.0067) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0036(0.0065) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0023  avg_val_loss: 0.0065  time: 861s\n","Epoch 4 - Score: 0.8102\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0001(0.0065) \n","Epoch: [5][0/2917] Elapsed 0m 0s (remain 32m 25s) Loss: 0.0014(0.0014) Grad: 5504.5728  LR: 0.00000193  \n","Epoch: [5][100/2917] Elapsed 0m 27s (remain 12m 47s) Loss: 0.0001(0.0019) Grad: 1544.5752  LR: 0.00000180  \n","Epoch: [5][200/2917] Elapsed 0m 54s (remain 12m 14s) Loss: 0.0018(0.0019) Grad: 11161.3711  LR: 0.00000168  \n","Epoch: [5][300/2917] Elapsed 1m 21s (remain 11m 45s) Loss: 0.0012(0.0019) Grad: 7764.0532  LR: 0.00000156  \n","Epoch: [5][400/2917] Elapsed 1m 47s (remain 11m 16s) Loss: 0.0014(0.0019) Grad: 11741.5459  LR: 0.00000145  \n","Epoch: [5][500/2917] Elapsed 2m 14s (remain 10m 50s) Loss: 0.0029(0.0019) Grad: 23714.1641  LR: 0.00000134  \n","Epoch: [5][600/2917] Elapsed 2m 41s (remain 10m 22s) Loss: 0.0005(0.0019) Grad: 2924.3599  LR: 0.00000123  \n","Epoch: [5][700/2917] Elapsed 3m 8s (remain 9m 54s) Loss: 0.0013(0.0019) Grad: 7649.2930  LR: 0.00000113  \n","Epoch: [5][800/2917] Elapsed 3m 34s (remain 9m 27s) Loss: 0.0002(0.0019) Grad: 2343.1670  LR: 0.00000103  \n","Epoch: [5][900/2917] Elapsed 4m 1s (remain 8m 59s) Loss: 0.0027(0.0019) Grad: 14344.0889  LR: 0.00000094  \n","Epoch: [5][1000/2917] Elapsed 4m 27s (remain 8m 32s) Loss: 0.0002(0.0019) Grad: 1565.9750  LR: 0.00000085  \n","Epoch: [5][1100/2917] Elapsed 4m 54s (remain 8m 6s) Loss: 0.0027(0.0019) Grad: 8230.1660  LR: 0.00000076  \n","Epoch: [5][1200/2917] Elapsed 5m 21s (remain 7m 39s) Loss: 0.0022(0.0019) Grad: 10857.8252  LR: 0.00000068  \n","Epoch: [5][1300/2917] Elapsed 5m 48s (remain 7m 12s) Loss: 0.0006(0.0019) Grad: 7359.7437  LR: 0.00000061  \n","Epoch: [5][1400/2917] Elapsed 6m 15s (remain 6m 45s) Loss: 0.0012(0.0019) Grad: 15106.4961  LR: 0.00000053  \n","Epoch: [5][1500/2917] Elapsed 6m 41s (remain 6m 19s) Loss: 0.0046(0.0019) Grad: 14817.1396  LR: 0.00000047  \n","Epoch: [5][1600/2917] Elapsed 7m 8s (remain 5m 52s) Loss: 0.0071(0.0019) Grad: 19028.2168  LR: 0.00000040  \n","Epoch: [5][1700/2917] Elapsed 7m 35s (remain 5m 25s) Loss: 0.0001(0.0019) Grad: 1485.2338  LR: 0.00000035  \n","Epoch: [5][1800/2917] Elapsed 8m 1s (remain 4m 58s) Loss: 0.0039(0.0019) Grad: 11530.2949  LR: 0.00000029  \n","Epoch: [5][1900/2917] Elapsed 8m 27s (remain 4m 31s) Loss: 0.0009(0.0019) Grad: 5795.3740  LR: 0.00000024  \n","Epoch: [5][2000/2917] Elapsed 8m 54s (remain 4m 4s) Loss: 0.0007(0.0019) Grad: 8512.3057  LR: 0.00000020  \n","Epoch: [5][2100/2917] Elapsed 9m 20s (remain 3m 37s) Loss: 0.0034(0.0019) Grad: 22817.8105  LR: 0.00000016  \n","Epoch: [5][2200/2917] Elapsed 9m 47s (remain 3m 11s) Loss: 0.0002(0.0019) Grad: 4273.3530  LR: 0.00000012  \n","Epoch: [5][2300/2917] Elapsed 10m 13s (remain 2m 44s) Loss: 0.0004(0.0018) Grad: 3349.0188  LR: 0.00000009  \n","Epoch: [5][2400/2917] Elapsed 10m 40s (remain 2m 17s) Loss: 0.0008(0.0018) Grad: 10450.8301  LR: 0.00000006  \n","Epoch: [5][2500/2917] Elapsed 11m 7s (remain 1m 50s) Loss: 0.0018(0.0018) Grad: 125442.3438  LR: 0.00000004  \n","Epoch: [5][2600/2917] Elapsed 11m 33s (remain 1m 24s) Loss: 0.0009(0.0018) Grad: 8254.6338  LR: 0.00000002  \n","Epoch: [5][2700/2917] Elapsed 12m 0s (remain 0m 57s) Loss: 0.0035(0.0018) Grad: 16931.8223  LR: 0.00000001  \n","Epoch: [5][2800/2917] Elapsed 12m 27s (remain 0m 30s) Loss: 0.0007(0.0018) Grad: 7609.9062  LR: 0.00000000  \n","Epoch: [5][2900/2917] Elapsed 12m 53s (remain 0m 4s) Loss: 0.0016(0.0018) Grad: 11886.9883  LR: 0.00000000  \n","Epoch: [5][2916/2917] Elapsed 12m 57s (remain 0m 0s) Loss: 0.0019(0.0018) Grad: 9894.5098  LR: 0.00000000  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 38s) Loss: 0.0045(0.0045) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0079(0.0059) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0052(0.0067) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0137(0.0066) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0096(0.0067) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0107(0.0070) \n","EVAL: [600/730] Elapsed 1m 4s (remain 0m 13s) Loss: 0.0041(0.0071) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0038(0.0069) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0018  avg_val_loss: 0.0069  time: 857s\n","Epoch 5 - Score: 0.8091\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0002(0.0069) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 3 result ==========\n","Score: 0.8172\n","========== fold: 4 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['lm_predictions.lm_head.dense.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2917] Elapsed 0m 0s (remain 31m 12s) Loss: 0.0258(0.0258) Grad: 21535.4492  LR: 0.00000040  \n","Epoch: [1][100/2917] Elapsed 0m 26s (remain 12m 27s) Loss: 0.0157(0.0248) Grad: 43444.0469  LR: 0.00002000  \n","Epoch: [1][200/2917] Elapsed 0m 52s (remain 11m 55s) Loss: 0.0148(0.0232) Grad: 13733.3223  LR: 0.00001999  \n","Epoch: [1][300/2917] Elapsed 1m 19s (remain 11m 28s) Loss: 0.0112(0.0219) Grad: 12893.9072  LR: 0.00001999  \n","Epoch: [1][400/2917] Elapsed 1m 45s (remain 10m 59s) Loss: 0.0126(0.0200) Grad: 17329.8789  LR: 0.00001997  \n","Epoch: [1][500/2917] Elapsed 2m 11s (remain 10m 34s) Loss: 0.0089(0.0183) Grad: 16203.1221  LR: 0.00001995  \n","Epoch: [1][600/2917] Elapsed 2m 37s (remain 10m 8s) Loss: 0.0107(0.0172) Grad: 21685.6855  LR: 0.00001993  \n","Epoch: [1][700/2917] Elapsed 3m 4s (remain 9m 43s) Loss: 0.0200(0.0162) Grad: 39326.2930  LR: 0.00001990  \n","Epoch: [1][800/2917] Elapsed 3m 31s (remain 9m 17s) Loss: 0.0118(0.0154) Grad: 36692.0977  LR: 0.00001987  \n","Epoch: [1][900/2917] Elapsed 3m 57s (remain 8m 51s) Loss: 0.0080(0.0148) Grad: 29557.0547  LR: 0.00001983  \n","Epoch: [1][1000/2917] Elapsed 4m 24s (remain 8m 26s) Loss: 0.0165(0.0142) Grad: 44659.9023  LR: 0.00001979  \n","Epoch: [1][1100/2917] Elapsed 4m 50s (remain 7m 59s) Loss: 0.0085(0.0138) Grad: 27082.5234  LR: 0.00001974  \n","Epoch: [1][1200/2917] Elapsed 5m 17s (remain 7m 33s) Loss: 0.0048(0.0134) Grad: 18631.6348  LR: 0.00001969  \n","Epoch: [1][1300/2917] Elapsed 5m 43s (remain 7m 6s) Loss: 0.0035(0.0129) Grad: 14958.8281  LR: 0.00001964  \n","Epoch: [1][1400/2917] Elapsed 6m 10s (remain 6m 40s) Loss: 0.0119(0.0125) Grad: 43988.7617  LR: 0.00001958  \n","Epoch: [1][1500/2917] Elapsed 6m 36s (remain 6m 14s) Loss: 0.0084(0.0122) Grad: 12955.2422  LR: 0.00001951  \n","Epoch: [1][1600/2917] Elapsed 7m 2s (remain 5m 47s) Loss: 0.0055(0.0119) Grad: 16012.0186  LR: 0.00001944  \n","Epoch: [1][1700/2917] Elapsed 7m 29s (remain 5m 21s) Loss: 0.0122(0.0116) Grad: 21718.4141  LR: 0.00001937  \n","Epoch: [1][1800/2917] Elapsed 7m 55s (remain 4m 54s) Loss: 0.0062(0.0115) Grad: 15412.0293  LR: 0.00001929  \n","Epoch: [1][1900/2917] Elapsed 8m 21s (remain 4m 27s) Loss: 0.0098(0.0113) Grad: 32220.6074  LR: 0.00001921  \n","Epoch: [1][2000/2917] Elapsed 8m 47s (remain 4m 1s) Loss: 0.0217(0.0111) Grad: 229183.7500  LR: 0.00001912  \n","Epoch: [1][2100/2917] Elapsed 9m 13s (remain 3m 35s) Loss: 0.0123(0.0110) Grad: 27709.6699  LR: 0.00001903  \n","Epoch: [1][2200/2917] Elapsed 9m 40s (remain 3m 8s) Loss: 0.0045(0.0108) Grad: 13505.8984  LR: 0.00001894  \n","Epoch: [1][2300/2917] Elapsed 10m 7s (remain 2m 42s) Loss: 0.0094(0.0107) Grad: 16675.8789  LR: 0.00001884  \n","Epoch: [1][2400/2917] Elapsed 10m 33s (remain 2m 16s) Loss: 0.0038(0.0105) Grad: 16395.0859  LR: 0.00001874  \n","Epoch: [1][2500/2917] Elapsed 11m 0s (remain 1m 49s) Loss: 0.0035(0.0104) Grad: 16961.8555  LR: 0.00001863  \n","Epoch: [1][2600/2917] Elapsed 11m 26s (remain 1m 23s) Loss: 0.0048(0.0103) Grad: 5002.1929  LR: 0.00001852  \n","Epoch: [1][2700/2917] Elapsed 11m 53s (remain 0m 57s) Loss: 0.0029(0.0103) Grad: 6305.1880  LR: 0.00001840  \n","Epoch: [1][2800/2917] Elapsed 12m 19s (remain 0m 30s) Loss: 0.0101(0.0102) Grad: 11382.5762  LR: 0.00001828  \n","Epoch: [1][2900/2917] Elapsed 12m 46s (remain 0m 4s) Loss: 0.0033(0.0101) Grad: 3841.6580  LR: 0.00001816  \n","Epoch: [1][2916/2917] Elapsed 12m 50s (remain 0m 0s) Loss: 0.0049(0.0101) Grad: 5887.7427  LR: 0.00001814  \n","EVAL: [0/730] Elapsed 0m 0s (remain 5m 18s) Loss: 0.0057(0.0057) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 10s) Loss: 0.0098(0.0069) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 58s) Loss: 0.0452(0.0070) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0094(0.0068) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0053(0.0069) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0055(0.0069) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 14s) Loss: 0.0042(0.0070) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0067(0.0071) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0101  avg_val_loss: 0.0071  time: 850s\n","Epoch 1 - Score: 0.8126\n","Epoch 1 - Save Best Score: 0.8126 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0021(0.0071) \n","Epoch: [2][0/2917] Elapsed 0m 0s (remain 34m 33s) Loss: 0.0083(0.0083) Grad: 13501.2402  LR: 0.00001814  \n","Epoch: [2][100/2917] Elapsed 0m 27s (remain 12m 58s) Loss: 0.0010(0.0051) Grad: 6424.7944  LR: 0.00001801  \n","Epoch: [2][200/2917] Elapsed 0m 55s (remain 12m 30s) Loss: 0.0029(0.0054) Grad: 5593.1099  LR: 0.00001788  \n","Epoch: [2][300/2917] Elapsed 1m 23s (remain 12m 1s) Loss: 0.0047(0.0056) Grad: 9292.2490  LR: 0.00001775  \n","Epoch: [2][400/2917] Elapsed 1m 49s (remain 11m 25s) Loss: 0.0062(0.0055) Grad: 13253.3174  LR: 0.00001761  \n","Epoch: [2][500/2917] Elapsed 2m 15s (remain 10m 53s) Loss: 0.0052(0.0055) Grad: 17107.7188  LR: 0.00001747  \n","Epoch: [2][600/2917] Elapsed 2m 42s (remain 10m 24s) Loss: 0.0030(0.0055) Grad: 9472.4326  LR: 0.00001732  \n","Epoch: [2][700/2917] Elapsed 3m 8s (remain 9m 56s) Loss: 0.0069(0.0055) Grad: 11112.4463  LR: 0.00001717  \n","Epoch: [2][800/2917] Elapsed 3m 35s (remain 9m 28s) Loss: 0.0018(0.0055) Grad: 5107.6104  LR: 0.00001702  \n","Epoch: [2][900/2917] Elapsed 4m 1s (remain 9m 0s) Loss: 0.0020(0.0054) Grad: 53390.3828  LR: 0.00001686  \n","Epoch: [2][1000/2917] Elapsed 4m 28s (remain 8m 33s) Loss: 0.0064(0.0054) Grad: 20675.9902  LR: 0.00001671  \n","Epoch: [2][1100/2917] Elapsed 4m 54s (remain 8m 6s) Loss: 0.0020(0.0054) Grad: 5104.2549  LR: 0.00001654  \n","Epoch: [2][1200/2917] Elapsed 5m 21s (remain 7m 39s) Loss: 0.0036(0.0054) Grad: 8718.9941  LR: 0.00001638  \n","Epoch: [2][1300/2917] Elapsed 5m 47s (remain 7m 12s) Loss: 0.0030(0.0054) Grad: 10050.3535  LR: 0.00001621  \n","Epoch: [2][1400/2917] Elapsed 6m 14s (remain 6m 45s) Loss: 0.0043(0.0054) Grad: 11479.5547  LR: 0.00001604  \n","Epoch: [2][1500/2917] Elapsed 6m 41s (remain 6m 18s) Loss: 0.0025(0.0054) Grad: 10208.0801  LR: 0.00001587  \n","Epoch: [2][1600/2917] Elapsed 7m 8s (remain 5m 52s) Loss: 0.0055(0.0053) Grad: 8130.5190  LR: 0.00001569  \n","Epoch: [2][1700/2917] Elapsed 7m 35s (remain 5m 25s) Loss: 0.0065(0.0054) Grad: 10458.1943  LR: 0.00001551  \n","Epoch: [2][1800/2917] Elapsed 8m 1s (remain 4m 58s) Loss: 0.0057(0.0054) Grad: 19570.2168  LR: 0.00001533  \n","Epoch: [2][1900/2917] Elapsed 8m 28s (remain 4m 31s) Loss: 0.0027(0.0054) Grad: 4624.7856  LR: 0.00001515  \n","Epoch: [2][2000/2917] Elapsed 8m 55s (remain 4m 4s) Loss: 0.0053(0.0054) Grad: 15697.4854  LR: 0.00001496  \n","Epoch: [2][2100/2917] Elapsed 9m 21s (remain 3m 38s) Loss: 0.0019(0.0054) Grad: 7571.3716  LR: 0.00001477  \n","Epoch: [2][2200/2917] Elapsed 9m 48s (remain 3m 11s) Loss: 0.0044(0.0054) Grad: 24347.2852  LR: 0.00001458  \n","Epoch: [2][2300/2917] Elapsed 10m 14s (remain 2m 44s) Loss: 0.0034(0.0054) Grad: 4525.6050  LR: 0.00001439  \n","Epoch: [2][2400/2917] Elapsed 10m 41s (remain 2m 17s) Loss: 0.0072(0.0054) Grad: 22897.2910  LR: 0.00001419  \n","Epoch: [2][2500/2917] Elapsed 11m 8s (remain 1m 51s) Loss: 0.0009(0.0053) Grad: 4597.7759  LR: 0.00001399  \n","Epoch: [2][2600/2917] Elapsed 11m 34s (remain 1m 24s) Loss: 0.0061(0.0053) Grad: 23237.8203  LR: 0.00001380  \n","Epoch: [2][2700/2917] Elapsed 12m 0s (remain 0m 57s) Loss: 0.0014(0.0053) Grad: 5396.9443  LR: 0.00001359  \n","Epoch: [2][2800/2917] Elapsed 12m 27s (remain 0m 30s) Loss: 0.0054(0.0053) Grad: 10374.0654  LR: 0.00001339  \n","Epoch: [2][2900/2917] Elapsed 12m 53s (remain 0m 4s) Loss: 0.0021(0.0053) Grad: 10093.0664  LR: 0.00001319  \n","Epoch: [2][2916/2917] Elapsed 12m 58s (remain 0m 0s) Loss: 0.0029(0.0053) Grad: 5389.7163  LR: 0.00001316  \n","EVAL: [0/730] Elapsed 0m 0s (remain 5m 16s) Loss: 0.0013(0.0013) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0060(0.0056) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0263(0.0057) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0046(0.0054) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0038(0.0056) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0093(0.0057) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0007(0.0057) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0045(0.0057) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0053  avg_val_loss: 0.0057  time: 857s\n","Epoch 2 - Score: 0.8201\n","Epoch 2 - Save Best Score: 0.8201 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0044(0.0057) \n","Epoch: [3][0/2917] Elapsed 0m 0s (remain 35m 0s) Loss: 0.0021(0.0021) Grad: 3719.4521  LR: 0.00001315  \n","Epoch: [3][100/2917] Elapsed 0m 28s (remain 13m 8s) Loss: 0.0017(0.0034) Grad: 4531.4282  LR: 0.00001295  \n","Epoch: [3][200/2917] Elapsed 0m 55s (remain 12m 36s) Loss: 0.0032(0.0035) Grad: 12259.6992  LR: 0.00001274  \n","Epoch: [3][300/2917] Elapsed 1m 23s (remain 12m 7s) Loss: 0.0020(0.0034) Grad: 4785.5728  LR: 0.00001253  \n","Epoch: [3][400/2917] Elapsed 1m 50s (remain 11m 32s) Loss: 0.0051(0.0036) Grad: 6210.2520  LR: 0.00001232  \n","Epoch: [3][500/2917] Elapsed 2m 16s (remain 10m 58s) Loss: 0.0031(0.0036) Grad: 9747.1768  LR: 0.00001211  \n","Epoch: [3][600/2917] Elapsed 2m 42s (remain 10m 25s) Loss: 0.0033(0.0036) Grad: 13803.9434  LR: 0.00001190  \n","Epoch: [3][700/2917] Elapsed 3m 9s (remain 9m 57s) Loss: 0.0017(0.0036) Grad: 4046.4275  LR: 0.00001169  \n","Epoch: [3][800/2917] Elapsed 3m 36s (remain 9m 30s) Loss: 0.0012(0.0036) Grad: 4300.3091  LR: 0.00001147  \n","Epoch: [3][900/2917] Elapsed 4m 2s (remain 9m 3s) Loss: 0.0022(0.0035) Grad: 5092.9219  LR: 0.00001126  \n","Epoch: [3][1000/2917] Elapsed 4m 28s (remain 8m 34s) Loss: 0.0024(0.0035) Grad: 4912.4731  LR: 0.00001104  \n","Epoch: [3][1100/2917] Elapsed 4m 55s (remain 8m 7s) Loss: 0.0046(0.0035) Grad: 11912.8457  LR: 0.00001083  \n","Epoch: [3][1200/2917] Elapsed 5m 22s (remain 7m 40s) Loss: 0.0007(0.0035) Grad: 4418.9102  LR: 0.00001061  \n","Epoch: [3][1300/2917] Elapsed 5m 48s (remain 7m 13s) Loss: 0.0020(0.0035) Grad: 9997.1514  LR: 0.00001040  \n","Epoch: [3][1400/2917] Elapsed 6m 15s (remain 6m 46s) Loss: 0.0007(0.0035) Grad: 4520.2227  LR: 0.00001018  \n","Epoch: [3][1500/2917] Elapsed 6m 42s (remain 6m 19s) Loss: 0.0055(0.0035) Grad: 13648.0098  LR: 0.00000997  \n","Epoch: [3][1600/2917] Elapsed 7m 8s (remain 5m 52s) Loss: 0.0064(0.0035) Grad: 8735.8350  LR: 0.00000975  \n","Epoch: [3][1700/2917] Elapsed 7m 35s (remain 5m 25s) Loss: 0.0036(0.0035) Grad: 10329.2832  LR: 0.00000953  \n","Epoch: [3][1800/2917] Elapsed 8m 1s (remain 4m 58s) Loss: 0.0025(0.0035) Grad: 5159.1934  LR: 0.00000932  \n","Epoch: [3][1900/2917] Elapsed 8m 27s (remain 4m 31s) Loss: 0.0028(0.0035) Grad: 9634.9912  LR: 0.00000910  \n","Epoch: [3][2000/2917] Elapsed 8m 54s (remain 4m 4s) Loss: 0.0016(0.0035) Grad: 17739.1777  LR: 0.00000889  \n","Epoch: [3][2100/2917] Elapsed 9m 20s (remain 3m 37s) Loss: 0.0005(0.0035) Grad: 5516.0093  LR: 0.00000867  \n","Epoch: [3][2200/2917] Elapsed 9m 47s (remain 3m 11s) Loss: 0.0010(0.0035) Grad: 5542.8799  LR: 0.00000846  \n","Epoch: [3][2300/2917] Elapsed 10m 14s (remain 2m 44s) Loss: 0.0027(0.0035) Grad: 25883.7715  LR: 0.00000825  \n","Epoch: [3][2400/2917] Elapsed 10m 41s (remain 2m 17s) Loss: 0.0040(0.0035) Grad: 40271.2422  LR: 0.00000803  \n","Epoch: [3][2500/2917] Elapsed 11m 7s (remain 1m 51s) Loss: 0.0032(0.0035) Grad: 49918.2188  LR: 0.00000782  \n","Epoch: [3][2600/2917] Elapsed 11m 33s (remain 1m 24s) Loss: 0.0015(0.0035) Grad: 7754.8374  LR: 0.00000761  \n","Epoch: [3][2700/2917] Elapsed 11m 59s (remain 0m 57s) Loss: 0.0036(0.0034) Grad: 24169.6875  LR: 0.00000740  \n","Epoch: [3][2800/2917] Elapsed 12m 25s (remain 0m 30s) Loss: 0.0049(0.0035) Grad: 32599.6699  LR: 0.00000720  \n","Epoch: [3][2900/2917] Elapsed 12m 51s (remain 0m 4s) Loss: 0.0014(0.0035) Grad: 17885.6445  LR: 0.00000699  \n","Epoch: [3][2916/2917] Elapsed 12m 55s (remain 0m 0s) Loss: 0.0026(0.0035) Grad: 14388.9004  LR: 0.00000696  \n","EVAL: [0/730] Elapsed 0m 0s (remain 4m 55s) Loss: 0.0010(0.0010) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0079(0.0058) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 57s) Loss: 0.0668(0.0064) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0155(0.0059) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0011(0.0060) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0100(0.0060) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0001(0.0059) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0010(0.0060) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0035  avg_val_loss: 0.0060  time: 855s\n","Epoch 3 - Score: 0.8198\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0019(0.0060) \n","Epoch: [4][0/2917] Elapsed 0m 0s (remain 32m 37s) Loss: 0.0018(0.0018) Grad: 6092.2280  LR: 0.00000695  \n","Epoch: [4][100/2917] Elapsed 0m 27s (remain 12m 49s) Loss: 0.0024(0.0023) Grad: 6458.5532  LR: 0.00000675  \n","Epoch: [4][200/2917] Elapsed 0m 54s (remain 12m 15s) Loss: 0.0007(0.0022) Grad: 3726.2756  LR: 0.00000655  \n","Epoch: [4][300/2917] Elapsed 1m 21s (remain 11m 44s) Loss: 0.0005(0.0024) Grad: 3719.3245  LR: 0.00000634  \n","Epoch: [4][400/2917] Elapsed 1m 47s (remain 11m 15s) Loss: 0.0007(0.0025) Grad: 4652.0649  LR: 0.00000614  \n","Epoch: [4][500/2917] Elapsed 2m 14s (remain 10m 48s) Loss: 0.0021(0.0024) Grad: 6289.2866  LR: 0.00000594  \n","Epoch: [4][600/2917] Elapsed 2m 41s (remain 10m 20s) Loss: 0.0026(0.0025) Grad: 6271.6543  LR: 0.00000575  \n","Epoch: [4][700/2917] Elapsed 3m 7s (remain 9m 53s) Loss: 0.0015(0.0025) Grad: 5030.8691  LR: 0.00000555  \n","Epoch: [4][800/2917] Elapsed 3m 34s (remain 9m 27s) Loss: 0.0007(0.0025) Grad: 4937.9287  LR: 0.00000536  \n","Epoch: [4][900/2917] Elapsed 4m 1s (remain 9m 0s) Loss: 0.0010(0.0025) Grad: 10209.2188  LR: 0.00000517  \n","Epoch: [4][1000/2917] Elapsed 4m 27s (remain 8m 32s) Loss: 0.0028(0.0025) Grad: 11694.7910  LR: 0.00000498  \n","Epoch: [4][1100/2917] Elapsed 4m 54s (remain 8m 6s) Loss: 0.0001(0.0025) Grad: 996.7591  LR: 0.00000480  \n","Epoch: [4][1200/2917] Elapsed 5m 21s (remain 7m 39s) Loss: 0.0011(0.0024) Grad: 3348.9802  LR: 0.00000461  \n","Epoch: [4][1300/2917] Elapsed 5m 48s (remain 7m 12s) Loss: 0.0054(0.0024) Grad: 14174.3711  LR: 0.00000443  \n","Epoch: [4][1400/2917] Elapsed 6m 15s (remain 6m 46s) Loss: 0.0027(0.0024) Grad: 10550.5332  LR: 0.00000425  \n","Epoch: [4][1500/2917] Elapsed 6m 42s (remain 6m 19s) Loss: 0.0009(0.0024) Grad: 10014.9775  LR: 0.00000408  \n","Epoch: [4][1600/2917] Elapsed 7m 9s (remain 5m 52s) Loss: 0.0003(0.0024) Grad: 1443.0028  LR: 0.00000391  \n","Epoch: [4][1700/2917] Elapsed 7m 35s (remain 5m 25s) Loss: 0.0012(0.0024) Grad: 2718.6038  LR: 0.00000374  \n","Epoch: [4][1800/2917] Elapsed 8m 1s (remain 4m 58s) Loss: 0.0002(0.0024) Grad: 2008.9653  LR: 0.00000357  \n","Epoch: [4][1900/2917] Elapsed 8m 27s (remain 4m 31s) Loss: 0.0020(0.0024) Grad: 8192.5596  LR: 0.00000341  \n","Epoch: [4][2000/2917] Elapsed 8m 54s (remain 4m 4s) Loss: 0.0005(0.0024) Grad: 10134.9297  LR: 0.00000324  \n","Epoch: [4][2100/2917] Elapsed 9m 21s (remain 3m 37s) Loss: 0.0024(0.0024) Grad: 26604.0117  LR: 0.00000309  \n","Epoch: [4][2200/2917] Elapsed 9m 47s (remain 3m 11s) Loss: 0.0036(0.0024) Grad: 24260.2344  LR: 0.00000293  \n","Epoch: [4][2300/2917] Elapsed 10m 14s (remain 2m 44s) Loss: 0.0024(0.0024) Grad: 18036.6250  LR: 0.00000278  \n","Epoch: [4][2400/2917] Elapsed 10m 40s (remain 2m 17s) Loss: 0.0023(0.0024) Grad: 15840.5156  LR: 0.00000263  \n","Epoch: [4][2500/2917] Elapsed 11m 7s (remain 1m 50s) Loss: 0.0010(0.0024) Grad: 8078.3706  LR: 0.00000249  \n","Epoch: [4][2600/2917] Elapsed 11m 34s (remain 1m 24s) Loss: 0.0014(0.0024) Grad: 6863.3286  LR: 0.00000235  \n","Epoch: [4][2700/2917] Elapsed 12m 1s (remain 0m 57s) Loss: 0.0023(0.0024) Grad: 45828.6992  LR: 0.00000221  \n","Epoch: [4][2800/2917] Elapsed 12m 28s (remain 0m 30s) Loss: 0.0009(0.0024) Grad: 25493.9316  LR: 0.00000208  \n","Epoch: [4][2900/2917] Elapsed 12m 54s (remain 0m 4s) Loss: 0.0031(0.0024) Grad: 19889.5684  LR: 0.00000195  \n","Epoch: [4][2916/2917] Elapsed 12m 59s (remain 0m 0s) Loss: 0.0028(0.0024) Grad: 17394.0938  LR: 0.00000193  \n","EVAL: [0/730] Elapsed 0m 0s (remain 5m 12s) Loss: 0.0007(0.0007) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 10s) Loss: 0.0087(0.0062) \n","EVAL: [200/730] Elapsed 0m 22s (remain 0m 57s) Loss: 0.0824(0.0067) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0132(0.0061) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0007(0.0061) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0207(0.0061) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 14s) Loss: 0.0001(0.0061) \n","EVAL: [700/730] Elapsed 1m 16s (remain 0m 3s) Loss: 0.0009(0.0061) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0024  avg_val_loss: 0.0061  time: 859s\n","Epoch 4 - Score: 0.8131\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 19s (remain 0m 0s) Loss: 0.0024(0.0061) \n","Epoch: [5][0/2917] Elapsed 0m 0s (remain 33m 25s) Loss: 0.0016(0.0016) Grad: 7461.2915  LR: 0.00000193  \n","Epoch: [5][100/2917] Elapsed 0m 27s (remain 12m 55s) Loss: 0.0014(0.0020) Grad: 4144.7212  LR: 0.00000180  \n","Epoch: [5][200/2917] Elapsed 0m 54s (remain 12m 18s) Loss: 0.0023(0.0022) Grad: 7017.9634  LR: 0.00000168  \n","Epoch: [5][300/2917] Elapsed 1m 21s (remain 11m 47s) Loss: 0.0021(0.0020) Grad: 9227.9629  LR: 0.00000156  \n","Epoch: [5][400/2917] Elapsed 1m 48s (remain 11m 17s) Loss: 0.0004(0.0020) Grad: 2531.0139  LR: 0.00000145  \n","Epoch: [5][500/2917] Elapsed 2m 14s (remain 10m 49s) Loss: 0.0007(0.0019) Grad: 6612.2695  LR: 0.00000134  \n","Epoch: [5][600/2917] Elapsed 2m 41s (remain 10m 21s) Loss: 0.0008(0.0019) Grad: 2702.9673  LR: 0.00000123  \n","Epoch: [5][700/2917] Elapsed 3m 7s (remain 9m 53s) Loss: 0.0016(0.0019) Grad: 5448.8032  LR: 0.00000113  \n","Epoch: [5][800/2917] Elapsed 3m 34s (remain 9m 25s) Loss: 0.0013(0.0019) Grad: 5443.8984  LR: 0.00000103  \n","Epoch: [5][900/2917] Elapsed 4m 0s (remain 8m 58s) Loss: 0.0052(0.0019) Grad: 44461.2148  LR: 0.00000094  \n","Epoch: [5][1000/2917] Elapsed 4m 27s (remain 8m 31s) Loss: 0.0001(0.0019) Grad: 934.8138  LR: 0.00000085  \n","Epoch: [5][1100/2917] Elapsed 4m 54s (remain 8m 4s) Loss: 0.0007(0.0019) Grad: 2691.0559  LR: 0.00000076  \n","Epoch: [5][1200/2917] Elapsed 5m 20s (remain 7m 38s) Loss: 0.0024(0.0019) Grad: 10723.6650  LR: 0.00000068  \n","Epoch: [5][1300/2917] Elapsed 5m 47s (remain 7m 11s) Loss: 0.0024(0.0019) Grad: 6512.6958  LR: 0.00000061  \n","Epoch: [5][1400/2917] Elapsed 6m 14s (remain 6m 45s) Loss: 0.0033(0.0019) Grad: 7943.7124  LR: 0.00000053  \n","Epoch: [5][1500/2917] Elapsed 6m 41s (remain 6m 18s) Loss: 0.0013(0.0019) Grad: 11923.1172  LR: 0.00000047  \n","Epoch: [5][1600/2917] Elapsed 7m 8s (remain 5m 52s) Loss: 0.0033(0.0020) Grad: 8255.4609  LR: 0.00000040  \n","Epoch: [5][1700/2917] Elapsed 7m 35s (remain 5m 25s) Loss: 0.0041(0.0020) Grad: 21159.6680  LR: 0.00000035  \n","Epoch: [5][1800/2917] Elapsed 8m 2s (remain 4m 58s) Loss: 0.0021(0.0019) Grad: 18542.0586  LR: 0.00000029  \n","Epoch: [5][1900/2917] Elapsed 8m 28s (remain 4m 32s) Loss: 0.0009(0.0019) Grad: 4319.9331  LR: 0.00000024  \n","Epoch: [5][2000/2917] Elapsed 8m 55s (remain 4m 5s) Loss: 0.0028(0.0020) Grad: 11138.4736  LR: 0.00000020  \n","Epoch: [5][2100/2917] Elapsed 9m 22s (remain 3m 38s) Loss: 0.0023(0.0019) Grad: 9450.4551  LR: 0.00000016  \n","Epoch: [5][2200/2917] Elapsed 9m 49s (remain 3m 11s) Loss: 0.0013(0.0019) Grad: 30963.3203  LR: 0.00000012  \n","Epoch: [5][2300/2917] Elapsed 10m 16s (remain 2m 45s) Loss: 0.0010(0.0019) Grad: 11768.4980  LR: 0.00000009  \n","Epoch: [5][2400/2917] Elapsed 10m 43s (remain 2m 18s) Loss: 0.0003(0.0019) Grad: 3632.5098  LR: 0.00000006  \n","Epoch: [5][2500/2917] Elapsed 11m 10s (remain 1m 51s) Loss: 0.0009(0.0019) Grad: 9801.4824  LR: 0.00000004  \n","Epoch: [5][2600/2917] Elapsed 11m 36s (remain 1m 24s) Loss: 0.0009(0.0019) Grad: 10983.2061  LR: 0.00000002  \n","Epoch: [5][2700/2917] Elapsed 12m 3s (remain 0m 57s) Loss: 0.0005(0.0019) Grad: 9711.4385  LR: 0.00000001  \n","Epoch: [5][2800/2917] Elapsed 12m 30s (remain 0m 31s) Loss: 0.0056(0.0019) Grad: 59940.6250  LR: 0.00000000  \n","Epoch: [5][2900/2917] Elapsed 12m 57s (remain 0m 4s) Loss: 0.0004(0.0019) Grad: 4082.6077  LR: 0.00000000  \n","Epoch: [5][2916/2917] Elapsed 13m 1s (remain 0m 0s) Loss: 0.0019(0.0019) Grad: 20556.6777  LR: 0.00000000  \n","EVAL: [0/730] Elapsed 0m 0s (remain 5m 16s) Loss: 0.0006(0.0006) \n","EVAL: [100/730] Elapsed 0m 11s (remain 1m 9s) Loss: 0.0092(0.0064) \n","EVAL: [200/730] Elapsed 0m 21s (remain 0m 57s) Loss: 0.0842(0.0072) \n","EVAL: [300/730] Elapsed 0m 32s (remain 0m 46s) Loss: 0.0122(0.0065) \n","EVAL: [400/730] Elapsed 0m 43s (remain 0m 35s) Loss: 0.0007(0.0065) \n","EVAL: [500/730] Elapsed 0m 54s (remain 0m 24s) Loss: 0.0204(0.0065) \n","EVAL: [600/730] Elapsed 1m 5s (remain 0m 13s) Loss: 0.0001(0.0065) \n","EVAL: [700/730] Elapsed 1m 15s (remain 0m 3s) Loss: 0.0007(0.0066) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0019  avg_val_loss: 0.0065  time: 860s\n","Epoch 5 - Score: 0.8142\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [729/730] Elapsed 1m 18s (remain 0m 0s) Loss: 0.0022(0.0065) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 4 result ==========\n","Score: 0.8201\n","========== CV ==========\n","Score: 0.8190\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64ea357fd2b34a66ad2a8e2e2e5174dd","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>█▄▂▁▁</td></tr><tr><td>[fold0] avg_val_loss</td><td>█▂▁▃▄</td></tr><tr><td>[fold0] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold0] loss</td><td>▆▃▄▄▃▃▂█▂▃▃▂▃▂▁▂▁▂▁▂▃▂▁▁▂▂▁▂▁▂▂▂▁▁▃▁▁▁▁▄</td></tr><tr><td>[fold0] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold0] score</td><td>▅█▅▁▁</td></tr><tr><td>[fold1] avg_train_loss</td><td>█▄▂▁▁</td></tr><tr><td>[fold1] avg_val_loss</td><td>█▂▃▁▂</td></tr><tr><td>[fold1] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold1] loss</td><td>█▄▃▃▂▂▂▂▁▂▂▂▃▂▃▃▁▃▁▂▃▂▁▁▁▁▁▁▁▂▁▁▁▁▂▂▁▁▁▁</td></tr><tr><td>[fold1] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] score</td><td>▄▂█▁▁</td></tr><tr><td>[fold2] avg_train_loss</td><td>█▄▂▁▁</td></tr><tr><td>[fold2] avg_val_loss</td><td>█▁▂▃▅</td></tr><tr><td>[fold2] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold2] loss</td><td>██▇▇▃▄▃▄▂▄▄▃▂▂▂▂▂▁▃▁▂▅▁▁▂▂▂▁▃▂▁▁▂▁▁▂▁▂▂▂</td></tr><tr><td>[fold2] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold2] score</td><td>▁▆█▆▆</td></tr><tr><td>[fold3] avg_train_loss</td><td>█▄▂▁▁</td></tr><tr><td>[fold3] avg_val_loss</td><td>▅▁▅▅█</td></tr><tr><td>[fold3] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold3] loss</td><td>█▄▂▃█▅▂▃▂▂▁▃▂▂▁▁▃▂▂▂▂▁▁▃▁▁▁▁▁▂▁▁▁▁▁▁▂▁▂▁</td></tr><tr><td>[fold3] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold3] score</td><td>█▁█▃▂</td></tr><tr><td>[fold4] avg_train_loss</td><td>█▄▂▁▁</td></tr><tr><td>[fold4] avg_val_loss</td><td>█▁▂▃▅</td></tr><tr><td>[fold4] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold4] loss</td><td>█▆▃█▅▂▃▁▃▅▁▃▃▁▂▂▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▅▁▂▁▂▂▁▇▂</td></tr><tr><td>[fold4] lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold4] score</td><td>▁██▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>0.00189</td></tr><tr><td>[fold0] avg_val_loss</td><td>0.00614</td></tr><tr><td>[fold0] epoch</td><td>5</td></tr><tr><td>[fold0] loss</td><td>0.00096</td></tr><tr><td>[fold0] lr</td><td>0.0</td></tr><tr><td>[fold0] score</td><td>0.82543</td></tr><tr><td>[fold1] avg_train_loss</td><td>0.002</td></tr><tr><td>[fold1] avg_val_loss</td><td>0.00664</td></tr><tr><td>[fold1] epoch</td><td>5</td></tr><tr><td>[fold1] loss</td><td>0.00269</td></tr><tr><td>[fold1] lr</td><td>0.0</td></tr><tr><td>[fold1] score</td><td>0.81654</td></tr><tr><td>[fold2] avg_train_loss</td><td>0.0021</td></tr><tr><td>[fold2] avg_val_loss</td><td>0.00692</td></tr><tr><td>[fold2] epoch</td><td>5</td></tr><tr><td>[fold2] loss</td><td>0.00047</td></tr><tr><td>[fold2] lr</td><td>0.0</td></tr><tr><td>[fold2] score</td><td>0.81763</td></tr><tr><td>[fold3] avg_train_loss</td><td>0.00183</td></tr><tr><td>[fold3] avg_val_loss</td><td>0.00687</td></tr><tr><td>[fold3] epoch</td><td>5</td></tr><tr><td>[fold3] loss</td><td>0.00192</td></tr><tr><td>[fold3] lr</td><td>0.0</td></tr><tr><td>[fold3] score</td><td>0.80907</td></tr><tr><td>[fold4] avg_train_loss</td><td>0.00194</td></tr><tr><td>[fold4] avg_val_loss</td><td>0.00654</td></tr><tr><td>[fold4] epoch</td><td>5</td></tr><tr><td>[fold4] loss</td><td>0.00195</td></tr><tr><td>[fold4] lr</td><td>0.0</td></tr><tr><td>[fold4] score</td><td>0.81421</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">microsoft/deberta-v3-large</strong>: <a href=\"https://wandb.ai/bluehills/PPPM-focal_loss/runs/3qani33c\" target=\"_blank\">https://wandb.ai/bluehills/PPPM-focal_loss/runs/3qani33c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20220505_113932-3qani33c/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tL7g_rhfN1sr"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"PPPM Transformer head.ipynb","provenance":[],"authorship_tag":"ABX9TyOSDC5XE4LuJOSZ000AkByB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"053622ad6b62496d9918efd68e086b70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87fc94aa16e0457d954d6448e8634d21","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0833bb9884c545a18ad187dbb1ecb76c","value":873673253}},"0595e45ee827428f97a58310a9e7c56b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07c27ab4282940fb90ef6291653f2cd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0833bb9884c545a18ad187dbb1ecb76c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1012de349be54576bde054bf8aa9d683":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1090c75efc8e49ca87eca44850f34430":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"184d82d6c5be4756868d7f981249d478":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5e243614e3942e8a87a26fd29d8a317","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0595e45ee827428f97a58310a9e7c56b","value":36473}},"1d50a6f4347a44d1a062997ef72959d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ef9cbc116cc41c6b029099d625d3854":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"215f401e97574f5abea2f401fde4b862":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f5ea483442a4b01ba352e9d70143cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30eb817352dc4faca2d3ca77336f0093":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3286928dd88c498db849a668306c0dc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"330ba59431f444e89d8d8a050567b02b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9af072f7c434858abb95de099757057","placeholder":"​","style":"IPY_MODEL_439511cc8853446a8e37141e168ac11e","value":"100%"}},"3c3bbc2770f14a5fba797208427c6d07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4159366ecd524e4fa47d613bcd7d5ae8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0646d9f26744d92be564153a5dfc0be","placeholder":"​","style":"IPY_MODEL_4fa26144866943c58accfc901b777444","value":" 136/136 [00:00&lt;00:00, 2799.19it/s]"}},"41ff7814d98b4890b8ae497fe46b1e74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b76859dd3da0471db7ac35fa116478f1","placeholder":"​","style":"IPY_MODEL_95f3684adc374590bcf8631f9990d73f","value":"Downloading: 100%"}},"42dbe699f48d408db53cdfb37eb70271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41ff7814d98b4890b8ae497fe46b1e74","IPY_MODEL_053622ad6b62496d9918efd68e086b70","IPY_MODEL_e4f39d2a23034b9d9ae048a525c64f4b"],"layout":"IPY_MODEL_ad4c3b4a38494c7db66148c71ac06460"}},"439511cc8853446a8e37141e168ac11e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4584dafed6c04a9c935217db69933959":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74d5ab946c947dd97ce87b7b3c9e741","placeholder":"​","style":"IPY_MODEL_215f401e97574f5abea2f401fde4b862","value":" 2.35M/2.35M [00:00&lt;00:00, 21.9MB/s]"}},"4e95de29bfef43c3a5296642297a9854":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa26144866943c58accfc901b777444":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59ef73f9d47b4403a159e0debbd898fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dbb57fda21647d6ae4142dc6390cc80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"696d1c127d524a3381a9bf309dde7bc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fda01ba8e8a435394d7a099dbaac94e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72793baee4834aaa99a83fde76e685e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72f8e2a6d041480fb1a4562998abbaed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f5ea483442a4b01ba352e9d70143cc3","placeholder":"​","style":"IPY_MODEL_d3ca43b3e96742bf82c03b29f7fe511d","value":"Downloading: 100%"}},"7318679ec4634d6794085796f242e163":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7454b824fc934e16a87c9906ccf1ea35","IPY_MODEL_184d82d6c5be4756868d7f981249d478","IPY_MODEL_c98dd7fd6f69415c9222ff376d4f1008"],"layout":"IPY_MODEL_85893440054f4adc802c17471d763918"}},"74176aaf4e6848d8ad74b486b31cbf2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef9cbc116cc41c6b029099d625d3854","placeholder":"​","style":"IPY_MODEL_1d50a6f4347a44d1a062997ef72959d2","value":"Downloading: 100%"}},"7454b824fc934e16a87c9906ccf1ea35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b359785ebec64649b24fcffe6166363a","placeholder":"​","style":"IPY_MODEL_30eb817352dc4faca2d3ca77336f0093","value":"100%"}},"74e741f14c9444c98fdd26abfb078dd8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a99a3dce71d4a8d8efcdd3a4ecc4ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bcf43b2805445b9952b0fa5258e374c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_330ba59431f444e89d8d8a050567b02b","IPY_MODEL_843011e5db384ecfa7ed55244b73ba32","IPY_MODEL_f452d436cc754f5d94745c02e155df20"],"layout":"IPY_MODEL_eb88f4588fd24245a5cc71496d804824"}},"8059312702864e949262da6af6a69908":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"822dd2c2b7bc48dcb5ab38226627c1ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fda01ba8e8a435394d7a099dbaac94e","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7b89f40ae1c4926804d5774d7275342","value":580}},"843011e5db384ecfa7ed55244b73ba32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dbb57fda21647d6ae4142dc6390cc80","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8059312702864e949262da6af6a69908","value":36473}},"856bcfe8302f4d7f9656d3b6eac8c746":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85893440054f4adc802c17471d763918":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"873dd0bfcfb84bcea41619bf4c271006":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87fc94aa16e0457d954d6448e8634d21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89067053b48a4e17bcd8fdbf564e82c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89b7cc5eb1d7455bae0b3da196810e3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dc718b94f18488e8fa0757f12c6ab58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8af80feee5f47e5a747b51dff63a613","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c103c92b8a6b42638169478960ed3d39","value":2464616}},"8f51b00af0c946b8971e8cf447b48d94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c706bb21d46a4752ba214257ac3eea26","IPY_MODEL_d3a3517a6e064e0caaec61c93c1a0806","IPY_MODEL_4159366ecd524e4fa47d613bcd7d5ae8"],"layout":"IPY_MODEL_873dd0bfcfb84bcea41619bf4c271006"}},"921dc24c9d7247e2a22b9e9c04eeeb61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fabbfd9f66844756bc1f313f05070d3f","IPY_MODEL_822dd2c2b7bc48dcb5ab38226627c1ac","IPY_MODEL_f748e106a41b48ebb098995b1ca080d3"],"layout":"IPY_MODEL_1012de349be54576bde054bf8aa9d683"}},"95f3684adc374590bcf8631f9990d73f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aac8e190da444ac3a218998ab1f0b32f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74176aaf4e6848d8ad74b486b31cbf2f","IPY_MODEL_8dc718b94f18488e8fa0757f12c6ab58","IPY_MODEL_4584dafed6c04a9c935217db69933959"],"layout":"IPY_MODEL_ef7588eccae94da8b696619a14449ea5"}},"ad4c3b4a38494c7db66148c71ac06460":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0646d9f26744d92be564153a5dfc0be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b359785ebec64649b24fcffe6166363a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b74d5ab946c947dd97ce87b7b3c9e741":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b76859dd3da0471db7ac35fa116478f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9af072f7c434858abb95de099757057":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c103c92b8a6b42638169478960ed3d39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2ba6397e84a46fea50852917cf717ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72f8e2a6d041480fb1a4562998abbaed","IPY_MODEL_e4838447dfae4356a9797e2586f7690e","IPY_MODEL_e844688ae13a46168a91d2241b6570da"],"layout":"IPY_MODEL_74e741f14c9444c98fdd26abfb078dd8"}},"c706bb21d46a4752ba214257ac3eea26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1090c75efc8e49ca87eca44850f34430","placeholder":"​","style":"IPY_MODEL_72793baee4834aaa99a83fde76e685e5","value":"100%"}},"c80f788aced44db7a0c1762f05c38a41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c98dd7fd6f69415c9222ff376d4f1008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c3bbc2770f14a5fba797208427c6d07","placeholder":"​","style":"IPY_MODEL_59ef73f9d47b4403a159e0debbd898fb","value":" 36473/36473 [00:02&lt;00:00, 12952.94it/s]"}},"cd2813defa9449969173c7ebfa74173c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a3517a6e064e0caaec61c93c1a0806":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89b7cc5eb1d7455bae0b3da196810e3f","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a99a3dce71d4a8d8efcdd3a4ecc4ef8","value":136}},"d3ca43b3e96742bf82c03b29f7fe511d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5e243614e3942e8a87a26fd29d8a317":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8bca4927a174b37a716d7ac21c4f2e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dac297841d154eeabe55b48eff97f922":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e24f1cc8f7b34cd7bed2538447e70006":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4838447dfae4356a9797e2586f7690e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd2813defa9449969173c7ebfa74173c","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89067053b48a4e17bcd8fdbf564e82c6","value":52}},"e4f39d2a23034b9d9ae048a525c64f4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24f1cc8f7b34cd7bed2538447e70006","placeholder":"​","style":"IPY_MODEL_07c27ab4282940fb90ef6291653f2cd6","value":" 833M/833M [00:13&lt;00:00, 67.6MB/s]"}},"e7b89f40ae1c4926804d5774d7275342":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e844688ae13a46168a91d2241b6570da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dac297841d154eeabe55b48eff97f922","placeholder":"​","style":"IPY_MODEL_696d1c127d524a3381a9bf309dde7bc3","value":" 52.0/52.0 [00:00&lt;00:00, 2.09kB/s]"}},"e8af80feee5f47e5a747b51dff63a613":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9709e11d8fa4acb9570aa7dbd19c106":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb88f4588fd24245a5cc71496d804824":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef7588eccae94da8b696619a14449ea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f452d436cc754f5d94745c02e155df20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8bca4927a174b37a716d7ac21c4f2e2","placeholder":"​","style":"IPY_MODEL_c80f788aced44db7a0c1762f05c38a41","value":" 36473/36473 [00:02&lt;00:00, 12401.15it/s]"}},"f748e106a41b48ebb098995b1ca080d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e95de29bfef43c3a5296642297a9854","placeholder":"​","style":"IPY_MODEL_3286928dd88c498db849a668306c0dc5","value":" 580/580 [00:00&lt;00:00, 23.7kB/s]"}},"fabbfd9f66844756bc1f313f05070d3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9709e11d8fa4acb9570aa7dbd19c106","placeholder":"​","style":"IPY_MODEL_856bcfe8302f4d7f9656d3b6eac8c746","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}