{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1juyGzghsMxC"},"outputs":[],"source":["# !pip install kaggle\n","# from google.colab import files\n","# files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16264,"status":"ok","timestamp":1651495059804,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"2qqloURAtVXk","outputId":"2fba0441-629e-445c-eebe-fd643fd3620c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQ42V6jOttQy"},"outputs":[],"source":["# !ls -1ha kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11450,"status":"ok","timestamp":1651495071252,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"5fQBEA6xxpMw","outputId":"2af1b2a2-c6ce-4626-bb18-13420fa24b23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 14.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 80.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 63.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.50.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 83.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.8)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2021.10.8)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Collecting click==8.0\n","  Downloading click-8.0.0-py3-none-any.whl (96 kB)\n","\u001b[K     |████████████████████████████████| 96 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.50-py3-none-any.whl size=895166 sha256=452c47474038ac563af537652af7c6f3c59f696f75812463729e3039ea022206\n","  Stored in directory: /root/.cache/pip/wheels/d9/72/54/519f0d5143cc6c73fa3297509123c86fc8586a7fdea8d25311\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, click, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: click\n","    Found existing installation: click 7.1.2\n","    Uninstalling click-7.1.2:\n","      Successfully uninstalled click-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","flask 1.1.4 requires click\u003c8.0,\u003e=5.1, but you have click 8.0.0 which is incompatible.\u001b[0m\n","Successfully installed click-8.0.0 huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.50 tokenizers-0.12.1 transformers-4.18.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 14.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6378,"status":"ok","timestamp":1651495077622,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"ayN821m8MeWX","outputId":"c9fa3e7f-6015-4d53-d3a0-0071e880fb72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wandb\n","  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 14.1 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting GitPython\u003e=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting docker-pycreds\u003e=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: protobuf\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting sentry-sdk\u003e=1.0.0\n","  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 85.2 MB/s \n","\u001b[?25hRequirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: python-dateutil\u003e=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting shortuuid\u003e=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting Click!=8.0.0,\u003e=7.0\n","  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n","\u001b[K     |████████████████████████████████| 96 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Click!=8.0.0,\u003e=7.0-\u003ewandb) (4.11.3)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.2.0)\n","Collecting smmap\u003c6,\u003e=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2021.10.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003eClick!=8.0.0,\u003e=7.0-\u003ewandb) (3.8.0)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=f00a3b839e84d46737c7f46474e6e5245a83be8d7644261b9da2f0fe9b427374\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, Click, wandb\n","  Attempting uninstall: Click\n","    Found existing installation: click 8.0.0\n","    Uninstalling click-8.0.0:\n","      Successfully uninstalled click-8.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sacremoses 0.0.50 requires click==8.0, but you have click 8.1.3 which is incompatible.\n","flask 1.1.4 requires click\u003c8.0,\u003e=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n","Successfully installed Click-8.1.3 GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.15\n"]}],"source":["!pip3 install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhO7fjARwhAB"},"outputs":[],"source":["# !pip3 install tokenizers wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXxUaSKftuvv"},"outputs":[],"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# # Permission Warning 이 일어나지 않도록 \n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 본인이 참가한 모든 대회 보기 \n","# !kaggle competitions list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7QsENfyuT0y"},"outputs":[],"source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUeBd2eGt1bW"},"outputs":[],"source":["# !kaggle competitions download -c nbme-score-clinical-patient-notes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvSSwcRstln8"},"outputs":[],"source":["# !unzip nbme-score-clinical-patient-notes.zip\n","\n","# !ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1552,"status":"ok","timestamp":1651495079169,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"EFqXCIzwoyzU","outputId":"00beeb24-61cc-4f54-dcbd-3057aa72b5ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["debert_v3_tokenizer_path = 'deberta-v2-v3-fast-tokenizer'\n","%env TOKENIZERS_PARALLELISM=true\n","\n","import shutil\n","from pathlib import Path\n","\n","transformers_path = Path('/usr/local/lib/python3.7/dist-packages/transformers')\n","input_dir = Path('./deberta-v2-v3-fast-tokenizer')\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path / convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    \n","    if filepath.exists():\n","        filepath.unlink()\n","    shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fl4G_mNCu1ed"},"outputs":[],"source":["OUTPUT_DIR = './nbme-pl-deberta-v3-outputs/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651495079169,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"Tf8VjiPVwSzF","outputId":"88577488-ca89-43f7-ce8e-687832caa15f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon May  2 12:37:58 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') \u003e= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"xOMdcujXv9Z_"},"source":["## CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9LW9quRvtoL"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    wandb=True\n","    competition='NBME'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"  # [\"microsoft/deberta-base\", \"microsoft/deberta-large\", \"microsoft/deberta-v3-large\"]\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=5\n","    encoder_lr= 1e-5 #2e-5\n","    decoder_lr= 1e-5 #2e-5\n","    min_lr=1e-6\n","    eps=2e-6 #1e-6\n","    betas=(0.9, 0.999)\n","    batch_size= 6  # 24 in inference\n","    fc_dropout= 0.2\n","    max_len=512\n","    weight_decay= 0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4] #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":11492,"status":"ok","timestamp":1651495090658,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"XA6QLrMQv-mc","outputId":"33468d46-b8f5-493c-fe92-4937d88b22e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["login to wandb\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) =\u003e {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() =\u003e {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() =\u003e reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data =\u003e {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluehills\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.15"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/drive/MyDrive/Kaggle/wandb/run-20220502_123804-3oznab0v\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/bluehills/NBME-Public2/runs/3oznab0v\" target=\"_blank\"\u003emicrosoft/deberta-v3-large\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/bluehills/NBME-Public2\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    import wandb\n","    try:\n","        # from kaggle_secrets import UserSecretsClient\n","        # user_secrets = UserSecretsClient()\n","        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        # wandb.login(key=secret_value_0)\n","        print('login to wandb')\n","        wandb.login()\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W\u0026B account, go to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as wandb_api. \\nGet your W\u0026B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='NBME-Public2', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"qR8EYRj4wX8U"},"source":["## Library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5942,"status":"ok","timestamp":1651495096586,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"a5048-HowFGB","outputId":"e5744795-a099-427f-ecfc-838d3bb1805c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.18.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","# os.system('pip uninstall -y transformers')\n","# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"8ac2ZriLrZ_W"},"source":["## Clean PL dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH9iexwTr6t3"},"outputs":[],"source":["# for i in range(5):\n","#     df = pd.read_csv(f'./merged_df_{i}.csv')\n","#     new_df = df.dropna()\n","#     new_df.to_csv(f'pl_{i}.csv', index=False)\n","\n","#     del df\n","#     del new_df"]},{"cell_type":"markdown","metadata":{"id":"Sw2QNpKyzBWS"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZS5qilDjwZHT"},"outputs":[],"source":["# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n","\n","def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","\n","def create_labels_for_scoring(df):\n","    # example: ['0 1', '3 4'] -\u003e ['0 1; 3 4']\n","    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n","    for i in range(len(df)):\n","        # lst = df.loc[i, 'location']\n","        lst = df['location'].iloc[i]\n","        if lst:\n","            new_lst = ';'.join(lst)\n","            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n","    # create labels\n","    truths = []\n","    for location_list in df['location_for_create_labels'].values:\n","        truth = []\n","        if len(location_list) \u003e 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(';')]:\n","                if len(loc) == 0:\n","                    continue\n","                elif len(loc) == 1:\n","                    continue\n","                first, second = loc[0], loc[1]\n","                first, second = first.replace('[', '').strip(), second.replace(']', '').strip()\n","                start, end = int(first), int(second)\n","                truth.append([start, end])\n","        truths.append(truth)\n","    return truths\n","\n","\n","def get_char_probs(texts, predictions, tokenizer):\n","    results = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n","        encoded = tokenizer(text, \n","                            add_special_tokens=True,\n","                            return_offsets_mapping=True)\n","        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n","            start = offset_mapping[0]\n","            end = offset_mapping[1]\n","            results[i][start:end] = pred\n","    return results\n","\n","\n","def get_results(char_probs, th=0.5):\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob \u003e= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    return results\n","\n","\n","def get_predictions(results):\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    return predictions"]},{"cell_type":"markdown","metadata":{"id":"8hAL46O9zDaV"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWEcVEvNy6iD"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"RoQICqwdmuat"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":637},"executionInfo":{"elapsed":2639,"status":"ok","timestamp":1651495099221,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"3J4wnJXszIx4","outputId":"49aa351c-e5ab-48c4-f891-a23808c6e552"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (14300, 6)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-820d041e-1e9d-45d6-b299-bdcc9eec963a\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003ecase_num\u003c/th\u003e\n","      \u003cth\u003epn_num\u003c/th\u003e\n","      \u003cth\u003efeature_num\u003c/th\u003e\n","      \u003cth\u003eannotation\u003c/th\u003e\n","      \u003cth\u003elocation\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e00016_000\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e[dad with recent heart attcak]\u003c/td\u003e\n","      \u003ctd\u003e[696 724]\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e00016_001\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[mom with \"thyroid disease]\u003c/td\u003e\n","      \u003ctd\u003e[668 693]\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e00016_002\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e[chest pressure]\u003c/td\u003e\n","      \u003ctd\u003e[203 217]\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e00016_003\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e[intermittent episodes, episode]\u003c/td\u003e\n","      \u003ctd\u003e[70 91, 176 183]\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e00016_004\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e[felt as if he were going to pass out]\u003c/td\u003e\n","      \u003ctd\u003e[222 258]\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-820d041e-1e9d-45d6-b299-bdcc9eec963a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-820d041e-1e9d-45d6-b299-bdcc9eec963a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-820d041e-1e9d-45d6-b299-bdcc9eec963a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["          id  case_num  pn_num  feature_num                              annotation          location\n","0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]\n","1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]\n","2  00016_002         0      16            2                        [chest pressure]         [203 217]\n","3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]\n","4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["features.shape: (143, 3)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-0e6f9140-fcff-4dbf-b138-c2ff2f54d971\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003efeature_num\u003c/th\u003e\n","      \u003cth\u003ecase_num\u003c/th\u003e\n","      \u003cth\u003efeature_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eFamily-history-of-MI-OR-Family-history-of-myoc...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eFamily-history-of-thyroid-disorder\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eChest-pressure\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eIntermittent-symptoms\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eLightheaded\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e6f9140-fcff-4dbf-b138-c2ff2f54d971')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-0e6f9140-fcff-4dbf-b138-c2ff2f54d971 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0e6f9140-fcff-4dbf-b138-c2ff2f54d971');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   feature_num  case_num                                       feature_text\n","0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n","1            1         0                 Family-history-of-thyroid-disorder\n","2            2         0                                     Chest-pressure\n","3            3         0                              Intermittent-symptoms\n","4            4         0                                        Lightheaded"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["patient_notes.shape: (42146, 3)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-b0e4e2be-b4be-43d0-9ee6-c384d4f1ecb2\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003epn_num\u003c/th\u003e\n","      \u003cth\u003ecase_num\u003c/th\u003e\n","      \u003cth\u003epn_history\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e17-year-old male, has come to the student heal...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e17 yo male with recurrent palpitations for the...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eDillon Cleveland is a 17 y.o. male patient wit...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ea 17 yo m c/o palpitation started 3 mos ago; \\...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e17yo male with no pmh here for evaluation of p...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0e4e2be-b4be-43d0-9ee6-c384d4f1ecb2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-b0e4e2be-b4be-43d0-9ee6-c384d4f1ecb2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b0e4e2be-b4be-43d0-9ee6-c384d4f1ecb2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   pn_num  case_num                                         pn_history\n","0       0         0  17-year-old male, has come to the student heal...\n","1       1         0  17 yo male with recurrent palpitations for the...\n","2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n","3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n","4       4         0  17yo male with no pmh here for evaluation of p..."]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('./train.csv')\n","train['annotation'] = train['annotation'].apply(ast.literal_eval)\n","train['location'] = train['location'].apply(ast.literal_eval)\n","features = pd.read_csv('./features.csv')\n","def preprocess_features(features):\n","    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n","    return features\n","features = preprocess_features(features)\n","patient_notes = pd.read_csv('./patient_notes.csv')\n","\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())\n","print(f\"features.shape: {features.shape}\")\n","display(features.head())\n","print(f\"patient_notes.shape: {patient_notes.shape}\")\n","display(patient_notes.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651495099221,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"owVK4NapzKtB","outputId":"f0813f12-1786-46b1-ea5f-49b12ebc7d69"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-8fc59188-2051-482a-9228-4c61a5d55232\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003ecase_num\u003c/th\u003e\n","      \u003cth\u003epn_num\u003c/th\u003e\n","      \u003cth\u003efeature_num\u003c/th\u003e\n","      \u003cth\u003eannotation\u003c/th\u003e\n","      \u003cth\u003elocation\u003c/th\u003e\n","      \u003cth\u003efeature_text\u003c/th\u003e\n","      \u003cth\u003epn_history\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e00016_000\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e[dad with recent heart attcak]\u003c/td\u003e\n","      \u003ctd\u003e[696 724]\u003c/td\u003e\n","      \u003ctd\u003eFamily-history-of-MI-OR-Family-history-of-myoc...\u003c/td\u003e\n","      \u003ctd\u003eHPI: 17yo M presents with palpitations. Patien...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e00016_001\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e[mom with \"thyroid disease]\u003c/td\u003e\n","      \u003ctd\u003e[668 693]\u003c/td\u003e\n","      \u003ctd\u003eFamily-history-of-thyroid-disorder\u003c/td\u003e\n","      \u003ctd\u003eHPI: 17yo M presents with palpitations. Patien...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e00016_002\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e[chest pressure]\u003c/td\u003e\n","      \u003ctd\u003e[203 217]\u003c/td\u003e\n","      \u003ctd\u003eChest-pressure\u003c/td\u003e\n","      \u003ctd\u003eHPI: 17yo M presents with palpitations. Patien...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e00016_003\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e[intermittent episodes, episode]\u003c/td\u003e\n","      \u003ctd\u003e[70 91, 176 183]\u003c/td\u003e\n","      \u003ctd\u003eIntermittent-symptoms\u003c/td\u003e\n","      \u003ctd\u003eHPI: 17yo M presents with palpitations. Patien...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e00016_004\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e16\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e[felt as if he were going to pass out]\u003c/td\u003e\n","      \u003ctd\u003e[222 258]\u003c/td\u003e\n","      \u003ctd\u003eLightheaded\u003c/td\u003e\n","      \u003ctd\u003eHPI: 17yo M presents with palpitations. Patien...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fc59188-2051-482a-9228-4c61a5d55232')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-8fc59188-2051-482a-9228-4c61a5d55232 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8fc59188-2051-482a-9228-4c61a5d55232');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["          id  case_num  pn_num  feature_num                              annotation          location                                       feature_text                                         pn_history\n","0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]  Family-history-of-MI-OR-Family-history-of-myoc...  HPI: 17yo M presents with palpitations. Patien...\n","1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]                 Family-history-of-thyroid-disorder  HPI: 17yo M presents with palpitations. Patien...\n","2  00016_002         0      16            2                        [chest pressure]         [203 217]                                     Chest-pressure  HPI: 17yo M presents with palpitations. Patien...\n","3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]                              Intermittent-symptoms  HPI: 17yo M presents with palpitations. Patien...\n","4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]                                        Lightheaded  HPI: 17yo M presents with palpitations. Patien..."]},"metadata":{},"output_type":"display_data"}],"source":["train = train.merge(features, on=['feature_num', 'case_num'], how='left')\n","train = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n","display(train.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rk9JwCZgzcFB"},"outputs":[],"source":["# incorrect annotation\n","train.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\n","train.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n","\n","train.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\n","train.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n","\n","train.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\n","train.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n","\n","train.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\n","train.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n","\n","train.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\n","train.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n","\n","train.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\n","train.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n","\n","train.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\n","train.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n","\n","train.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\n","train.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n","\n","train.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\n","train.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n","\n","train.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\n","train.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n","\n","train.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\n","train.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n","\n","train.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\n","train.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n","\n","train.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\n","train.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n","\n","train.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\n","train.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n","\n","train.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\n","train.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n","\n","train.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\n","train.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n","\n","train.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\n","train.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n","\n","train.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\n","train.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n","\n","train.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\n","train.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n","\n","train.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\n","train.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n","\n","train.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\n","train.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n","\n","train.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\n","train.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n","\n","train.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\n","train.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n","\n","train.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\n","train.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n","\n","train.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\n","train.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n","\n","train.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\n","train.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n","\n","train.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\n","train.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n","\n","train.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\n","train.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n","\n","train.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\n","train.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n","\n","train.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\n","train.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n","\n","train.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\n","train.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n","\n","train.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\n","train.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n","\n","train.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\n","train.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n","\n","train.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\n","train.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n","\n","train.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\n","train.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n","\n","train.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\n","train.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n","\n","train.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\n","train.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n","\n","train.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\n","train.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n","\n","train.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\n","train.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n","\n","train.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\n","train.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n","\n","train.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\n","train.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n","\n","train.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\n","train.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"elapsed":585,"status":"ok","timestamp":1651495099803,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"6OKNeveOzfeG","outputId":"0af1ae95-464f-4cb0-ce38-2a71a2052825"},"outputs":[{"data":{"text/plain":["1    8185\n","0    4399\n","2    1292\n","3     287\n","4      99\n","5      27\n","6       9\n","7       1\n","8       1\n","Name: annotation_length, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["train['annotation_length'] = train['annotation'].apply(len)\n","display(train['annotation_length'].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"QM2WfrOuzkGG"},"source":["## CV split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651495099803,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qLsEGvn6ziAl","outputId":"7df6aa14-42cd-47c5-b832-5b4ee5b7933f"},"outputs":[{"data":{"text/plain":["fold\n","0    2860\n","1    2860\n","2    2860\n","3    2860\n","4    2860\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = GroupKFold(n_splits=CFG.n_fold)\n","groups = train['pn_num'].values\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7Uwy_TIzm46"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())\n"]},{"cell_type":"markdown","metadata":{"id":"l3QrVKDBzrNj"},"source":["## Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Is3kfHJVnneZ"},"outputs":[],"source":["from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","from transformers.models.deberta_v2.tokenization_deberta_v2 import DebertaV2Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSWhHwRuzpM1"},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","if CFG.model == 'microsoft/deberta-v3-large' or CFG.model == 'microsoft/deberta-v3-xlarge' or CFG.model == 'microsoft/deberta-v2-xlarge':\n","    tokenizer = DebertaV2TokenizerFast.from_pretrained('./pretrained_deberta_v2_v3_tokenizer/')\n","    # tokenizer = DebertaV2Tokenizer.from_pretrained('./pretrained_deberta_v2_v3_tokenizer/')\n","    CFG.tokenizer = tokenizer\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","    tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","    CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"TdPB7Q2dzwlB"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133},"executionInfo":{"elapsed":22544,"status":"ok","timestamp":1651495124402,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"VyjM4MdWzuTa","outputId":"ebfc1856-c6f0-4990-a1c8-81ecfe2a54e7"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b05b1163e2d4fd7b3b71d7417efc431","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42146 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["pn_history max(lengths): 323\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e34e50c8bc047c19c192ba3eff3e163","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["feature_text max(lengths): 28\n","max_len: 354\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","\n","def define_max_len_(text_col, df):\n","    max_lenghts = []\n","    tk0 = tqdm(df[text_col].fillna(\"\").values, total=len(df))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        max_lenghts.append(length)\n","    LOGGER.info(f'{text_col} max(lengths): {max(max_lenghts)}')\n","    \n","    return max_lenghts\n","\n","\n","\n","pn_history_lengths = define_max_len_('pn_history', patient_notes)\n","features_lengths = define_max_len_('feature_text', features)\n","CFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls \u0026 sep \u0026 sep\n","# CFG.max_len = 512\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1ol14Phzxd6"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text, feature_text):\n","    inputs = cfg.tokenizer(text, feature_text, \n","                           add_special_tokens=True,\n","                           max_length=CFG.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","def create_label(cfg, text, annotation_length, location_list):\n","    encoded = cfg.tokenizer(text,\n","                            add_special_tokens=True,\n","                            max_length=CFG.max_len,\n","                            padding=\"max_length\",\n","                            return_offsets_mapping=True)\n","\n","    offset_mapping = encoded['offset_mapping']\n","    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n","    label = np.zeros(len(offset_mapping))\n","    label[ignore_idxes] = -1\n","    if annotation_length != 0:\n","        for location in location_list:\n","            for loc in [s.split() for s in location.split(';')]:\n","                start_idx = -1\n","                end_idx = -1\n","                start, end = int(loc[0]), int(loc[1])\n","                for idx in range(len(offset_mapping)):\n","                    if (start_idx == -1) \u0026 (start \u003c offset_mapping[idx][0]):\n","                        start_idx = idx - 1\n","                    if (end_idx == -1) \u0026 (end \u003c= offset_mapping[idx][1]):\n","                        end_idx = idx + 1\n","                if start_idx == -1:\n","                    start_idx = end_idx\n","                if (start_idx != -1) \u0026 (end_idx != -1):\n","                    label[start_idx:end_idx] = 1\n","    return torch.tensor(label, dtype=torch.float)\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.feature_texts = df['feature_text'].values\n","        self.pn_historys = df['pn_history'].values\n","        self.annotation_lengths = df['annotation_length'].values\n","        self.locations = df['location'].values\n","\n","    def __len__(self):\n","        return len(self.feature_texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, \n","                               self.pn_historys[item], \n","                               self.feature_texts[item])\n","        label = create_label(self.cfg, \n","                             self.pn_historys[item], \n","                             self.annotation_lengths[item], \n","                             self.locations[item])\n","        return inputs, label"]},{"cell_type":"markdown","metadata":{"id":"4GtpqO_rz6FD"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmbliWj6z1-v"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        print(self.config)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, 1)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        return last_hidden_states\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"OQ0GNu8R0BHC"},"source":["## Helper function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Au791lcz-Tp"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def pl_train_fn(fold, test_loader, model, teacher, criterion, optimizer, epoch, scheduler, device):\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            model.to('cpu')\n","            teacher.to(device)\n","            labels = teacher(inputs)\n","            teacher.to('cpu')\n","            model.to(device)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        #TODO print(inputs.items())\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0BClInlwH7WT"},"outputs":[],"source":["def parse_inner_value(vals):\n","    return vals.strip().split(' ')\n","\n","def parse_values(vals):\n","    new_vals = []\n","    for v in vals:\n","        if ';' in v:\n","            splitted = v.split(';')\n","            inner_vals = []\n","            for s in splitted:\n","                inner_vals.append(list(map(int, parse_inner_value(s))))\n","            new_vals.append(inner_vals)\n","        elif v.strip() == '':\n","            new_vals.append([])\n","        else:\n","            new_vals.append(list(map(int, parse_inner_value(v))))\n","    return new_vals\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtcrBqniGn4G"},"outputs":[],"source":["# vals1 = create_labels_for_scoring(train)\n","# df = pd.read_csv(f'pl_{0}.csv')\n","# pl_df = df.sample(frac = 0.2, replace=True, random_state=1).reset_index()\n","# vals2 = pl_df['location'].values\n","\n","# print('vals1')\n","# print(vals1)\n","# print('vals2')\n","# print(parse_values(pl_df['location'].values))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbRozESi0C3r"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(my_folds, fold, n_fold):\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # folds['location'] = create_labels_for_scoring(folds)\n","\n","    pl_index = fold // 2\n","    df = pd.read_csv(f'nbme_pl_{pl_index}.csv')\n","\n","    # make temp dataframes\n","    temp_df1 = df[df['annotation_length'] \u003e 3].reset_index()\n","    temp_df2 = df[df['annotation_length'] == 1].sample(frac = 0.05, replace=True, random_state=1).reset_index()\n","    temp_df3 = df[df['annotation_length'] == 2].sample(frac = 0.1, replace=True, random_state=1).reset_index()\n","    temp_df4 = df[df['annotation_length'] == 3].sample(frac = 0.2, replace=True, random_state=1).reset_index()\n","    temp_df5 = df[df['annotation_length'] \u003c 1].sample(frac=0.1, replace=True, random_state=1).reset_index()\n","\n","    #TODO sample only 20% -\u003e 10%, 15%도 도전해보기\n","    #pl_df = df.sample(frac = 0.2, replace=True, random_state=1).reset_index()\n","    # merge dataframes\n","    frames1 = [temp_df1, temp_df2, temp_df3, temp_df4, temp_df5]\n","    pl_df = pd.concat(frames1).reset_index()\n","\n","    del temp_df1\n","    del temp_df2\n","    del temp_df3\n","    del temp_df4\n","    del temp_df5\n","\n","    pl_df['annotation'] = pl_df['annotation'].apply(ast.literal_eval)\n","    pl_df['location'] = pl_df['location'].apply(ast.literal_eval)\n","\n","    del df\n","    gc.collect()\n","\n","    kFold = GroupKFold(n_splits=n_fold)\n","    groups = pl_df['pn_num'].values\n","\n","    pl_df['fold'] = pl_df['case_num']\n","    pl_df_fold = pl_df['fold']\n","\n","    for n, (train_index, val_index) in enumerate(kFold.split(pl_df, pl_df['location'], groups)):\n","        # pandas select rows by index\n","        # \u003chttps://www.statology.org/pandas-select-rows-by-index/\u003e\n","        pl_df_fold.iloc[val_index] = int(n)\n","\n","    pl_df['fold'] = pl_df_fold\n","    pl_df['fold'] = pl_df['fold'].astype(int)\n","\n","    # concat dataframes vertically\n","    frames = [my_folds, pl_df]\n","    folds = pd.concat(frames)\n","    # folds = my_folds\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_texts = valid_folds['pn_history'].values\n","\n","    # pl_train_folds = pl_df[pl_df['fold'] != fold].reset_index(drop=True)\n","    # validation_tr_df = my_folds[my_folds['fold'] == fold].reset_index(drop=True)\n","    # vals1 = create_labels_for_scoring(validation_tr_df)\n","    # validation_pl_df = pl_df[pl_df['fold'] == fold].reset_index(drop=True)\n","    # vals2 = parse_values(validation_pl_df['location'].values)\n","    # valid_labels = vals1.extend(vals2)\n","\n","    valid_labels = create_labels_for_scoring(valid_folds)\n","\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    \n","\n","    train_folds2 = my_folds[my_folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds2 = my_folds[my_folds['fold'] == fold].reset_index(drop=True)\n","    valid_texts2 = valid_folds2['pn_history'].values\n","    valid_labels2 = create_labels_for_scoring(valid_folds2)\n","\n","    train_dataset2 = TrainDataset(CFG, train_folds2)\n","    valid_dataset2 = TrainDataset(CFG, valid_folds2)\n","    train_loader2 = DataLoader(train_dataset2,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader2 = DataLoader(valid_dataset2,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # test_loader\n","    # test_loader = DataLoader(pl_train_folds,\n","    #                      batch_size=CFG.batch_size,\n","    #                      shuffle=False,\n","    #                      num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model \u0026 optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","\n","    # teacher_model = CustomModel(CFG, config_path='./nbme-deberta-v3-outputs-ep5/config.pth', pretrained=False)\n","    # state = torch.load('./nbme-deberta-v3-outputs-ep5/' +f\"{CFG.model.replace('/', '-')}_fold{pl_index}_best.pth\", map_location=torch.device('cpu'))\n","    # teacher_model.load_state_dict(state['model'])\n","    # teacher_model.eval()\n","    # teacher_model.to('cpu')\n","    #teacher_model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler=='linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler=='cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    \n","    best_score = 0.\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","\n","        if epoch \u003c 4:\n","            # train\n","            avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","            # meta pseudo labeling\n","            # pl_avg_loss = pl_train_fn(fold, test_loader, model, teacher_model, criterion, optimizer, epoch, scheduler, device)\n","            # avg_loss = (avg_loss + pl_avg_loss) / 2\n","\n","            # eval\n","            avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","            predictions = predictions.reshape((len(valid_folds), CFG.max_len))\n","            \n","            # scoring\n","            char_probs = get_char_probs(valid_texts, predictions, CFG.tokenizer)\n","            results = get_results(char_probs, th=0.5)\n","            preds = get_predictions(results)\n","            score = get_score(valid_labels, preds)\n","        else:\n","            # train\n","            avg_loss = train_fn(fold, train_loader2, model, criterion, optimizer, epoch, scheduler, device)\n","\n","            # meta pseudo labeling\n","            # pl_avg_loss = pl_train_fn(fold, test_loader, model, teacher_model, criterion, optimizer, epoch, scheduler, device)\n","            # avg_loss = (avg_loss + pl_avg_loss) / 2\n","\n","            # eval\n","            avg_val_loss, predictions = valid_fn(valid_loader2, model, criterion, device)\n","            predictions = predictions.reshape((len(valid_folds2), CFG.max_len))\n","            \n","            # scoring\n","            char_probs = get_char_probs(valid_texts2, predictions, CFG.tokenizer)\n","            results = get_results(char_probs, th=0.5)\n","            preds = get_predictions(results)\n","            score = get_score(valid_labels2, preds)\n","        \n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score \u003c score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1F1pwTIV0Fd6"},"outputs":[],"source":["def get_result(oof_df):\n","    labels = create_labels_for_scoring(oof_df)\n","    predictions = oof_df[[i for i in range(CFG.max_len)]].values\n","    char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n","    results = get_results(char_probs, th=0.5)\n","    preds = get_predictions(results)\n","    score = get_score(labels, preds)\n","    LOGGER.info(f'Score: {score:\u003c.4f}')"]},{"cell_type":"markdown","metadata":{"id":"838KSKWa0Ktz"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"no8nLUEy0J-k"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2cab3cee8da46d6bab1c08c765b07aa","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18cac28641d44cfaad5b5548c4ba6a7e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/9397] Elapsed 0m 0s (remain 148m 59s) Loss: 0.6260(0.6260) Grad: inf  LR: 0.00001000  \n","Epoch: [1][100/9397] Elapsed 0m 35s (remain 54m 4s) Loss: 0.0193(0.1130) Grad: 1437.3835  LR: 0.00001000  \n","Epoch: [1][200/9397] Elapsed 1m 9s (remain 53m 12s) Loss: 0.0373(0.0754) Grad: 8669.0693  LR: 0.00001000  \n","Epoch: [1][300/9397] Elapsed 1m 44s (remain 52m 32s) Loss: 0.0073(0.0600) Grad: 1783.1423  LR: 0.00001000  \n","Epoch: [1][400/9397] Elapsed 2m 18s (remain 51m 53s) Loss: 0.0085(0.0509) Grad: 1289.9156  LR: 0.00001000  \n","Epoch: [1][500/9397] Elapsed 2m 53s (remain 51m 18s) Loss: 0.0810(0.0450) Grad: 7995.2329  LR: 0.00001000  \n","Epoch: [1][600/9397] Elapsed 3m 28s (remain 50m 45s) Loss: 0.0118(0.0411) Grad: 1627.4908  LR: 0.00001000  \n","Epoch: [1][700/9397] Elapsed 4m 2s (remain 50m 9s) Loss: 0.0116(0.0382) Grad: 1784.3026  LR: 0.00000999  \n","Epoch: [1][800/9397] Elapsed 4m 37s (remain 49m 39s) Loss: 0.0072(0.0358) Grad: 1924.9160  LR: 0.00000999  \n","Epoch: [1][900/9397] Elapsed 5m 12s (remain 49m 4s) Loss: 0.0274(0.0337) Grad: 2231.5049  LR: 0.00000999  \n","Epoch: [1][1000/9397] Elapsed 5m 46s (remain 48m 29s) Loss: 0.0115(0.0317) Grad: 1539.1132  LR: 0.00000999  \n","Epoch: [1][1100/9397] Elapsed 6m 21s (remain 47m 54s) Loss: 0.0144(0.0301) Grad: 2099.2598  LR: 0.00000999  \n","Epoch: [1][1200/9397] Elapsed 6m 56s (remain 47m 19s) Loss: 0.0329(0.0288) Grad: 15260.2607  LR: 0.00000998  \n","Epoch: [1][1300/9397] Elapsed 7m 30s (remain 46m 41s) Loss: 0.0050(0.0275) Grad: 1470.8805  LR: 0.00000998  \n","Epoch: [1][1400/9397] Elapsed 8m 4s (remain 46m 4s) Loss: 0.0195(0.0266) Grad: 2432.5498  LR: 0.00000998  \n","Epoch: [1][1500/9397] Elapsed 8m 38s (remain 45m 27s) Loss: 0.0180(0.0258) Grad: 1161.0525  LR: 0.00000997  \n","Epoch: [1][1600/9397] Elapsed 9m 12s (remain 44m 51s) Loss: 0.0047(0.0249) Grad: 1238.2894  LR: 0.00000997  \n","Epoch: [1][1700/9397] Elapsed 9m 46s (remain 44m 14s) Loss: 0.0005(0.0242) Grad: 178.0793  LR: 0.00000997  \n","Epoch: [1][1800/9397] Elapsed 10m 20s (remain 43m 38s) Loss: 0.0031(0.0235) Grad: 774.9050  LR: 0.00000996  \n","Epoch: [1][1900/9397] Elapsed 10m 54s (remain 43m 2s) Loss: 0.0174(0.0229) Grad: 2638.1343  LR: 0.00000996  \n","Epoch: [1][2000/9397] Elapsed 11m 29s (remain 42m 26s) Loss: 0.0030(0.0222) Grad: 1151.6558  LR: 0.00000996  \n","Epoch: [1][2100/9397] Elapsed 12m 3s (remain 41m 51s) Loss: 0.0132(0.0216) Grad: 5140.6157  LR: 0.00000995  \n","Epoch: [1][2200/9397] Elapsed 12m 37s (remain 41m 15s) Loss: 0.0129(0.0211) Grad: 28945.5215  LR: 0.00000995  \n","Epoch: [1][2300/9397] Elapsed 13m 11s (remain 40m 39s) Loss: 0.0157(0.0207) Grad: 4883.5488  LR: 0.00000994  \n","Epoch: [1][2400/9397] Elapsed 13m 45s (remain 40m 4s) Loss: 0.0152(0.0204) Grad: 3872.6257  LR: 0.00000994  \n","Epoch: [1][2500/9397] Elapsed 14m 19s (remain 39m 29s) Loss: 0.0053(0.0200) Grad: 1601.8969  LR: 0.00000993  \n","Epoch: [1][2600/9397] Elapsed 14m 53s (remain 38m 55s) Loss: 0.0143(0.0196) Grad: 7447.1821  LR: 0.00000992  \n","Epoch: [1][2700/9397] Elapsed 15m 27s (remain 38m 20s) Loss: 0.0013(0.0193) Grad: 986.5566  LR: 0.00000992  \n","Epoch: [1][2800/9397] Elapsed 16m 1s (remain 37m 45s) Loss: 0.0065(0.0189) Grad: 2073.8538  LR: 0.00000991  \n","Epoch: [1][2900/9397] Elapsed 16m 36s (remain 37m 10s) Loss: 0.0038(0.0187) Grad: 3189.1033  LR: 0.00000991  \n","Epoch: [1][3000/9397] Elapsed 17m 10s (remain 36m 35s) Loss: 0.0004(0.0184) Grad: 594.7064  LR: 0.00000990  \n","Epoch: [1][3100/9397] Elapsed 17m 44s (remain 36m 0s) Loss: 0.0012(0.0181) Grad: 813.7961  LR: 0.00000989  \n","Epoch: [1][3200/9397] Elapsed 18m 18s (remain 35m 26s) Loss: 0.0192(0.0179) Grad: 10008.3467  LR: 0.00000989  \n","Epoch: [1][3300/9397] Elapsed 18m 52s (remain 34m 51s) Loss: 0.0281(0.0176) Grad: 13705.0703  LR: 0.00000988  \n","Epoch: [1][3400/9397] Elapsed 19m 26s (remain 34m 16s) Loss: 0.0006(0.0174) Grad: 268.6551  LR: 0.00000987  \n","Epoch: [1][3500/9397] Elapsed 20m 0s (remain 33m 41s) Loss: 0.0188(0.0171) Grad: 17056.0059  LR: 0.00000986  \n","Epoch: [1][3600/9397] Elapsed 20m 34s (remain 33m 6s) Loss: 0.0026(0.0169) Grad: 654.2992  LR: 0.00000986  \n","Epoch: [1][3700/9397] Elapsed 21m 8s (remain 32m 32s) Loss: 0.0044(0.0168) Grad: 1273.4929  LR: 0.00000985  \n","Epoch: [1][3800/9397] Elapsed 21m 42s (remain 31m 57s) Loss: 0.0007(0.0166) Grad: 1131.2448  LR: 0.00000984  \n","Epoch: [1][3900/9397] Elapsed 22m 16s (remain 31m 22s) Loss: 0.0010(0.0164) Grad: 933.4910  LR: 0.00000983  \n","Epoch: [1][4000/9397] Elapsed 22m 50s (remain 30m 48s) Loss: 0.0070(0.0163) Grad: 5401.2749  LR: 0.00000982  \n","Epoch: [1][4100/9397] Elapsed 23m 24s (remain 30m 13s) Loss: 0.0228(0.0161) Grad: 14843.3584  LR: 0.00000981  \n","Epoch: [1][4200/9397] Elapsed 23m 58s (remain 29m 39s) Loss: 0.0061(0.0159) Grad: 3771.2935  LR: 0.00000980  \n","Epoch: [1][4300/9397] Elapsed 24m 32s (remain 29m 5s) Loss: 0.0075(0.0158) Grad: 5636.3926  LR: 0.00000979  \n","Epoch: [1][4400/9397] Elapsed 25m 6s (remain 28m 30s) Loss: 0.0217(0.0157) Grad: 24058.6582  LR: 0.00000979  \n","Epoch: [1][4500/9397] Elapsed 25m 41s (remain 27m 56s) Loss: 0.0017(0.0155) Grad: 790.5748  LR: 0.00000978  \n","Epoch: [1][4600/9397] Elapsed 26m 15s (remain 27m 22s) Loss: 0.0012(0.0154) Grad: 1554.5338  LR: 0.00000977  \n","Epoch: [1][4700/9397] Elapsed 26m 49s (remain 26m 47s) Loss: 0.1441(0.0153) Grad: 26366.5273  LR: 0.00000976  \n","Epoch: [1][4800/9397] Elapsed 27m 23s (remain 26m 13s) Loss: 0.0228(0.0151) Grad: 7241.0640  LR: 0.00000974  \n","Epoch: [1][4900/9397] Elapsed 27m 57s (remain 25m 38s) Loss: 0.0180(0.0151) Grad: 12662.1025  LR: 0.00000973  \n","Epoch: [1][5000/9397] Elapsed 28m 31s (remain 25m 4s) Loss: 0.0233(0.0149) Grad: 8668.2139  LR: 0.00000972  \n","Epoch: [1][5100/9397] Elapsed 29m 5s (remain 24m 30s) Loss: 0.0376(0.0148) Grad: 18463.3555  LR: 0.00000971  \n","Epoch: [1][5200/9397] Elapsed 29m 39s (remain 23m 56s) Loss: 0.0059(0.0147) Grad: 6798.1479  LR: 0.00000970  \n","Epoch: [1][5300/9397] Elapsed 30m 14s (remain 23m 21s) Loss: 0.0194(0.0146) Grad: 4552.9829  LR: 0.00000969  \n","Epoch: [1][5400/9397] Elapsed 30m 48s (remain 22m 47s) Loss: 0.0004(0.0145) Grad: 380.1126  LR: 0.00000968  \n","Epoch: [1][5500/9397] Elapsed 31m 22s (remain 22m 12s) Loss: 0.0064(0.0143) Grad: 6768.1118  LR: 0.00000967  \n","Epoch: [1][5600/9397] Elapsed 31m 56s (remain 21m 38s) Loss: 0.0256(0.0142) Grad: 13887.8477  LR: 0.00000965  \n","Epoch: [1][5700/9397] Elapsed 32m 29s (remain 21m 4s) Loss: 0.0106(0.0142) Grad: 20057.2988  LR: 0.00000964  \n","Epoch: [1][5800/9397] Elapsed 33m 4s (remain 20m 29s) Loss: 0.0013(0.0140) Grad: 1530.0459  LR: 0.00000963  \n","Epoch: [1][5900/9397] Elapsed 33m 38s (remain 19m 55s) Loss: 0.0083(0.0139) Grad: 22447.5176  LR: 0.00000962  \n","Epoch: [1][6000/9397] Elapsed 34m 12s (remain 19m 21s) Loss: 0.0101(0.0139) Grad: 7639.5273  LR: 0.00000960  \n","Epoch: [1][6100/9397] Elapsed 34m 46s (remain 18m 46s) Loss: 0.0008(0.0138) Grad: 2395.7458  LR: 0.00000959  \n","Epoch: [1][6200/9397] Elapsed 35m 20s (remain 18m 12s) Loss: 0.0129(0.0137) Grad: 14314.7939  LR: 0.00000958  \n","Epoch: [1][6300/9397] Elapsed 35m 54s (remain 17m 38s) Loss: 0.0000(0.0137) Grad: 37.9281  LR: 0.00000956  \n","Epoch: [1][6400/9397] Elapsed 36m 28s (remain 17m 4s) Loss: 0.0006(0.0136) Grad: 1607.3909  LR: 0.00000955  \n","Epoch: [1][6500/9397] Elapsed 37m 2s (remain 16m 30s) Loss: 0.0086(0.0135) Grad: 10152.1270  LR: 0.00000954  \n","Epoch: [1][6600/9397] Elapsed 37m 36s (remain 15m 55s) Loss: 0.0016(0.0135) Grad: 2802.9822  LR: 0.00000952  \n","Epoch: [1][6700/9397] Elapsed 38m 10s (remain 15m 21s) Loss: 0.0023(0.0134) Grad: 4692.7764  LR: 0.00000951  \n","Epoch: [1][6800/9397] Elapsed 38m 44s (remain 14m 47s) Loss: 0.0110(0.0133) Grad: 36080.6602  LR: 0.00000949  \n","Epoch: [1][6900/9397] Elapsed 39m 18s (remain 14m 13s) Loss: 0.0028(0.0132) Grad: 4152.5815  LR: 0.00000948  \n","Epoch: [1][7000/9397] Elapsed 39m 52s (remain 13m 38s) Loss: 0.0021(0.0131) Grad: 3756.1531  LR: 0.00000946  \n","Epoch: [1][7100/9397] Elapsed 40m 26s (remain 13m 4s) Loss: 0.0033(0.0131) Grad: 4769.8193  LR: 0.00000945  \n","Epoch: [1][7200/9397] Elapsed 41m 0s (remain 12m 30s) Loss: 0.0008(0.0130) Grad: 2984.0051  LR: 0.00000943  \n","Epoch: [1][7300/9397] Elapsed 41m 34s (remain 11m 56s) Loss: 0.0073(0.0130) Grad: 10284.4912  LR: 0.00000942  \n","Epoch: [1][7400/9397] Elapsed 42m 8s (remain 11m 22s) Loss: 0.0039(0.0129) Grad: 7409.9136  LR: 0.00000940  \n","Epoch: [1][7500/9397] Elapsed 42m 42s (remain 10m 47s) Loss: 0.0027(0.0128) Grad: 6898.3452  LR: 0.00000938  \n","Epoch: [1][7600/9397] Elapsed 43m 17s (remain 10m 13s) Loss: 0.0300(0.0128) Grad: 28724.4453  LR: 0.00000937  \n","Epoch: [1][7700/9397] Elapsed 43m 51s (remain 9m 39s) Loss: 0.0286(0.0127) Grad: 26733.5488  LR: 0.00000935  \n","Epoch: [1][7800/9397] Elapsed 44m 26s (remain 9m 5s) Loss: 0.0078(0.0127) Grad: 7619.9492  LR: 0.00000934  \n","Epoch: [1][7900/9397] Elapsed 45m 1s (remain 8m 31s) Loss: 0.0249(0.0126) Grad: 85926.8125  LR: 0.00000932  \n","Epoch: [1][8000/9397] Elapsed 45m 35s (remain 7m 57s) Loss: 0.0031(0.0126) Grad: 10267.6709  LR: 0.00000930  \n","Epoch: [1][8100/9397] Elapsed 46m 10s (remain 7m 23s) Loss: 0.0108(0.0125) Grad: 32649.0742  LR: 0.00000928  \n","Epoch: [1][8200/9397] Elapsed 46m 44s (remain 6m 49s) Loss: 0.0118(0.0125) Grad: 38379.9297  LR: 0.00000927  \n","Epoch: [1][8300/9397] Elapsed 47m 19s (remain 6m 14s) Loss: 0.0092(0.0124) Grad: 13269.0762  LR: 0.00000925  \n","Epoch: [1][8400/9397] Elapsed 47m 53s (remain 5m 40s) Loss: 0.0869(0.0124) Grad: 113959.8359  LR: 0.00000923  \n","Epoch: [1][8500/9397] Elapsed 48m 28s (remain 5m 6s) Loss: 0.0223(0.0123) Grad: 43471.0430  LR: 0.00000921  \n","Epoch: [1][8600/9397] Elapsed 49m 2s (remain 4m 32s) Loss: 0.0064(0.0123) Grad: 23092.5918  LR: 0.00000920  \n","Epoch: [1][8700/9397] Elapsed 49m 37s (remain 3m 58s) Loss: 0.0017(0.0122) Grad: 11542.8438  LR: 0.00000918  \n","Epoch: [1][8800/9397] Elapsed 50m 11s (remain 3m 23s) Loss: 0.0002(0.0121) Grad: 1124.2977  LR: 0.00000916  \n","Epoch: [1][8900/9397] Elapsed 50m 46s (remain 2m 49s) Loss: 0.0004(0.0121) Grad: 1970.7104  LR: 0.00000914  \n","Epoch: [1][9000/9397] Elapsed 51m 20s (remain 2m 15s) Loss: 0.0000(0.0121) Grad: 187.6176  LR: 0.00000912  \n","Epoch: [1][9100/9397] Elapsed 51m 55s (remain 1m 41s) Loss: 0.0106(0.0120) Grad: 28437.8984  LR: 0.00000910  \n","Epoch: [1][9200/9397] Elapsed 52m 29s (remain 1m 7s) Loss: 0.0043(0.0120) Grad: 22863.8672  LR: 0.00000908  \n","Epoch: [1][9300/9397] Elapsed 53m 3s (remain 0m 32s) Loss: 0.0001(0.0120) Grad: 318.5258  LR: 0.00000906  \n","Epoch: [1][9396/9397] Elapsed 53m 36s (remain 0m 0s) Loss: 0.0061(0.0119) Grad: 19484.4570  LR: 0.00000905  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 23m 36s) Loss: 0.0001(0.0001) \n","EVAL: [100/2350] Elapsed 0m 21s (remain 7m 56s) Loss: 0.0071(0.0159) \n","EVAL: [200/2350] Elapsed 0m 42s (remain 7m 31s) Loss: 0.0000(0.0157) \n","EVAL: [300/2350] Elapsed 1m 3s (remain 7m 9s) Loss: 0.0050(0.0185) \n","EVAL: [400/2350] Elapsed 1m 23s (remain 6m 48s) Loss: 0.0107(0.0175) \n","EVAL: [500/2350] Elapsed 1m 44s (remain 6m 27s) Loss: 0.0144(0.0165) \n","EVAL: [600/2350] Elapsed 2m 5s (remain 6m 5s) Loss: 0.0362(0.0161) \n","EVAL: [700/2350] Elapsed 2m 26s (remain 5m 44s) Loss: 0.0227(0.0166) \n","EVAL: [800/2350] Elapsed 2m 47s (remain 5m 23s) Loss: 0.0001(0.0168) \n","EVAL: [900/2350] Elapsed 3m 8s (remain 5m 2s) Loss: 0.0005(0.0152) \n","EVAL: [1000/2350] Elapsed 3m 29s (remain 4m 42s) Loss: 0.0003(0.0139) \n","EVAL: [1100/2350] Elapsed 3m 50s (remain 4m 21s) Loss: 0.0057(0.0128) \n","EVAL: [1200/2350] Elapsed 4m 10s (remain 4m 0s) Loss: 0.0130(0.0120) \n","EVAL: [1300/2350] Elapsed 4m 31s (remain 3m 39s) Loss: 0.0058(0.0112) \n","EVAL: [1400/2350] Elapsed 4m 52s (remain 3m 18s) Loss: 0.0094(0.0109) \n","EVAL: [1500/2350] Elapsed 5m 13s (remain 2m 57s) Loss: 0.0003(0.0106) \n","EVAL: [1600/2350] Elapsed 5m 34s (remain 2m 36s) Loss: 0.0153(0.0104) \n","EVAL: [1700/2350] Elapsed 5m 55s (remain 2m 15s) Loss: 0.0077(0.0105) \n","EVAL: [1800/2350] Elapsed 6m 16s (remain 1m 54s) Loss: 0.0000(0.0103) \n","EVAL: [1900/2350] Elapsed 6m 37s (remain 1m 33s) Loss: 0.0000(0.0098) \n","EVAL: [2000/2350] Elapsed 6m 58s (remain 1m 12s) Loss: 0.0000(0.0094) \n","EVAL: [2100/2350] Elapsed 7m 19s (remain 0m 52s) Loss: 0.0001(0.0091) \n","EVAL: [2200/2350] Elapsed 7m 40s (remain 0m 31s) Loss: 0.0000(0.0087) \n","EVAL: [2300/2350] Elapsed 8m 0s (remain 0m 10s) Loss: 0.0000(0.0084) \n","EVAL: [2349/2350] Elapsed 8m 11s (remain 0m 0s) Loss: 0.0000(0.0083) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0119  avg_val_loss: 0.0083  time: 3751s\n","Epoch 1 - Score: 0.9442\n","Epoch 1 - Save Best Score: 0.9442 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/9397] Elapsed 0m 0s (remain 147m 21s) Loss: 0.0039(0.0039) Grad: 13554.1582  LR: 0.00000904  \n","Epoch: [2][100/9397] Elapsed 0m 35s (remain 54m 23s) Loss: 0.0021(0.0067) Grad: 9279.2344  LR: 0.00000903  \n","Epoch: [2][200/9397] Elapsed 1m 9s (remain 53m 8s) Loss: 0.0001(0.0073) Grad: 214.2248  LR: 0.00000901  \n","Epoch: [2][300/9397] Elapsed 1m 43s (remain 52m 19s) Loss: 0.0075(0.0069) Grad: 32825.9336  LR: 0.00000899  \n","Epoch: [2][400/9397] Elapsed 2m 18s (remain 51m 36s) Loss: 0.0067(0.0069) Grad: 99486.9453  LR: 0.00000896  \n","Epoch: [2][500/9397] Elapsed 2m 52s (remain 50m 57s) Loss: 0.0018(0.0066) Grad: 8742.8281  LR: 0.00000894  \n","Epoch: [2][600/9397] Elapsed 3m 26s (remain 50m 22s) Loss: 0.0091(0.0065) Grad: 23190.3984  LR: 0.00000892  \n","Epoch: [2][700/9397] Elapsed 4m 0s (remain 49m 48s) Loss: 0.0006(0.0066) Grad: 1879.0072  LR: 0.00000890  \n","Epoch: [2][800/9397] Elapsed 4m 35s (remain 49m 14s) Loss: 0.0032(0.0067) Grad: 12827.0703  LR: 0.00000888  \n","Epoch: [2][900/9397] Elapsed 5m 9s (remain 48m 40s) Loss: 0.0026(0.0066) Grad: 9849.7188  LR: 0.00000886  \n","Epoch: [2][1000/9397] Elapsed 5m 44s (remain 48m 6s) Loss: 0.0008(0.0065) Grad: 5601.5132  LR: 0.00000884  \n","Epoch: [2][1100/9397] Elapsed 6m 18s (remain 47m 32s) Loss: 0.0001(0.0065) Grad: 580.1244  LR: 0.00000882  \n","Epoch: [2][1200/9397] Elapsed 6m 52s (remain 46m 57s) Loss: 0.0053(0.0066) Grad: 27513.8008  LR: 0.00000880  \n","Epoch: [2][1300/9397] Elapsed 7m 27s (remain 46m 23s) Loss: 0.0096(0.0065) Grad: 78585.7422  LR: 0.00000877  \n","Epoch: [2][1400/9397] Elapsed 8m 1s (remain 45m 48s) Loss: 0.0032(0.0065) Grad: 10718.8057  LR: 0.00000875  \n","Epoch: [2][1500/9397] Elapsed 8m 35s (remain 45m 14s) Loss: 0.0015(0.0065) Grad: 9464.8477  LR: 0.00000873  \n","Epoch: [2][1600/9397] Elapsed 9m 10s (remain 44m 39s) Loss: 0.0051(0.0064) Grad: 42556.9688  LR: 0.00000871  \n","Epoch: [2][1700/9397] Elapsed 9m 44s (remain 44m 4s) Loss: 0.0112(0.0064) Grad: 38270.5000  LR: 0.00000869  \n","Epoch: [2][1800/9397] Elapsed 10m 18s (remain 43m 29s) Loss: 0.0001(0.0064) Grad: 1852.8226  LR: 0.00000866  \n","Epoch: [2][1900/9397] Elapsed 10m 53s (remain 42m 55s) Loss: 0.0075(0.0064) Grad: 33264.9297  LR: 0.00000864  \n","Epoch: [2][2000/9397] Elapsed 11m 27s (remain 42m 22s) Loss: 0.0002(0.0064) Grad: 6336.4868  LR: 0.00000862  \n","Epoch: [2][2100/9397] Elapsed 12m 2s (remain 41m 47s) Loss: 0.0085(0.0064) Grad: 58272.4297  LR: 0.00000859  \n","Epoch: [2][2200/9397] Elapsed 12m 36s (remain 41m 13s) Loss: 0.0175(0.0063) Grad: 54587.3477  LR: 0.00000857  \n","Epoch: [2][2300/9397] Elapsed 13m 11s (remain 40m 39s) Loss: 0.0000(0.0063) Grad: 41.8209  LR: 0.00000855  \n","Epoch: [2][2400/9397] Elapsed 13m 45s (remain 40m 4s) Loss: 0.0099(0.0063) Grad: 85877.6719  LR: 0.00000852  \n","Epoch: [2][2500/9397] Elapsed 14m 19s (remain 39m 30s) Loss: 0.0024(0.0064) Grad: 65297.2148  LR: 0.00000850  \n","Epoch: [2][2600/9397] Elapsed 14m 53s (remain 38m 55s) Loss: 0.0019(0.0064) Grad: 44177.4648  LR: 0.00000848  \n","Epoch: [2][2700/9397] Elapsed 15m 28s (remain 38m 21s) Loss: 0.0100(0.0064) Grad: 117638.1875  LR: 0.00000845  \n","Epoch: [2][2800/9397] Elapsed 16m 2s (remain 37m 46s) Loss: 0.0020(0.0065) Grad: 12460.6699  LR: 0.00000843  \n","Epoch: [2][2900/9397] Elapsed 16m 37s (remain 37m 12s) Loss: 0.0115(0.0065) Grad: 50367.0039  LR: 0.00000840  \n","Epoch: [2][3000/9397] Elapsed 17m 11s (remain 36m 38s) Loss: 0.0043(0.0065) Grad: 49777.6328  LR: 0.00000838  \n","Epoch: [2][3100/9397] Elapsed 17m 45s (remain 36m 3s) Loss: 0.0013(0.0065) Grad: 15989.5283  LR: 0.00000835  \n","Epoch: [2][3200/9397] Elapsed 18m 20s (remain 35m 29s) Loss: 0.0040(0.0064) Grad: 37437.2578  LR: 0.00000833  \n","Epoch: [2][3300/9397] Elapsed 18m 54s (remain 34m 54s) Loss: 0.0001(0.0064) Grad: 1232.1229  LR: 0.00000830  \n","Epoch: [2][3400/9397] Elapsed 19m 28s (remain 34m 20s) Loss: 0.0027(0.0064) Grad: 38797.5391  LR: 0.00000828  \n","Epoch: [2][3500/9397] Elapsed 20m 3s (remain 33m 46s) Loss: 0.0004(0.0064) Grad: 9068.2910  LR: 0.00000825  \n","Epoch: [2][3600/9397] Elapsed 20m 37s (remain 33m 11s) Loss: 0.0138(0.0064) Grad: 84997.6562  LR: 0.00000823  \n","Epoch: [2][3700/9397] Elapsed 21m 11s (remain 32m 37s) Loss: 0.0036(0.0064) Grad: 32848.6641  LR: 0.00000820  \n","Epoch: [2][3800/9397] Elapsed 21m 45s (remain 32m 2s) Loss: 0.0025(0.0064) Grad: 19018.1016  LR: 0.00000818  \n","Epoch: [2][3900/9397] Elapsed 22m 20s (remain 31m 28s) Loss: 0.0210(0.0064) Grad: 117163.3984  LR: 0.00000815  \n","Epoch: [2][4000/9397] Elapsed 22m 54s (remain 30m 54s) Loss: 0.0000(0.0064) Grad: 944.3686  LR: 0.00000812  \n","Epoch: [2][4100/9397] Elapsed 23m 29s (remain 30m 19s) Loss: 0.0010(0.0065) Grad: 56490.6641  LR: 0.00000810  \n","Epoch: [2][4200/9397] Elapsed 24m 3s (remain 29m 45s) Loss: 0.0034(0.0065) Grad: 148351.3438  LR: 0.00000807  \n","Epoch: [2][4300/9397] Elapsed 24m 37s (remain 29m 11s) Loss: 0.0271(0.0065) Grad: 256305.8594  LR: 0.00000805  \n","Epoch: [2][4400/9397] Elapsed 25m 12s (remain 28m 36s) Loss: 0.0005(0.0065) Grad: 6985.8164  LR: 0.00000802  \n","Epoch: [2][4500/9397] Elapsed 25m 46s (remain 28m 2s) Loss: 0.0063(0.0065) Grad: 36243.5078  LR: 0.00000799  \n","Epoch: [2][4600/9397] Elapsed 26m 20s (remain 27m 27s) Loss: 0.0045(0.0065) Grad: 27855.4688  LR: 0.00000797  \n","Epoch: [2][4700/9397] Elapsed 26m 55s (remain 26m 53s) Loss: 0.0184(0.0064) Grad: 79410.5469  LR: 0.00000794  \n","Epoch: [2][4800/9397] Elapsed 27m 29s (remain 26m 19s) Loss: 0.0021(0.0064) Grad: 30084.1758  LR: 0.00000791  \n","Epoch: [2][4900/9397] Elapsed 28m 4s (remain 25m 45s) Loss: 0.0006(0.0064) Grad: 17149.9355  LR: 0.00000788  \n","Epoch: [2][5000/9397] Elapsed 28m 38s (remain 25m 10s) Loss: 0.0024(0.0064) Grad: 26572.4336  LR: 0.00000786  \n","Epoch: [2][5100/9397] Elapsed 29m 13s (remain 24m 36s) Loss: 0.0003(0.0064) Grad: 2709.2161  LR: 0.00000783  \n","Epoch: [2][5200/9397] Elapsed 29m 47s (remain 24m 2s) Loss: 0.0007(0.0065) Grad: 41043.2617  LR: 0.00000780  \n","Epoch: [2][5300/9397] Elapsed 30m 21s (remain 23m 27s) Loss: 0.0112(0.0065) Grad: 69222.5547  LR: 0.00000777  \n","Epoch: [2][5400/9397] Elapsed 30m 56s (remain 22m 53s) Loss: 0.0001(0.0065) Grad: 954.4636  LR: 0.00000775  \n","Epoch: [2][5500/9397] Elapsed 31m 30s (remain 22m 18s) Loss: 0.0093(0.0065) Grad: 18489.0195  LR: 0.00000772  \n","Epoch: [2][5600/9397] Elapsed 32m 4s (remain 21m 44s) Loss: 0.0072(0.0065) Grad: 21815.1309  LR: 0.00000769  \n","Epoch: [2][5700/9397] Elapsed 32m 39s (remain 21m 10s) Loss: 0.0001(0.0065) Grad: 281.7838  LR: 0.00000766  \n","Epoch: [2][5800/9397] Elapsed 33m 13s (remain 20m 36s) Loss: 0.0050(0.0065) Grad: 14770.8896  LR: 0.00000763  \n","Epoch: [2][5900/9397] Elapsed 33m 48s (remain 20m 1s) Loss: 0.0056(0.0066) Grad: 20278.0645  LR: 0.00000760  \n","Epoch: [2][6000/9397] Elapsed 34m 23s (remain 19m 27s) Loss: 0.0001(0.0066) Grad: 1387.2788  LR: 0.00000758  \n","Epoch: [2][6100/9397] Elapsed 34m 57s (remain 18m 53s) Loss: 0.0005(0.0065) Grad: 9214.2998  LR: 0.00000755  \n","Epoch: [2][6200/9397] Elapsed 35m 32s (remain 18m 18s) Loss: 0.0042(0.0066) Grad: 19234.9238  LR: 0.00000752  \n","Epoch: [2][6300/9397] Elapsed 36m 6s (remain 17m 44s) Loss: 0.0014(0.0066) Grad: 9736.8877  LR: 0.00000749  \n","Epoch: [2][6400/9397] Elapsed 36m 40s (remain 17m 10s) Loss: 0.0002(0.0066) Grad: 1234.7167  LR: 0.00000746  \n","Epoch: [2][6500/9397] Elapsed 37m 15s (remain 16m 35s) Loss: 0.0068(0.0066) Grad: 30430.8516  LR: 0.00000743  \n","Epoch: [2][6600/9397] Elapsed 37m 49s (remain 16m 1s) Loss: 0.0006(0.0066) Grad: 7384.7993  LR: 0.00000740  \n","Epoch: [2][6700/9397] Elapsed 38m 23s (remain 15m 26s) Loss: 0.0055(0.0066) Grad: 36251.7773  LR: 0.00000737  \n","Epoch: [2][6800/9397] Elapsed 38m 58s (remain 14m 52s) Loss: 0.0040(0.0066) Grad: 46113.8086  LR: 0.00000734  \n","Epoch: [2][6900/9397] Elapsed 39m 32s (remain 14m 18s) Loss: 0.0064(0.0066) Grad: 30503.6602  LR: 0.00000731  \n","Epoch: [2][7000/9397] Elapsed 40m 7s (remain 13m 43s) Loss: 0.0003(0.0067) Grad: 2587.5063  LR: 0.00000728  \n","Epoch: [2][7100/9397] Elapsed 40m 41s (remain 13m 9s) Loss: 0.1141(0.0067) Grad: 69844.9375  LR: 0.00000725  \n","Epoch: [2][7200/9397] Elapsed 41m 16s (remain 12m 35s) Loss: 0.0001(0.0067) Grad: 758.5089  LR: 0.00000722  \n","Epoch: [2][7300/9397] Elapsed 41m 50s (remain 12m 0s) Loss: 0.0033(0.0067) Grad: 25548.5391  LR: 0.00000719  \n","Epoch: [2][7400/9397] Elapsed 42m 25s (remain 11m 26s) Loss: 0.0013(0.0067) Grad: 15231.2217  LR: 0.00000716  \n","Epoch: [2][7500/9397] Elapsed 42m 59s (remain 10m 52s) Loss: 0.0000(0.0067) Grad: 286.5868  LR: 0.00000713  \n","Epoch: [2][7600/9397] Elapsed 43m 34s (remain 10m 17s) Loss: 0.0013(0.0067) Grad: 24598.2461  LR: 0.00000710  \n","Epoch: [2][7700/9397] Elapsed 44m 8s (remain 9m 43s) Loss: 0.0026(0.0067) Grad: 63262.8867  LR: 0.00000707  \n","Epoch: [2][7800/9397] Elapsed 44m 42s (remain 9m 8s) Loss: 0.0067(0.0067) Grad: 62410.9102  LR: 0.00000704  \n","Epoch: [2][7900/9397] Elapsed 45m 17s (remain 8m 34s) Loss: 0.0003(0.0066) Grad: 12887.6104  LR: 0.00000701  \n","Epoch: [2][8000/9397] Elapsed 45m 51s (remain 8m 0s) Loss: 0.0223(0.0066) Grad: 95967.2031  LR: 0.00000698  \n","Epoch: [2][8100/9397] Elapsed 46m 26s (remain 7m 25s) Loss: 0.0012(0.0066) Grad: 26396.4648  LR: 0.00000695  \n","Epoch: [2][8200/9397] Elapsed 47m 0s (remain 6m 51s) Loss: 0.0015(0.0067) Grad: 20322.7578  LR: 0.00000692  \n","Epoch: [2][8300/9397] Elapsed 47m 35s (remain 6m 16s) Loss: 0.0013(0.0067) Grad: 47365.5625  LR: 0.00000689  \n","Epoch: [2][8400/9397] Elapsed 48m 9s (remain 5m 42s) Loss: 0.0029(0.0066) Grad: 35651.1055  LR: 0.00000686  \n","Epoch: [2][8500/9397] Elapsed 48m 43s (remain 5m 8s) Loss: 0.0001(0.0066) Grad: 2017.9457  LR: 0.00000683  \n","Epoch: [2][8600/9397] Elapsed 49m 18s (remain 4m 33s) Loss: 0.0105(0.0066) Grad: 29341.7246  LR: 0.00000680  \n","Epoch: [2][8700/9397] Elapsed 49m 52s (remain 3m 59s) Loss: 0.0075(0.0066) Grad: 67301.2891  LR: 0.00000676  \n","Epoch: [2][8800/9397] Elapsed 50m 27s (remain 3m 24s) Loss: 0.0046(0.0066) Grad: 57313.5391  LR: 0.00000673  \n","Epoch: [2][8900/9397] Elapsed 51m 1s (remain 2m 50s) Loss: 0.0000(0.0066) Grad: 281.2337  LR: 0.00000670  \n","Epoch: [2][9000/9397] Elapsed 51m 35s (remain 2m 16s) Loss: 0.0001(0.0066) Grad: 1348.4214  LR: 0.00000667  \n","Epoch: [2][9100/9397] Elapsed 52m 10s (remain 1m 41s) Loss: 0.0040(0.0066) Grad: 28988.0410  LR: 0.00000664  \n","Epoch: [2][9200/9397] Elapsed 52m 44s (remain 1m 7s) Loss: 0.0036(0.0066) Grad: 46620.3711  LR: 0.00000661  \n","Epoch: [2][9300/9397] Elapsed 53m 19s (remain 0m 33s) Loss: 0.0226(0.0066) Grad: 47014.7695  LR: 0.00000658  \n","Epoch: [2][9396/9397] Elapsed 53m 52s (remain 0m 0s) Loss: 0.0037(0.0066) Grad: 42689.9844  LR: 0.00000655  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 22m 0s) Loss: 0.0003(0.0003) \n","EVAL: [100/2350] Elapsed 0m 21s (remain 7m 55s) Loss: 0.0123(0.0196) \n","EVAL: [200/2350] Elapsed 0m 42s (remain 7m 30s) Loss: 0.0000(0.0183) \n","EVAL: [300/2350] Elapsed 1m 2s (remain 7m 8s) Loss: 0.0056(0.0215) \n","EVAL: [400/2350] Elapsed 1m 23s (remain 6m 46s) Loss: 0.0049(0.0206) \n","EVAL: [500/2350] Elapsed 1m 44s (remain 6m 25s) Loss: 0.0217(0.0192) \n","EVAL: [600/2350] Elapsed 2m 5s (remain 6m 4s) Loss: 0.0132(0.0181) \n","EVAL: [700/2350] Elapsed 2m 26s (remain 5m 43s) Loss: 0.0278(0.0183) \n","EVAL: [800/2350] Elapsed 2m 46s (remain 5m 22s) Loss: 0.0000(0.0183) \n","EVAL: [900/2350] Elapsed 3m 7s (remain 5m 1s) Loss: 0.0002(0.0166) \n","EVAL: [1000/2350] Elapsed 3m 28s (remain 4m 40s) Loss: 0.0008(0.0151) \n","EVAL: [1100/2350] Elapsed 3m 49s (remain 4m 19s) Loss: 0.0198(0.0140) \n","EVAL: [1200/2350] Elapsed 4m 9s (remain 3m 59s) Loss: 0.0126(0.0130) \n","EVAL: [1300/2350] Elapsed 4m 30s (remain 3m 38s) Loss: 0.0023(0.0121) \n","EVAL: [1400/2350] Elapsed 4m 51s (remain 3m 17s) Loss: 0.0113(0.0117) \n","EVAL: [1500/2350] Elapsed 5m 12s (remain 2m 56s) Loss: 0.0001(0.0114) \n","EVAL: [1600/2350] Elapsed 5m 32s (remain 2m 35s) Loss: 0.0177(0.0112) \n","EVAL: [1700/2350] Elapsed 5m 53s (remain 2m 14s) Loss: 0.0058(0.0111) \n","EVAL: [1800/2350] Elapsed 6m 14s (remain 1m 54s) Loss: 0.0000(0.0110) \n","EVAL: [1900/2350] Elapsed 6m 35s (remain 1m 33s) Loss: 0.0000(0.0104) \n","EVAL: [2000/2350] Elapsed 6m 55s (remain 1m 12s) Loss: 0.0000(0.0099) \n","EVAL: [2100/2350] Elapsed 7m 16s (remain 0m 51s) Loss: 0.0000(0.0095) \n","EVAL: [2200/2350] Elapsed 7m 37s (remain 0m 30s) Loss: 0.0000(0.0091) \n","EVAL: [2300/2350] Elapsed 7m 58s (remain 0m 10s) Loss: 0.0000(0.0088) \n","EVAL: [2349/2350] Elapsed 8m 8s (remain 0m 0s) Loss: 0.0000(0.0086) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0066  avg_val_loss: 0.0086  time: 3762s\n","Epoch 2 - Score: 0.9496\n","Epoch 2 - Save Best Score: 0.9496 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/9397] Elapsed 0m 0s (remain 131m 10s) Loss: 0.0039(0.0039) Grad: 40278.2734  LR: 0.00000655  \n","Epoch: [3][100/9397] Elapsed 0m 33s (remain 51m 52s) Loss: 0.0045(0.0047) Grad: 79040.0312  LR: 0.00000651  \n","Epoch: [3][200/9397] Elapsed 1m 6s (remain 50m 42s) Loss: 0.0001(0.0050) Grad: 368.1505  LR: 0.00000648  \n","Epoch: [3][300/9397] Elapsed 1m 39s (remain 49m 55s) Loss: 0.0006(0.0050) Grad: 5403.3438  LR: 0.00000645  \n","Epoch: [3][400/9397] Elapsed 2m 11s (remain 49m 15s) Loss: 0.0055(0.0051) Grad: 30022.5410  LR: 0.00000642  \n","Epoch: [3][500/9397] Elapsed 2m 44s (remain 48m 38s) Loss: 0.0067(0.0051) Grad: 15775.4727  LR: 0.00000639  \n","Epoch: [3][600/9397] Elapsed 3m 16s (remain 48m 1s) Loss: 0.0069(0.0053) Grad: 113360.8203  LR: 0.00000635  \n","Epoch: [3][700/9397] Elapsed 3m 49s (remain 47m 27s) Loss: 0.0092(0.0051) Grad: 25114.9043  LR: 0.00000632  \n","Epoch: [3][800/9397] Elapsed 4m 22s (remain 46m 52s) Loss: 0.0002(0.0051) Grad: 2666.7148  LR: 0.00000629  \n","Epoch: [3][900/9397] Elapsed 4m 54s (remain 46m 18s) Loss: 0.0082(0.0051) Grad: 33799.4141  LR: 0.00000626  \n","Epoch: [3][1000/9397] Elapsed 5m 27s (remain 45m 44s) Loss: 0.0201(0.0052) Grad: 80590.2188  LR: 0.00000622  \n","Epoch: [3][1100/9397] Elapsed 5m 59s (remain 45m 11s) Loss: 0.0059(0.0052) Grad: 43707.3047  LR: 0.00000619  \n","Epoch: [3][1200/9397] Elapsed 6m 32s (remain 44m 37s) Loss: 0.0000(0.0053) Grad: 38.3436  LR: 0.00000616  \n","Epoch: [3][1300/9397] Elapsed 7m 5s (remain 44m 5s) Loss: 0.0015(0.0053) Grad: 42364.8164  LR: 0.00000613  \n","Epoch: [3][1400/9397] Elapsed 7m 37s (remain 43m 32s) Loss: 0.0009(0.0053) Grad: 16227.3408  LR: 0.00000609  \n","Epoch: [3][1500/9397] Elapsed 8m 10s (remain 42m 59s) Loss: 0.0000(0.0052) Grad: 442.4005  LR: 0.00000606  \n","Epoch: [3][1600/9397] Elapsed 8m 42s (remain 42m 25s) Loss: 0.0003(0.0052) Grad: 4482.4990  LR: 0.00000603  \n","Epoch: [3][1700/9397] Elapsed 9m 15s (remain 41m 52s) Loss: 0.0030(0.0053) Grad: 41575.9023  LR: 0.00000600  \n","Epoch: [3][1800/9397] Elapsed 9m 47s (remain 41m 19s) Loss: 0.0213(0.0055) Grad: 67868.8672  LR: 0.00000596  \n","Epoch: [3][1900/9397] Elapsed 10m 20s (remain 40m 47s) Loss: 0.0001(0.0054) Grad: 755.6720  LR: 0.00000593  \n","Epoch: [3][2000/9397] Elapsed 10m 53s (remain 40m 14s) Loss: 0.0213(0.0054) Grad: 55517.0391  LR: 0.00000590  \n","Epoch: [3][2100/9397] Elapsed 11m 25s (remain 39m 41s) Loss: 0.0022(0.0055) Grad: 30767.5859  LR: 0.00000586  \n","Epoch: [3][2200/9397] Elapsed 11m 58s (remain 39m 9s) Loss: 0.0082(0.0055) Grad: 30656.2891  LR: 0.00000583  \n","Epoch: [3][2300/9397] Elapsed 12m 31s (remain 38m 36s) Loss: 0.0003(0.0056) Grad: 7363.7310  LR: 0.00000580  \n","Epoch: [3][2400/9397] Elapsed 13m 3s (remain 38m 3s) Loss: 0.0001(0.0056) Grad: 1423.9733  LR: 0.00000577  \n","Epoch: [3][2500/9397] Elapsed 13m 36s (remain 37m 30s) Loss: 0.0000(0.0056) Grad: 228.9700  LR: 0.00000573  \n","Epoch: [3][2600/9397] Elapsed 14m 8s (remain 36m 58s) Loss: 0.0009(0.0057) Grad: 17533.7500  LR: 0.00000570  \n","Epoch: [3][2700/9397] Elapsed 14m 41s (remain 36m 25s) Loss: 0.0010(0.0057) Grad: 21171.0254  LR: 0.00000567  \n","Epoch: [3][2800/9397] Elapsed 15m 14s (remain 35m 53s) Loss: 0.0146(0.0057) Grad: 141340.4531  LR: 0.00000563  \n","Epoch: [3][2900/9397] Elapsed 15m 47s (remain 35m 20s) Loss: 0.0030(0.0057) Grad: 93416.1250  LR: 0.00000560  \n","Epoch: [3][3000/9397] Elapsed 16m 19s (remain 34m 48s) Loss: 0.0030(0.0057) Grad: 38715.1367  LR: 0.00000557  \n","Epoch: [3][3100/9397] Elapsed 16m 52s (remain 34m 15s) Loss: 0.0023(0.0057) Grad: 51760.8945  LR: 0.00000553  \n","Epoch: [3][3200/9397] Elapsed 17m 25s (remain 33m 42s) Loss: 0.0001(0.0057) Grad: 4566.0107  LR: 0.00000550  \n","Epoch: [3][3300/9397] Elapsed 17m 57s (remain 33m 10s) Loss: 0.0017(0.0057) Grad: 40898.2109  LR: 0.00000547  \n","Epoch: [3][3400/9397] Elapsed 18m 30s (remain 32m 37s) Loss: 0.0875(0.0057) Grad: 202398.4531  LR: 0.00000543  \n","Epoch: [3][3500/9397] Elapsed 19m 2s (remain 32m 4s) Loss: 0.0135(0.0057) Grad: 294722.2188  LR: 0.00000540  \n","Epoch: [3][3600/9397] Elapsed 19m 35s (remain 31m 31s) Loss: 0.0002(0.0057) Grad: 2994.8286  LR: 0.00000537  \n","Epoch: [3][3700/9397] Elapsed 20m 7s (remain 30m 58s) Loss: 0.0028(0.0057) Grad: 28459.1895  LR: 0.00000533  \n","Epoch: [3][3800/9397] Elapsed 20m 40s (remain 30m 26s) Loss: 0.0178(0.0057) Grad: 29754.7656  LR: 0.00000530  \n","Epoch: [3][3900/9397] Elapsed 21m 13s (remain 29m 54s) Loss: 0.0083(0.0057) Grad: 161165.4688  LR: 0.00000527  \n","Epoch: [3][4000/9397] Elapsed 21m 46s (remain 29m 21s) Loss: 0.0033(0.0057) Grad: 82820.4062  LR: 0.00000523  \n","Epoch: [3][4100/9397] Elapsed 22m 18s (remain 28m 48s) Loss: 0.0000(0.0057) Grad: 331.1211  LR: 0.00000520  \n","Epoch: [3][4200/9397] Elapsed 22m 51s (remain 28m 16s) Loss: 0.0092(0.0057) Grad: 115140.0078  LR: 0.00000517  \n","Epoch: [3][4300/9397] Elapsed 23m 24s (remain 27m 43s) Loss: 0.0442(0.0057) Grad: 421964.6875  LR: 0.00000513  \n","Epoch: [3][4400/9397] Elapsed 23m 56s (remain 27m 10s) Loss: 0.0133(0.0057) Grad: 113334.0469  LR: 0.00000510  \n","Epoch: [3][4500/9397] Elapsed 24m 29s (remain 26m 38s) Loss: 0.0070(0.0057) Grad: 93092.4141  LR: 0.00000507  \n","Epoch: [3][4600/9397] Elapsed 25m 2s (remain 26m 5s) Loss: 0.0003(0.0057) Grad: 9252.2529  LR: 0.00000503  \n","Epoch: [3][4700/9397] Elapsed 25m 34s (remain 25m 32s) Loss: 0.0001(0.0057) Grad: 767.8350  LR: 0.00000500  \n","Epoch: [3][4800/9397] Elapsed 26m 7s (remain 25m 0s) Loss: 0.0001(0.0057) Grad: 2904.3777  LR: 0.00000497  \n","Epoch: [3][4900/9397] Elapsed 26m 39s (remain 24m 27s) Loss: 0.0019(0.0057) Grad: 40996.0703  LR: 0.00000493  \n","Epoch: [3][5000/9397] Elapsed 27m 12s (remain 23m 54s) Loss: 0.0000(0.0057) Grad: 589.8691  LR: 0.00000490  \n","Epoch: [3][5100/9397] Elapsed 27m 45s (remain 23m 22s) Loss: 0.0000(0.0057) Grad: 32.1815  LR: 0.00000487  \n","Epoch: [3][5200/9397] Elapsed 28m 17s (remain 22m 49s) Loss: 0.0273(0.0057) Grad: 252281.4688  LR: 0.00000483  \n","Epoch: [3][5300/9397] Elapsed 28m 50s (remain 22m 16s) Loss: 0.0000(0.0057) Grad: 594.6562  LR: 0.00000480  \n","Epoch: [3][5400/9397] Elapsed 29m 22s (remain 21m 44s) Loss: 0.0048(0.0056) Grad: 65301.8633  LR: 0.00000477  \n","Epoch: [3][5500/9397] Elapsed 29m 55s (remain 21m 11s) Loss: 0.0043(0.0057) Grad: 59852.6016  LR: 0.00000473  \n","Epoch: [3][5600/9397] Elapsed 30m 27s (remain 20m 38s) Loss: 0.0131(0.0057) Grad: 138660.5000  LR: 0.00000470  \n","Epoch: [3][5700/9397] Elapsed 30m 59s (remain 20m 5s) Loss: 0.0078(0.0057) Grad: 103417.6953  LR: 0.00000467  \n","Epoch: [3][5800/9397] Elapsed 31m 32s (remain 19m 33s) Loss: 0.0031(0.0057) Grad: 122919.8906  LR: 0.00000463  \n","Epoch: [3][5900/9397] Elapsed 32m 5s (remain 19m 0s) Loss: 0.0064(0.0057) Grad: 49528.4922  LR: 0.00000460  \n","Epoch: [3][6000/9397] Elapsed 32m 37s (remain 18m 27s) Loss: 0.0085(0.0057) Grad: 88849.2500  LR: 0.00000457  \n","Epoch: [3][6100/9397] Elapsed 33m 9s (remain 17m 55s) Loss: 0.0001(0.0057) Grad: 5334.6069  LR: 0.00000453  \n","Epoch: [3][6200/9397] Elapsed 33m 42s (remain 17m 22s) Loss: 0.0075(0.0056) Grad: 92852.3047  LR: 0.00000450  \n","Epoch: [3][6300/9397] Elapsed 34m 14s (remain 16m 49s) Loss: 0.0000(0.0056) Grad: 298.4546  LR: 0.00000447  \n","Epoch: [3][6400/9397] Elapsed 34m 47s (remain 16m 17s) Loss: 0.0003(0.0056) Grad: 12251.0293  LR: 0.00000443  \n","Epoch: [3][6500/9397] Elapsed 35m 19s (remain 15m 44s) Loss: 0.0065(0.0056) Grad: 178173.6562  LR: 0.00000440  \n","Epoch: [3][6600/9397] Elapsed 35m 52s (remain 15m 11s) Loss: 0.0050(0.0056) Grad: 50274.2500  LR: 0.00000437  \n","Epoch: [3][6700/9397] Elapsed 36m 24s (remain 14m 39s) Loss: 0.0039(0.0056) Grad: 447656.4375  LR: 0.00000433  \n","Epoch: [3][6800/9397] Elapsed 36m 57s (remain 14m 6s) Loss: 0.0039(0.0056) Grad: 174560.4531  LR: 0.00000430  \n","Epoch: [3][6900/9397] Elapsed 37m 29s (remain 13m 33s) Loss: 0.0033(0.0056) Grad: 45378.1250  LR: 0.00000427  \n","Epoch: [3][7000/9397] Elapsed 38m 2s (remain 13m 1s) Loss: 0.0120(0.0056) Grad: 356952.5000  LR: 0.00000423  \n","Epoch: [3][7100/9397] Elapsed 38m 35s (remain 12m 28s) Loss: 0.0029(0.0056) Grad: 85598.1484  LR: 0.00000420  \n","Epoch: [3][7200/9397] Elapsed 39m 7s (remain 11m 55s) Loss: 0.0000(0.0056) Grad: 912.3229  LR: 0.00000417  \n","Epoch: [3][7300/9397] Elapsed 39m 40s (remain 11m 23s) Loss: 0.0057(0.0056) Grad: 48323.1055  LR: 0.00000413  \n","Epoch: [3][7400/9397] Elapsed 40m 12s (remain 10m 50s) Loss: 0.0000(0.0056) Grad: 508.6441  LR: 0.00000410  \n","Epoch: [3][7500/9397] Elapsed 40m 45s (remain 10m 18s) Loss: 0.0001(0.0056) Grad: 2289.6438  LR: 0.00000407  \n","Epoch: [3][7600/9397] Elapsed 41m 18s (remain 9m 45s) Loss: 0.0089(0.0056) Grad: 103612.0156  LR: 0.00000404  \n","Epoch: [3][7700/9397] Elapsed 41m 50s (remain 9m 12s) Loss: 0.0001(0.0056) Grad: 3850.6450  LR: 0.00000400  \n","Epoch: [3][7800/9397] Elapsed 42m 23s (remain 8m 40s) Loss: 0.0001(0.0056) Grad: 5108.3198  LR: 0.00000397  \n","Epoch: [3][7900/9397] Elapsed 42m 56s (remain 8m 7s) Loss: 0.0000(0.0056) Grad: 208.8854  LR: 0.00000394  \n","Epoch: [3][8000/9397] Elapsed 43m 28s (remain 7m 35s) Loss: 0.0716(0.0056) Grad: 328753.1562  LR: 0.00000391  \n","Epoch: [3][8100/9397] Elapsed 44m 1s (remain 7m 2s) Loss: 0.0002(0.0056) Grad: 2154.5283  LR: 0.00000387  \n","Epoch: [3][8200/9397] Elapsed 44m 33s (remain 6m 29s) Loss: 0.0000(0.0056) Grad: 553.9631  LR: 0.00000384  \n","Epoch: [3][8300/9397] Elapsed 45m 5s (remain 5m 57s) Loss: 0.0004(0.0056) Grad: 17917.9434  LR: 0.00000381  \n","Epoch: [3][8400/9397] Elapsed 45m 38s (remain 5m 24s) Loss: 0.0001(0.0056) Grad: 1307.1812  LR: 0.00000378  \n","Epoch: [3][8500/9397] Elapsed 46m 10s (remain 4m 52s) Loss: 0.0007(0.0056) Grad: 9412.7295  LR: 0.00000374  \n","Epoch: [3][8600/9397] Elapsed 46m 43s (remain 4m 19s) Loss: 0.0010(0.0056) Grad: 67448.7578  LR: 0.00000371  \n","Epoch: [3][8700/9397] Elapsed 47m 15s (remain 3m 46s) Loss: 0.0001(0.0056) Grad: 3697.3506  LR: 0.00000368  \n","Epoch: [3][8800/9397] Elapsed 47m 48s (remain 3m 14s) Loss: 0.0156(0.0056) Grad: 104762.6094  LR: 0.00000365  \n","Epoch: [3][8900/9397] Elapsed 48m 21s (remain 2m 41s) Loss: 0.0034(0.0056) Grad: 40271.6484  LR: 0.00000361  \n","Epoch: [3][9000/9397] Elapsed 48m 53s (remain 2m 9s) Loss: 0.0089(0.0056) Grad: 61524.7266  LR: 0.00000358  \n","Epoch: [3][9100/9397] Elapsed 49m 26s (remain 1m 36s) Loss: 0.0153(0.0056) Grad: 158020.7812  LR: 0.00000355  \n","Epoch: [3][9200/9397] Elapsed 49m 59s (remain 1m 3s) Loss: 0.0000(0.0056) Grad: 107.1085  LR: 0.00000352  \n","Epoch: [3][9300/9397] Elapsed 50m 31s (remain 0m 31s) Loss: 0.0070(0.0056) Grad: 360925.6562  LR: 0.00000349  \n","Epoch: [3][9396/9397] Elapsed 51m 3s (remain 0m 0s) Loss: 0.0132(0.0056) Grad: 110695.0078  LR: 0.00000346  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 17m 24s) Loss: 0.0001(0.0001) \n","EVAL: [100/2350] Elapsed 0m 19s (remain 7m 19s) Loss: 0.0093(0.0210) \n","EVAL: [200/2350] Elapsed 0m 39s (remain 6m 57s) Loss: 0.0000(0.0198) \n","EVAL: [300/2350] Elapsed 0m 58s (remain 6m 37s) Loss: 0.0057(0.0232) \n","EVAL: [400/2350] Elapsed 1m 17s (remain 6m 17s) Loss: 0.0126(0.0220) \n","EVAL: [500/2350] Elapsed 1m 37s (remain 5m 58s) Loss: 0.0113(0.0206) \n","EVAL: [600/2350] Elapsed 1m 56s (remain 5m 38s) Loss: 0.0255(0.0194) \n","EVAL: [700/2350] Elapsed 2m 15s (remain 5m 19s) Loss: 0.0280(0.0194) \n","EVAL: [800/2350] Elapsed 2m 35s (remain 5m 0s) Loss: 0.0000(0.0193) \n","EVAL: [900/2350] Elapsed 2m 54s (remain 4m 40s) Loss: 0.0010(0.0174) \n","EVAL: [1000/2350] Elapsed 3m 13s (remain 4m 21s) Loss: 0.0004(0.0158) \n","EVAL: [1100/2350] Elapsed 3m 33s (remain 4m 2s) Loss: 0.0390(0.0147) \n","EVAL: [1200/2350] Elapsed 3m 52s (remain 3m 42s) Loss: 0.0134(0.0136) \n","EVAL: [1300/2350] Elapsed 4m 12s (remain 3m 23s) Loss: 0.0054(0.0127) \n","EVAL: [1400/2350] Elapsed 4m 31s (remain 3m 3s) Loss: 0.0074(0.0123) \n","EVAL: [1500/2350] Elapsed 4m 50s (remain 2m 44s) Loss: 0.0000(0.0120) \n","EVAL: [1600/2350] Elapsed 5m 10s (remain 2m 25s) Loss: 0.0250(0.0117) \n","EVAL: [1700/2350] Elapsed 5m 29s (remain 2m 5s) Loss: 0.0081(0.0117) \n","EVAL: [1800/2350] Elapsed 5m 49s (remain 1m 46s) Loss: 0.0000(0.0115) \n","EVAL: [1900/2350] Elapsed 6m 8s (remain 1m 27s) Loss: 0.0000(0.0109) \n","EVAL: [2000/2350] Elapsed 6m 27s (remain 1m 7s) Loss: 0.0000(0.0104) \n","EVAL: [2100/2350] Elapsed 6m 46s (remain 0m 48s) Loss: 0.0000(0.0100) \n","EVAL: [2200/2350] Elapsed 7m 6s (remain 0m 28s) Loss: 0.0000(0.0095) \n","EVAL: [2300/2350] Elapsed 7m 25s (remain 0m 9s) Loss: 0.0000(0.0092) \n","EVAL: [2349/2350] Elapsed 7m 34s (remain 0m 0s) Loss: 0.0000(0.0090) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0056  avg_val_loss: 0.0090  time: 3531s\n","Epoch 3 - Score: 0.9511\n","Epoch 3 - Save Best Score: 0.9511 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/9397] Elapsed 0m 0s (remain 128m 48s) Loss: 0.0052(0.0052) Grad: 5617.0898  LR: 0.00000345  \n","Epoch: [4][100/9397] Elapsed 0m 33s (remain 51m 46s) Loss: 0.0003(0.0042) Grad: 7017.5693  LR: 0.00000342  \n","Epoch: [4][200/9397] Elapsed 1m 6s (remain 50m 34s) Loss: 0.0088(0.0050) Grad: 15667.7695  LR: 0.00000339  \n","Epoch: [4][300/9397] Elapsed 1m 38s (remain 49m 48s) Loss: 0.0013(0.0049) Grad: 10484.1211  LR: 0.00000336  \n","Epoch: [4][400/9397] Elapsed 2m 11s (remain 49m 9s) Loss: 0.0076(0.0047) Grad: 57631.7930  LR: 0.00000333  \n","Epoch: [4][500/9397] Elapsed 2m 43s (remain 48m 31s) Loss: 0.0028(0.0046) Grad: 25548.3984  LR: 0.00000330  \n","Epoch: [4][600/9397] Elapsed 3m 16s (remain 47m 57s) Loss: 0.0038(0.0044) Grad: 22023.7012  LR: 0.00000327  \n","Epoch: [4][700/9397] Elapsed 3m 49s (remain 47m 23s) Loss: 0.0217(0.0048) Grad: 59761.1289  LR: 0.00000323  \n","Epoch: [4][800/9397] Elapsed 4m 21s (remain 46m 49s) Loss: 0.0082(0.0046) Grad: 70858.1875  LR: 0.00000320  \n","Epoch: [4][900/9397] Elapsed 4m 54s (remain 46m 16s) Loss: 0.0005(0.0045) Grad: 8193.6230  LR: 0.00000317  \n","Epoch: [4][1000/9397] Elapsed 5m 27s (remain 45m 43s) Loss: 0.0010(0.0045) Grad: 9614.5020  LR: 0.00000314  \n","Epoch: [4][1100/9397] Elapsed 5m 59s (remain 45m 9s) Loss: 0.0001(0.0046) Grad: 946.6524  LR: 0.00000311  \n","Epoch: [4][1200/9397] Elapsed 6m 32s (remain 44m 36s) Loss: 0.0057(0.0047) Grad: 28561.6465  LR: 0.00000308  \n","Epoch: [4][1300/9397] Elapsed 7m 4s (remain 44m 3s) Loss: 0.0033(0.0047) Grad: 41568.4648  LR: 0.00000305  \n","Epoch: [4][1400/9397] Elapsed 7m 37s (remain 43m 30s) Loss: 0.0000(0.0047) Grad: 39.1306  LR: 0.00000302  \n","Epoch: [4][1500/9397] Elapsed 8m 10s (remain 42m 57s) Loss: 0.0008(0.0047) Grad: 7288.6885  LR: 0.00000299  \n","Epoch: [4][1600/9397] Elapsed 8m 42s (remain 42m 25s) Loss: 0.0038(0.0048) Grad: 9749.9600  LR: 0.00000296  \n","Epoch: [4][1700/9397] Elapsed 9m 15s (remain 41m 52s) Loss: 0.0000(0.0048) Grad: 233.8224  LR: 0.00000293  \n","Epoch: [4][1800/9397] Elapsed 9m 47s (remain 41m 19s) Loss: 0.0001(0.0048) Grad: 661.5039  LR: 0.00000290  \n","Epoch: [4][1900/9397] Elapsed 10m 20s (remain 40m 48s) Loss: 0.0024(0.0048) Grad: 16338.7910  LR: 0.00000286  \n","Epoch: [4][2000/9397] Elapsed 10m 53s (remain 40m 15s) Loss: 0.0161(0.0048) Grad: 78776.0312  LR: 0.00000283  \n","Epoch: [4][2100/9397] Elapsed 11m 26s (remain 39m 42s) Loss: 0.0052(0.0047) Grad: 196273.9688  LR: 0.00000280  \n","Epoch: [4][2200/9397] Elapsed 11m 58s (remain 39m 10s) Loss: 0.0040(0.0048) Grad: 122181.8281  LR: 0.00000277  \n","Epoch: [4][2300/9397] Elapsed 12m 31s (remain 38m 37s) Loss: 0.0006(0.0048) Grad: 41811.7617  LR: 0.00000274  \n","Epoch: [4][2400/9397] Elapsed 13m 4s (remain 38m 4s) Loss: 0.0021(0.0048) Grad: 38725.6602  LR: 0.00000272  \n","Epoch: [4][2500/9397] Elapsed 13m 36s (remain 37m 31s) Loss: 0.0063(0.0048) Grad: 78556.5938  LR: 0.00000269  \n","Epoch: [4][2600/9397] Elapsed 14m 9s (remain 36m 59s) Loss: 0.0008(0.0048) Grad: 19923.2109  LR: 0.00000266  \n","Epoch: [4][2700/9397] Elapsed 14m 41s (remain 36m 26s) Loss: 0.0000(0.0048) Grad: 492.0738  LR: 0.00000263  \n","Epoch: [4][2800/9397] Elapsed 15m 14s (remain 35m 53s) Loss: 0.0173(0.0048) Grad: 66520.0938  LR: 0.00000260  \n","Epoch: [4][2900/9397] Elapsed 15m 47s (remain 35m 21s) Loss: 0.0117(0.0048) Grad: 206649.4688  LR: 0.00000257  \n","Epoch: [4][3000/9397] Elapsed 16m 20s (remain 34m 48s) Loss: 0.0023(0.0048) Grad: 82789.0000  LR: 0.00000254  \n","Epoch: [4][3100/9397] Elapsed 16m 52s (remain 34m 16s) Loss: 0.0027(0.0049) Grad: 109931.7812  LR: 0.00000251  \n","Epoch: [4][3200/9397] Elapsed 17m 25s (remain 33m 43s) Loss: 0.0011(0.0049) Grad: 29317.5918  LR: 0.00000248  \n","Epoch: [4][3300/9397] Elapsed 17m 57s (remain 33m 10s) Loss: 0.0084(0.0049) Grad: 91833.1328  LR: 0.00000245  \n","Epoch: [4][3400/9397] Elapsed 18m 30s (remain 32m 37s) Loss: 0.0000(0.0049) Grad: 182.0508  LR: 0.00000242  \n","Epoch: [4][3500/9397] Elapsed 19m 3s (remain 32m 5s) Loss: 0.0000(0.0049) Grad: 1326.9900  LR: 0.00000239  \n","Epoch: [4][3600/9397] Elapsed 19m 35s (remain 31m 32s) Loss: 0.0002(0.0048) Grad: 9917.4580  LR: 0.00000237  \n","Epoch: [4][3700/9397] Elapsed 20m 8s (remain 30m 59s) Loss: 0.0001(0.0048) Grad: 895.0128  LR: 0.00000234  \n","Epoch: [4][3800/9397] Elapsed 20m 40s (remain 30m 26s) Loss: 0.0090(0.0048) Grad: 90310.3047  LR: 0.00000231  \n","Epoch: [4][3900/9397] Elapsed 21m 13s (remain 29m 54s) Loss: 0.0010(0.0048) Grad: 32324.6484  LR: 0.00000228  \n","Epoch: [4][4000/9397] Elapsed 21m 46s (remain 29m 21s) Loss: 0.0044(0.0048) Grad: 205777.4688  LR: 0.00000225  \n","Epoch: [4][4100/9397] Elapsed 22m 18s (remain 28m 48s) Loss: 0.0236(0.0049) Grad: 294864.6562  LR: 0.00000223  \n","Epoch: [4][4200/9397] Elapsed 22m 51s (remain 28m 16s) Loss: 0.0037(0.0048) Grad: 170427.3438  LR: 0.00000220  \n","Epoch: [4][4300/9397] Elapsed 23m 24s (remain 27m 43s) Loss: 0.0000(0.0049) Grad: 1043.1943  LR: 0.00000217  \n","Epoch: [4][4400/9397] Elapsed 23m 56s (remain 27m 10s) Loss: 0.0008(0.0048) Grad: 44619.8008  LR: 0.00000214  \n","Epoch: [4][4500/9397] Elapsed 24m 29s (remain 26m 38s) Loss: 0.0000(0.0048) Grad: 66.3779  LR: 0.00000212  \n","Epoch: [4][4600/9397] Elapsed 25m 1s (remain 26m 5s) Loss: 0.0017(0.0048) Grad: 191757.1406  LR: 0.00000209  \n","Epoch: [4][4700/9397] Elapsed 25m 34s (remain 25m 32s) Loss: 0.0295(0.0049) Grad: 95411.7109  LR: 0.00000206  \n","Epoch: [4][4800/9397] Elapsed 26m 6s (remain 24m 59s) Loss: 0.0028(0.0049) Grad: 41596.4141  LR: 0.00000203  \n","Epoch: [4][4900/9397] Elapsed 26m 39s (remain 24m 27s) Loss: 0.0040(0.0049) Grad: 43502.0039  LR: 0.00000201  \n","Epoch: [4][5000/9397] Elapsed 27m 11s (remain 23m 54s) Loss: 0.0000(0.0049) Grad: 135.3938  LR: 0.00000198  \n","Epoch: [4][5100/9397] Elapsed 27m 44s (remain 23m 21s) Loss: 0.0000(0.0049) Grad: 73.0999  LR: 0.00000195  \n","Epoch: [4][5200/9397] Elapsed 28m 17s (remain 22m 49s) Loss: 0.0001(0.0049) Grad: 4949.3984  LR: 0.00000193  \n","Epoch: [4][5300/9397] Elapsed 28m 49s (remain 22m 16s) Loss: 0.0003(0.0049) Grad: 15059.6191  LR: 0.00000190  \n","Epoch: [4][5400/9397] Elapsed 29m 22s (remain 21m 43s) Loss: 0.0031(0.0049) Grad: 60603.9688  LR: 0.00000187  \n","Epoch: [4][5500/9397] Elapsed 29m 54s (remain 21m 11s) Loss: 0.0040(0.0049) Grad: 11456.0693  LR: 0.00000185  \n","Epoch: [4][5600/9397] Elapsed 30m 27s (remain 20m 38s) Loss: 0.0000(0.0049) Grad: 82.9409  LR: 0.00000182  \n","Epoch: [4][5700/9397] Elapsed 30m 59s (remain 20m 5s) Loss: 0.0043(0.0049) Grad: 90321.4141  LR: 0.00000180  \n","Epoch: [4][5800/9397] Elapsed 31m 32s (remain 19m 33s) Loss: 0.0088(0.0049) Grad: 117044.7109  LR: 0.00000177  \n","Epoch: [4][5900/9397] Elapsed 32m 5s (remain 19m 0s) Loss: 0.0001(0.0049) Grad: 2624.7009  LR: 0.00000175  \n","Epoch: [4][6000/9397] Elapsed 32m 37s (remain 18m 27s) Loss: 0.0034(0.0049) Grad: 112741.7344  LR: 0.00000172  \n","Epoch: [4][6100/9397] Elapsed 33m 10s (remain 17m 55s) Loss: 0.0149(0.0049) Grad: 65097.0898  LR: 0.00000170  \n","Epoch: [4][6200/9397] Elapsed 33m 42s (remain 17m 22s) Loss: 0.0004(0.0049) Grad: 7790.9141  LR: 0.00000167  \n","Epoch: [4][6300/9397] Elapsed 34m 15s (remain 16m 49s) Loss: 0.0000(0.0050) Grad: 137.7406  LR: 0.00000165  \n","Epoch: [4][6400/9397] Elapsed 34m 47s (remain 16m 17s) Loss: 0.0473(0.0049) Grad: 374103.8750  LR: 0.00000162  \n","Epoch: [4][6500/9397] Elapsed 35m 20s (remain 15m 44s) Loss: 0.0000(0.0049) Grad: 186.1567  LR: 0.00000160  \n","Epoch: [4][6600/9397] Elapsed 35m 53s (remain 15m 12s) Loss: 0.0002(0.0049) Grad: 3539.6643  LR: 0.00000157  \n","Epoch: [4][6700/9397] Elapsed 36m 25s (remain 14m 39s) Loss: 0.0003(0.0050) Grad: 3247.3721  LR: 0.00000155  \n","Epoch: [4][6800/9397] Elapsed 36m 58s (remain 14m 6s) Loss: 0.0007(0.0050) Grad: 10938.4961  LR: 0.00000152  \n","Epoch: [4][6900/9397] Elapsed 37m 30s (remain 13m 34s) Loss: 0.0003(0.0050) Grad: 5511.0537  LR: 0.00000150  \n","Epoch: [4][7000/9397] Elapsed 38m 3s (remain 13m 1s) Loss: 0.0000(0.0050) Grad: 367.7203  LR: 0.00000148  \n","Epoch: [4][7100/9397] Elapsed 38m 35s (remain 12m 28s) Loss: 0.0011(0.0050) Grad: 21797.6934  LR: 0.00000145  \n","Epoch: [4][7200/9397] Elapsed 39m 8s (remain 11m 56s) Loss: 0.0156(0.0050) Grad: 25731.7285  LR: 0.00000143  \n","Epoch: [4][7300/9397] Elapsed 39m 40s (remain 11m 23s) Loss: 0.0044(0.0050) Grad: 7005.3628  LR: 0.00000141  \n","Epoch: [4][7400/9397] Elapsed 40m 13s (remain 10m 50s) Loss: 0.0001(0.0050) Grad: 1231.8958  LR: 0.00000138  \n","Epoch: [4][7500/9397] Elapsed 40m 45s (remain 10m 18s) Loss: 0.0062(0.0050) Grad: 35976.1562  LR: 0.00000136  \n","Epoch: [4][7600/9397] Elapsed 41m 18s (remain 9m 45s) Loss: 0.0092(0.0050) Grad: 19942.3320  LR: 0.00000134  \n","Epoch: [4][7700/9397] Elapsed 41m 51s (remain 9m 13s) Loss: 0.0000(0.0050) Grad: 249.0519  LR: 0.00000131  \n","Epoch: [4][7800/9397] Elapsed 42m 23s (remain 8m 40s) Loss: 0.0000(0.0049) Grad: 16.4756  LR: 0.00000129  \n","Epoch: [4][7900/9397] Elapsed 42m 56s (remain 8m 7s) Loss: 0.0002(0.0049) Grad: 5578.1748  LR: 0.00000127  \n","Epoch: [4][8000/9397] Elapsed 43m 28s (remain 7m 35s) Loss: 0.0018(0.0049) Grad: 11463.5820  LR: 0.00000125  \n","Epoch: [4][8100/9397] Elapsed 44m 1s (remain 7m 2s) Loss: 0.0000(0.0049) Grad: 952.7766  LR: 0.00000122  \n","Epoch: [4][8200/9397] Elapsed 44m 33s (remain 6m 29s) Loss: 0.0063(0.0049) Grad: 25751.8242  LR: 0.00000120  \n","Epoch: [4][8300/9397] Elapsed 45m 6s (remain 5m 57s) Loss: 0.0095(0.0049) Grad: 13726.8906  LR: 0.00000118  \n","Epoch: [4][8400/9397] Elapsed 45m 38s (remain 5m 24s) Loss: 0.0047(0.0049) Grad: 37799.7773  LR: 0.00000116  \n","Epoch: [4][8500/9397] Elapsed 46m 10s (remain 4m 52s) Loss: 0.0013(0.0049) Grad: 20045.6855  LR: 0.00000114  \n","Epoch: [4][8600/9397] Elapsed 46m 43s (remain 4m 19s) Loss: 0.0086(0.0049) Grad: 35330.7969  LR: 0.00000112  \n","Epoch: [4][8700/9397] Elapsed 47m 15s (remain 3m 46s) Loss: 0.0012(0.0049) Grad: 32348.4023  LR: 0.00000110  \n","Epoch: [4][8800/9397] Elapsed 47m 48s (remain 3m 14s) Loss: 0.0000(0.0049) Grad: 107.2260  LR: 0.00000108  \n","Epoch: [4][8900/9397] Elapsed 48m 20s (remain 2m 41s) Loss: 0.0045(0.0049) Grad: 100278.7422  LR: 0.00000105  \n","Epoch: [4][9000/9397] Elapsed 48m 53s (remain 2m 9s) Loss: 0.0002(0.0049) Grad: 3186.9060  LR: 0.00000103  \n","Epoch: [4][9100/9397] Elapsed 49m 25s (remain 1m 36s) Loss: 0.0005(0.0049) Grad: 14357.6240  LR: 0.00000101  \n","Epoch: [4][9200/9397] Elapsed 49m 58s (remain 1m 3s) Loss: 0.0075(0.0049) Grad: 57786.8633  LR: 0.00000099  \n","Epoch: [4][9300/9397] Elapsed 50m 30s (remain 0m 31s) Loss: 0.0016(0.0049) Grad: 32373.5742  LR: 0.00000097  \n","Epoch: [4][9396/9397] Elapsed 51m 1s (remain 0m 0s) Loss: 0.0111(0.0049) Grad: 169431.3594  LR: 0.00000096  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 16m 54s) Loss: 0.0002(0.0002) \n","EVAL: [100/2350] Elapsed 0m 19s (remain 7m 19s) Loss: 0.0122(0.0217) \n","EVAL: [200/2350] Elapsed 0m 38s (remain 6m 56s) Loss: 0.0000(0.0204) \n","EVAL: [300/2350] Elapsed 0m 58s (remain 6m 36s) Loss: 0.0056(0.0240) \n","EVAL: [400/2350] Elapsed 1m 17s (remain 6m 17s) Loss: 0.0143(0.0229) \n","EVAL: [500/2350] Elapsed 1m 36s (remain 5m 57s) Loss: 0.0070(0.0214) \n","EVAL: [600/2350] Elapsed 1m 56s (remain 5m 38s) Loss: 0.0224(0.0202) \n","EVAL: [700/2350] Elapsed 2m 15s (remain 5m 19s) Loss: 0.0266(0.0202) \n","EVAL: [800/2350] Elapsed 2m 35s (remain 4m 59s) Loss: 0.0000(0.0199) \n","EVAL: [900/2350] Elapsed 2m 54s (remain 4m 40s) Loss: 0.0012(0.0180) \n","EVAL: [1000/2350] Elapsed 3m 13s (remain 4m 21s) Loss: 0.0004(0.0164) \n","EVAL: [1100/2350] Elapsed 3m 33s (remain 4m 1s) Loss: 0.0393(0.0151) \n","EVAL: [1200/2350] Elapsed 3m 52s (remain 3m 42s) Loss: 0.0094(0.0141) \n","EVAL: [1300/2350] Elapsed 4m 11s (remain 3m 23s) Loss: 0.0049(0.0131) \n","EVAL: [1400/2350] Elapsed 4m 31s (remain 3m 3s) Loss: 0.0103(0.0127) \n","EVAL: [1500/2350] Elapsed 4m 50s (remain 2m 44s) Loss: 0.0000(0.0123) \n","EVAL: [1600/2350] Elapsed 5m 10s (remain 2m 25s) Loss: 0.0237(0.0120) \n","EVAL: [1700/2350] Elapsed 5m 29s (remain 2m 5s) Loss: 0.0132(0.0120) \n","EVAL: [1800/2350] Elapsed 5m 48s (remain 1m 46s) Loss: 0.0000(0.0118) \n","EVAL: [1900/2350] Elapsed 6m 8s (remain 1m 26s) Loss: 0.0000(0.0112) \n","EVAL: [2000/2350] Elapsed 6m 27s (remain 1m 7s) Loss: 0.0000(0.0107) \n","EVAL: [2100/2350] Elapsed 6m 46s (remain 0m 48s) Loss: 0.0000(0.0103) \n","EVAL: [2200/2350] Elapsed 7m 5s (remain 0m 28s) Loss: 0.0000(0.0099) \n","EVAL: [2300/2350] Elapsed 7m 25s (remain 0m 9s) Loss: 0.0000(0.0095) \n","EVAL: [2349/2350] Elapsed 7m 34s (remain 0m 0s) Loss: 0.0000(0.0094) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0049  avg_val_loss: 0.0094  time: 3557s\n","Epoch 4 - Score: 0.9518\n","Epoch 4 - Save Best Score: 0.9518 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/1906] Elapsed 0m 0s (remain 26m 11s) Loss: 0.0001(0.0001) Grad: 1971.2548  LR: 0.00000096  \n","Epoch: [5][100/1906] Elapsed 0m 33s (remain 9m 58s) Loss: 0.0172(0.0085) Grad: 60374.5312  LR: 0.00000094  \n","Epoch: [5][200/1906] Elapsed 1m 6s (remain 9m 20s) Loss: 0.0143(0.0098) Grad: 26323.6504  LR: 0.00000092  \n","Epoch: [5][300/1906] Elapsed 1m 38s (remain 8m 45s) Loss: 0.0004(0.0104) Grad: 2290.9126  LR: 0.00000090  \n","Epoch: [5][400/1906] Elapsed 2m 11s (remain 8m 12s) Loss: 0.0149(0.0100) Grad: 43678.1758  LR: 0.00000088  \n","Epoch: [5][500/1906] Elapsed 2m 43s (remain 7m 39s) Loss: 0.0013(0.0095) Grad: 14564.1484  LR: 0.00000086  \n","Epoch: [5][600/1906] Elapsed 3m 16s (remain 7m 5s) Loss: 0.0004(0.0093) Grad: 3899.7129  LR: 0.00000084  \n","Epoch: [5][700/1906] Elapsed 3m 48s (remain 6m 32s) Loss: 0.0270(0.0090) Grad: 17543.6230  LR: 0.00000082  \n","Epoch: [5][800/1906] Elapsed 4m 21s (remain 6m 0s) Loss: 0.0049(0.0088) Grad: 9675.3545  LR: 0.00000080  \n","Epoch: [5][900/1906] Elapsed 4m 53s (remain 5m 27s) Loss: 0.0000(0.0087) Grad: 50.3477  LR: 0.00000079  \n","Epoch: [5][1000/1906] Elapsed 5m 26s (remain 4m 54s) Loss: 0.0002(0.0085) Grad: 707.8932  LR: 0.00000077  \n","Epoch: [5][1100/1906] Elapsed 5m 58s (remain 4m 22s) Loss: 0.0186(0.0086) Grad: 62363.0859  LR: 0.00000075  \n","Epoch: [5][1200/1906] Elapsed 6m 31s (remain 3m 49s) Loss: 0.0022(0.0085) Grad: 15641.7412  LR: 0.00000073  \n","Epoch: [5][1300/1906] Elapsed 7m 3s (remain 3m 17s) Loss: 0.0001(0.0087) Grad: 389.1917  LR: 0.00000072  \n","Epoch: [5][1400/1906] Elapsed 7m 36s (remain 2m 44s) Loss: 0.0039(0.0086) Grad: 12339.3184  LR: 0.00000070  \n","Epoch: [5][1500/1906] Elapsed 8m 8s (remain 2m 11s) Loss: 0.0097(0.0085) Grad: 35796.4023  LR: 0.00000068  \n","Epoch: [5][1600/1906] Elapsed 8m 40s (remain 1m 39s) Loss: 0.0171(0.0084) Grad: 15965.0938  LR: 0.00000066  \n","Epoch: [5][1700/1906] Elapsed 9m 13s (remain 1m 6s) Loss: 0.0011(0.0083) Grad: 5796.0488  LR: 0.00000065  \n","Epoch: [5][1800/1906] Elapsed 9m 46s (remain 0m 34s) Loss: 0.0002(0.0082) Grad: 2725.3770  LR: 0.00000063  \n","Epoch: [5][1900/1906] Elapsed 10m 18s (remain 0m 1s) Loss: 0.0303(0.0081) Grad: 89059.7188  LR: 0.00000062  \n","Epoch: [5][1905/1906] Elapsed 10m 20s (remain 0m 0s) Loss: 0.0067(0.0081) Grad: 26721.5430  LR: 0.00000061  \n","EVAL: [0/477] Elapsed 0m 0s (remain 3m 23s) Loss: 0.0007(0.0007) \n","EVAL: [100/477] Elapsed 0m 19s (remain 1m 13s) Loss: 0.0118(0.0166) \n","EVAL: [200/477] Elapsed 0m 38s (remain 0m 53s) Loss: 0.0000(0.0156) \n","EVAL: [300/477] Elapsed 0m 58s (remain 0m 33s) Loss: 0.0026(0.0185) \n","EVAL: [400/477] Elapsed 1m 17s (remain 0m 14s) Loss: 0.0108(0.0177) \n","EVAL: [476/477] Elapsed 1m 31s (remain 0m 0s) Loss: 0.0062(0.0165) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0081  avg_val_loss: 0.0165  time: 715s\n","Epoch 5 - Score: 0.8849\n","========== fold: 0 result ==========\n","Score: 0.9518\n","========== fold: 1 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/9397] Elapsed 0m 0s (remain 96m 23s) Loss: 0.6756(0.6756) Grad: inf  LR: 0.00001000  \n","Epoch: [1][100/9397] Elapsed 0m 33s (remain 50m 43s) Loss: 0.0458(0.1268) Grad: 2704.1565  LR: 0.00001000  \n","Epoch: [1][200/9397] Elapsed 1m 5s (remain 50m 6s) Loss: 0.0329(0.0833) Grad: 6798.9556  LR: 0.00001000  \n","Epoch: [1][300/9397] Elapsed 1m 38s (remain 49m 24s) Loss: 0.0307(0.0655) Grad: 5289.9844  LR: 0.00001000  \n","Epoch: [1][400/9397] Elapsed 2m 10s (remain 48m 50s) Loss: 0.0255(0.0549) Grad: 7109.9517  LR: 0.00001000  \n","Epoch: [1][500/9397] Elapsed 2m 43s (remain 48m 14s) Loss: 0.0126(0.0475) Grad: 1325.2186  LR: 0.00001000  \n","Epoch: [1][600/9397] Elapsed 3m 15s (remain 47m 41s) Loss: 0.0047(0.0430) Grad: 1108.8176  LR: 0.00001000  \n","Epoch: [1][700/9397] Elapsed 3m 47s (remain 47m 7s) Loss: 0.0128(0.0396) Grad: 7496.9507  LR: 0.00000999  \n","Epoch: [1][800/9397] Elapsed 4m 20s (remain 46m 34s) Loss: 0.0360(0.0370) Grad: 3110.5815  LR: 0.00000999  \n","Epoch: [1][900/9397] Elapsed 4m 53s (remain 46m 3s) Loss: 0.0376(0.0347) Grad: 4637.8975  LR: 0.00000999  \n","Epoch: [1][1000/9397] Elapsed 5m 25s (remain 45m 30s) Loss: 0.0164(0.0328) Grad: 3088.0139  LR: 0.00000999  \n","Epoch: [1][1100/9397] Elapsed 5m 58s (remain 44m 59s) Loss: 0.0017(0.0310) Grad: 442.2647  LR: 0.00000999  \n","Epoch: [1][1200/9397] Elapsed 6m 30s (remain 44m 26s) Loss: 0.0076(0.0295) Grad: 1373.4823  LR: 0.00000998  \n","Epoch: [1][1300/9397] Elapsed 7m 3s (remain 43m 53s) Loss: 0.0219(0.0283) Grad: 3484.8704  LR: 0.00000998  \n","Epoch: [1][1400/9397] Elapsed 7m 35s (remain 43m 20s) Loss: 0.0049(0.0272) Grad: 2075.6580  LR: 0.00000998  \n","Epoch: [1][1500/9397] Elapsed 8m 8s (remain 42m 47s) Loss: 0.0098(0.0262) Grad: 2144.9031  LR: 0.00000997  \n","Epoch: [1][1600/9397] Elapsed 8m 40s (remain 42m 15s) Loss: 0.0138(0.0254) Grad: 1302.9486  LR: 0.00000997  \n","Epoch: [1][1700/9397] Elapsed 9m 13s (remain 41m 42s) Loss: 0.0385(0.0247) Grad: 4436.6836  LR: 0.00000997  \n","Epoch: [1][1800/9397] Elapsed 9m 45s (remain 41m 10s) Loss: 0.0060(0.0240) Grad: 785.7155  LR: 0.00000996  \n","Epoch: [1][1900/9397] Elapsed 10m 18s (remain 40m 38s) Loss: 0.0178(0.0233) Grad: 2277.6550  LR: 0.00000996  \n","Epoch: [1][2000/9397] Elapsed 10m 50s (remain 40m 5s) Loss: 0.0041(0.0228) Grad: 520.2619  LR: 0.00000996  \n","Epoch: [1][2100/9397] Elapsed 11m 23s (remain 39m 33s) Loss: 0.0182(0.0222) Grad: 4795.2661  LR: 0.00000995  \n","Epoch: [1][2200/9397] Elapsed 11m 55s (remain 39m 0s) Loss: 0.0093(0.0217) Grad: 6857.1470  LR: 0.00000995  \n","Epoch: [1][2300/9397] Elapsed 12m 28s (remain 38m 28s) Loss: 0.0025(0.0213) Grad: 750.2159  LR: 0.00000994  \n","Epoch: [1][2400/9397] Elapsed 13m 0s (remain 37m 55s) Loss: 0.0017(0.0209) Grad: 1244.8427  LR: 0.00000994  \n","Epoch: [1][2500/9397] Elapsed 13m 33s (remain 37m 22s) Loss: 0.0087(0.0205) Grad: 2156.1101  LR: 0.00000993  \n","Epoch: [1][2600/9397] Elapsed 14m 5s (remain 36m 50s) Loss: 0.0012(0.0201) Grad: 707.1921  LR: 0.00000992  \n","Epoch: [1][2700/9397] Elapsed 14m 38s (remain 36m 17s) Loss: 0.0079(0.0197) Grad: 5293.8311  LR: 0.00000992  \n","Epoch: [1][2800/9397] Elapsed 15m 10s (remain 35m 45s) Loss: 0.0617(0.0194) Grad: 7964.6343  LR: 0.00000991  \n","Epoch: [1][2900/9397] Elapsed 15m 43s (remain 35m 12s) Loss: 0.0103(0.0191) Grad: 6435.7690  LR: 0.00000991  \n","Epoch: [1][3000/9397] Elapsed 16m 16s (remain 34m 40s) Loss: 0.0110(0.0188) Grad: 2199.9285  LR: 0.00000990  \n","Epoch: [1][3100/9397] Elapsed 16m 48s (remain 34m 7s) Loss: 0.0005(0.0185) Grad: 181.2858  LR: 0.00000989  \n","Epoch: [1][3200/9397] Elapsed 17m 21s (remain 33m 35s) Loss: 0.0047(0.0182) Grad: 1039.5725  LR: 0.00000989  \n","Epoch: [1][3300/9397] Elapsed 17m 53s (remain 33m 2s) Loss: 0.0005(0.0180) Grad: 303.3996  LR: 0.00000988  \n","Epoch: [1][3400/9397] Elapsed 18m 26s (remain 32m 30s) Loss: 0.0058(0.0177) Grad: 1365.7836  LR: 0.00000987  \n","Epoch: [1][3500/9397] Elapsed 18m 58s (remain 31m 57s) Loss: 0.0043(0.0175) Grad: 845.1141  LR: 0.00000986  \n","Epoch: [1][3600/9397] Elapsed 19m 31s (remain 31m 25s) Loss: 0.0078(0.0173) Grad: 7499.7900  LR: 0.00000986  \n","Epoch: [1][3700/9397] Elapsed 20m 3s (remain 30m 52s) Loss: 0.0110(0.0171) Grad: 2536.5334  LR: 0.00000985  \n","Epoch: [1][3800/9397] Elapsed 20m 36s (remain 30m 19s) Loss: 0.0130(0.0169) Grad: 3850.4810  LR: 0.00000984  \n","Epoch: [1][3900/9397] Elapsed 21m 8s (remain 29m 47s) Loss: 0.0095(0.0168) Grad: 1712.4745  LR: 0.00000983  \n","Epoch: [1][4000/9397] Elapsed 21m 41s (remain 29m 14s) Loss: 0.0020(0.0166) Grad: 809.9283  LR: 0.00000982  \n","Epoch: [1][4100/9397] Elapsed 22m 13s (remain 28m 42s) Loss: 0.0076(0.0164) Grad: 4428.2637  LR: 0.00000981  \n","Epoch: [1][4200/9397] Elapsed 22m 46s (remain 28m 9s) Loss: 0.0002(0.0163) Grad: 236.0267  LR: 0.00000980  \n","Epoch: [1][4300/9397] Elapsed 23m 18s (remain 27m 36s) Loss: 0.0038(0.0161) Grad: 6821.8145  LR: 0.00000979  \n","Epoch: [1][4400/9397] Elapsed 23m 51s (remain 27m 4s) Loss: 0.0056(0.0160) Grad: 4503.4619  LR: 0.00000979  \n","Epoch: [1][4500/9397] Elapsed 24m 23s (remain 26m 31s) Loss: 0.0074(0.0158) Grad: 13792.0596  LR: 0.00000978  \n","Epoch: [1][4600/9397] Elapsed 24m 55s (remain 25m 59s) Loss: 0.0168(0.0157) Grad: 9604.4756  LR: 0.00000977  \n","Epoch: [1][4700/9397] Elapsed 25m 28s (remain 25m 26s) Loss: 0.0142(0.0155) Grad: 8447.8311  LR: 0.00000976  \n","Epoch: [1][4800/9397] Elapsed 26m 0s (remain 24m 54s) Loss: 0.0001(0.0153) Grad: 95.1348  LR: 0.00000974  \n","Epoch: [1][4900/9397] Elapsed 26m 33s (remain 24m 21s) Loss: 0.0479(0.0152) Grad: 5150.7134  LR: 0.00000973  \n","Epoch: [1][5000/9397] Elapsed 27m 5s (remain 23m 49s) Loss: 0.0214(0.0151) Grad: 12533.2246  LR: 0.00000972  \n","Epoch: [1][5100/9397] Elapsed 27m 38s (remain 23m 16s) Loss: 0.0082(0.0150) Grad: 6448.5166  LR: 0.00000971  \n","Epoch: [1][5200/9397] Elapsed 28m 10s (remain 22m 43s) Loss: 0.0010(0.0149) Grad: 1483.9398  LR: 0.00000970  \n","Epoch: [1][5300/9397] Elapsed 28m 43s (remain 22m 11s) Loss: 0.0002(0.0148) Grad: 279.9539  LR: 0.00000969  \n","Epoch: [1][5400/9397] Elapsed 29m 15s (remain 21m 38s) Loss: 0.0259(0.0147) Grad: 10720.4229  LR: 0.00000968  \n","Epoch: [1][5500/9397] Elapsed 29m 47s (remain 21m 6s) Loss: 0.0001(0.0146) Grad: 82.8477  LR: 0.00000967  \n","Epoch: [1][5600/9397] Elapsed 30m 20s (remain 20m 33s) Loss: 0.0158(0.0145) Grad: 7407.8633  LR: 0.00000965  \n","Epoch: [1][5700/9397] Elapsed 30m 52s (remain 20m 1s) Loss: 0.0141(0.0144) Grad: 8457.0010  LR: 0.00000964  \n","Epoch: [1][5800/9397] Elapsed 31m 25s (remain 19m 28s) Loss: 0.0041(0.0143) Grad: 2768.3262  LR: 0.00000963  \n","Epoch: [1][5900/9397] Elapsed 31m 57s (remain 18m 56s) Loss: 0.0124(0.0142) Grad: 5942.2085  LR: 0.00000962  \n","Epoch: [1][6000/9397] Elapsed 32m 30s (remain 18m 23s) Loss: 0.0116(0.0141) Grad: 3293.3340  LR: 0.00000960  \n","Epoch: [1][6100/9397] Elapsed 33m 2s (remain 17m 51s) Loss: 0.0021(0.0141) Grad: 5496.6279  LR: 0.00000959  \n","Epoch: [1][6200/9397] Elapsed 33m 34s (remain 17m 18s) Loss: 0.0088(0.0140) Grad: 13065.0859  LR: 0.00000958  \n","Epoch: [1][6300/9397] Elapsed 34m 7s (remain 16m 45s) Loss: 0.0189(0.0139) Grad: 19167.8223  LR: 0.00000956  \n","Epoch: [1][6400/9397] Elapsed 34m 39s (remain 16m 13s) Loss: 0.0004(0.0138) Grad: 1883.8264  LR: 0.00000955  \n","Epoch: [1][6500/9397] Elapsed 35m 12s (remain 15m 40s) Loss: 0.0000(0.0138) Grad: 211.2011  LR: 0.00000954  \n","Epoch: [1][6600/9397] Elapsed 35m 44s (remain 15m 8s) Loss: 0.0010(0.0137) Grad: 2473.4575  LR: 0.00000952  \n","Epoch: [1][6700/9397] Elapsed 36m 17s (remain 14m 35s) Loss: 0.0001(0.0136) Grad: 1004.6156  LR: 0.00000951  \n","Epoch: [1][6800/9397] Elapsed 36m 49s (remain 14m 3s) Loss: 0.0142(0.0136) Grad: 12164.5391  LR: 0.00000949  \n","Epoch: [1][6900/9397] Elapsed 37m 22s (remain 13m 30s) Loss: 0.0032(0.0136) Grad: 5910.6519  LR: 0.00000948  \n","Epoch: [1][7000/9397] Elapsed 37m 54s (remain 12m 58s) Loss: 0.0347(0.0135) Grad: 22832.3301  LR: 0.00000946  \n","Epoch: [1][7100/9397] Elapsed 38m 27s (remain 12m 25s) Loss: 0.0044(0.0134) Grad: 7184.4722  LR: 0.00000945  \n","Epoch: [1][7200/9397] Elapsed 38m 59s (remain 11m 53s) Loss: 0.0166(0.0134) Grad: 9995.8223  LR: 0.00000943  \n","Epoch: [1][7300/9397] Elapsed 39m 32s (remain 11m 20s) Loss: 0.0087(0.0133) Grad: 11451.4971  LR: 0.00000942  \n","Epoch: [1][7400/9397] Elapsed 40m 4s (remain 10m 48s) Loss: 0.0024(0.0133) Grad: 5943.9639  LR: 0.00000940  \n","Epoch: [1][7500/9397] Elapsed 40m 36s (remain 10m 15s) Loss: 0.0000(0.0132) Grad: 107.3049  LR: 0.00000938  \n","Epoch: [1][7600/9397] Elapsed 41m 9s (remain 9m 43s) Loss: 0.0041(0.0131) Grad: 6041.8984  LR: 0.00000937  \n","Epoch: [1][7700/9397] Elapsed 41m 41s (remain 9m 10s) Loss: 0.0015(0.0130) Grad: 6104.1953  LR: 0.00000935  \n","Epoch: [1][7800/9397] Elapsed 42m 14s (remain 8m 38s) Loss: 0.0127(0.0129) Grad: 84140.1250  LR: 0.00000934  \n","Epoch: [1][7900/9397] Elapsed 42m 46s (remain 8m 6s) Loss: 0.0034(0.0129) Grad: 9278.9932  LR: 0.00000932  \n","Epoch: [1][8000/9397] Elapsed 43m 19s (remain 7m 33s) Loss: 0.0114(0.0128) Grad: 11198.3906  LR: 0.00000930  \n","Epoch: [1][8100/9397] Elapsed 43m 51s (remain 7m 1s) Loss: 0.0086(0.0128) Grad: 39983.3359  LR: 0.00000928  \n","Epoch: [1][8200/9397] Elapsed 44m 24s (remain 6m 28s) Loss: 0.0057(0.0127) Grad: 21147.0156  LR: 0.00000927  \n","Epoch: [1][8300/9397] Elapsed 44m 56s (remain 5m 56s) Loss: 0.0020(0.0127) Grad: 11045.0156  LR: 0.00000925  \n","Epoch: [1][8400/9397] Elapsed 45m 29s (remain 5m 23s) Loss: 0.0015(0.0126) Grad: 9404.1035  LR: 0.00000923  \n","Epoch: [1][8500/9397] Elapsed 46m 1s (remain 4m 51s) Loss: 0.0021(0.0126) Grad: 7536.1455  LR: 0.00000921  \n","Epoch: [1][8600/9397] Elapsed 46m 34s (remain 4m 18s) Loss: 0.0019(0.0125) Grad: 8330.0713  LR: 0.00000920  \n","Epoch: [1][8700/9397] Elapsed 47m 6s (remain 3m 46s) Loss: 0.0044(0.0125) Grad: 16579.2168  LR: 0.00000918  \n","Epoch: [1][8800/9397] Elapsed 47m 39s (remain 3m 13s) Loss: 0.0058(0.0124) Grad: 11160.9492  LR: 0.00000916  \n","Epoch: [1][8900/9397] Elapsed 48m 12s (remain 2m 41s) Loss: 0.0126(0.0124) Grad: 77340.9453  LR: 0.00000914  \n","Epoch: [1][9000/9397] Elapsed 48m 45s (remain 2m 8s) Loss: 0.0053(0.0123) Grad: 9751.1035  LR: 0.00000912  \n","Epoch: [1][9100/9397] Elapsed 49m 17s (remain 1m 36s) Loss: 0.0058(0.0123) Grad: 14423.5664  LR: 0.00000910  \n","Epoch: [1][9200/9397] Elapsed 49m 50s (remain 1m 3s) Loss: 0.0119(0.0122) Grad: 12727.7285  LR: 0.00000908  \n","Epoch: [1][9300/9397] Elapsed 50m 22s (remain 0m 31s) Loss: 0.0279(0.0122) Grad: 51400.6641  LR: 0.00000906  \n","Epoch: [1][9396/9397] Elapsed 50m 53s (remain 0m 0s) Loss: 0.0386(0.0122) Grad: 90096.6094  LR: 0.00000905  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 18m 31s) Loss: 0.0025(0.0025) \n","EVAL: [100/2350] Elapsed 0m 19s (remain 7m 19s) Loss: 0.0203(0.0138) \n","EVAL: [200/2350] Elapsed 0m 39s (remain 6m 57s) Loss: 0.0000(0.0127) \n","EVAL: [300/2350] Elapsed 0m 58s (remain 6m 37s) Loss: 0.0028(0.0158) \n","EVAL: [400/2350] Elapsed 1m 17s (remain 6m 17s) Loss: 0.0232(0.0150) \n","EVAL: [500/2350] Elapsed 1m 36s (remain 5m 57s) Loss: 0.0556(0.0150) \n","EVAL: [600/2350] Elapsed 1m 56s (remain 5m 38s) Loss: 0.0193(0.0150) \n","EVAL: [700/2350] Elapsed 2m 15s (remain 5m 19s) Loss: 0.0438(0.0164) \n","EVAL: [800/2350] Elapsed 2m 34s (remain 4m 59s) Loss: 0.0000(0.0171) \n","EVAL: [900/2350] Elapsed 2m 54s (remain 4m 40s) Loss: 0.0026(0.0154) \n","EVAL: [1000/2350] Elapsed 3m 13s (remain 4m 21s) Loss: 0.0012(0.0141) \n","EVAL: [1100/2350] Elapsed 3m 33s (remain 4m 1s) Loss: 0.0001(0.0130) \n","EVAL: [1200/2350] Elapsed 3m 52s (remain 3m 42s) Loss: 0.0001(0.0121) \n","EVAL: [1300/2350] Elapsed 4m 11s (remain 3m 22s) Loss: 0.0001(0.0114) \n","EVAL: [1400/2350] Elapsed 4m 31s (remain 3m 3s) Loss: 0.0138(0.0112) \n","EVAL: [1500/2350] Elapsed 4m 50s (remain 2m 44s) Loss: 0.0022(0.0109) \n","EVAL: [1600/2350] Elapsed 5m 9s (remain 2m 24s) Loss: 0.0051(0.0108) \n","EVAL: [1700/2350] Elapsed 5m 29s (remain 2m 5s) Loss: 0.0161(0.0109) \n","EVAL: [1800/2350] Elapsed 5m 48s (remain 1m 46s) Loss: 0.0000(0.0107) \n","EVAL: [1900/2350] Elapsed 6m 7s (remain 1m 26s) Loss: 0.0000(0.0102) \n","EVAL: [2000/2350] Elapsed 6m 27s (remain 1m 7s) Loss: 0.0000(0.0097) \n","EVAL: [2100/2350] Elapsed 6m 46s (remain 0m 48s) Loss: 0.0000(0.0093) \n","EVAL: [2200/2350] Elapsed 7m 5s (remain 0m 28s) Loss: 0.0000(0.0089) \n","EVAL: [2300/2350] Elapsed 7m 25s (remain 0m 9s) Loss: 0.0000(0.0085) \n","EVAL: [2349/2350] Elapsed 7m 34s (remain 0m 0s) Loss: 0.0000(0.0084) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0122  avg_val_loss: 0.0084  time: 3521s\n","Epoch 1 - Score: 0.9436\n","Epoch 1 - Save Best Score: 0.9436 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/9397] Elapsed 0m 0s (remain 136m 9s) Loss: 0.0040(0.0040) Grad: 25383.4492  LR: 0.00000904  \n","Epoch: [2][100/9397] Elapsed 0m 33s (remain 51m 33s) Loss: 0.0047(0.0073) Grad: 13061.3594  LR: 0.00000903  \n","Epoch: [2][200/9397] Elapsed 1m 6s (remain 50m 28s) Loss: 0.0011(0.0061) Grad: 11922.2295  LR: 0.00000901  \n","Epoch: [2][300/9397] Elapsed 1m 38s (remain 49m 42s) Loss: 0.0043(0.0063) Grad: 38995.0352  LR: 0.00000899  \n","Epoch: [2][400/9397] Elapsed 2m 11s (remain 49m 2s) Loss: 0.0023(0.0070) Grad: 27046.0859  LR: 0.00000896  \n","Epoch: [2][500/9397] Elapsed 2m 43s (remain 48m 28s) Loss: 0.0079(0.0069) Grad: 43749.6367  LR: 0.00000894  \n","Epoch: [2][600/9397] Elapsed 3m 16s (remain 47m 53s) Loss: 0.0025(0.0070) Grad: 12372.8291  LR: 0.00000892  \n","Epoch: [2][700/9397] Elapsed 3m 48s (remain 47m 18s) Loss: 0.0024(0.0072) Grad: 27998.6465  LR: 0.00000890  \n","Epoch: [2][800/9397] Elapsed 4m 21s (remain 46m 43s) Loss: 0.0123(0.0071) Grad: 35336.9219  LR: 0.00000888  \n","Epoch: [2][900/9397] Elapsed 4m 53s (remain 46m 10s) Loss: 0.0233(0.0071) Grad: 67788.2812  LR: 0.00000886  \n","Epoch: [2][1000/9397] Elapsed 5m 26s (remain 45m 37s) Loss: 0.0001(0.0071) Grad: 543.5803  LR: 0.00000884  \n","Epoch: [2][1100/9397] Elapsed 5m 58s (remain 45m 4s) Loss: 0.0000(0.0071) Grad: 82.6833  LR: 0.00000882  \n","Epoch: [2][1200/9397] Elapsed 6m 31s (remain 44m 31s) Loss: 0.0019(0.0071) Grad: 3417.5095  LR: 0.00000880  \n","Epoch: [2][1300/9397] Elapsed 7m 4s (remain 43m 58s) Loss: 0.0049(0.0070) Grad: 19309.7266  LR: 0.00000877  \n","Epoch: [2][1400/9397] Elapsed 7m 36s (remain 43m 26s) Loss: 0.0000(0.0069) Grad: 89.3939  LR: 0.00000875  \n","Epoch: [2][1500/9397] Elapsed 8m 9s (remain 42m 53s) Loss: 0.0062(0.0069) Grad: 20764.2129  LR: 0.00000873  \n","Epoch: [2][1600/9397] Elapsed 8m 41s (remain 42m 21s) Loss: 0.0001(0.0070) Grad: 213.0593  LR: 0.00000871  \n","Epoch: [2][1700/9397] Elapsed 9m 14s (remain 41m 48s) Loss: 0.0047(0.0069) Grad: 17090.3105  LR: 0.00000869  \n","Epoch: [2][1800/9397] Elapsed 9m 47s (remain 41m 16s) Loss: 0.0056(0.0069) Grad: 29760.5605  LR: 0.00000866  \n","Epoch: [2][1900/9397] Elapsed 10m 19s (remain 40m 43s) Loss: 0.0110(0.0069) Grad: 20112.6367  LR: 0.00000864  \n","Epoch: [2][2000/9397] Elapsed 10m 52s (remain 40m 10s) Loss: 0.0000(0.0068) Grad: 173.4544  LR: 0.00000862  \n","Epoch: [2][2100/9397] Elapsed 11m 25s (remain 39m 39s) Loss: 0.0009(0.0067) Grad: 16259.4863  LR: 0.00000859  \n","Epoch: [2][2200/9397] Elapsed 11m 57s (remain 39m 6s) Loss: 0.0179(0.0067) Grad: 72349.1953  LR: 0.00000857  \n","Epoch: [2][2300/9397] Elapsed 12m 30s (remain 38m 33s) Loss: 0.0097(0.0068) Grad: 67035.3203  LR: 0.00000855  \n","Epoch: [2][2400/9397] Elapsed 13m 2s (remain 38m 0s) Loss: 0.0000(0.0068) Grad: 123.3334  LR: 0.00000852  \n","Epoch: [2][2500/9397] Elapsed 13m 35s (remain 37m 28s) Loss: 0.0000(0.0068) Grad: 607.5955  LR: 0.00000850  \n","Epoch: [2][2600/9397] Elapsed 14m 7s (remain 36m 55s) Loss: 0.0000(0.0068) Grad: 324.2230  LR: 0.00000848  \n","Epoch: [2][2700/9397] Elapsed 14m 40s (remain 36m 22s) Loss: 0.0078(0.0068) Grad: 31045.0254  LR: 0.00000845  \n","Epoch: [2][2800/9397] Elapsed 15m 13s (remain 35m 50s) Loss: 0.0032(0.0068) Grad: 46961.9648  LR: 0.00000843  \n","Epoch: [2][2900/9397] Elapsed 15m 45s (remain 35m 17s) Loss: 0.0073(0.0068) Grad: 34641.0078  LR: 0.00000840  \n","Epoch: [2][3000/9397] Elapsed 16m 18s (remain 34m 44s) Loss: 0.0009(0.0068) Grad: 25452.3184  LR: 0.00000838  \n","Epoch: [2][3100/9397] Elapsed 16m 50s (remain 34m 12s) Loss: 0.0030(0.0068) Grad: 25053.4004  LR: 0.00000835  \n","Epoch: [2][3200/9397] Elapsed 17m 23s (remain 33m 39s) Loss: 0.0001(0.0068) Grad: 3236.8232  LR: 0.00000833  \n","Epoch: [2][3300/9397] Elapsed 17m 56s (remain 33m 7s) Loss: 0.0004(0.0068) Grad: 10709.5869  LR: 0.00000830  \n","Epoch: [2][3400/9397] Elapsed 18m 28s (remain 32m 34s) Loss: 0.0017(0.0068) Grad: 32100.5645  LR: 0.00000828  \n","Epoch: [2][3500/9397] Elapsed 19m 1s (remain 32m 1s) Loss: 0.0003(0.0068) Grad: 4389.6904  LR: 0.00000825  \n","Epoch: [2][3600/9397] Elapsed 19m 33s (remain 31m 29s) Loss: 0.0058(0.0068) Grad: 42321.4023  LR: 0.00000823  \n","Epoch: [2][3700/9397] Elapsed 20m 6s (remain 30m 56s) Loss: 0.0000(0.0068) Grad: 180.7477  LR: 0.00000820  \n","Epoch: [2][3800/9397] Elapsed 20m 38s (remain 30m 23s) Loss: 0.0114(0.0068) Grad: 47329.9336  LR: 0.00000818  \n","Epoch: [2][3900/9397] Elapsed 21m 11s (remain 29m 51s) Loss: 0.0021(0.0068) Grad: 23308.8281  LR: 0.00000815  \n","Epoch: [2][4000/9397] Elapsed 21m 43s (remain 29m 18s) Loss: 0.0159(0.0068) Grad: 198879.6406  LR: 0.00000812  \n","Epoch: [2][4100/9397] Elapsed 22m 16s (remain 28m 46s) Loss: 0.0080(0.0068) Grad: 106355.8828  LR: 0.00000810  \n","Epoch: [2][4200/9397] Elapsed 22m 49s (remain 28m 13s) Loss: 0.0021(0.0067) Grad: 32163.7207  LR: 0.00000807  \n","Epoch: [2][4300/9397] Elapsed 23m 21s (remain 27m 40s) Loss: 0.0000(0.0068) Grad: 423.1379  LR: 0.00000805  \n","Epoch: [2][4400/9397] Elapsed 23m 54s (remain 27m 8s) Loss: 0.0013(0.0067) Grad: 42848.3906  LR: 0.00000802  \n","Epoch: [2][4500/9397] Elapsed 24m 26s (remain 26m 35s) Loss: 0.0000(0.0068) Grad: 284.6785  LR: 0.00000799  \n","Epoch: [2][4600/9397] Elapsed 24m 59s (remain 26m 3s) Loss: 0.0108(0.0067) Grad: 93552.9062  LR: 0.00000797  \n","Epoch: [2][4700/9397] Elapsed 25m 32s (remain 25m 30s) Loss: 0.0074(0.0068) Grad: 65962.8359  LR: 0.00000794  \n","Epoch: [2][4800/9397] Elapsed 26m 4s (remain 24m 58s) Loss: 0.0095(0.0067) Grad: 78665.1641  LR: 0.00000791  \n","Epoch: [2][4900/9397] Elapsed 26m 37s (remain 24m 25s) Loss: 0.0019(0.0067) Grad: 7329.1562  LR: 0.00000788  \n","Epoch: [2][5000/9397] Elapsed 27m 10s (remain 23m 52s) Loss: 0.0062(0.0068) Grad: 67439.4219  LR: 0.00000786  \n","Epoch: [2][5100/9397] Elapsed 27m 42s (remain 23m 20s) Loss: 0.0001(0.0068) Grad: 3633.7517  LR: 0.00000783  \n","Epoch: [2][5200/9397] Elapsed 28m 15s (remain 22m 47s) Loss: 0.0011(0.0068) Grad: 31033.2383  LR: 0.00000780  \n","Epoch: [2][5300/9397] Elapsed 28m 47s (remain 22m 15s) Loss: 0.0020(0.0068) Grad: 24297.5508  LR: 0.00000777  \n","Epoch: [2][5400/9397] Elapsed 29m 20s (remain 21m 42s) Loss: 0.0008(0.0068) Grad: 19344.1426  LR: 0.00000775  \n","Epoch: [2][5500/9397] Elapsed 29m 53s (remain 21m 9s) Loss: 0.0146(0.0068) Grad: 123726.2656  LR: 0.00000772  \n","Epoch: [2][5600/9397] Elapsed 30m 25s (remain 20m 37s) Loss: 0.0044(0.0068) Grad: 56886.9570  LR: 0.00000769  \n","Epoch: [2][5700/9397] Elapsed 30m 58s (remain 20m 4s) Loss: 0.0007(0.0067) Grad: 10162.5049  LR: 0.00000766  \n","Epoch: [2][5800/9397] Elapsed 31m 30s (remain 19m 32s) Loss: 0.0040(0.0068) Grad: 24415.0508  LR: 0.00000763  \n","Epoch: [2][5900/9397] Elapsed 32m 3s (remain 18m 59s) Loss: 0.0039(0.0067) Grad: 61700.7148  LR: 0.00000760  \n","Epoch: [2][6000/9397] Elapsed 32m 35s (remain 18m 26s) Loss: 0.0058(0.0067) Grad: 72677.3828  LR: 0.00000758  \n","Epoch: [2][6100/9397] Elapsed 33m 8s (remain 17m 54s) Loss: 0.0160(0.0067) Grad: 61156.0742  LR: 0.00000755  \n","Epoch: [2][6200/9397] Elapsed 33m 41s (remain 17m 21s) Loss: 0.0083(0.0067) Grad: 291087.9688  LR: 0.00000752  \n","Epoch: [2][6300/9397] Elapsed 34m 14s (remain 16m 49s) Loss: 0.0033(0.0067) Grad: 98239.1641  LR: 0.00000749  \n","Epoch: [2][6400/9397] Elapsed 34m 46s (remain 16m 16s) Loss: 0.0300(0.0067) Grad: 167585.7812  LR: 0.00000746  \n","Epoch: [2][6500/9397] Elapsed 35m 19s (remain 15m 44s) Loss: 0.0065(0.0067) Grad: 244900.0469  LR: 0.00000743  \n","Epoch: [2][6600/9397] Elapsed 35m 51s (remain 15m 11s) Loss: 0.0029(0.0067) Grad: 44165.5742  LR: 0.00000740  \n","Epoch: [2][6700/9397] Elapsed 36m 24s (remain 14m 38s) Loss: 0.0000(0.0067) Grad: 853.5245  LR: 0.00000737  \n","Epoch: [2][6800/9397] Elapsed 36m 56s (remain 14m 6s) Loss: 0.0023(0.0067) Grad: 28980.5664  LR: 0.00000734  \n","Epoch: [2][6900/9397] Elapsed 37m 29s (remain 13m 33s) Loss: 0.0071(0.0067) Grad: 94380.1719  LR: 0.00000731  \n","Epoch: [2][7000/9397] Elapsed 38m 1s (remain 13m 0s) Loss: 0.0000(0.0067) Grad: 49.8314  LR: 0.00000728  \n","Epoch: [2][7100/9397] Elapsed 38m 34s (remain 12m 28s) Loss: 0.0015(0.0067) Grad: 27976.8984  LR: 0.00000725  \n","Epoch: [2][7200/9397] Elapsed 39m 6s (remain 11m 55s) Loss: 0.0050(0.0067) Grad: 59637.5781  LR: 0.00000722  \n","Epoch: [2][7300/9397] Elapsed 39m 39s (remain 11m 23s) Loss: 0.0036(0.0067) Grad: 33101.7422  LR: 0.00000719  \n","Epoch: [2][7400/9397] Elapsed 40m 12s (remain 10m 50s) Loss: 0.0003(0.0067) Grad: 3977.6755  LR: 0.00000716  \n","Epoch: [2][7500/9397] Elapsed 40m 44s (remain 10m 17s) Loss: 0.0065(0.0067) Grad: 203111.6406  LR: 0.00000713  \n","Epoch: [2][7600/9397] Elapsed 41m 17s (remain 9m 45s) Loss: 0.0000(0.0067) Grad: 2056.1631  LR: 0.00000710  \n","Epoch: [2][7700/9397] Elapsed 41m 49s (remain 9m 12s) Loss: 0.0049(0.0067) Grad: 38658.6641  LR: 0.00000707  \n","Epoch: [2][7800/9397] Elapsed 42m 22s (remain 8m 40s) Loss: 0.0250(0.0067) Grad: 71180.8125  LR: 0.00000704  \n","Epoch: [2][7900/9397] Elapsed 42m 54s (remain 8m 7s) Loss: 0.0032(0.0067) Grad: 32595.7656  LR: 0.00000701  \n","Epoch: [2][8000/9397] Elapsed 43m 27s (remain 7m 34s) Loss: 0.0020(0.0067) Grad: 73504.7812  LR: 0.00000698  \n","Epoch: [2][8100/9397] Elapsed 43m 59s (remain 7m 2s) Loss: 0.0060(0.0067) Grad: 56572.9805  LR: 0.00000695  \n","Epoch: [2][8200/9397] Elapsed 44m 32s (remain 6m 29s) Loss: 0.0001(0.0067) Grad: 1926.5593  LR: 0.00000692  \n","Epoch: [2][8300/9397] Elapsed 45m 5s (remain 5m 57s) Loss: 0.0008(0.0067) Grad: 13146.2070  LR: 0.00000689  \n","Epoch: [2][8400/9397] Elapsed 45m 37s (remain 5m 24s) Loss: 0.0001(0.0067) Grad: 1871.8994  LR: 0.00000686  \n","Epoch: [2][8500/9397] Elapsed 46m 10s (remain 4m 51s) Loss: 0.0963(0.0067) Grad: 77383.0234  LR: 0.00000683  \n","Epoch: [2][8600/9397] Elapsed 46m 43s (remain 4m 19s) Loss: 0.0002(0.0067) Grad: 3430.1594  LR: 0.00000680  \n","Epoch: [2][8700/9397] Elapsed 47m 15s (remain 3m 46s) Loss: 0.0001(0.0067) Grad: 4110.7314  LR: 0.00000676  \n","Epoch: [2][8800/9397] Elapsed 47m 48s (remain 3m 14s) Loss: 0.0319(0.0067) Grad: 333800.4688  LR: 0.00000673  \n","Epoch: [2][8900/9397] Elapsed 48m 20s (remain 2m 41s) Loss: 0.0039(0.0067) Grad: 107280.2344  LR: 0.00000670  \n","Epoch: [2][9000/9397] Elapsed 48m 53s (remain 2m 9s) Loss: 0.0000(0.0067) Grad: 665.1868  LR: 0.00000667  \n","Epoch: [2][9100/9397] Elapsed 49m 26s (remain 1m 36s) Loss: 0.0113(0.0066) Grad: 146325.5156  LR: 0.00000664  \n","Epoch: [2][9200/9397] Elapsed 49m 58s (remain 1m 3s) Loss: 0.0001(0.0066) Grad: 5707.0278  LR: 0.00000661  \n","Epoch: [2][9300/9397] Elapsed 50m 31s (remain 0m 31s) Loss: 0.0036(0.0066) Grad: 48517.7773  LR: 0.00000658  \n","Epoch: [2][9396/9397] Elapsed 51m 2s (remain 0m 0s) Loss: 0.0280(0.0066) Grad: 43955.7695  LR: 0.00000655  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 18m 24s) Loss: 0.0028(0.0028) \n","EVAL: [100/2350] Elapsed 0m 19s (remain 7m 21s) Loss: 0.0171(0.0143) \n","EVAL: [200/2350] Elapsed 0m 39s (remain 6m 57s) Loss: 0.0000(0.0142) \n","EVAL: [300/2350] Elapsed 0m 58s (remain 6m 37s) Loss: 0.0017(0.0180) \n","EVAL: [400/2350] Elapsed 1m 17s (remain 6m 17s) Loss: 0.0296(0.0171) \n","EVAL: [500/2350] Elapsed 1m 37s (remain 5m 57s) Loss: 0.0525(0.0168) \n","EVAL: [600/2350] Elapsed 1m 56s (remain 5m 38s) Loss: 0.0143(0.0165) \n","EVAL: [700/2350] Elapsed 2m 15s (remain 5m 19s) Loss: 0.0358(0.0177) \n","EVAL: [800/2350] Elapsed 2m 34s (remain 4m 59s) Loss: 0.0000(0.0181) \n","EVAL: [900/2350] Elapsed 2m 54s (remain 4m 40s) Loss: 0.0023(0.0163) \n","EVAL: [1000/2350] Elapsed 3m 13s (remain 4m 21s) Loss: 0.0008(0.0150) \n","EVAL: [1100/2350] Elapsed 3m 33s (remain 4m 1s) Loss: 0.0001(0.0139) \n","EVAL: [1200/2350] Elapsed 3m 52s (remain 3m 42s) Loss: 0.0001(0.0129) \n","EVAL: [1300/2350] Elapsed 4m 11s (remain 3m 22s) Loss: 0.0000(0.0122) \n","EVAL: [1400/2350] Elapsed 4m 31s (remain 3m 3s) Loss: 0.0082(0.0118) \n","EVAL: [1500/2350] Elapsed 4m 50s (remain 2m 44s) Loss: 0.0018(0.0115) \n","EVAL: [1600/2350] Elapsed 5m 9s (remain 2m 24s) Loss: 0.0018(0.0113) \n","EVAL: [1700/2350] Elapsed 5m 29s (remain 2m 5s) Loss: 0.0167(0.0113) \n","EVAL: [1800/2350] Elapsed 5m 48s (remain 1m 46s) Loss: 0.0000(0.0111) \n","EVAL: [1900/2350] Elapsed 6m 7s (remain 1m 26s) Loss: 0.0000(0.0105) \n","EVAL: [2000/2350] Elapsed 6m 26s (remain 1m 7s) Loss: 0.0000(0.0100) \n","EVAL: [2100/2350] Elapsed 6m 46s (remain 0m 48s) Loss: 0.0000(0.0096) \n","EVAL: [2200/2350] Elapsed 7m 5s (remain 0m 28s) Loss: 0.0000(0.0092) \n","EVAL: [2300/2350] Elapsed 7m 24s (remain 0m 9s) Loss: 0.0000(0.0088) \n","EVAL: [2349/2350] Elapsed 7m 34s (remain 0m 0s) Loss: 0.0000(0.0086) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0066  avg_val_loss: 0.0086  time: 3548s\n","Epoch 2 - Score: 0.9495\n","Epoch 2 - Save Best Score: 0.9495 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/9397] Elapsed 0m 0s (remain 137m 20s) Loss: 0.0012(0.0012) Grad: 27632.8809  LR: 0.00000655  \n","Epoch: [3][100/9397] Elapsed 0m 35s (remain 53m 57s) Loss: 0.0055(0.0045) Grad: 12132.2197  LR: 0.00000651  \n","Epoch: [3][200/9397] Elapsed 1m 9s (remain 52m 44s) Loss: 0.0053(0.0051) Grad: 4529.1035  LR: 0.00000648  \n","Epoch: [3][300/9397] Elapsed 1m 43s (remain 51m 54s) Loss: 0.0021(0.0054) Grad: 43316.6172  LR: 0.00000645  \n","Epoch: [3][400/9397] Elapsed 2m 17s (remain 51m 13s) Loss: 0.0001(0.0055) Grad: 632.1907  LR: 0.00000642  \n","Epoch: [3][500/9397] Elapsed 2m 50s (remain 50m 34s) Loss: 0.0042(0.0052) Grad: 15325.3711  LR: 0.00000639  \n","Epoch: [3][600/9397] Elapsed 3m 24s (remain 49m 58s) Loss: 0.0059(0.0053) Grad: 22358.2988  LR: 0.00000635  \n","Epoch: [3][700/9397] Elapsed 3m 58s (remain 49m 21s) Loss: 0.0062(0.0053) Grad: 55967.0586  LR: 0.00000632  \n","Epoch: [3][800/9397] Elapsed 4m 32s (remain 48m 45s) Loss: 0.0019(0.0053) Grad: 23557.1172  LR: 0.00000629  \n","Epoch: [3][900/9397] Elapsed 5m 6s (remain 48m 9s) Loss: 0.0088(0.0054) Grad: 20887.2188  LR: 0.00000626  \n","Epoch: [3][1000/9397] Elapsed 5m 40s (remain 47m 34s) Loss: 0.0021(0.0054) Grad: 13063.6152  LR: 0.00000622  \n","Epoch: [3][1100/9397] Elapsed 6m 14s (remain 46m 59s) Loss: 0.0009(0.0054) Grad: 4391.0430  LR: 0.00000619  \n","Epoch: [3][1200/9397] Elapsed 6m 48s (remain 46m 25s) Loss: 0.0050(0.0055) Grad: 21827.9922  LR: 0.00000616  \n","Epoch: [3][1300/9397] Elapsed 7m 22s (remain 45m 51s) Loss: 0.0024(0.0054) Grad: 8429.0488  LR: 0.00000613  \n","Epoch: [3][1400/9397] Elapsed 7m 55s (remain 45m 16s) Loss: 0.0125(0.0056) Grad: 20483.9746  LR: 0.00000609  \n","Epoch: [3][1500/9397] Elapsed 8m 29s (remain 44m 42s) Loss: 0.0113(0.0056) Grad: 8925.8086  LR: 0.00000606  \n","Epoch: [3][1600/9397] Elapsed 9m 3s (remain 44m 8s) Loss: 0.0200(0.0056) Grad: 21718.9844  LR: 0.00000603  \n","Epoch: [3][1700/9397] Elapsed 9m 37s (remain 43m 33s) Loss: 0.0067(0.0056) Grad: 36351.2969  LR: 0.00000600  \n","Epoch: [3][1800/9397] Elapsed 10m 11s (remain 42m 59s) Loss: 0.0000(0.0056) Grad: 116.6438  LR: 0.00000596  \n","Epoch: [3][1900/9397] Elapsed 10m 45s (remain 42m 26s) Loss: 0.0024(0.0056) Grad: 19302.4668  LR: 0.00000593  \n","Epoch: [3][2000/9397] Elapsed 11m 19s (remain 41m 52s) Loss: 0.0174(0.0056) Grad: 52802.7266  LR: 0.00000590  \n","Epoch: [3][2100/9397] Elapsed 11m 53s (remain 41m 18s) Loss: 0.0046(0.0056) Grad: 26566.6699  LR: 0.00000586  \n","Epoch: [3][2200/9397] Elapsed 12m 27s (remain 40m 44s) Loss: 0.0003(0.0055) Grad: 4166.5010  LR: 0.00000583  \n","Epoch: [3][2300/9397] Elapsed 13m 1s (remain 40m 10s) Loss: 0.0000(0.0055) Grad: 18.6992  LR: 0.00000580  \n","Epoch: [3][2400/9397] Elapsed 13m 35s (remain 39m 36s) Loss: 0.0055(0.0054) Grad: 75324.0703  LR: 0.00000577  \n","Epoch: [3][2500/9397] Elapsed 14m 9s (remain 39m 2s) Loss: 0.0074(0.0054) Grad: 66858.1484  LR: 0.00000573  \n","Epoch: [3][2600/9397] Elapsed 14m 43s (remain 38m 28s) Loss: 0.0015(0.0055) Grad: 11577.3418  LR: 0.00000570  \n","Epoch: [3][2700/9397] Elapsed 15m 17s (remain 37m 54s) Loss: 0.0036(0.0055) Grad: 19075.5625  LR: 0.00000567  \n","Epoch: [3][2800/9397] Elapsed 15m 51s (remain 37m 20s) Loss: 0.0000(0.0055) Grad: 876.9828  LR: 0.00000563  \n","Epoch: [3][2900/9397] Elapsed 16m 25s (remain 36m 46s) Loss: 0.0037(0.0055) Grad: 41523.6484  LR: 0.00000560  \n","Epoch: [3][3000/9397] Elapsed 16m 59s (remain 36m 11s) Loss: 0.0041(0.0056) Grad: 65562.8203  LR: 0.00000557  \n","Epoch: [3][3100/9397] Elapsed 17m 32s (remain 35m 37s) Loss: 0.0008(0.0056) Grad: 15836.9307  LR: 0.00000553  \n","Epoch: [3][3200/9397] Elapsed 18m 6s (remain 35m 3s) Loss: 0.0001(0.0056) Grad: 1295.2651  LR: 0.00000550  \n","Epoch: [3][3300/9397] Elapsed 18m 40s (remain 34m 30s) Loss: 0.0002(0.0056) Grad: 2617.0586  LR: 0.00000547  \n","Epoch: [3][3400/9397] Elapsed 19m 14s (remain 33m 56s) Loss: 0.0288(0.0056) Grad: 37466.5547  LR: 0.00000543  \n","Epoch: [3][3500/9397] Elapsed 19m 48s (remain 33m 22s) Loss: 0.0026(0.0057) Grad: 61916.8438  LR: 0.00000540  \n","Epoch: [3][3600/9397] Elapsed 20m 22s (remain 32m 48s) Loss: 0.0014(0.0057) Grad: 24922.4648  LR: 0.00000537  \n","Epoch: [3][3700/9397] Elapsed 20m 56s (remain 32m 14s) Loss: 0.0024(0.0057) Grad: 24249.5488  LR: 0.00000533  \n","Epoch: [3][3800/9397] Elapsed 21m 30s (remain 31m 40s) Loss: 0.0025(0.0057) Grad: 46106.8516  LR: 0.00000530  \n","Epoch: [3][3900/9397] Elapsed 22m 4s (remain 31m 6s) Loss: 0.0134(0.0057) Grad: 121460.3438  LR: 0.00000527  \n","Epoch: [3][4000/9397] Elapsed 22m 38s (remain 30m 32s) Loss: 0.0300(0.0057) Grad: 147370.4531  LR: 0.00000523  \n","Epoch: [3][4100/9397] Elapsed 23m 12s (remain 29m 58s) Loss: 0.0000(0.0057) Grad: 279.2426  LR: 0.00000520  \n","Epoch: [3][4200/9397] Elapsed 23m 46s (remain 29m 24s) Loss: 0.0103(0.0057) Grad: 199783.7500  LR: 0.00000517  \n","Epoch: [3][4300/9397] Elapsed 24m 20s (remain 28m 50s) Loss: 0.0042(0.0057) Grad: 57199.7422  LR: 0.00000513  \n","Epoch: [3][4400/9397] Elapsed 24m 54s (remain 28m 16s) Loss: 0.0094(0.0057) Grad: 107218.8750  LR: 0.00000510  \n","Epoch: [3][4500/9397] Elapsed 25m 28s (remain 27m 42s) Loss: 0.0045(0.0057) Grad: 147363.9844  LR: 0.00000507  \n","Epoch: [3][4600/9397] Elapsed 26m 2s (remain 27m 8s) Loss: 0.0020(0.0057) Grad: 68985.9609  LR: 0.00000503  \n","Epoch: [3][4700/9397] Elapsed 26m 36s (remain 26m 34s) Loss: 0.0180(0.0057) Grad: 187284.9688  LR: 0.00000500  \n","Epoch: [3][4800/9397] Elapsed 27m 10s (remain 26m 0s) Loss: 0.0022(0.0057) Grad: 72059.4062  LR: 0.00000497  \n","Epoch: [3][4900/9397] Elapsed 27m 44s (remain 25m 26s) Loss: 0.0028(0.0057) Grad: 143374.2500  LR: 0.00000493  \n","Epoch: [3][5000/9397] Elapsed 28m 18s (remain 24m 52s) Loss: 0.0004(0.0057) Grad: 18530.3418  LR: 0.00000490  \n","Epoch: [3][5100/9397] Elapsed 28m 52s (remain 24m 18s) Loss: 0.0003(0.0057) Grad: 22610.8457  LR: 0.00000487  \n","Epoch: [3][5200/9397] Elapsed 29m 25s (remain 23m 44s) Loss: 0.0037(0.0058) Grad: 172620.9844  LR: 0.00000483  \n","Epoch: [3][5300/9397] Elapsed 29m 59s (remain 23m 10s) Loss: 0.0040(0.0058) Grad: 72963.8281  LR: 0.00000480  \n","Epoch: [3][5400/9397] Elapsed 30m 33s (remain 22m 36s) Loss: 0.0029(0.0057) Grad: 333110.0000  LR: 0.00000477  \n","Epoch: [3][5500/9397] Elapsed 31m 7s (remain 22m 2s) Loss: 0.0057(0.0057) Grad: 33294.9609  LR: 0.00000473  \n","Epoch: [3][5600/9397] Elapsed 31m 41s (remain 21m 28s) Loss: 0.0062(0.0057) Grad: 139570.7969  LR: 0.00000470  \n","Epoch: [3][5700/9397] Elapsed 32m 15s (remain 20m 54s) Loss: 0.0000(0.0057) Grad: 801.3079  LR: 0.00000467  \n","Epoch: [3][5800/9397] Elapsed 32m 49s (remain 20m 20s) Loss: 0.0024(0.0057) Grad: 118180.4375  LR: 0.00000463  \n","Epoch: [3][5900/9397] Elapsed 33m 23s (remain 19m 46s) Loss: 0.0003(0.0057) Grad: 22374.6934  LR: 0.00000460  \n","Epoch: [3][6000/9397] Elapsed 33m 57s (remain 19m 12s) Loss: 0.0019(0.0057) Grad: 198395.2500  LR: 0.00000457  \n","Epoch: [3][6100/9397] Elapsed 34m 31s (remain 18m 38s) Loss: 0.0165(0.0058) Grad: 577401.5000  LR: 0.00000453  \n","Epoch: [3][6200/9397] Elapsed 35m 5s (remain 18m 5s) Loss: 0.0013(0.0058) Grad: 52111.2188  LR: 0.00000450  \n","Epoch: [3][6300/9397] Elapsed 35m 39s (remain 17m 31s) Loss: 0.0091(0.0058) Grad: 133075.4219  LR: 0.00000447  \n","Epoch: [3][6400/9397] Elapsed 36m 12s (remain 16m 57s) Loss: 0.0001(0.0058) Grad: 2077.3284  LR: 0.00000443  \n","Epoch: [3][6500/9397] Elapsed 36m 46s (remain 16m 23s) Loss: 0.0003(0.0058) Grad: 25943.3066  LR: 0.00000440  \n","Epoch: [3][6600/9397] Elapsed 37m 20s (remain 15m 49s) Loss: 0.0000(0.0058) Grad: 164.7723  LR: 0.00000437  \n","Epoch: [3][6700/9397] Elapsed 37m 54s (remain 15m 15s) Loss: 0.0153(0.0058) Grad: 143350.6562  LR: 0.00000433  \n","Epoch: [3][6800/9397] Elapsed 38m 28s (remain 14m 41s) Loss: 0.0052(0.0058) Grad: 60059.5938  LR: 0.00000430  \n","Epoch: [3][6900/9397] Elapsed 39m 2s (remain 14m 7s) Loss: 0.0000(0.0058) Grad: 51.3239  LR: 0.00000427  \n","Epoch: [3][7000/9397] Elapsed 39m 36s (remain 13m 33s) Loss: 0.0006(0.0058) Grad: 23036.1836  LR: 0.00000423  \n","Epoch: [3][7100/9397] Elapsed 40m 10s (remain 12m 59s) Loss: 0.0001(0.0057) Grad: 5694.0913  LR: 0.00000420  \n","Epoch: [3][7200/9397] Elapsed 40m 44s (remain 12m 25s) Loss: 0.0009(0.0057) Grad: 97352.0234  LR: 0.00000417  \n","Epoch: [3][7300/9397] Elapsed 41m 18s (remain 11m 51s) Loss: 0.0059(0.0057) Grad: 135804.5938  LR: 0.00000413  \n","Epoch: [3][7400/9397] Elapsed 41m 52s (remain 11m 17s) Loss: 0.0000(0.0057) Grad: 1089.9240  LR: 0.00000410  \n","Epoch: [3][7500/9397] Elapsed 42m 26s (remain 10m 43s) Loss: 0.0108(0.0057) Grad: 111019.6719  LR: 0.00000407  \n","Epoch: [3][7600/9397] Elapsed 43m 0s (remain 10m 9s) Loss: 0.0002(0.0057) Grad: 16082.9893  LR: 0.00000404  \n","Epoch: [3][7700/9397] Elapsed 43m 34s (remain 9m 35s) Loss: 0.0131(0.0057) Grad: 1145689.2500  LR: 0.00000400  \n","Epoch: [3][7800/9397] Elapsed 44m 7s (remain 9m 1s) Loss: 0.0093(0.0057) Grad: 165024.8125  LR: 0.00000397  \n","Epoch: [3][7900/9397] Elapsed 44m 41s (remain 8m 27s) Loss: 0.0041(0.0057) Grad: 87620.3750  LR: 0.00000394  \n","Epoch: [3][8000/9397] Elapsed 45m 15s (remain 7m 53s) Loss: 0.0059(0.0057) Grad: 283834.6250  LR: 0.00000391  \n","Epoch: [3][8100/9397] Elapsed 45m 49s (remain 7m 19s) Loss: 0.0073(0.0057) Grad: 140131.1094  LR: 0.00000387  \n","Epoch: [3][8200/9397] Elapsed 46m 23s (remain 6m 45s) Loss: 0.0057(0.0057) Grad: 241343.9531  LR: 0.00000384  \n","Epoch: [3][8300/9397] Elapsed 46m 57s (remain 6m 12s) Loss: 0.0008(0.0058) Grad: 52720.6016  LR: 0.00000381  \n","Epoch: [3][8400/9397] Elapsed 47m 32s (remain 5m 38s) Loss: 0.0000(0.0058) Grad: 794.8359  LR: 0.00000378  \n","Epoch: [3][8500/9397] Elapsed 48m 6s (remain 5m 4s) Loss: 0.0181(0.0058) Grad: 408153.8125  LR: 0.00000374  \n","Epoch: [3][8600/9397] Elapsed 48m 40s (remain 4m 30s) Loss: 0.0127(0.0058) Grad: 353265.3750  LR: 0.00000371  \n","Epoch: [3][8700/9397] Elapsed 49m 13s (remain 3m 56s) Loss: 0.0000(0.0057) Grad: 60.6628  LR: 0.00000368  \n","Epoch: [3][8800/9397] Elapsed 49m 47s (remain 3m 22s) Loss: 0.0000(0.0058) Grad: 320.6839  LR: 0.00000365  \n","Epoch: [3][8900/9397] Elapsed 50m 21s (remain 2m 48s) Loss: 0.0000(0.0058) Grad: 10249.8594  LR: 0.00000361  \n","Epoch: [3][9000/9397] Elapsed 50m 55s (remain 2m 14s) Loss: 0.0001(0.0057) Grad: 9244.0068  LR: 0.00000358  \n","Epoch: [3][9100/9397] Elapsed 51m 29s (remain 1m 40s) Loss: 0.0002(0.0057) Grad: 26036.3184  LR: 0.00000355  \n","Epoch: [3][9200/9397] Elapsed 52m 3s (remain 1m 6s) Loss: 0.0189(0.0058) Grad: 435378.5938  LR: 0.00000352  \n","Epoch: [3][9300/9397] Elapsed 52m 37s (remain 0m 32s) Loss: 0.0000(0.0058) Grad: 69.2663  LR: 0.00000349  \n","Epoch: [3][9396/9397] Elapsed 53m 10s (remain 0m 0s) Loss: 0.0021(0.0058) Grad: 51162.6562  LR: 0.00000346  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 19m 31s) Loss: 0.0024(0.0024) \n","EVAL: [100/2350] Elapsed 0m 20s (remain 7m 45s) Loss: 0.0149(0.0156) \n","EVAL: [200/2350] Elapsed 0m 41s (remain 7m 21s) Loss: 0.0000(0.0152) \n","EVAL: [300/2350] Elapsed 1m 1s (remain 6m 59s) Loss: 0.0056(0.0194) \n","EVAL: [400/2350] Elapsed 1m 22s (remain 6m 39s) Loss: 0.0302(0.0185) \n","EVAL: [500/2350] Elapsed 1m 42s (remain 6m 18s) Loss: 0.0583(0.0182) \n","EVAL: [600/2350] Elapsed 2m 2s (remain 5m 57s) Loss: 0.0115(0.0179) \n","EVAL: [700/2350] Elapsed 2m 23s (remain 5m 37s) Loss: 0.0328(0.0190) \n","EVAL: [800/2350] Elapsed 2m 43s (remain 5m 16s) Loss: 0.0000(0.0193) \n","EVAL: [900/2350] Elapsed 3m 4s (remain 4m 56s) Loss: 0.0014(0.0174) \n","EVAL: [1000/2350] Elapsed 3m 24s (remain 4m 35s) Loss: 0.0022(0.0160) \n","EVAL: [1100/2350] Elapsed 3m 44s (remain 4m 15s) Loss: 0.0000(0.0147) \n","EVAL: [1200/2350] Elapsed 4m 5s (remain 3m 54s) Loss: 0.0000(0.0137) \n","EVAL: [1300/2350] Elapsed 4m 25s (remain 3m 34s) Loss: 0.0000(0.0129) \n","EVAL: [1400/2350] Elapsed 4m 46s (remain 3m 13s) Loss: 0.0089(0.0126) \n","EVAL: [1500/2350] Elapsed 5m 6s (remain 2m 53s) Loss: 0.0006(0.0122) \n","EVAL: [1600/2350] Elapsed 5m 26s (remain 2m 32s) Loss: 0.0011(0.0120) \n","EVAL: [1700/2350] Elapsed 5m 47s (remain 2m 12s) Loss: 0.0197(0.0121) \n","EVAL: [1800/2350] Elapsed 6m 7s (remain 1m 52s) Loss: 0.0000(0.0118) \n","EVAL: [1900/2350] Elapsed 6m 28s (remain 1m 31s) Loss: 0.0000(0.0112) \n","EVAL: [2000/2350] Elapsed 6m 48s (remain 1m 11s) Loss: 0.0000(0.0107) \n","EVAL: [2100/2350] Elapsed 7m 8s (remain 0m 50s) Loss: 0.0000(0.0102) \n","EVAL: [2200/2350] Elapsed 7m 29s (remain 0m 30s) Loss: 0.0000(0.0097) \n","EVAL: [2300/2350] Elapsed 7m 49s (remain 0m 10s) Loss: 0.0000(0.0094) \n","EVAL: [2349/2350] Elapsed 7m 59s (remain 0m 0s) Loss: 0.0000(0.0092) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0058  avg_val_loss: 0.0092  time: 3683s\n","Epoch 3 - Score: 0.9511\n","Epoch 3 - Save Best Score: 0.9511 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/9397] Elapsed 0m 0s (remain 136m 34s) Loss: 0.0313(0.0313) Grad: 69979.4844  LR: 0.00000345  \n","Epoch: [4][100/9397] Elapsed 0m 33s (remain 51m 53s) Loss: 0.0017(0.0037) Grad: 21661.2383  LR: 0.00000342  \n","Epoch: [4][200/9397] Elapsed 1m 6s (remain 50m 40s) Loss: 0.0024(0.0053) Grad: 112653.3047  LR: 0.00000339  \n","Epoch: [4][300/9397] Elapsed 1m 38s (remain 49m 49s) Loss: 0.0003(0.0052) Grad: 5156.6187  LR: 0.00000336  \n","Epoch: [4][400/9397] Elapsed 2m 11s (remain 49m 5s) Loss: 0.0030(0.0054) Grad: 22722.4668  LR: 0.00000333  \n","Epoch: [4][500/9397] Elapsed 2m 43s (remain 48m 28s) Loss: 0.0034(0.0051) Grad: 36378.6367  LR: 0.00000330  \n","Epoch: [4][600/9397] Elapsed 3m 16s (remain 47m 52s) Loss: 0.0003(0.0050) Grad: 2817.6860  LR: 0.00000327  \n","Epoch: [4][700/9397] Elapsed 3m 48s (remain 47m 18s) Loss: 0.0059(0.0049) Grad: 9525.4072  LR: 0.00000323  \n","Epoch: [4][800/9397] Elapsed 4m 21s (remain 46m 43s) Loss: 0.0189(0.0049) Grad: 38972.0977  LR: 0.00000320  \n","Epoch: [4][900/9397] Elapsed 4m 53s (remain 46m 7s) Loss: 0.0000(0.0048) Grad: 438.2426  LR: 0.00000317  \n","Epoch: [4][1000/9397] Elapsed 5m 25s (remain 45m 33s) Loss: 0.0008(0.0049) Grad: 20129.3281  LR: 0.00000314  \n","Epoch: [4][1100/9397] Elapsed 5m 58s (remain 44m 59s) Loss: 0.0013(0.0049) Grad: 26366.6445  LR: 0.00000311  \n","Epoch: [4][1200/9397] Elapsed 6m 30s (remain 44m 27s) Loss: 0.0000(0.0049) Grad: 340.1171  LR: 0.00000308  \n","Epoch: [4][1300/9397] Elapsed 7m 3s (remain 43m 54s) Loss: 0.0043(0.0051) Grad: 19671.1270  LR: 0.00000305  \n","Epoch: [4][1400/9397] Elapsed 7m 35s (remain 43m 20s) Loss: 0.0000(0.0051) Grad: 1101.6841  LR: 0.00000302  \n","Epoch: [4][1500/9397] Elapsed 8m 8s (remain 42m 47s) Loss: 0.0040(0.0050) Grad: 18373.0781  LR: 0.00000299  \n","Epoch: [4][1600/9397] Elapsed 8m 40s (remain 42m 14s) Loss: 0.0040(0.0050) Grad: 36333.0234  LR: 0.00000296  \n","Epoch: [4][1700/9397] Elapsed 9m 12s (remain 41m 41s) Loss: 0.0050(0.0051) Grad: 16079.6758  LR: 0.00000293  \n","Epoch: [4][1800/9397] Elapsed 9m 45s (remain 41m 9s) Loss: 0.0001(0.0051) Grad: 554.5373  LR: 0.00000290  \n","Epoch: [4][1900/9397] Elapsed 10m 17s (remain 40m 36s) Loss: 0.0064(0.0050) Grad: 48736.0352  LR: 0.00000286  \n","Epoch: [4][2000/9397] Elapsed 10m 50s (remain 40m 3s) Loss: 0.0000(0.0050) Grad: 225.6956  LR: 0.00000283  \n","Epoch: [4][2100/9397] Elapsed 11m 23s (remain 39m 32s) Loss: 0.0005(0.0050) Grad: 13634.0420  LR: 0.00000280  \n","Epoch: [4][2200/9397] Elapsed 11m 55s (remain 39m 0s) Loss: 0.0154(0.0051) Grad: 63397.3125  LR: 0.00000277  \n","Epoch: [4][2300/9397] Elapsed 12m 28s (remain 38m 27s) Loss: 0.0000(0.0050) Grad: 186.9452  LR: 0.00000274  \n","Epoch: [4][2400/9397] Elapsed 13m 0s (remain 37m 55s) Loss: 0.0084(0.0051) Grad: 139483.6094  LR: 0.00000272  \n","Epoch: [4][2500/9397] Elapsed 13m 33s (remain 37m 22s) Loss: 0.0373(0.0050) Grad: 186827.0469  LR: 0.00000269  \n","Epoch: [4][2600/9397] Elapsed 14m 5s (remain 36m 50s) Loss: 0.0024(0.0050) Grad: 35892.9414  LR: 0.00000266  \n","Epoch: [4][2700/9397] Elapsed 14m 38s (remain 36m 17s) Loss: 0.0015(0.0050) Grad: 14542.9590  LR: 0.00000263  \n","Epoch: [4][2800/9397] Elapsed 15m 11s (remain 35m 45s) Loss: 0.0001(0.0050) Grad: 1954.8293  LR: 0.00000260  \n","Epoch: [4][2900/9397] Elapsed 15m 43s (remain 35m 13s) Loss: 0.0470(0.0050) Grad: 345346.6875  LR: 0.00000257  \n","Epoch: [4][3000/9397] Elapsed 16m 16s (remain 34m 40s) Loss: 0.0046(0.0050) Grad: 14234.3115  LR: 0.00000254  \n","Epoch: [4][3100/9397] Elapsed 16m 48s (remain 34m 8s) Loss: 0.0001(0.0050) Grad: 1682.5852  LR: 0.00000251  \n","Epoch: [4][3200/9397] Elapsed 17m 21s (remain 33m 35s) Loss: 0.0002(0.0050) Grad: 15419.9287  LR: 0.00000248  \n","Epoch: [4][3300/9397] Elapsed 17m 53s (remain 33m 3s) Loss: 0.0000(0.0051) Grad: 1546.9457  LR: 0.00000245  \n","Epoch: [4][3400/9397] Elapsed 18m 26s (remain 32m 30s) Loss: 0.0000(0.0051) Grad: 182.5059  LR: 0.00000242  \n","Epoch: [4][3500/9397] Elapsed 18m 59s (remain 31m 58s) Loss: 0.0000(0.0051) Grad: 1540.9379  LR: 0.00000239  \n","Epoch: [4][3600/9397] Elapsed 19m 31s (remain 31m 25s) Loss: 0.0009(0.0051) Grad: 55539.9844  LR: 0.00000237  \n","Epoch: [4][3700/9397] Elapsed 20m 4s (remain 30m 53s) Loss: 0.0073(0.0051) Grad: 87824.5234  LR: 0.00000234  \n","Epoch: [4][3800/9397] Elapsed 20m 36s (remain 30m 20s) Loss: 0.0293(0.0051) Grad: 140591.9844  LR: 0.00000231  \n","Epoch: [4][3900/9397] Elapsed 21m 9s (remain 29m 48s) Loss: 0.0023(0.0051) Grad: 27206.5645  LR: 0.00000228  \n","Epoch: [4][4000/9397] Elapsed 21m 41s (remain 29m 15s) Loss: 0.0000(0.0051) Grad: 78.7902  LR: 0.00000225  \n","Epoch: [4][4100/9397] Elapsed 22m 14s (remain 28m 43s) Loss: 0.0004(0.0051) Grad: 21691.4980  LR: 0.00000223  \n","Epoch: [4][4200/9397] Elapsed 22m 47s (remain 28m 11s) Loss: 0.0000(0.0051) Grad: 752.4988  LR: 0.00000220  \n","Epoch: [4][4300/9397] Elapsed 23m 19s (remain 27m 38s) Loss: 0.0158(0.0051) Grad: 230649.7969  LR: 0.00000217  \n","Epoch: [4][4400/9397] Elapsed 23m 52s (remain 27m 6s) Loss: 0.0000(0.0051) Grad: 971.0310  LR: 0.00000214  \n","Epoch: [4][4500/9397] Elapsed 24m 25s (remain 26m 33s) Loss: 0.0032(0.0052) Grad: 181009.7344  LR: 0.00000212  \n","Epoch: [4][4600/9397] Elapsed 24m 57s (remain 26m 0s) Loss: 0.0047(0.0052) Grad: 21809.5039  LR: 0.00000209  \n","Epoch: [4][4700/9397] Elapsed 25m 30s (remain 25m 28s) Loss: 0.0088(0.0052) Grad: 146124.1406  LR: 0.00000206  \n","Epoch: [4][4800/9397] Elapsed 26m 2s (remain 24m 55s) Loss: 0.0064(0.0052) Grad: 38471.1328  LR: 0.00000203  \n","Epoch: [4][4900/9397] Elapsed 26m 35s (remain 24m 23s) Loss: 0.0309(0.0052) Grad: 213727.1094  LR: 0.00000201  \n","Epoch: [4][5000/9397] Elapsed 27m 7s (remain 23m 50s) Loss: 0.0000(0.0052) Grad: 65.4426  LR: 0.00000198  \n","Epoch: [4][5100/9397] Elapsed 27m 40s (remain 23m 18s) Loss: 0.0044(0.0053) Grad: 49415.6406  LR: 0.00000195  \n","Epoch: [4][5200/9397] Elapsed 28m 13s (remain 22m 45s) Loss: 0.0001(0.0053) Grad: 1433.9048  LR: 0.00000193  \n","Epoch: [4][5300/9397] Elapsed 28m 45s (remain 22m 13s) Loss: 0.0001(0.0053) Grad: 2396.8245  LR: 0.00000190  \n","Epoch: [4][5400/9397] Elapsed 29m 18s (remain 21m 40s) Loss: 0.0061(0.0053) Grad: 52811.0508  LR: 0.00000187  \n","Epoch: [4][5500/9397] Elapsed 29m 50s (remain 21m 8s) Loss: 0.0056(0.0052) Grad: 125597.4766  LR: 0.00000185  \n","Epoch: [4][5600/9397] Elapsed 30m 23s (remain 20m 35s) Loss: 0.0052(0.0052) Grad: 43366.7734  LR: 0.00000182  \n","Epoch: [4][5700/9397] Elapsed 30m 56s (remain 20m 3s) Loss: 0.0020(0.0052) Grad: 66937.8281  LR: 0.00000180  \n","Epoch: [4][5800/9397] Elapsed 31m 28s (remain 19m 30s) Loss: 0.0008(0.0052) Grad: 16720.9180  LR: 0.00000177  \n","Epoch: [4][5900/9397] Elapsed 32m 1s (remain 18m 58s) Loss: 0.0070(0.0052) Grad: 64505.3438  LR: 0.00000175  \n","Epoch: [4][6000/9397] Elapsed 32m 33s (remain 18m 25s) Loss: 0.0021(0.0052) Grad: 137464.9062  LR: 0.00000172  \n","Epoch: [4][6100/9397] Elapsed 33m 6s (remain 17m 52s) Loss: 0.0004(0.0052) Grad: 9665.2168  LR: 0.00000170  \n","Epoch: [4][6200/9397] Elapsed 33m 38s (remain 17m 20s) Loss: 0.0000(0.0052) Grad: 1530.5035  LR: 0.00000167  \n","Epoch: [4][6300/9397] Elapsed 34m 11s (remain 16m 47s) Loss: 0.0074(0.0053) Grad: 116836.6172  LR: 0.00000165  \n","Epoch: [4][6400/9397] Elapsed 34m 44s (remain 16m 15s) Loss: 0.0165(0.0053) Grad: 75413.9141  LR: 0.00000162  \n","Epoch: [4][6500/9397] Elapsed 35m 16s (remain 15m 42s) Loss: 0.0129(0.0053) Grad: 71994.4531  LR: 0.00000160  \n","Epoch: [4][6600/9397] Elapsed 35m 49s (remain 15m 10s) Loss: 0.0001(0.0053) Grad: 1770.6069  LR: 0.00000157  \n","Epoch: [4][6700/9397] Elapsed 36m 21s (remain 14m 37s) Loss: 0.0000(0.0053) Grad: 40.4991  LR: 0.00000155  \n","Epoch: [4][6800/9397] Elapsed 36m 54s (remain 14m 5s) Loss: 0.0042(0.0053) Grad: 113083.7656  LR: 0.00000152  \n","Epoch: [4][6900/9397] Elapsed 37m 26s (remain 13m 32s) Loss: 0.0030(0.0053) Grad: 30393.5176  LR: 0.00000150  \n","Epoch: [4][7000/9397] Elapsed 37m 59s (remain 13m 0s) Loss: 0.0001(0.0053) Grad: 10597.9717  LR: 0.00000148  \n","Epoch: [4][7100/9397] Elapsed 38m 31s (remain 12m 27s) Loss: 0.0013(0.0053) Grad: 156161.3906  LR: 0.00000145  \n","Epoch: [4][7200/9397] Elapsed 39m 4s (remain 11m 54s) Loss: 0.0067(0.0053) Grad: 69392.3516  LR: 0.00000143  \n","Epoch: [4][7300/9397] Elapsed 39m 37s (remain 11m 22s) Loss: 0.0000(0.0052) Grad: 180.2429  LR: 0.00000141  \n","Epoch: [4][7400/9397] Elapsed 40m 9s (remain 10m 49s) Loss: 0.0006(0.0052) Grad: 70080.6875  LR: 0.00000138  \n","Epoch: [4][7500/9397] Elapsed 40m 42s (remain 10m 17s) Loss: 0.0045(0.0052) Grad: 123358.4141  LR: 0.00000136  \n","Epoch: [4][7600/9397] Elapsed 41m 14s (remain 9m 44s) Loss: 0.0035(0.0052) Grad: 98144.9219  LR: 0.00000134  \n","Epoch: [4][7700/9397] Elapsed 41m 47s (remain 9m 12s) Loss: 0.0020(0.0052) Grad: 21912.8125  LR: 0.00000131  \n","Epoch: [4][7800/9397] Elapsed 42m 19s (remain 8m 39s) Loss: 0.0012(0.0052) Grad: 73504.9766  LR: 0.00000129  \n","Epoch: [4][7900/9397] Elapsed 42m 52s (remain 8m 7s) Loss: 0.0000(0.0052) Grad: 379.4883  LR: 0.00000127  \n","Epoch: [4][8000/9397] Elapsed 43m 24s (remain 7m 34s) Loss: 0.0007(0.0052) Grad: 73470.2891  LR: 0.00000125  \n","Epoch: [4][8100/9397] Elapsed 43m 56s (remain 7m 1s) Loss: 0.0022(0.0052) Grad: 76928.8438  LR: 0.00000122  \n","Epoch: [4][8200/9397] Elapsed 44m 29s (remain 6m 29s) Loss: 0.0028(0.0052) Grad: 114882.1562  LR: 0.00000120  \n","Epoch: [4][8300/9397] Elapsed 45m 2s (remain 5m 56s) Loss: 0.0068(0.0052) Grad: 311421.9375  LR: 0.00000118  \n","Epoch: [4][8400/9397] Elapsed 45m 34s (remain 5m 24s) Loss: 0.0029(0.0052) Grad: 143445.2500  LR: 0.00000116  \n","Epoch: [4][8500/9397] Elapsed 46m 7s (remain 4m 51s) Loss: 0.0223(0.0052) Grad: 273582.0000  LR: 0.00000114  \n","Epoch: [4][8600/9397] Elapsed 46m 40s (remain 4m 19s) Loss: 0.0011(0.0052) Grad: 55156.3242  LR: 0.00000112  \n","Epoch: [4][8700/9397] Elapsed 47m 12s (remain 3m 46s) Loss: 0.0078(0.0052) Grad: 136779.3750  LR: 0.00000110  \n","Epoch: [4][8800/9397] Elapsed 47m 45s (remain 3m 14s) Loss: 0.0000(0.0052) Grad: 25.5237  LR: 0.00000108  \n","Epoch: [4][8900/9397] Elapsed 48m 17s (remain 2m 41s) Loss: 0.0062(0.0052) Grad: 157569.7344  LR: 0.00000105  \n","Epoch: [4][9000/9397] Elapsed 48m 50s (remain 2m 8s) Loss: 0.0018(0.0052) Grad: 81360.5938  LR: 0.00000103  \n","Epoch: [4][9100/9397] Elapsed 49m 22s (remain 1m 36s) Loss: 0.0034(0.0052) Grad: 85100.8125  LR: 0.00000101  \n","Epoch: [4][9200/9397] Elapsed 49m 55s (remain 1m 3s) Loss: 0.0036(0.0052) Grad: 67351.4844  LR: 0.00000099  \n","Epoch: [4][9300/9397] Elapsed 50m 28s (remain 0m 31s) Loss: 0.0000(0.0052) Grad: 2373.3396  LR: 0.00000097  \n","Epoch: [4][9396/9397] Elapsed 50m 59s (remain 0m 0s) Loss: 0.0004(0.0052) Grad: 40517.2461  LR: 0.00000096  \n","EVAL: [0/2350] Elapsed 0m 0s (remain 18m 34s) Loss: 0.0024(0.0024) \n","EVAL: [100/2350] Elapsed 0m 19s (remain 7m 21s) Loss: 0.0144(0.0157) \n","EVAL: [200/2350] Elapsed 0m 39s (remain 6m 58s) Loss: 0.0000(0.0155) \n","EVAL: [300/2350] Elapsed 0m 58s (remain 6m 37s) Loss: 0.0066(0.0197) \n","EVAL: [400/2350] Elapsed 1m 17s (remain 6m 18s) Loss: 0.0308(0.0187) \n","EVAL: [500/2350] Elapsed 1m 37s (remain 5m 58s) Loss: 0.0614(0.0185) \n","EVAL: [600/2350] Elapsed 1m 56s (remain 5m 39s) Loss: 0.0148(0.0183) \n","EVAL: [700/2350] Elapsed 2m 15s (remain 5m 19s) Loss: 0.0386(0.0195) \n","EVAL: [800/2350] Elapsed 2m 35s (remain 5m 0s) Loss: 0.0000(0.0198) \n","EVAL: [900/2350] Elapsed 2m 54s (remain 4m 40s) Loss: 0.0012(0.0179) \n","EVAL: [1000/2350] Elapsed 3m 13s (remain 4m 21s) Loss: 0.0033(0.0164) \n","EVAL: [1100/2350] Elapsed 3m 33s (remain 4m 1s) Loss: 0.0000(0.0151) \n","EVAL: [1200/2350] Elapsed 3m 52s (remain 3m 42s) Loss: 0.0001(0.0140) \n","EVAL: [1300/2350] Elapsed 4m 12s (remain 3m 23s) Loss: 0.0000(0.0132) \n","EVAL: [1400/2350] Elapsed 4m 31s (remain 3m 3s) Loss: 0.0070(0.0129) \n","EVAL: [1500/2350] Elapsed 4m 50s (remain 2m 44s) Loss: 0.0007(0.0125) \n","EVAL: [1600/2350] Elapsed 5m 10s (remain 2m 25s) Loss: 0.0010(0.0122) \n","EVAL: [1700/2350] Elapsed 5m 29s (remain 2m 5s) Loss: 0.0163(0.0123) \n","EVAL: [1800/2350] Elapsed 5m 48s (remain 1m 46s) Loss: 0.0000(0.0119) \n","EVAL: [1900/2350] Elapsed 6m 8s (remain 1m 26s) Loss: 0.0000(0.0114) \n","EVAL: [2000/2350] Elapsed 6m 27s (remain 1m 7s) Loss: 0.0000(0.0108) \n","EVAL: [2100/2350] Elapsed 6m 46s (remain 0m 48s) Loss: 0.0000(0.0103) \n","EVAL: [2200/2350] Elapsed 7m 6s (remain 0m 28s) Loss: 0.0000(0.0099) \n","EVAL: [2300/2350] Elapsed 7m 25s (remain 0m 9s) Loss: 0.0000(0.0095) \n","EVAL: [2349/2350] Elapsed 7m 34s (remain 0m 0s) Loss: 0.0000(0.0093) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0052  avg_val_loss: 0.0093  time: 3528s\n","Epoch 4 - Score: 0.9518\n","Epoch 4 - Save Best Score: 0.9518 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/1906] Elapsed 0m 0s (remain 27m 15s) Loss: 0.0257(0.0257) Grad: 46638.1250  LR: 0.00000096  \n","Epoch: [5][100/1906] Elapsed 0m 33s (remain 10m 2s) Loss: 0.0000(0.0114) Grad: 14.1150  LR: 0.00000094  \n","Epoch: [5][200/1906] Elapsed 1m 6s (remain 9m 22s) Loss: 0.0157(0.0100) Grad: 49153.3398  LR: 0.00000092  \n","Epoch: [5][300/1906] Elapsed 1m 39s (remain 8m 47s) Loss: 0.0002(0.0107) Grad: 2320.0134  LR: 0.00000090  \n","Epoch: [5][400/1906] Elapsed 2m 11s (remain 8m 14s) Loss: 0.0016(0.0101) Grad: 7360.4023  LR: 0.00000088  \n","Epoch: [5][500/1906] Elapsed 2m 44s (remain 7m 40s) Loss: 0.0000(0.0099) Grad: 299.8039  LR: 0.00000086  \n","Epoch: [5][600/1906] Elapsed 3m 16s (remain 7m 7s) Loss: 0.0001(0.0102) Grad: 890.1874  LR: 0.00000084  \n","Epoch: [5][700/1906] Elapsed 3m 49s (remain 6m 34s) Loss: 0.0372(0.0101) Grad: 35709.9648  LR: 0.00000082  \n","Epoch: [5][800/1906] Elapsed 4m 22s (remain 6m 1s) Loss: 0.0013(0.0098) Grad: 8867.3105  LR: 0.00000080  \n","Epoch: [5][900/1906] Elapsed 4m 54s (remain 5m 28s) Loss: 0.0001(0.0097) Grad: 740.4544  LR: 0.00000079  \n","Epoch: [5][1000/1906] Elapsed 5m 27s (remain 4m 55s) Loss: 0.0026(0.0096) Grad: 20358.7598  LR: 0.00000077  \n","Epoch: [5][1100/1906] Elapsed 5m 59s (remain 4m 23s) Loss: 0.0009(0.0095) Grad: 5700.3862  LR: 0.00000075  \n","Epoch: [5][1200/1906] Elapsed 6m 32s (remain 3m 50s) Loss: 0.0054(0.0092) Grad: 21174.5508  LR: 0.00000073  \n","Epoch: [5][1300/1906] Elapsed 7m 5s (remain 3m 17s) Loss: 0.0001(0.0091) Grad: 841.2289  LR: 0.00000072  \n","Epoch: [5][1400/1906] Elapsed 7m 37s (remain 2m 44s) Loss: 0.0020(0.0089) Grad: 9297.1943  LR: 0.00000070  \n","Epoch: [5][1500/1906] Elapsed 8m 10s (remain 2m 12s) Loss: 0.0001(0.0088) Grad: 252.8832  LR: 0.00000068  \n","Epoch: [5][1600/1906] Elapsed 8m 42s (remain 1m 39s) Loss: 0.0003(0.0088) Grad: 2084.9023  LR: 0.00000066  \n","Epoch: [5][1700/1906] Elapsed 9m 15s (remain 1m 6s) Loss: 0.0167(0.0087) Grad: 20569.1973  LR: 0.00000065  \n","Epoch: [5][1800/1906] Elapsed 9m 47s (remain 0m 34s) Loss: 0.0000(0.0086) Grad: 138.7880  LR: 0.00000063  \n","Epoch: [5][1900/1906] Elapsed 10m 20s (remain 0m 1s) Loss: 0.0000(0.0085) Grad: 347.3300  LR: 0.00000062  \n","Epoch: [5][1905/1906] Elapsed 10m 21s (remain 0m 0s) Loss: 0.0057(0.0085) Grad: 28246.4863  LR: 0.00000061  \n","EVAL: [0/477] Elapsed 0m 0s (remain 3m 44s) Loss: 0.0016(0.0016) \n","EVAL: [100/477] Elapsed 0m 19s (remain 1m 13s) Loss: 0.0098(0.0114) \n","EVAL: [200/477] Elapsed 0m 39s (remain 0m 53s) Loss: 0.0000(0.0112) \n","EVAL: [300/477] Elapsed 0m 58s (remain 0m 34s) Loss: 0.0033(0.0142) \n","EVAL: [400/477] Elapsed 1m 17s (remain 0m 14s) Loss: 0.0261(0.0135) \n","EVAL: [476/477] Elapsed 1m 32s (remain 0m 0s) Loss: 0.0000(0.0129) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0085  avg_val_loss: 0.0129  time: 717s\n","Epoch 5 - Score: 0.9038\n","========== fold: 1 result ==========\n","Score: 0.9518\n","========== fold: 2 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/9497] Elapsed 0m 0s (remain 101m 38s) Loss: 0.6202(0.6202) Grad: inf  LR: 0.00001000  \n","Epoch: [1][100/9497] Elapsed 0m 33s (remain 51m 28s) Loss: 0.1932(0.1152) Grad: 6913.7827  LR: 0.00001000  \n","Epoch: [1][200/9497] Elapsed 1m 5s (remain 50m 43s) Loss: 0.0087(0.0761) Grad: 1599.2474  LR: 0.00001000  \n","Epoch: [1][300/9497] Elapsed 1m 38s (remain 50m 7s) Loss: 0.0237(0.0594) Grad: 2582.3538  LR: 0.00001000  \n","Epoch: [1][400/9497] Elapsed 2m 11s (remain 49m 34s) Loss: 0.0287(0.0503) Grad: 17423.6113  LR: 0.00001000  \n","Epoch: [1][500/9497] Elapsed 2m 43s (remain 48m 57s) Loss: 0.0223(0.0447) Grad: 2233.6633  LR: 0.00001000  \n","Epoch: [1][600/9497] Elapsed 3m 16s (remain 48m 24s) Loss: 0.0200(0.0405) Grad: 5090.9062  LR: 0.00001000  \n","Epoch: [1][700/9497] Elapsed 3m 48s (remain 47m 52s) Loss: 0.0058(0.0372) Grad: 1654.0614  LR: 0.00000999  \n","Epoch: [1][800/9497] Elapsed 4m 21s (remain 47m 18s) Loss: 0.0011(0.0344) Grad: 705.2306  LR: 0.00000999  \n","Epoch: [1][900/9497] Elapsed 4m 54s (remain 46m 45s) Loss: 0.0227(0.0323) Grad: 3586.5591  LR: 0.00000999  \n","Epoch: [1][1000/9497] Elapsed 5m 26s (remain 46m 12s) Loss: 0.0270(0.0306) Grad: 6879.6230  LR: 0.00000999  \n","Epoch: [1][1100/9497] Elapsed 5m 59s (remain 45m 39s) Loss: 0.0111(0.0293) Grad: 2228.4653  LR: 0.00000999  \n","Epoch: [1][1200/9497] Elapsed 6m 32s (remain 45m 8s) Loss: 0.0079(0.0282) Grad: 3931.5713  LR: 0.00000998  \n","Epoch: [1][1300/9497] Elapsed 7m 4s (remain 44m 35s) Loss: 0.0390(0.0271) Grad: 17531.2578  LR: 0.00000998  \n","Epoch: [1][1400/9497] Elapsed 7m 37s (remain 44m 1s) Loss: 0.0115(0.0261) Grad: 1469.9882  LR: 0.00000998  \n","Epoch: [1][1500/9497] Elapsed 8m 9s (remain 43m 28s) Loss: 0.0121(0.0253) Grad: 1572.6260  LR: 0.00000998  \n","Epoch: [1][1600/9497] Elapsed 8m 42s (remain 42m 54s) Loss: 0.0174(0.0245) Grad: 3525.4453  LR: 0.00000997  \n","Epoch: [1][1700/9497] Elapsed 9m 14s (remain 42m 22s) Loss: 0.0102(0.0239) Grad: 1249.0879  LR: 0.00000997  \n","Epoch: [1][1800/9497] Elapsed 9m 47s (remain 41m 49s) Loss: 0.0089(0.0233) Grad: 1634.7046  LR: 0.00000996  \n","Epoch: [1][1900/9497] Elapsed 10m 19s (remain 41m 16s) Loss: 0.0088(0.0227) Grad: 1955.2112  LR: 0.00000996  \n","Epoch: [1][2000/9497] Elapsed 10m 52s (remain 40m 44s) Loss: 0.0061(0.0222) Grad: 733.1532  LR: 0.00000996  \n","Epoch: [1][2100/9497] Elapsed 11m 25s (remain 40m 12s) Loss: 0.0033(0.0217) Grad: 2556.6836  LR: 0.00000995  \n","Epoch: [1][2200/9497] Elapsed 11m 57s (remain 39m 39s) Loss: 0.0181(0.0214) Grad: 5672.9111  LR: 0.00000995  \n","Epoch: [1][2300/9497] Elapsed 12m 30s (remain 39m 6s) Loss: 0.0075(0.0208) Grad: 4917.1040  LR: 0.00000994  \n","Epoch: [1][2400/9497] Elapsed 13m 3s (remain 38m 34s) Loss: 0.0253(0.0205) Grad: 9057.0469  LR: 0.00000994  \n","Epoch: [1][2500/9497] Elapsed 13m 35s (remain 38m 1s) Loss: 0.0049(0.0201) Grad: 2715.1077  LR: 0.00000993  \n","Epoch: [1][2600/9497] Elapsed 14m 8s (remain 37m 29s) Loss: 0.0002(0.0196) Grad: 116.4833  LR: 0.00000993  \n","Epoch: [1][2700/9497] Elapsed 14m 40s (remain 36m 56s) Loss: 0.0093(0.0192) Grad: 6468.4609  LR: 0.00000992  \n","Epoch: [1][2800/9497] Elapsed 15m 13s (remain 36m 23s) Loss: 0.0092(0.0189) Grad: 2207.2117  LR: 0.00000991  \n","Epoch: [1][2900/9497] Elapsed 15m 46s (remain 35m 50s) Loss: 0.0065(0.0186) Grad: 7942.2637  LR: 0.00000991  \n","Epoch: [1][3000/9497] Elapsed 16m 18s (remain 35m 18s) Loss: 0.0091(0.0183) Grad: 3719.2114  LR: 0.00000990  \n","Epoch: [1][3100/9497] Elapsed 16m 51s (remain 34m 45s) Loss: 0.0026(0.0180) Grad: 2987.2756  LR: 0.00000990  \n","Epoch: [1][3200/9497] Elapsed 17m 23s (remain 34m 13s) Loss: 0.0149(0.0178) Grad: 5341.6509  LR: 0.00000989  \n","Epoch: [1][3300/9497] Elapsed 17m 56s (remain 33m 40s) Loss: 0.0077(0.0176) Grad: 9626.4248  LR: 0.00000988  \n","Epoch: [1][3400/9497] Elapsed 18m 28s (remain 33m 7s) Loss: 0.0078(0.0174) Grad: 1505.6934  LR: 0.00000987  \n","Epoch: [1][3500/9497] Elapsed 19m 1s (remain 32m 34s) Loss: 0.0010(0.0172) Grad: 389.4788  LR: 0.00000987  \n","Epoch: [1][3600/9497] Elapsed 19m 33s (remain 32m 2s) Loss: 0.0211(0.0170) Grad: 8911.7002  LR: 0.00000986  \n","Epoch: [1][3700/9497] Elapsed 20m 6s (remain 31m 29s) Loss: 0.0014(0.0168) Grad: 2458.3020  LR: 0.00000985  \n","Epoch: [1][3800/9497] Elapsed 20m 38s (remain 30m 56s) Loss: 0.0036(0.0167) Grad: 2585.4458  LR: 0.00000984  \n","Epoch: [1][3900/9497] Elapsed 21m 11s (remain 30m 23s) Loss: 0.0101(0.0164) Grad: 1629.6556  LR: 0.00000983  \n","Epoch: [1][4000/9497] Elapsed 21m 43s (remain 29m 51s) Loss: 0.0041(0.0163) Grad: 2169.7717  LR: 0.00000983  \n","Epoch: [1][4100/9497] Elapsed 22m 16s (remain 29m 18s) Loss: 0.0023(0.0161) Grad: 3928.1978  LR: 0.00000982  \n","Epoch: [1][4200/9497] Elapsed 22m 49s (remain 28m 45s) Loss: 0.0159(0.0160) Grad: 7617.0273  LR: 0.00000981  \n","Epoch: [1][4300/9497] Elapsed 23m 21s (remain 28m 13s) Loss: 0.0118(0.0158) Grad: 5385.9834  LR: 0.00000980  \n","Epoch: [1][4400/9497] Elapsed 23m 54s (remain 27m 40s) Loss: 0.0293(0.0156) Grad: 45612.0000  LR: 0.00000979  \n","Epoch: [1][4500/9497] Elapsed 24m 26s (remain 27m 7s) Loss: 0.0499(0.0155) Grad: 22047.6562  LR: 0.00000978  \n","Epoch: [1][4600/9497] Elapsed 24m 59s (remain 26m 35s) Loss: 0.0076(0.0154) Grad: 4964.5122  LR: 0.00000977  \n","Epoch: [1][4700/9497] Elapsed 25m 31s (remain 26m 2s) Loss: 0.0004(0.0153) Grad: 320.0870  LR: 0.00000976  \n","Epoch: [1][4800/9497] Elapsed 26m 4s (remain 25m 30s) Loss: 0.0019(0.0152) Grad: 2836.1536  LR: 0.00000975  \n","Epoch: [1][4900/9497] Elapsed 26m 36s (remain 24m 57s) Loss: 0.0062(0.0151) Grad: 5280.0400  LR: 0.00000974  \n","Epoch: [1][5000/9497] Elapsed 27m 9s (remain 24m 25s) Loss: 0.0034(0.0149) Grad: 2898.5105  LR: 0.00000973  \n","Epoch: [1][5100/9497] Elapsed 27m 42s (remain 23m 52s) Loss: 0.0003(0.0148) Grad: 315.7811  LR: 0.00000972  \n","Epoch: [1][5200/9497] Elapsed 28m 14s (remain 23m 19s) Loss: 0.0121(0.0148) Grad: 4687.0972  LR: 0.00000971  \n","Epoch: [1][5300/9497] Elapsed 28m 47s (remain 22m 47s) Loss: 0.0008(0.0147) Grad: 1688.0001  LR: 0.00000970  \n","Epoch: [1][5400/9497] Elapsed 29m 20s (remain 22m 14s) Loss: 0.0006(0.0145) Grad: 480.0015  LR: 0.00000968  \n","Epoch: [1][5500/9497] Elapsed 29m 52s (remain 21m 42s) Loss: 0.0221(0.0144) Grad: 13812.3633  LR: 0.00000967  \n","Epoch: [1][5600/9497] Elapsed 30m 25s (remain 21m 9s) Loss: 0.0034(0.0144) Grad: 3634.9253  LR: 0.00000966  \n","Epoch: [1][5700/9497] Elapsed 30m 57s (remain 20m 37s) Loss: 0.0183(0.0143) Grad: 6242.2856  LR: 0.00000965  \n","Epoch: [1][5800/9497] Elapsed 31m 30s (remain 20m 4s) Loss: 0.0103(0.0142) Grad: 9569.1904  LR: 0.00000964  \n","Epoch: [1][5900/9497] Elapsed 32m 2s (remain 19m 31s) Loss: 0.0001(0.0141) Grad: 148.8042  LR: 0.00000962  \n","Epoch: [1][6000/9497] Elapsed 32m 35s (remain 18m 59s) Loss: 0.0018(0.0140) Grad: 2762.0801  LR: 0.00000961  \n","Epoch: [1][6100/9497] Elapsed 33m 8s (remain 18m 26s) Loss: 0.0076(0.0139) Grad: 7052.9326  LR: 0.00000960  \n","Epoch: [1][6200/9497] Elapsed 33m 40s (remain 17m 54s) Loss: 0.0001(0.0138) Grad: 165.6419  LR: 0.00000959  \n","Epoch: [1][6300/9497] Elapsed 34m 13s (remain 17m 21s) Loss: 0.0030(0.0138) Grad: 5583.3296  LR: 0.00000957  \n","Epoch: [1][6400/9497] Elapsed 34m 46s (remain 16m 48s) Loss: 0.0048(0.0137) Grad: 12890.9180  LR: 0.00000956  \n","Epoch: [1][6500/9497] Elapsed 35m 18s (remain 16m 16s) Loss: 0.0021(0.0136) Grad: 4607.9819  LR: 0.00000954  \n","Epoch: [1][6600/9497] Elapsed 35m 51s (remain 15m 43s) Loss: 0.0049(0.0135) Grad: 7148.4297  LR: 0.00000953  \n","Epoch: [1][6700/9497] Elapsed 36m 24s (remain 15m 11s) Loss: 0.0119(0.0134) Grad: 8114.3066  LR: 0.00000952  \n","Epoch: [1][6800/9497] Elapsed 36m 56s (remain 14m 38s) Loss: 0.0078(0.0133) Grad: 8071.6055  LR: 0.00000950  \n","Epoch: [1][6900/9497] Elapsed 37m 29s (remain 14m 6s) Loss: 0.0138(0.0133) Grad: 14267.3096  LR: 0.00000949  \n","Epoch: [1][7000/9497] Elapsed 38m 2s (remain 13m 33s) Loss: 0.0121(0.0132) Grad: 29763.7734  LR: 0.00000947  \n","Epoch: [1][7100/9497] Elapsed 38m 34s (remain 13m 1s) Loss: 0.0018(0.0132) Grad: 1959.6531  LR: 0.00000946  \n","Epoch: [1][7200/9497] Elapsed 39m 7s (remain 12m 28s) Loss: 0.0070(0.0131) Grad: 7478.2236  LR: 0.00000944  \n","Epoch: [1][7300/9497] Elapsed 39m 40s (remain 11m 55s) Loss: 0.0004(0.0130) Grad: 6962.4902  LR: 0.00000943  \n","Epoch: [1][7400/9497] Elapsed 40m 12s (remain 11m 23s) Loss: 0.0085(0.0130) Grad: 14007.9990  LR: 0.00000941  \n","Epoch: [1][7500/9497] Elapsed 40m 45s (remain 10m 50s) Loss: 0.0108(0.0129) Grad: 14958.3193  LR: 0.00000940  \n","Epoch: [1][7600/9497] Elapsed 41m 17s (remain 10m 18s) Loss: 0.0000(0.0129) Grad: 64.3192  LR: 0.00000938  \n","Epoch: [1][7700/9497] Elapsed 41m 50s (remain 9m 45s) Loss: 0.0015(0.0128) Grad: 4214.8267  LR: 0.00000937  \n","Epoch: [1][7800/9497] Elapsed 42m 23s (remain 9m 12s) Loss: 0.0000(0.0127) Grad: 62.7401  LR: 0.00000935  \n","Epoch: [1][7900/9497] Elapsed 42m 55s (remain 8m 40s) Loss: 0.0078(0.0127) Grad: 12912.3945  LR: 0.00000933  \n","Epoch: [1][8000/9497] Elapsed 43m 28s (remain 8m 7s) Loss: 0.0319(0.0127) Grad: 34746.5273  LR: 0.00000932  \n","Epoch: [1][8100/9497] Elapsed 44m 0s (remain 7m 35s) Loss: 0.0022(0.0126) Grad: 6255.1440  LR: 0.00000930  \n","Epoch: [1][8200/9497] Elapsed 44m 33s (remain 7m 2s) Loss: 0.0002(0.0125) Grad: 1187.6077  LR: 0.00000928  \n","Epoch: [1][8300/9497] Elapsed 45m 6s (remain 6m 29s) Loss: 0.0098(0.0125) Grad: 30276.9199  LR: 0.00000926  \n","Epoch: [1][8400/9497] Elapsed 45m 38s (remain 5m 57s) Loss: 0.0250(0.0125) Grad: 11858.3389  LR: 0.00000925  \n","Epoch: [1][8500/9497] Elapsed 46m 11s (remain 5m 24s) Loss: 0.0005(0.0124) Grad: 2203.1541  LR: 0.00000923  \n","Epoch: [1][8600/9497] Elapsed 46m 43s (remain 4m 52s) Loss: 0.0028(0.0123) Grad: 10267.7471  LR: 0.00000921  \n","Epoch: [1][8700/9497] Elapsed 47m 16s (remain 4m 19s) Loss: 0.0131(0.0123) Grad: 21259.6250  LR: 0.00000919  \n","Epoch: [1][8800/9497] Elapsed 47m 49s (remain 3m 46s) Loss: 0.0041(0.0122) Grad: 17544.1738  LR: 0.00000918  \n","Epoch: [1][8900/9497] Elapsed 48m 21s (remain 3m 14s) Loss: 0.0009(0.0122) Grad: 8203.8262  LR: 0.00000916  \n","Epoch: [1][9000/9497] Elapsed 48m 54s (remain 2m 41s) Loss: 0.0000(0.0121) Grad: 40.4517  LR: 0.00000914  \n","Epoch: [1][9100/9497] Elapsed 49m 26s (remain 2m 9s) Loss: 0.0051(0.0121) Grad: 18153.8594  LR: 0.00000912  \n","Epoch: [1][9200/9497] Elapsed 49m 59s (remain 1m 36s) Loss: 0.0070(0.0121) Grad: 12354.4170  LR: 0.00000910  \n","Epoch: [1][9300/9497] Elapsed 50m 32s (remain 1m 3s) Loss: 0.0259(0.0120) Grad: 15097.5469  LR: 0.00000908  \n","Epoch: [1][9400/9497] Elapsed 51m 4s (remain 0m 31s) Loss: 0.0123(0.0120) Grad: 176429.8906  LR: 0.00000906  \n","Epoch: [1][9496/9497] Elapsed 51m 36s (remain 0m 0s) Loss: 0.0486(0.0119) Grad: 46810.0703  LR: 0.00000905  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 18m 22s) Loss: 0.0002(0.0002) \n","EVAL: [100/2375] Elapsed 0m 19s (remain 7m 25s) Loss: 0.0287(0.0159) \n","EVAL: [200/2375] Elapsed 0m 39s (remain 7m 2s) Loss: 0.0000(0.0153) \n","EVAL: [300/2375] Elapsed 0m 58s (remain 6m 41s) Loss: 0.0088(0.0157) \n","EVAL: [400/2375] Elapsed 1m 17s (remain 6m 22s) Loss: 0.0229(0.0151) \n","EVAL: [500/2375] Elapsed 1m 36s (remain 6m 2s) Loss: 0.0192(0.0143) \n","EVAL: [600/2375] Elapsed 1m 56s (remain 5m 43s) Loss: 0.0146(0.0144) \n","EVAL: [700/2375] Elapsed 2m 15s (remain 5m 24s) Loss: 0.0190(0.0151) \n","EVAL: [800/2375] Elapsed 2m 35s (remain 5m 4s) Loss: 0.0138(0.0159) \n","EVAL: [900/2375] Elapsed 2m 54s (remain 4m 45s) Loss: 0.0000(0.0145) \n","EVAL: [1000/2375] Elapsed 3m 13s (remain 4m 26s) Loss: 0.0001(0.0133) \n","EVAL: [1100/2375] Elapsed 3m 33s (remain 4m 6s) Loss: 0.0003(0.0123) \n","EVAL: [1200/2375] Elapsed 3m 52s (remain 3m 47s) Loss: 0.0150(0.0116) \n","EVAL: [1300/2375] Elapsed 4m 11s (remain 3m 27s) Loss: 0.0000(0.0109) \n","EVAL: [1400/2375] Elapsed 4m 31s (remain 3m 8s) Loss: 0.0113(0.0107) \n","EVAL: [1500/2375] Elapsed 4m 50s (remain 2m 49s) Loss: 0.0056(0.0106) \n","EVAL: [1600/2375] Elapsed 5m 10s (remain 2m 29s) Loss: 0.0042(0.0104) \n","EVAL: [1700/2375] Elapsed 5m 29s (remain 2m 10s) Loss: 0.0176(0.0106) \n","EVAL: [1800/2375] Elapsed 5m 48s (remain 1m 51s) Loss: 0.0000(0.0104) \n","EVAL: [1900/2375] Elapsed 6m 8s (remain 1m 31s) Loss: 0.0000(0.0099) \n","EVAL: [2000/2375] Elapsed 6m 27s (remain 1m 12s) Loss: 0.0000(0.0094) \n","EVAL: [2100/2375] Elapsed 6m 46s (remain 0m 53s) Loss: 0.0000(0.0090) \n","EVAL: [2200/2375] Elapsed 7m 6s (remain 0m 33s) Loss: 0.0000(0.0087) \n","EVAL: [2300/2375] Elapsed 7m 25s (remain 0m 14s) Loss: 0.0000(0.0084) \n","EVAL: [2374/2375] Elapsed 7m 39s (remain 0m 0s) Loss: 0.0000(0.0081) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0119  avg_val_loss: 0.0081  time: 3569s\n","Epoch 1 - Score: 0.9460\n","Epoch 1 - Save Best Score: 0.9460 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/9497] Elapsed 0m 0s (remain 139m 49s) Loss: 0.0002(0.0002) Grad: 1214.2795  LR: 0.00000905  \n","Epoch: [2][100/9497] Elapsed 0m 33s (remain 52m 40s) Loss: 0.0078(0.0063) Grad: 35540.7891  LR: 0.00000903  \n","Epoch: [2][200/9497] Elapsed 1m 6s (remain 51m 16s) Loss: 0.0001(0.0062) Grad: 824.1057  LR: 0.00000901  \n","Epoch: [2][300/9497] Elapsed 1m 38s (remain 50m 24s) Loss: 0.0002(0.0063) Grad: 1035.6394  LR: 0.00000899  \n","Epoch: [2][400/9497] Elapsed 2m 11s (remain 49m 44s) Loss: 0.0143(0.0061) Grad: 41081.4219  LR: 0.00000897  \n","Epoch: [2][500/9497] Elapsed 2m 44s (remain 49m 7s) Loss: 0.0156(0.0065) Grad: 26213.0391  LR: 0.00000895  \n","Epoch: [2][600/9497] Elapsed 3m 16s (remain 48m 30s) Loss: 0.0000(0.0069) Grad: 334.7528  LR: 0.00000893  \n","Epoch: [2][700/9497] Elapsed 3m 49s (remain 47m 54s) Loss: 0.0055(0.0067) Grad: 36711.0820  LR: 0.00000890  \n","Epoch: [2][800/9497] Elapsed 4m 21s (remain 47m 21s) Loss: 0.0001(0.0068) Grad: 348.2130  LR: 0.00000888  \n","Epoch: [2][900/9497] Elapsed 4m 54s (remain 46m 48s) Loss: 0.0001(0.0068) Grad: 225.1320  LR: 0.00000886  \n","Epoch: [2][1000/9497] Elapsed 5m 27s (remain 46m 15s) Loss: 0.0026(0.0067) Grad: 16807.1855  LR: 0.00000884  \n","Epoch: [2][1100/9497] Elapsed 5m 59s (remain 45m 42s) Loss: 0.0196(0.0067) Grad: 42523.1797  LR: 0.00000882  \n","Epoch: [2][1200/9497] Elapsed 6m 32s (remain 45m 9s) Loss: 0.0001(0.0066) Grad: 1145.0676  LR: 0.00000880  \n","Epoch: [2][1300/9497] Elapsed 7m 4s (remain 44m 36s) Loss: 0.0032(0.0066) Grad: 28934.0566  LR: 0.00000878  \n","Epoch: [2][1400/9497] Elapsed 7m 37s (remain 44m 3s) Loss: 0.0059(0.0065) Grad: 13576.4502  LR: 0.00000876  \n","Epoch: [2][1500/9497] Elapsed 8m 9s (remain 43m 29s) Loss: 0.0013(0.0066) Grad: 11875.3018  LR: 0.00000873  \n","Epoch: [2][1600/9497] Elapsed 8m 42s (remain 42m 56s) Loss: 0.0001(0.0066) Grad: 385.0219  LR: 0.00000871  \n","Epoch: [2][1700/9497] Elapsed 9m 15s (remain 42m 24s) Loss: 0.0049(0.0067) Grad: 31431.0996  LR: 0.00000869  \n","Epoch: [2][1800/9497] Elapsed 9m 47s (remain 41m 51s) Loss: 0.0009(0.0066) Grad: 5180.8545  LR: 0.00000867  \n","Epoch: [2][1900/9497] Elapsed 10m 20s (remain 41m 18s) Loss: 0.0017(0.0066) Grad: 16437.3691  LR: 0.00000864  \n","Epoch: [2][2000/9497] Elapsed 10m 52s (remain 40m 45s) Loss: 0.0022(0.0066) Grad: 32316.8145  LR: 0.00000862  \n","Epoch: [2][2100/9497] Elapsed 11m 25s (remain 40m 13s) Loss: 0.0000(0.0066) Grad: 326.7246  LR: 0.00000860  \n","Epoch: [2][2200/9497] Elapsed 11m 58s (remain 39m 40s) Loss: 0.0077(0.0066) Grad: 49204.2070  LR: 0.00000858  \n","Epoch: [2][2300/9497] Elapsed 12m 30s (remain 39m 8s) Loss: 0.0004(0.0066) Grad: 6137.8491  LR: 0.00000855  \n","Epoch: [2][2400/9497] Elapsed 13m 3s (remain 38m 35s) Loss: 0.0076(0.0066) Grad: 53419.7969  LR: 0.00000853  \n","Epoch: [2][2500/9497] Elapsed 13m 36s (remain 38m 2s) Loss: 0.0406(0.0066) Grad: 32594.2656  LR: 0.00000851  \n","Epoch: [2][2600/9497] Elapsed 14m 8s (remain 37m 29s) Loss: 0.0000(0.0066) Grad: 115.2179  LR: 0.00000848  \n","Epoch: [2][2700/9497] Elapsed 14m 41s (remain 36m 57s) Loss: 0.0089(0.0066) Grad: 65011.0820  LR: 0.00000846  \n","Epoch: [2][2800/9497] Elapsed 15m 13s (remain 36m 24s) Loss: 0.0001(0.0066) Grad: 2060.1826  LR: 0.00000843  \n","Epoch: [2][2900/9497] Elapsed 15m 46s (remain 35m 52s) Loss: 0.0009(0.0066) Grad: 17787.3320  LR: 0.00000841  \n","Epoch: [2][3000/9497] Elapsed 16m 19s (remain 35m 19s) Loss: 0.0000(0.0066) Grad: 471.6125  LR: 0.00000839  \n","Epoch: [2][3100/9497] Elapsed 16m 51s (remain 34m 46s) Loss: 0.0001(0.0066) Grad: 870.6777  LR: 0.00000836  \n","Epoch: [2][3200/9497] Elapsed 17m 24s (remain 34m 14s) Loss: 0.0049(0.0066) Grad: 56227.2969  LR: 0.00000834  \n","Epoch: [2][3300/9497] Elapsed 17m 57s (remain 33m 41s) Loss: 0.0002(0.0066) Grad: 2836.9409  LR: 0.00000831  \n","Epoch: [2][3400/9497] Elapsed 18m 29s (remain 33m 8s) Loss: 0.0229(0.0067) Grad: 319486.7812  LR: 0.00000829  \n","Epoch: [2][3500/9497] Elapsed 19m 2s (remain 32m 36s) Loss: 0.0007(0.0066) Grad: 9447.2227  LR: 0.00000826  \n","Epoch: [2][3600/9497] Elapsed 19m 34s (remain 32m 3s) Loss: 0.0043(0.0066) Grad: 38271.1797  LR: 0.00000824  \n","Epoch: [2][3700/9497] Elapsed 20m 7s (remain 31m 30s) Loss: 0.0001(0.0066) Grad: 1166.7430  LR: 0.00000821  \n","Epoch: [2][3800/9497] Elapsed 20m 40s (remain 30m 58s) Loss: 0.0195(0.0066) Grad: 76284.7031  LR: 0.00000819  \n","Epoch: [2][3900/9497] Elapsed 21m 12s (remain 30m 25s) Loss: 0.0303(0.0066) Grad: 146993.5781  LR: 0.00000816  \n","Epoch: [2][4000/9497] Elapsed 21m 44s (remain 29m 52s) Loss: 0.0011(0.0066) Grad: 56500.3789  LR: 0.00000814  \n","Epoch: [2][4100/9497] Elapsed 22m 17s (remain 29m 19s) Loss: 0.0001(0.0066) Grad: 5784.1045  LR: 0.00000811  \n","Epoch: [2][4200/9497] Elapsed 22m 50s (remain 28m 47s) Loss: 0.0065(0.0066) Grad: 200569.2969  LR: 0.00000808  \n","Epoch: [2][4300/9497] Elapsed 23m 22s (remain 28m 14s) Loss: 0.0076(0.0066) Grad: 103488.2109  LR: 0.00000806  \n","Epoch: [2][4400/9497] Elapsed 23m 55s (remain 27m 41s) Loss: 0.0127(0.0066) Grad: 675254.1250  LR: 0.00000803  \n","Epoch: [2][4500/9497] Elapsed 24m 27s (remain 27m 9s) Loss: 0.0197(0.0066) Grad: 146224.3750  LR: 0.00000800  \n","Epoch: [2][4600/9497] Elapsed 25m 0s (remain 26m 36s) Loss: 0.0011(0.0067) Grad: 39505.9180  LR: 0.00000798  \n","Epoch: [2][4700/9497] Elapsed 25m 32s (remain 26m 3s) Loss: 0.0036(0.0067) Grad: 134195.8125  LR: 0.00000795  \n","Epoch: [2][4800/9497] Elapsed 26m 5s (remain 25m 31s) Loss: 0.0026(0.0067) Grad: 46640.6211  LR: 0.00000793  \n","Epoch: [2][4900/9497] Elapsed 26m 37s (remain 24m 58s) Loss: 0.0004(0.0067) Grad: 19012.0312  LR: 0.00000790  \n","Epoch: [2][5000/9497] Elapsed 27m 10s (remain 24m 25s) Loss: 0.0002(0.0067) Grad: 16540.7324  LR: 0.00000787  \n","Epoch: [2][5100/9497] Elapsed 27m 42s (remain 23m 52s) Loss: 0.0052(0.0067) Grad: 116263.0625  LR: 0.00000784  \n","Epoch: [2][5200/9497] Elapsed 28m 15s (remain 23m 20s) Loss: 0.0004(0.0067) Grad: 24832.6230  LR: 0.00000782  \n","Epoch: [2][5300/9497] Elapsed 28m 47s (remain 22m 47s) Loss: 0.0028(0.0067) Grad: 72504.5469  LR: 0.00000779  \n","Epoch: [2][5400/9497] Elapsed 29m 20s (remain 22m 15s) Loss: 0.0009(0.0067) Grad: 76612.2109  LR: 0.00000776  \n","Epoch: [2][5500/9497] Elapsed 29m 53s (remain 21m 42s) Loss: 0.0025(0.0067) Grad: 127094.9453  LR: 0.00000773  \n","Epoch: [2][5600/9497] Elapsed 30m 25s (remain 21m 9s) Loss: 0.0005(0.0067) Grad: 29974.1855  LR: 0.00000771  \n","Epoch: [2][5700/9497] Elapsed 30m 58s (remain 20m 37s) Loss: 0.0085(0.0067) Grad: 211535.9062  LR: 0.00000768  \n","Epoch: [2][5800/9497] Elapsed 31m 30s (remain 20m 4s) Loss: 0.0033(0.0067) Grad: 127037.0469  LR: 0.00000765  \n","Epoch: [2][5900/9497] Elapsed 32m 3s (remain 19m 31s) Loss: 0.0057(0.0067) Grad: 243345.9844  LR: 0.00000762  \n","Epoch: [2][6000/9497] Elapsed 32m 35s (remain 18m 59s) Loss: 0.0319(0.0067) Grad: 327918.3750  LR: 0.00000759  \n","Epoch: [2][6100/9497] Elapsed 33m 8s (remain 18m 26s) Loss: 0.0001(0.0067) Grad: 3480.2966  LR: 0.00000757  \n","Epoch: [2][6200/9497] Elapsed 33m 40s (remain 17m 54s) Loss: 0.0010(0.0067) Grad: 22940.7090  LR: 0.00000754  \n","Epoch: [2][6300/9497] Elapsed 34m 13s (remain 17m 21s) Loss: 0.0022(0.0067) Grad: 64957.8281  LR: 0.00000751  \n","Epoch: [2][6400/9497] Elapsed 34m 45s (remain 16m 48s) Loss: 0.0078(0.0067) Grad: 44464.9648  LR: 0.00000748  \n","Epoch: [2][6500/9497] Elapsed 35m 18s (remain 16m 16s) Loss: 0.0018(0.0067) Grad: 13120.0771  LR: 0.00000745  \n","Epoch: [2][6600/9497] Elapsed 35m 51s (remain 15m 43s) Loss: 0.0103(0.0067) Grad: 100553.1953  LR: 0.00000742  \n","Epoch: [2][6700/9497] Elapsed 36m 23s (remain 15m 11s) Loss: 0.0020(0.0067) Grad: 21470.8730  LR: 0.00000739  \n","Epoch: [2][6800/9497] Elapsed 36m 56s (remain 14m 38s) Loss: 0.0000(0.0067) Grad: 1312.3397  LR: 0.00000736  \n","Epoch: [2][6900/9497] Elapsed 37m 29s (remain 14m 6s) Loss: 0.0057(0.0068) Grad: 25558.2793  LR: 0.00000734  \n","Epoch: [2][7000/9497] Elapsed 38m 1s (remain 13m 33s) Loss: 0.0149(0.0068) Grad: 31525.7520  LR: 0.00000731  \n","Epoch: [2][7100/9497] Elapsed 38m 34s (remain 13m 0s) Loss: 0.0072(0.0067) Grad: 18440.8105  LR: 0.00000728  \n","Epoch: [2][7200/9497] Elapsed 39m 6s (remain 12m 28s) Loss: 0.0000(0.0067) Grad: 45.7759  LR: 0.00000725  \n","Epoch: [2][7300/9497] Elapsed 39m 39s (remain 11m 55s) Loss: 0.0000(0.0067) Grad: 158.8882  LR: 0.00000722  \n","Epoch: [2][7400/9497] Elapsed 40m 11s (remain 11m 22s) Loss: 0.0172(0.0067) Grad: 19154.8145  LR: 0.00000719  \n","Epoch: [2][7500/9497] Elapsed 40m 44s (remain 10m 50s) Loss: 0.0019(0.0067) Grad: 17277.0664  LR: 0.00000716  \n","Epoch: [2][7600/9497] Elapsed 41m 16s (remain 10m 17s) Loss: 0.0070(0.0068) Grad: 116096.4688  LR: 0.00000713  \n","Epoch: [2][7700/9497] Elapsed 41m 49s (remain 9m 45s) Loss: 0.0045(0.0068) Grad: 17421.3926  LR: 0.00000710  \n","Epoch: [2][7800/9497] Elapsed 42m 21s (remain 9m 12s) Loss: 0.0003(0.0068) Grad: 4251.8550  LR: 0.00000707  \n","Epoch: [2][7900/9497] Elapsed 42m 54s (remain 8m 40s) Loss: 0.0046(0.0068) Grad: 17137.9219  LR: 0.00000704  \n","Epoch: [2][8000/9497] Elapsed 43m 26s (remain 8m 7s) Loss: 0.0106(0.0068) Grad: 51184.1562  LR: 0.00000701  \n","Epoch: [2][8100/9497] Elapsed 43m 59s (remain 7m 34s) Loss: 0.0031(0.0068) Grad: 13625.4199  LR: 0.00000698  \n","Epoch: [2][8200/9497] Elapsed 44m 31s (remain 7m 2s) Loss: 0.0029(0.0068) Grad: 23102.9863  LR: 0.00000695  \n","Epoch: [2][8300/9497] Elapsed 45m 4s (remain 6m 29s) Loss: 0.0087(0.0068) Grad: 65019.4648  LR: 0.00000692  \n","Epoch: [2][8400/9497] Elapsed 45m 36s (remain 5m 57s) Loss: 0.0095(0.0068) Grad: 105489.3672  LR: 0.00000689  \n","Epoch: [2][8500/9497] Elapsed 46m 9s (remain 5m 24s) Loss: 0.0055(0.0068) Grad: 32810.9609  LR: 0.00000686  \n","Epoch: [2][8600/9497] Elapsed 46m 41s (remain 4m 51s) Loss: 0.0000(0.0068) Grad: 68.2811  LR: 0.00000682  \n","Epoch: [2][8700/9497] Elapsed 47m 14s (remain 4m 19s) Loss: 0.0006(0.0068) Grad: 10657.1885  LR: 0.00000679  \n","Epoch: [2][8800/9497] Elapsed 47m 46s (remain 3m 46s) Loss: 0.0007(0.0068) Grad: 33439.9805  LR: 0.00000676  \n","Epoch: [2][8900/9497] Elapsed 48m 19s (remain 3m 14s) Loss: 0.0033(0.0068) Grad: 52522.4258  LR: 0.00000673  \n","Epoch: [2][9000/9497] Elapsed 48m 51s (remain 2m 41s) Loss: 0.0002(0.0068) Grad: 4070.0930  LR: 0.00000670  \n","Epoch: [2][9100/9497] Elapsed 49m 24s (remain 2m 8s) Loss: 0.0109(0.0068) Grad: 102605.7422  LR: 0.00000667  \n","Epoch: [2][9200/9497] Elapsed 49m 57s (remain 1m 36s) Loss: 0.0035(0.0068) Grad: 89738.0703  LR: 0.00000664  \n","Epoch: [2][9300/9497] Elapsed 50m 29s (remain 1m 3s) Loss: 0.0262(0.0068) Grad: 183580.8281  LR: 0.00000661  \n","Epoch: [2][9400/9497] Elapsed 51m 1s (remain 0m 31s) Loss: 0.0003(0.0068) Grad: 13387.0127  LR: 0.00000658  \n","Epoch: [2][9496/9497] Elapsed 51m 33s (remain 0m 0s) Loss: 0.0099(0.0068) Grad: 124628.1797  LR: 0.00000655  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 17m 56s) Loss: 0.0002(0.0002) \n","EVAL: [100/2375] Elapsed 0m 19s (remain 7m 22s) Loss: 0.0287(0.0170) \n","EVAL: [200/2375] Elapsed 0m 38s (remain 7m 1s) Loss: 0.0000(0.0165) \n","EVAL: [300/2375] Elapsed 0m 58s (remain 6m 41s) Loss: 0.0087(0.0169) \n","EVAL: [400/2375] Elapsed 1m 17s (remain 6m 21s) Loss: 0.0266(0.0164) \n","EVAL: [500/2375] Elapsed 1m 36s (remain 6m 2s) Loss: 0.0211(0.0150) \n","EVAL: [600/2375] Elapsed 1m 56s (remain 5m 42s) Loss: 0.0086(0.0151) \n","EVAL: [700/2375] Elapsed 2m 15s (remain 5m 23s) Loss: 0.0199(0.0156) \n","EVAL: [800/2375] Elapsed 2m 34s (remain 5m 4s) Loss: 0.0135(0.0164) \n","EVAL: [900/2375] Elapsed 2m 54s (remain 4m 44s) Loss: 0.0000(0.0149) \n","EVAL: [1000/2375] Elapsed 3m 13s (remain 4m 25s) Loss: 0.0001(0.0137) \n","EVAL: [1100/2375] Elapsed 3m 32s (remain 4m 6s) Loss: 0.0007(0.0126) \n","EVAL: [1200/2375] Elapsed 3m 52s (remain 3m 46s) Loss: 0.0089(0.0118) \n","EVAL: [1300/2375] Elapsed 4m 11s (remain 3m 27s) Loss: 0.0000(0.0111) \n","EVAL: [1400/2375] Elapsed 4m 30s (remain 3m 8s) Loss: 0.0112(0.0109) \n","EVAL: [1500/2375] Elapsed 4m 50s (remain 2m 48s) Loss: 0.0013(0.0107) \n","EVAL: [1600/2375] Elapsed 5m 9s (remain 2m 29s) Loss: 0.0049(0.0105) \n","EVAL: [1700/2375] Elapsed 5m 28s (remain 2m 10s) Loss: 0.0148(0.0106) \n","EVAL: [1800/2375] Elapsed 5m 48s (remain 1m 50s) Loss: 0.0000(0.0104) \n","EVAL: [1900/2375] Elapsed 6m 7s (remain 1m 31s) Loss: 0.0000(0.0099) \n","EVAL: [2000/2375] Elapsed 6m 26s (remain 1m 12s) Loss: 0.0000(0.0094) \n","EVAL: [2100/2375] Elapsed 6m 46s (remain 0m 52s) Loss: 0.0000(0.0090) \n","EVAL: [2200/2375] Elapsed 7m 5s (remain 0m 33s) Loss: 0.0000(0.0087) \n","EVAL: [2300/2375] Elapsed 7m 24s (remain 0m 14s) Loss: 0.0000(0.0083) \n","EVAL: [2374/2375] Elapsed 7m 38s (remain 0m 0s) Loss: 0.0000(0.0081) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0068  avg_val_loss: 0.0081  time: 3565s\n","Epoch 2 - Score: 0.9505\n","Epoch 2 - Save Best Score: 0.9505 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/9497] Elapsed 0m 0s (remain 143m 12s) Loss: 0.0051(0.0051) Grad: 70348.9922  LR: 0.00000655  \n","Epoch: [3][100/9497] Elapsed 0m 34s (remain 53m 55s) Loss: 0.0193(0.0061) Grad: 29608.8594  LR: 0.00000651  \n","Epoch: [3][200/9497] Elapsed 1m 8s (remain 52m 41s) Loss: 0.0019(0.0060) Grad: 29713.9688  LR: 0.00000648  \n","Epoch: [3][300/9497] Elapsed 1m 41s (remain 51m 55s) Loss: 0.0013(0.0058) Grad: 4478.2632  LR: 0.00000645  \n","Epoch: [3][400/9497] Elapsed 2m 15s (remain 51m 15s) Loss: 0.0000(0.0057) Grad: 116.2315  LR: 0.00000642  \n","Epoch: [3][500/9497] Elapsed 2m 49s (remain 50m 35s) Loss: 0.0005(0.0056) Grad: 11212.9844  LR: 0.00000639  \n","Epoch: [3][600/9497] Elapsed 3m 22s (remain 49m 58s) Loss: 0.0001(0.0057) Grad: 353.2912  LR: 0.00000636  \n","Epoch: [3][700/9497] Elapsed 3m 56s (remain 49m 22s) Loss: 0.0037(0.0057) Grad: 19649.5000  LR: 0.00000632  \n","Epoch: [3][800/9497] Elapsed 4m 29s (remain 48m 47s) Loss: 0.0132(0.0058) Grad: 66588.7188  LR: 0.00000629  \n","Epoch: [3][900/9497] Elapsed 5m 3s (remain 48m 11s) Loss: 0.0151(0.0058) Grad: 83637.4141  LR: 0.00000626  \n","Epoch: [3][1000/9497] Elapsed 5m 36s (remain 47m 37s) Loss: 0.0054(0.0058) Grad: 16224.4268  LR: 0.00000623  \n","Epoch: [3][1100/9497] Elapsed 6m 10s (remain 47m 2s) Loss: 0.0003(0.0060) Grad: 3834.2937  LR: 0.00000620  \n","Epoch: [3][1200/9497] Elapsed 6m 43s (remain 46m 27s) Loss: 0.0040(0.0060) Grad: 13711.8994  LR: 0.00000616  \n","Epoch: [3][1300/9497] Elapsed 7m 17s (remain 45m 53s) Loss: 0.0089(0.0059) Grad: 59488.9375  LR: 0.00000613  \n","Epoch: [3][1400/9497] Elapsed 7m 50s (remain 45m 19s) Loss: 0.0117(0.0059) Grad: 7254.6113  LR: 0.00000610  \n","Epoch: [3][1500/9497] Elapsed 8m 24s (remain 44m 46s) Loss: 0.0000(0.0058) Grad: 283.1602  LR: 0.00000607  \n","Epoch: [3][1600/9497] Elapsed 8m 57s (remain 44m 12s) Loss: 0.0123(0.0059) Grad: 31655.3145  LR: 0.00000603  \n","Epoch: [3][1700/9497] Elapsed 9m 31s (remain 43m 38s) Loss: 0.0218(0.0058) Grad: 41207.4570  LR: 0.00000600  \n","Epoch: [3][1800/9497] Elapsed 10m 4s (remain 43m 4s) Loss: 0.0066(0.0058) Grad: 28350.0039  LR: 0.00000597  \n","Epoch: [3][1900/9497] Elapsed 10m 38s (remain 42m 31s) Loss: 0.0029(0.0058) Grad: 11674.3984  LR: 0.00000594  \n","Epoch: [3][2000/9497] Elapsed 11m 12s (remain 41m 58s) Loss: 0.0000(0.0058) Grad: 137.4684  LR: 0.00000590  \n","Epoch: [3][2100/9497] Elapsed 11m 45s (remain 41m 25s) Loss: 0.0001(0.0058) Grad: 1720.5652  LR: 0.00000587  \n","Epoch: [3][2200/9497] Elapsed 12m 19s (remain 40m 52s) Loss: 0.0000(0.0058) Grad: 596.6826  LR: 0.00000584  \n","Epoch: [3][2300/9497] Elapsed 12m 53s (remain 40m 18s) Loss: 0.0004(0.0059) Grad: 10438.5205  LR: 0.00000581  \n","Epoch: [3][2400/9497] Elapsed 13m 26s (remain 39m 44s) Loss: 0.0004(0.0059) Grad: 10727.3516  LR: 0.00000577  \n","Epoch: [3][2500/9497] Elapsed 14m 0s (remain 39m 11s) Loss: 0.0006(0.0058) Grad: 9453.6250  LR: 0.00000574  \n","Epoch: [3][2600/9497] Elapsed 14m 34s (remain 38m 37s) Loss: 0.0000(0.0058) Grad: 834.5375  LR: 0.00000571  \n","Epoch: [3][2700/9497] Elapsed 15m 7s (remain 38m 4s) Loss: 0.0057(0.0058) Grad: 151089.4844  LR: 0.00000568  \n","Epoch: [3][2800/9497] Elapsed 15m 41s (remain 37m 30s) Loss: 0.0000(0.0058) Grad: 505.5343  LR: 0.00000564  \n","Epoch: [3][2900/9497] Elapsed 16m 15s (remain 36m 57s) Loss: 0.0249(0.0059) Grad: 126870.9922  LR: 0.00000561  \n","Epoch: [3][3000/9497] Elapsed 16m 48s (remain 36m 23s) Loss: 0.0042(0.0058) Grad: 38324.7266  LR: 0.00000558  \n","Epoch: [3][3100/9497] Elapsed 17m 22s (remain 35m 50s) Loss: 0.0000(0.0058) Grad: 275.7238  LR: 0.00000554  \n","Epoch: [3][3200/9497] Elapsed 17m 55s (remain 35m 16s) Loss: 0.0290(0.0058) Grad: 268944.4375  LR: 0.00000551  \n","Epoch: [3][3300/9497] Elapsed 18m 29s (remain 34m 42s) Loss: 0.0005(0.0058) Grad: 13409.9434  LR: 0.00000548  \n","Epoch: [3][3400/9497] Elapsed 19m 2s (remain 34m 8s) Loss: 0.0020(0.0058) Grad: 44735.7578  LR: 0.00000545  \n","Epoch: [3][3500/9497] Elapsed 19m 36s (remain 33m 34s) Loss: 0.0012(0.0057) Grad: 20551.3984  LR: 0.00000541  \n","Epoch: [3][3600/9497] Elapsed 20m 10s (remain 33m 1s) Loss: 0.0009(0.0058) Grad: 15865.0996  LR: 0.00000538  \n","Epoch: [3][3700/9497] Elapsed 20m 43s (remain 32m 27s) Loss: 0.0045(0.0058) Grad: 57947.3359  LR: 0.00000535  \n","Epoch: [3][3800/9497] Elapsed 21m 17s (remain 31m 54s) Loss: 0.0016(0.0058) Grad: 27938.1230  LR: 0.00000531  \n","Epoch: [3][3900/9497] Elapsed 21m 50s (remain 31m 20s) Loss: 0.0144(0.0057) Grad: 183746.5312  LR: 0.00000528  \n","Epoch: [3][4000/9497] Elapsed 22m 24s (remain 30m 46s) Loss: 0.0001(0.0058) Grad: 2372.8423  LR: 0.00000525  \n","Epoch: [3][4100/9497] Elapsed 22m 57s (remain 30m 13s) Loss: 0.0001(0.0057) Grad: 2849.3105  LR: 0.00000521  \n","Epoch: [3][4200/9497] Elapsed 23m 31s (remain 29m 39s) Loss: 0.0002(0.0057) Grad: 20827.5391  LR: 0.00000518  \n","Epoch: [3][4300/9497] Elapsed 24m 4s (remain 29m 5s) Loss: 0.0119(0.0057) Grad: 144082.6250  LR: 0.00000515  \n","Epoch: [3][4400/9497] Elapsed 24m 38s (remain 28m 32s) Loss: 0.0110(0.0057) Grad: 344932.6562  LR: 0.00000512  \n","Epoch: [3][4500/9497] Elapsed 25m 12s (remain 27m 58s) Loss: 0.0010(0.0057) Grad: 35117.6602  LR: 0.00000508  \n","Epoch: [3][4600/9497] Elapsed 25m 46s (remain 27m 25s) Loss: 0.0000(0.0057) Grad: 244.0789  LR: 0.00000505  \n","Epoch: [3][4700/9497] Elapsed 26m 19s (remain 26m 51s) Loss: 0.0090(0.0057) Grad: 426714.3125  LR: 0.00000502  \n","Epoch: [3][4800/9497] Elapsed 26m 53s (remain 26m 18s) Loss: 0.0065(0.0057) Grad: 215515.7344  LR: 0.00000498  \n","Epoch: [3][4900/9497] Elapsed 27m 27s (remain 25m 44s) Loss: 0.0000(0.0057) Grad: 3458.6143  LR: 0.00000495  \n","Epoch: [3][5000/9497] Elapsed 28m 0s (remain 25m 11s) Loss: 0.0096(0.0058) Grad: 158124.5156  LR: 0.00000492  \n","Epoch: [3][5100/9497] Elapsed 28m 34s (remain 24m 37s) Loss: 0.0003(0.0058) Grad: 13740.5293  LR: 0.00000488  \n","Epoch: [3][5200/9497] Elapsed 29m 7s (remain 24m 3s) Loss: 0.0040(0.0058) Grad: 63164.8320  LR: 0.00000485  \n","Epoch: [3][5300/9497] Elapsed 29m 41s (remain 23m 30s) Loss: 0.0160(0.0058) Grad: 29199.6602  LR: 0.00000482  \n","Epoch: [3][5400/9497] Elapsed 30m 15s (remain 22m 56s) Loss: 0.0120(0.0057) Grad: 261128.5781  LR: 0.00000478  \n","Epoch: [3][5500/9497] Elapsed 30m 48s (remain 22m 23s) Loss: 0.0066(0.0057) Grad: 270699.8125  LR: 0.00000475  \n","Epoch: [3][5600/9497] Elapsed 31m 22s (remain 21m 49s) Loss: 0.0173(0.0058) Grad: 140579.4219  LR: 0.00000472  \n","Epoch: [3][5700/9497] Elapsed 31m 56s (remain 21m 15s) Loss: 0.0030(0.0057) Grad: 588155.9375  LR: 0.00000469  \n","Epoch: [3][5800/9497] Elapsed 32m 29s (remain 20m 42s) Loss: 0.0069(0.0058) Grad: 173647.8906  LR: 0.00000465  \n","Epoch: [3][5900/9497] Elapsed 33m 3s (remain 20m 8s) Loss: 0.0017(0.0058) Grad: 77324.3047  LR: 0.00000462  \n","Epoch: [3][6000/9497] Elapsed 33m 36s (remain 19m 34s) Loss: 0.0000(0.0058) Grad: 1632.5929  LR: 0.00000459  \n","Epoch: [3][6100/9497] Elapsed 34m 10s (remain 19m 1s) Loss: 0.0087(0.0058) Grad: 167275.6875  LR: 0.00000455  \n","Epoch: [3][6200/9497] Elapsed 34m 43s (remain 18m 27s) Loss: 0.0050(0.0058) Grad: 80024.2812  LR: 0.00000452  \n","Epoch: [3][6300/9497] Elapsed 35m 17s (remain 17m 54s) Loss: 0.0009(0.0058) Grad: 43999.2891  LR: 0.00000449  \n","Epoch: [3][6400/9497] Elapsed 35m 51s (remain 17m 20s) Loss: 0.0002(0.0058) Grad: 14808.2822  LR: 0.00000445  \n","Epoch: [3][6500/9497] Elapsed 36m 24s (remain 16m 46s) Loss: 0.0015(0.0058) Grad: 86544.4062  LR: 0.00000442  \n","Epoch: [3][6600/9497] Elapsed 36m 58s (remain 16m 13s) Loss: 0.0021(0.0058) Grad: 330370.7500  LR: 0.00000439  \n","Epoch: [3][6700/9497] Elapsed 37m 32s (remain 15m 39s) Loss: 0.0000(0.0058) Grad: 145.6361  LR: 0.00000436  \n","Epoch: [3][6800/9497] Elapsed 38m 5s (remain 15m 6s) Loss: 0.0314(0.0057) Grad: 335576.4062  LR: 0.00000432  \n","Epoch: [3][6900/9497] Elapsed 38m 39s (remain 14m 32s) Loss: 0.0083(0.0058) Grad: 113559.7188  LR: 0.00000429  \n","Epoch: [3][7000/9497] Elapsed 39m 13s (remain 13m 58s) Loss: 0.0028(0.0058) Grad: 56816.7422  LR: 0.00000426  \n","Epoch: [3][7100/9497] Elapsed 39m 46s (remain 13m 25s) Loss: 0.0000(0.0058) Grad: 8619.1367  LR: 0.00000423  \n","Epoch: [3][7200/9497] Elapsed 40m 20s (remain 12m 51s) Loss: 0.0000(0.0058) Grad: 1295.4192  LR: 0.00000419  \n","Epoch: [3][7300/9497] Elapsed 40m 53s (remain 12m 17s) Loss: 0.0010(0.0058) Grad: 65250.0195  LR: 0.00000416  \n","Epoch: [3][7400/9497] Elapsed 41m 26s (remain 11m 44s) Loss: 0.0074(0.0058) Grad: 235543.2188  LR: 0.00000413  \n","Epoch: [3][7500/9497] Elapsed 42m 0s (remain 11m 10s) Loss: 0.0000(0.0058) Grad: 1041.5312  LR: 0.00000410  \n","Epoch: [3][7600/9497] Elapsed 42m 33s (remain 10m 37s) Loss: 0.0000(0.0058) Grad: 113.8777  LR: 0.00000406  \n","Epoch: [3][7700/9497] Elapsed 43m 7s (remain 10m 3s) Loss: 0.0018(0.0058) Grad: 46551.8281  LR: 0.00000403  \n","Epoch: [3][7800/9497] Elapsed 43m 40s (remain 9m 29s) Loss: 0.0056(0.0058) Grad: 93288.7344  LR: 0.00000400  \n","Epoch: [3][7900/9497] Elapsed 44m 14s (remain 8m 56s) Loss: 0.0406(0.0058) Grad: 49323.8203  LR: 0.00000397  \n","Epoch: [3][8000/9497] Elapsed 44m 47s (remain 8m 22s) Loss: 0.0214(0.0058) Grad: 168775.3438  LR: 0.00000393  \n","Epoch: [3][8100/9497] Elapsed 45m 21s (remain 7m 48s) Loss: 0.0088(0.0058) Grad: 82572.8828  LR: 0.00000390  \n","Epoch: [3][8200/9497] Elapsed 45m 54s (remain 7m 15s) Loss: 0.0007(0.0058) Grad: 17320.5352  LR: 0.00000387  \n","Epoch: [3][8300/9497] Elapsed 46m 28s (remain 6m 41s) Loss: 0.0036(0.0058) Grad: 32803.3594  LR: 0.00000384  \n","Epoch: [3][8400/9497] Elapsed 47m 2s (remain 6m 8s) Loss: 0.0088(0.0058) Grad: 49202.4531  LR: 0.00000380  \n","Epoch: [3][8500/9497] Elapsed 47m 35s (remain 5m 34s) Loss: 0.0046(0.0058) Grad: 47469.6641  LR: 0.00000377  \n","Epoch: [3][8600/9497] Elapsed 48m 8s (remain 5m 0s) Loss: 0.0015(0.0058) Grad: 25292.8906  LR: 0.00000374  \n","Epoch: [3][8700/9497] Elapsed 48m 42s (remain 4m 27s) Loss: 0.0098(0.0058) Grad: 157371.9531  LR: 0.00000371  \n","Epoch: [3][8800/9497] Elapsed 49m 16s (remain 3m 53s) Loss: 0.0013(0.0058) Grad: 19349.3125  LR: 0.00000368  \n","Epoch: [3][8900/9497] Elapsed 49m 49s (remain 3m 20s) Loss: 0.0008(0.0058) Grad: 17629.3594  LR: 0.00000364  \n","Epoch: [3][9000/9497] Elapsed 50m 23s (remain 2m 46s) Loss: 0.0007(0.0058) Grad: 34252.3750  LR: 0.00000361  \n","Epoch: [3][9100/9497] Elapsed 50m 56s (remain 2m 13s) Loss: 0.0000(0.0058) Grad: 47.5555  LR: 0.00000358  \n","Epoch: [3][9200/9497] Elapsed 51m 30s (remain 1m 39s) Loss: 0.0050(0.0058) Grad: 42233.4883  LR: 0.00000355  \n","Epoch: [3][9300/9497] Elapsed 52m 3s (remain 1m 5s) Loss: 0.0054(0.0058) Grad: 59347.1719  LR: 0.00000352  \n","Epoch: [3][9400/9497] Elapsed 52m 37s (remain 0m 32s) Loss: 0.0002(0.0058) Grad: 9677.0146  LR: 0.00000349  \n","Epoch: [3][9496/9497] Elapsed 53m 9s (remain 0m 0s) Loss: 0.0072(0.0058) Grad: 127244.0781  LR: 0.00000346  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 18m 15s) Loss: 0.0002(0.0002) \n","EVAL: [100/2375] Elapsed 0m 20s (remain 7m 31s) Loss: 0.0306(0.0172) \n","EVAL: [200/2375] Elapsed 0m 39s (remain 7m 8s) Loss: 0.0000(0.0169) \n","EVAL: [300/2375] Elapsed 0m 59s (remain 6m 47s) Loss: 0.0100(0.0174) \n","EVAL: [400/2375] Elapsed 1m 18s (remain 6m 27s) Loss: 0.0228(0.0171) \n","EVAL: [500/2375] Elapsed 1m 38s (remain 6m 8s) Loss: 0.0184(0.0156) \n","EVAL: [600/2375] Elapsed 1m 58s (remain 5m 48s) Loss: 0.0126(0.0156) \n","EVAL: [700/2375] Elapsed 2m 17s (remain 5m 28s) Loss: 0.0207(0.0160) \n","EVAL: [800/2375] Elapsed 2m 37s (remain 5m 9s) Loss: 0.0119(0.0167) \n","EVAL: [900/2375] Elapsed 2m 57s (remain 4m 49s) Loss: 0.0000(0.0151) \n","EVAL: [1000/2375] Elapsed 3m 16s (remain 4m 29s) Loss: 0.0000(0.0139) \n","EVAL: [1100/2375] Elapsed 3m 36s (remain 4m 10s) Loss: 0.0012(0.0129) \n","EVAL: [1200/2375] Elapsed 3m 55s (remain 3m 50s) Loss: 0.0122(0.0120) \n","EVAL: [1300/2375] Elapsed 4m 15s (remain 3m 30s) Loss: 0.0000(0.0113) \n","EVAL: [1400/2375] Elapsed 4m 34s (remain 3m 11s) Loss: 0.0084(0.0111) \n","EVAL: [1500/2375] Elapsed 4m 54s (remain 2m 51s) Loss: 0.0032(0.0109) \n","EVAL: [1600/2375] Elapsed 5m 14s (remain 2m 31s) Loss: 0.0058(0.0107) \n","EVAL: [1700/2375] Elapsed 5m 33s (remain 2m 12s) Loss: 0.0188(0.0108) \n","EVAL: [1800/2375] Elapsed 5m 53s (remain 1m 52s) Loss: 0.0000(0.0106) \n","EVAL: [1900/2375] Elapsed 6m 12s (remain 1m 32s) Loss: 0.0000(0.0101) \n","EVAL: [2000/2375] Elapsed 6m 32s (remain 1m 13s) Loss: 0.0000(0.0096) \n","EVAL: [2100/2375] Elapsed 6m 51s (remain 0m 53s) Loss: 0.0000(0.0092) \n","EVAL: [2200/2375] Elapsed 7m 11s (remain 0m 34s) Loss: 0.0000(0.0089) \n","EVAL: [2300/2375] Elapsed 7m 31s (remain 0m 14s) Loss: 0.0000(0.0085) \n","EVAL: [2374/2375] Elapsed 7m 45s (remain 0m 0s) Loss: 0.0000(0.0083) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0058  avg_val_loss: 0.0083  time: 3669s\n","Epoch 3 - Score: 0.9525\n","Epoch 3 - Save Best Score: 0.9525 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/9497] Elapsed 0m 0s (remain 139m 37s) Loss: 0.0055(0.0055) Grad: 36849.6602  LR: 0.00000346  \n","Epoch: [4][100/9497] Elapsed 0m 33s (remain 52m 9s) Loss: 0.0049(0.0060) Grad: 49845.9805  LR: 0.00000342  \n","Epoch: [4][200/9497] Elapsed 1m 6s (remain 50m 55s) Loss: 0.0007(0.0055) Grad: 6973.7476  LR: 0.00000339  \n","Epoch: [4][300/9497] Elapsed 1m 38s (remain 50m 12s) Loss: 0.0031(0.0051) Grad: 24374.3516  LR: 0.00000336  \n","Epoch: [4][400/9497] Elapsed 2m 11s (remain 49m 33s) Loss: 0.0037(0.0054) Grad: 19367.5527  LR: 0.00000333  \n","Epoch: [4][500/9497] Elapsed 2m 43s (remain 48m 57s) Loss: 0.0001(0.0055) Grad: 460.0440  LR: 0.00000330  \n","Epoch: [4][600/9497] Elapsed 3m 16s (remain 48m 22s) Loss: 0.0000(0.0054) Grad: 217.1443  LR: 0.00000327  \n","Epoch: [4][700/9497] Elapsed 3m 48s (remain 47m 49s) Loss: 0.0014(0.0053) Grad: 24120.5957  LR: 0.00000324  \n","Epoch: [4][800/9497] Elapsed 4m 21s (remain 47m 15s) Loss: 0.0054(0.0052) Grad: 26138.1953  LR: 0.00000321  \n","Epoch: [4][900/9497] Elapsed 4m 53s (remain 46m 43s) Loss: 0.0000(0.0052) Grad: 63.0768  LR: 0.00000317  \n","Epoch: [4][1000/9497] Elapsed 5m 26s (remain 46m 9s) Loss: 0.0045(0.0051) Grad: 9651.1973  LR: 0.00000314  \n","Epoch: [4][1100/9497] Elapsed 5m 58s (remain 45m 35s) Loss: 0.0225(0.0052) Grad: 74444.3906  LR: 0.00000311  \n","Epoch: [4][1200/9497] Elapsed 6m 31s (remain 45m 1s) Loss: 0.0110(0.0052) Grad: 115424.1484  LR: 0.00000308  \n","Epoch: [4][1300/9497] Elapsed 7m 3s (remain 44m 28s) Loss: 0.0006(0.0051) Grad: 12644.8721  LR: 0.00000305  \n","Epoch: [4][1400/9497] Elapsed 7m 36s (remain 43m 55s) Loss: 0.0068(0.0051) Grad: 34860.3398  LR: 0.00000302  \n","Epoch: [4][1500/9497] Elapsed 8m 8s (remain 43m 23s) Loss: 0.0001(0.0050) Grad: 438.1582  LR: 0.00000299  \n","Epoch: [4][1600/9497] Elapsed 8m 41s (remain 42m 50s) Loss: 0.0007(0.0051) Grad: 5221.5166  LR: 0.00000296  \n","Epoch: [4][1700/9497] Elapsed 9m 13s (remain 42m 17s) Loss: 0.0045(0.0050) Grad: 32457.2910  LR: 0.00000293  \n","Epoch: [4][1800/9497] Elapsed 9m 46s (remain 41m 44s) Loss: 0.0016(0.0050) Grad: 47984.9531  LR: 0.00000290  \n","Epoch: [4][1900/9497] Elapsed 10m 18s (remain 41m 12s) Loss: 0.0001(0.0049) Grad: 1592.6193  LR: 0.00000287  \n","Epoch: [4][2000/9497] Elapsed 10m 51s (remain 40m 39s) Loss: 0.0017(0.0049) Grad: 34004.1484  LR: 0.00000284  \n","Epoch: [4][2100/9497] Elapsed 11m 23s (remain 40m 6s) Loss: 0.0038(0.0049) Grad: 52266.0117  LR: 0.00000281  \n","Epoch: [4][2200/9497] Elapsed 11m 56s (remain 39m 34s) Loss: 0.0003(0.0049) Grad: 6135.3237  LR: 0.00000278  \n","Epoch: [4][2300/9497] Elapsed 12m 28s (remain 39m 1s) Loss: 0.0035(0.0049) Grad: 46637.9453  LR: 0.00000275  \n","Epoch: [4][2400/9497] Elapsed 13m 1s (remain 38m 29s) Loss: 0.0004(0.0049) Grad: 16467.8379  LR: 0.00000272  \n","Epoch: [4][2500/9497] Elapsed 13m 33s (remain 37m 56s) Loss: 0.0171(0.0050) Grad: 71793.6484  LR: 0.00000269  \n","Epoch: [4][2600/9497] Elapsed 14m 6s (remain 37m 23s) Loss: 0.0050(0.0050) Grad: 49630.8125  LR: 0.00000266  \n","Epoch: [4][2700/9497] Elapsed 14m 38s (remain 36m 51s) Loss: 0.0001(0.0050) Grad: 1716.8462  LR: 0.00000263  \n","Epoch: [4][2800/9497] Elapsed 15m 11s (remain 36m 18s) Loss: 0.0001(0.0051) Grad: 1662.5392  LR: 0.00000261  \n","Epoch: [4][2900/9497] Elapsed 15m 43s (remain 35m 46s) Loss: 0.0004(0.0051) Grad: 7754.9604  LR: 0.00000258  \n","Epoch: [4][3000/9497] Elapsed 16m 16s (remain 35m 13s) Loss: 0.0019(0.0051) Grad: 54261.8516  LR: 0.00000255  \n","Epoch: [4][3100/9497] Elapsed 16m 48s (remain 34m 40s) Loss: 0.0002(0.0051) Grad: 8676.4229  LR: 0.00000252  \n","Epoch: [4][3200/9497] Elapsed 17m 21s (remain 34m 8s) Loss: 0.0046(0.0050) Grad: 27336.6562  LR: 0.00000249  \n","Epoch: [4][3300/9497] Elapsed 17m 53s (remain 33m 35s) Loss: 0.0000(0.0050) Grad: 316.6711  LR: 0.00000246  \n","Epoch: [4][3400/9497] Elapsed 18m 26s (remain 33m 3s) Loss: 0.0013(0.0050) Grad: 28515.2812  LR: 0.00000243  \n","Epoch: [4][3500/9497] Elapsed 18m 59s (remain 32m 30s) Loss: 0.0022(0.0051) Grad: 72528.3672  LR: 0.00000241  \n","Epoch: [4][3600/9497] Elapsed 19m 31s (remain 31m 58s) Loss: 0.0191(0.0050) Grad: 187749.3281  LR: 0.00000238  \n","Epoch: [4][3700/9497] Elapsed 20m 4s (remain 31m 25s) Loss: 0.0109(0.0051) Grad: 108722.5156  LR: 0.00000235  \n","Epoch: [4][3800/9497] Elapsed 20m 36s (remain 30m 53s) Loss: 0.0073(0.0051) Grad: 167832.7344  LR: 0.00000232  \n","Epoch: [4][3900/9497] Elapsed 21m 9s (remain 30m 20s) Loss: 0.0031(0.0051) Grad: 45766.0625  LR: 0.00000229  \n","Epoch: [4][4000/9497] Elapsed 21m 41s (remain 29m 48s) Loss: 0.0000(0.0051) Grad: 191.7925  LR: 0.00000227  \n","Epoch: [4][4100/9497] Elapsed 22m 14s (remain 29m 15s) Loss: 0.0102(0.0051) Grad: 155439.1250  LR: 0.00000224  \n","Epoch: [4][4200/9497] Elapsed 22m 47s (remain 28m 43s) Loss: 0.0002(0.0051) Grad: 12940.7148  LR: 0.00000221  \n","Epoch: [4][4300/9497] Elapsed 23m 19s (remain 28m 10s) Loss: 0.0004(0.0052) Grad: 19281.4688  LR: 0.00000218  \n","Epoch: [4][4400/9497] Elapsed 23m 52s (remain 27m 38s) Loss: 0.0004(0.0051) Grad: 27632.8633  LR: 0.00000216  \n","Epoch: [4][4500/9497] Elapsed 24m 24s (remain 27m 6s) Loss: 0.0059(0.0051) Grad: 98934.2969  LR: 0.00000213  \n","Epoch: [4][4600/9497] Elapsed 24m 57s (remain 26m 33s) Loss: 0.0082(0.0051) Grad: 129780.6641  LR: 0.00000210  \n","Epoch: [4][4700/9497] Elapsed 25m 30s (remain 26m 1s) Loss: 0.0002(0.0051) Grad: 10903.2236  LR: 0.00000207  \n","Epoch: [4][4800/9497] Elapsed 26m 2s (remain 25m 28s) Loss: 0.0409(0.0051) Grad: 801053.2500  LR: 0.00000205  \n","Epoch: [4][4900/9497] Elapsed 26m 35s (remain 24m 56s) Loss: 0.0029(0.0051) Grad: 86310.5625  LR: 0.00000202  \n","Epoch: [4][5000/9497] Elapsed 27m 8s (remain 24m 23s) Loss: 0.0017(0.0052) Grad: 47907.4375  LR: 0.00000199  \n","Epoch: [4][5100/9497] Elapsed 27m 40s (remain 23m 51s) Loss: 0.0220(0.0052) Grad: 411121.0625  LR: 0.00000197  \n","Epoch: [4][5200/9497] Elapsed 28m 13s (remain 23m 18s) Loss: 0.0000(0.0052) Grad: 107.4431  LR: 0.00000194  \n","Epoch: [4][5300/9497] Elapsed 28m 45s (remain 22m 45s) Loss: 0.0983(0.0052) Grad: 355992.7812  LR: 0.00000192  \n","Epoch: [4][5400/9497] Elapsed 29m 18s (remain 22m 13s) Loss: 0.0007(0.0052) Grad: 37537.8281  LR: 0.00000189  \n","Epoch: [4][5500/9497] Elapsed 29m 50s (remain 21m 40s) Loss: 0.0036(0.0052) Grad: 108329.3125  LR: 0.00000186  \n","Epoch: [4][5600/9497] Elapsed 30m 23s (remain 21m 8s) Loss: 0.0000(0.0052) Grad: 170.4849  LR: 0.00000184  \n","Epoch: [4][5700/9497] Elapsed 30m 55s (remain 20m 35s) Loss: 0.0146(0.0053) Grad: 127667.9062  LR: 0.00000181  \n","Epoch: [4][5800/9497] Elapsed 31m 27s (remain 20m 2s) Loss: 0.0014(0.0053) Grad: 81141.5469  LR: 0.00000179  \n","Epoch: [4][5900/9497] Elapsed 32m 0s (remain 19m 30s) Loss: 0.0009(0.0053) Grad: 35868.3672  LR: 0.00000176  \n","Epoch: [4][6000/9497] Elapsed 32m 32s (remain 18m 57s) Loss: 0.0002(0.0053) Grad: 6989.7593  LR: 0.00000174  \n","Epoch: [4][6100/9497] Elapsed 33m 5s (remain 18m 25s) Loss: 0.0087(0.0053) Grad: 295093.3125  LR: 0.00000171  \n","Epoch: [4][6200/9497] Elapsed 33m 37s (remain 17m 52s) Loss: 0.0025(0.0053) Grad: 39239.9102  LR: 0.00000169  \n","Epoch: [4][6300/9497] Elapsed 34m 10s (remain 17m 19s) Loss: 0.0000(0.0053) Grad: 322.0403  LR: 0.00000166  \n","Epoch: [4][6400/9497] Elapsed 34m 42s (remain 16m 47s) Loss: 0.0008(0.0053) Grad: 14512.2998  LR: 0.00000164  \n","Epoch: [4][6500/9497] Elapsed 35m 15s (remain 16m 14s) Loss: 0.0015(0.0053) Grad: 17573.5723  LR: 0.00000161  \n","Epoch: [4][6600/9497] Elapsed 35m 48s (remain 15m 42s) Loss: 0.0082(0.0053) Grad: 41722.5430  LR: 0.00000159  \n","Epoch: [4][6700/9497] Elapsed 36m 20s (remain 15m 9s) Loss: 0.0058(0.0053) Grad: 60316.1445  LR: 0.00000157  \n","Epoch: [4][6800/9497] Elapsed 36m 52s (remain 14m 37s) Loss: 0.0001(0.0053) Grad: 556.3769  LR: 0.00000154  \n","Epoch: [4][6900/9497] Elapsed 37m 25s (remain 14m 4s) Loss: 0.0005(0.0052) Grad: 4901.0796  LR: 0.00000152  \n","Epoch: [4][7000/9497] Elapsed 37m 57s (remain 13m 32s) Loss: 0.0002(0.0053) Grad: 3696.1023  LR: 0.00000149  \n","Epoch: [4][7100/9497] Elapsed 38m 30s (remain 12m 59s) Loss: 0.0094(0.0052) Grad: 25878.5117  LR: 0.00000147  \n","Epoch: [4][7200/9497] Elapsed 39m 2s (remain 12m 27s) Loss: 0.0005(0.0052) Grad: 12842.8945  LR: 0.00000145  \n","Epoch: [4][7300/9497] Elapsed 39m 35s (remain 11m 54s) Loss: 0.0003(0.0052) Grad: 2928.9070  LR: 0.00000142  \n","Epoch: [4][7400/9497] Elapsed 40m 8s (remain 11m 21s) Loss: 0.0000(0.0052) Grad: 23.3900  LR: 0.00000140  \n","Epoch: [4][7500/9497] Elapsed 40m 40s (remain 10m 49s) Loss: 0.0036(0.0052) Grad: 23975.2871  LR: 0.00000138  \n","Epoch: [4][7600/9497] Elapsed 41m 13s (remain 10m 16s) Loss: 0.0000(0.0052) Grad: 184.2850  LR: 0.00000135  \n","Epoch: [4][7700/9497] Elapsed 41m 45s (remain 9m 44s) Loss: 0.0001(0.0052) Grad: 651.0805  LR: 0.00000133  \n","Epoch: [4][7800/9497] Elapsed 42m 18s (remain 9m 11s) Loss: 0.0029(0.0052) Grad: 38111.6367  LR: 0.00000131  \n","Epoch: [4][7900/9497] Elapsed 42m 50s (remain 8m 39s) Loss: 0.0001(0.0052) Grad: 1841.9418  LR: 0.00000129  \n","Epoch: [4][8000/9497] Elapsed 43m 23s (remain 8m 6s) Loss: 0.0080(0.0052) Grad: 23636.2871  LR: 0.00000127  \n","Epoch: [4][8100/9497] Elapsed 43m 55s (remain 7m 34s) Loss: 0.0042(0.0052) Grad: 20670.5586  LR: 0.00000124  \n","Epoch: [4][8200/9497] Elapsed 44m 28s (remain 7m 1s) Loss: 0.0019(0.0052) Grad: 24520.3203  LR: 0.00000122  \n","Epoch: [4][8300/9497] Elapsed 45m 0s (remain 6m 29s) Loss: 0.0005(0.0052) Grad: 20503.1855  LR: 0.00000120  \n","Epoch: [4][8400/9497] Elapsed 45m 32s (remain 5m 56s) Loss: 0.0006(0.0052) Grad: 11958.1387  LR: 0.00000118  \n","Epoch: [4][8500/9497] Elapsed 46m 5s (remain 5m 23s) Loss: 0.0040(0.0052) Grad: 33200.6367  LR: 0.00000116  \n","Epoch: [4][8600/9497] Elapsed 46m 37s (remain 4m 51s) Loss: 0.0000(0.0052) Grad: 973.5419  LR: 0.00000114  \n","Epoch: [4][8700/9497] Elapsed 47m 10s (remain 4m 18s) Loss: 0.0130(0.0052) Grad: 109332.3359  LR: 0.00000112  \n","Epoch: [4][8800/9497] Elapsed 47m 42s (remain 3m 46s) Loss: 0.0025(0.0051) Grad: 13386.0234  LR: 0.00000109  \n","Epoch: [4][8900/9497] Elapsed 48m 15s (remain 3m 13s) Loss: 0.0001(0.0052) Grad: 2464.8767  LR: 0.00000107  \n","Epoch: [4][9000/9497] Elapsed 48m 48s (remain 2m 41s) Loss: 0.0092(0.0052) Grad: 46489.8320  LR: 0.00000105  \n","Epoch: [4][9100/9497] Elapsed 49m 20s (remain 2m 8s) Loss: 0.0036(0.0052) Grad: 29993.2637  LR: 0.00000103  \n","Epoch: [4][9200/9497] Elapsed 49m 53s (remain 1m 36s) Loss: 0.0011(0.0052) Grad: 30550.5723  LR: 0.00000101  \n","Epoch: [4][9300/9497] Elapsed 50m 25s (remain 1m 3s) Loss: 0.0075(0.0051) Grad: 72091.7578  LR: 0.00000099  \n","Epoch: [4][9400/9497] Elapsed 50m 58s (remain 0m 31s) Loss: 0.0044(0.0052) Grad: 37115.8672  LR: 0.00000097  \n","Epoch: [4][9496/9497] Elapsed 51m 29s (remain 0m 0s) Loss: 0.0001(0.0051) Grad: 976.2700  LR: 0.00000096  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 18m 21s) Loss: 0.0001(0.0001) \n","EVAL: [100/2375] Elapsed 0m 19s (remain 7m 25s) Loss: 0.0327(0.0177) \n","EVAL: [200/2375] Elapsed 0m 39s (remain 7m 2s) Loss: 0.0000(0.0177) \n","EVAL: [300/2375] Elapsed 0m 58s (remain 6m 42s) Loss: 0.0101(0.0182) \n","EVAL: [400/2375] Elapsed 1m 17s (remain 6m 22s) Loss: 0.0238(0.0178) \n","EVAL: [500/2375] Elapsed 1m 36s (remain 6m 2s) Loss: 0.0213(0.0162) \n","EVAL: [600/2375] Elapsed 1m 56s (remain 5m 43s) Loss: 0.0173(0.0163) \n","EVAL: [700/2375] Elapsed 2m 15s (remain 5m 24s) Loss: 0.0172(0.0166) \n","EVAL: [800/2375] Elapsed 2m 35s (remain 5m 4s) Loss: 0.0136(0.0173) \n","EVAL: [900/2375] Elapsed 2m 54s (remain 4m 45s) Loss: 0.0000(0.0157) \n","EVAL: [1000/2375] Elapsed 3m 13s (remain 4m 26s) Loss: 0.0000(0.0144) \n","EVAL: [1100/2375] Elapsed 3m 33s (remain 4m 6s) Loss: 0.0010(0.0133) \n","EVAL: [1200/2375] Elapsed 3m 52s (remain 3m 47s) Loss: 0.0130(0.0125) \n","EVAL: [1300/2375] Elapsed 4m 11s (remain 3m 27s) Loss: 0.0000(0.0117) \n","EVAL: [1400/2375] Elapsed 4m 31s (remain 3m 8s) Loss: 0.0095(0.0115) \n","EVAL: [1500/2375] Elapsed 4m 50s (remain 2m 49s) Loss: 0.0037(0.0113) \n","EVAL: [1600/2375] Elapsed 5m 9s (remain 2m 29s) Loss: 0.0051(0.0111) \n","EVAL: [1700/2375] Elapsed 5m 29s (remain 2m 10s) Loss: 0.0193(0.0112) \n","EVAL: [1800/2375] Elapsed 5m 48s (remain 1m 51s) Loss: 0.0000(0.0109) \n","EVAL: [1900/2375] Elapsed 6m 7s (remain 1m 31s) Loss: 0.0000(0.0104) \n","EVAL: [2000/2375] Elapsed 6m 27s (remain 1m 12s) Loss: 0.0000(0.0099) \n","EVAL: [2100/2375] Elapsed 6m 46s (remain 0m 52s) Loss: 0.0000(0.0095) \n","EVAL: [2200/2375] Elapsed 7m 5s (remain 0m 33s) Loss: 0.0000(0.0091) \n","EVAL: [2300/2375] Elapsed 7m 24s (remain 0m 14s) Loss: 0.0000(0.0088) \n","EVAL: [2374/2375] Elapsed 7m 39s (remain 0m 0s) Loss: 0.0000(0.0086) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0051  avg_val_loss: 0.0086  time: 3562s\n","Epoch 4 - Score: 0.9527\n","Epoch 4 - Save Best Score: 0.9527 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/1906] Elapsed 0m 0s (remain 27m 31s) Loss: 0.0002(0.0002) Grad: 2171.6509  LR: 0.00000096  \n","Epoch: [5][100/1906] Elapsed 0m 33s (remain 10m 3s) Loss: 0.0012(0.0104) Grad: 27650.3594  LR: 0.00000094  \n","Epoch: [5][200/1906] Elapsed 1m 6s (remain 9m 23s) Loss: 0.0057(0.0100) Grad: 72021.3438  LR: 0.00000092  \n","Epoch: [5][300/1906] Elapsed 1m 38s (remain 8m 47s) Loss: 0.0700(0.0101) Grad: 106597.1172  LR: 0.00000090  \n","Epoch: [5][400/1906] Elapsed 2m 11s (remain 8m 13s) Loss: 0.0030(0.0096) Grad: 40826.8477  LR: 0.00000088  \n","Epoch: [5][500/1906] Elapsed 2m 43s (remain 7m 39s) Loss: 0.0000(0.0093) Grad: 88.3844  LR: 0.00000086  \n","Epoch: [5][600/1906] Elapsed 3m 16s (remain 7m 6s) Loss: 0.0002(0.0089) Grad: 3012.7590  LR: 0.00000084  \n","Epoch: [5][700/1906] Elapsed 3m 49s (remain 6m 33s) Loss: 0.0000(0.0088) Grad: 97.0801  LR: 0.00000082  \n","Epoch: [5][800/1906] Elapsed 4m 21s (remain 6m 1s) Loss: 0.0136(0.0089) Grad: 14064.1787  LR: 0.00000081  \n","Epoch: [5][900/1906] Elapsed 4m 54s (remain 5m 28s) Loss: 0.0004(0.0086) Grad: 4236.4575  LR: 0.00000079  \n","Epoch: [5][1000/1906] Elapsed 5m 27s (remain 4m 55s) Loss: 0.0002(0.0087) Grad: 1143.6918  LR: 0.00000077  \n","Epoch: [5][1100/1906] Elapsed 5m 59s (remain 4m 23s) Loss: 0.0048(0.0086) Grad: 6184.9209  LR: 0.00000075  \n","Epoch: [5][1200/1906] Elapsed 6m 32s (remain 3m 50s) Loss: 0.0134(0.0084) Grad: 23053.5273  LR: 0.00000073  \n","Epoch: [5][1300/1906] Elapsed 7m 5s (remain 3m 17s) Loss: 0.0079(0.0082) Grad: 16075.1260  LR: 0.00000072  \n","Epoch: [5][1400/1906] Elapsed 7m 37s (remain 2m 45s) Loss: 0.0062(0.0082) Grad: 15959.4170  LR: 0.00000070  \n","Epoch: [5][1500/1906] Elapsed 8m 10s (remain 2m 12s) Loss: 0.0035(0.0082) Grad: 20872.6094  LR: 0.00000068  \n","Epoch: [5][1600/1906] Elapsed 8m 43s (remain 1m 39s) Loss: 0.0147(0.0081) Grad: 35152.2656  LR: 0.00000067  \n","Epoch: [5][1700/1906] Elapsed 9m 15s (remain 1m 6s) Loss: 0.0052(0.0082) Grad: 23950.0391  LR: 0.00000065  \n","Epoch: [5][1800/1906] Elapsed 9m 48s (remain 0m 34s) Loss: 0.0128(0.0081) Grad: 25810.5742  LR: 0.00000063  \n","Epoch: [5][1900/1906] Elapsed 10m 20s (remain 0m 1s) Loss: 0.0006(0.0081) Grad: 4238.4980  LR: 0.00000062  \n","Epoch: [5][1905/1906] Elapsed 10m 22s (remain 0m 0s) Loss: 0.0083(0.0081) Grad: 17805.4883  LR: 0.00000062  \n","EVAL: [0/477] Elapsed 0m 0s (remain 3m 55s) Loss: 0.0005(0.0005) \n","EVAL: [100/477] Elapsed 0m 19s (remain 1m 13s) Loss: 0.0242(0.0134) \n","EVAL: [200/477] Elapsed 0m 39s (remain 0m 53s) Loss: 0.0000(0.0129) \n","EVAL: [300/477] Elapsed 0m 58s (remain 0m 34s) Loss: 0.0086(0.0131) \n","EVAL: [400/477] Elapsed 1m 17s (remain 0m 14s) Loss: 0.0149(0.0128) \n","EVAL: [476/477] Elapsed 1m 32s (remain 0m 0s) Loss: 0.0000(0.0115) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0081  avg_val_loss: 0.0115  time: 718s\n","Epoch 5 - Score: 0.9065\n","========== fold: 2 result ==========\n","Score: 0.9527\n","========== fold: 3 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/9497] Elapsed 0m 0s (remain 99m 6s) Loss: 0.5187(0.5187) Grad: inf  LR: 0.00001000  \n","Epoch: [1][100/9497] Elapsed 0m 33s (remain 51m 20s) Loss: 0.0217(0.1086) Grad: 4153.2866  LR: 0.00001000  \n","Epoch: [1][200/9497] Elapsed 1m 5s (remain 50m 37s) Loss: 0.0264(0.0745) Grad: 9323.1514  LR: 0.00001000  \n","Epoch: [1][300/9497] Elapsed 1m 38s (remain 50m 1s) Loss: 0.0313(0.0584) Grad: 10243.7734  LR: 0.00001000  \n","Epoch: [1][400/9497] Elapsed 2m 10s (remain 49m 27s) Loss: 0.0058(0.0502) Grad: 5321.1460  LR: 0.00001000  \n","Epoch: [1][500/9497] Elapsed 2m 43s (remain 48m 53s) Loss: 0.0066(0.0439) Grad: 2531.2649  LR: 0.00001000  \n","Epoch: [1][600/9497] Elapsed 3m 15s (remain 48m 19s) Loss: 0.0088(0.0397) Grad: 2260.7952  LR: 0.00001000  \n","Epoch: [1][700/9497] Elapsed 3m 48s (remain 47m 45s) Loss: 0.0255(0.0365) Grad: 4012.6921  LR: 0.00000999  \n","Epoch: [1][800/9497] Elapsed 4m 20s (remain 47m 12s) Loss: 0.0156(0.0345) Grad: 3713.1755  LR: 0.00000999  \n","Epoch: [1][900/9497] Elapsed 4m 53s (remain 46m 39s) Loss: 0.0063(0.0325) Grad: 4176.2715  LR: 0.00000999  \n","Epoch: [1][1000/9497] Elapsed 5m 26s (remain 46m 7s) Loss: 0.0111(0.0308) Grad: 4081.1670  LR: 0.00000999  \n","Epoch: [1][1100/9497] Elapsed 5m 58s (remain 45m 34s) Loss: 0.0317(0.0294) Grad: 14273.0098  LR: 0.00000999  \n","Epoch: [1][1200/9497] Elapsed 6m 31s (remain 45m 1s) Loss: 0.0065(0.0283) Grad: 2527.8604  LR: 0.00000998  \n","Epoch: [1][1300/9497] Elapsed 7m 4s (remain 44m 31s) Loss: 0.0267(0.0274) Grad: 13576.5293  LR: 0.00000998  \n","Epoch: [1][1400/9497] Elapsed 7m 36s (remain 43m 58s) Loss: 0.0222(0.0262) Grad: 6348.5659  LR: 0.00000998  \n","Epoch: [1][1500/9497] Elapsed 8m 9s (remain 43m 25s) Loss: 0.0147(0.0255) Grad: 6746.3745  LR: 0.00000998  \n","Epoch: [1][1600/9497] Elapsed 8m 41s (remain 42m 53s) Loss: 0.0080(0.0247) Grad: 2164.3979  LR: 0.00000997  \n","Epoch: [1][1700/9497] Elapsed 9m 14s (remain 42m 20s) Loss: 0.0161(0.0241) Grad: 9083.2520  LR: 0.00000997  \n","Epoch: [1][1800/9497] Elapsed 9m 46s (remain 41m 47s) Loss: 0.0065(0.0234) Grad: 980.0241  LR: 0.00000996  \n","Epoch: [1][1900/9497] Elapsed 10m 19s (remain 41m 14s) Loss: 0.0326(0.0229) Grad: 28287.2168  LR: 0.00000996  \n","Epoch: [1][2000/9497] Elapsed 10m 51s (remain 40m 41s) Loss: 0.0024(0.0223) Grad: 1049.3668  LR: 0.00000996  \n","Epoch: [1][2100/9497] Elapsed 11m 24s (remain 40m 8s) Loss: 0.0114(0.0220) Grad: 12412.6543  LR: 0.00000995  \n","Epoch: [1][2200/9497] Elapsed 11m 56s (remain 39m 36s) Loss: 0.0043(0.0214) Grad: 2395.1211  LR: 0.00000995  \n","Epoch: [1][2300/9497] Elapsed 12m 29s (remain 39m 3s) Loss: 0.0031(0.0210) Grad: 3004.1729  LR: 0.00000994  \n","Epoch: [1][2400/9497] Elapsed 13m 1s (remain 38m 31s) Loss: 0.0029(0.0206) Grad: 5073.1934  LR: 0.00000994  \n","Epoch: [1][2500/9497] Elapsed 13m 34s (remain 37m 58s) Loss: 0.0169(0.0202) Grad: 10894.5439  LR: 0.00000993  \n","Epoch: [1][2600/9497] Elapsed 14m 7s (remain 37m 25s) Loss: 0.0179(0.0197) Grad: 10646.4873  LR: 0.00000993  \n","Epoch: [1][2700/9497] Elapsed 14m 39s (remain 36m 53s) Loss: 0.0177(0.0193) Grad: 7514.6426  LR: 0.00000992  \n","Epoch: [1][2800/9497] Elapsed 15m 12s (remain 36m 21s) Loss: 0.0075(0.0190) Grad: 5030.6963  LR: 0.00000991  \n","Epoch: [1][2900/9497] Elapsed 15m 44s (remain 35m 48s) Loss: 0.0006(0.0188) Grad: 638.9847  LR: 0.00000991  \n","Epoch: [1][3000/9497] Elapsed 16m 17s (remain 35m 15s) Loss: 0.1016(0.0185) Grad: 11552.9678  LR: 0.00000990  \n","Epoch: [1][3100/9497] Elapsed 16m 49s (remain 34m 42s) Loss: 0.0067(0.0182) Grad: 5955.1929  LR: 0.00000990  \n","Epoch: [1][3200/9497] Elapsed 17m 22s (remain 34m 9s) Loss: 0.0255(0.0179) Grad: 67125.1406  LR: 0.00000989  \n","Epoch: [1][3300/9497] Elapsed 17m 54s (remain 33m 37s) Loss: 0.0300(0.0177) Grad: 15122.9385  LR: 0.00000988  \n","Epoch: [1][3400/9497] Elapsed 18m 27s (remain 33m 5s) Loss: 0.0071(0.0175) Grad: 9659.5996  LR: 0.00000987  \n","Epoch: [1][3500/9497] Elapsed 19m 0s (remain 32m 32s) Loss: 0.0131(0.0173) Grad: 8406.9160  LR: 0.00000987  \n","Epoch: [1][3600/9497] Elapsed 19m 32s (remain 32m 0s) Loss: 0.0099(0.0171) Grad: 6690.0771  LR: 0.00000986  \n","Epoch: [1][3700/9497] Elapsed 20m 5s (remain 31m 27s) Loss: 0.0183(0.0169) Grad: 8592.3057  LR: 0.00000985  \n","Epoch: [1][3800/9497] Elapsed 20m 37s (remain 30m 54s) Loss: 0.0035(0.0167) Grad: 4217.3765  LR: 0.00000984  \n","Epoch: [1][3900/9497] Elapsed 21m 10s (remain 30m 22s) Loss: 0.0004(0.0166) Grad: 385.7876  LR: 0.00000983  \n","Epoch: [1][4000/9497] Elapsed 21m 42s (remain 29m 49s) Loss: 0.0117(0.0164) Grad: 30689.6895  LR: 0.00000983  \n","Epoch: [1][4100/9497] Elapsed 22m 15s (remain 29m 16s) Loss: 0.0240(0.0163) Grad: 64210.5234  LR: 0.00000982  \n","Epoch: [1][4200/9497] Elapsed 22m 47s (remain 28m 44s) Loss: 0.0001(0.0161) Grad: 210.5410  LR: 0.00000981  \n","Epoch: [1][4300/9497] Elapsed 23m 20s (remain 28m 11s) Loss: 0.0063(0.0160) Grad: 8011.2583  LR: 0.00000980  \n","Epoch: [1][4400/9497] Elapsed 23m 53s (remain 27m 39s) Loss: 0.0101(0.0158) Grad: 8741.6113  LR: 0.00000979  \n","Epoch: [1][4500/9497] Elapsed 24m 25s (remain 27m 6s) Loss: 0.0001(0.0157) Grad: 170.4127  LR: 0.00000978  \n","Epoch: [1][4600/9497] Elapsed 24m 58s (remain 26m 34s) Loss: 0.0067(0.0156) Grad: 6722.3638  LR: 0.00000977  \n","Epoch: [1][4700/9497] Elapsed 25m 30s (remain 26m 1s) Loss: 0.0160(0.0154) Grad: 16435.8008  LR: 0.00000976  \n","Epoch: [1][4800/9497] Elapsed 26m 3s (remain 25m 29s) Loss: 0.0239(0.0153) Grad: 26785.7109  LR: 0.00000975  \n","Epoch: [1][4900/9497] Elapsed 26m 35s (remain 24m 56s) Loss: 0.0050(0.0152) Grad: 14202.0479  LR: 0.00000974  \n","Epoch: [1][5000/9497] Elapsed 27m 8s (remain 24m 24s) Loss: 0.0110(0.0151) Grad: 40363.4766  LR: 0.00000973  \n","Epoch: [1][5100/9497] Elapsed 27m 41s (remain 23m 51s) Loss: 0.0053(0.0150) Grad: 9353.9766  LR: 0.00000972  \n","Epoch: [1][5200/9497] Elapsed 28m 13s (remain 23m 18s) Loss: 0.0037(0.0149) Grad: 5114.5879  LR: 0.00000971  \n","Epoch: [1][5300/9497] Elapsed 28m 46s (remain 22m 46s) Loss: 0.0045(0.0148) Grad: 4480.1978  LR: 0.00000970  \n","Epoch: [1][5400/9497] Elapsed 29m 18s (remain 22m 13s) Loss: 0.0002(0.0147) Grad: 678.4744  LR: 0.00000968  \n","Epoch: [1][5500/9497] Elapsed 29m 51s (remain 21m 41s) Loss: 0.0110(0.0146) Grad: 15911.7217  LR: 0.00000967  \n","Epoch: [1][5600/9497] Elapsed 30m 23s (remain 21m 8s) Loss: 0.0049(0.0145) Grad: 15062.1562  LR: 0.00000966  \n","Epoch: [1][5700/9497] Elapsed 30m 56s (remain 20m 36s) Loss: 0.0001(0.0144) Grad: 377.5069  LR: 0.00000965  \n","Epoch: [1][5800/9497] Elapsed 31m 29s (remain 20m 3s) Loss: 0.0001(0.0143) Grad: 160.4094  LR: 0.00000964  \n","Epoch: [1][5900/9497] Elapsed 32m 1s (remain 19m 31s) Loss: 0.0043(0.0142) Grad: 5171.3672  LR: 0.00000962  \n","Epoch: [1][6000/9497] Elapsed 32m 34s (remain 18m 58s) Loss: 0.0360(0.0141) Grad: 10196.0283  LR: 0.00000961  \n","Epoch: [1][6100/9497] Elapsed 33m 6s (remain 18m 25s) Loss: 0.0002(0.0140) Grad: 528.2327  LR: 0.00000960  \n","Epoch: [1][6200/9497] Elapsed 33m 39s (remain 17m 53s) Loss: 0.0033(0.0139) Grad: 10907.6836  LR: 0.00000959  \n","Epoch: [1][6300/9497] Elapsed 34m 11s (remain 17m 20s) Loss: 0.0145(0.0139) Grad: 33697.2383  LR: 0.00000957  \n","Epoch: [1][6400/9497] Elapsed 34m 44s (remain 16m 48s) Loss: 0.0001(0.0138) Grad: 547.1770  LR: 0.00000956  \n","Epoch: [1][6500/9497] Elapsed 35m 16s (remain 16m 15s) Loss: 0.0381(0.0137) Grad: 50799.7031  LR: 0.00000954  \n","Epoch: [1][6600/9497] Elapsed 35m 49s (remain 15m 42s) Loss: 0.0396(0.0136) Grad: 113236.1797  LR: 0.00000953  \n","Epoch: [1][6700/9497] Elapsed 36m 22s (remain 15m 10s) Loss: 0.0002(0.0135) Grad: 1964.8043  LR: 0.00000952  \n","Epoch: [1][6800/9497] Elapsed 36m 54s (remain 14m 37s) Loss: 0.0096(0.0135) Grad: 21679.3770  LR: 0.00000950  \n","Epoch: [1][6900/9497] Elapsed 37m 27s (remain 14m 5s) Loss: 0.0124(0.0134) Grad: 45058.8555  LR: 0.00000949  \n","Epoch: [1][7000/9497] Elapsed 37m 59s (remain 13m 32s) Loss: 0.0034(0.0133) Grad: 14771.8818  LR: 0.00000947  \n","Epoch: [1][7100/9497] Elapsed 38m 32s (remain 13m 0s) Loss: 0.0065(0.0132) Grad: 15444.3965  LR: 0.00000946  \n","Epoch: [1][7200/9497] Elapsed 39m 4s (remain 12m 27s) Loss: 0.0000(0.0132) Grad: 47.9883  LR: 0.00000944  \n","Epoch: [1][7300/9497] Elapsed 39m 37s (remain 11m 55s) Loss: 0.0218(0.0131) Grad: 100230.7500  LR: 0.00000943  \n","Epoch: [1][7400/9497] Elapsed 40m 10s (remain 11m 22s) Loss: 0.0234(0.0130) Grad: 37716.8125  LR: 0.00000941  \n","Epoch: [1][7500/9497] Elapsed 40m 42s (remain 10m 49s) Loss: 0.0096(0.0130) Grad: 32071.5098  LR: 0.00000940  \n","Epoch: [1][7600/9497] Elapsed 41m 14s (remain 10m 17s) Loss: 0.0042(0.0129) Grad: 12147.4131  LR: 0.00000938  \n","Epoch: [1][7700/9497] Elapsed 41m 47s (remain 9m 44s) Loss: 0.0026(0.0128) Grad: 17155.9961  LR: 0.00000937  \n","Epoch: [1][7800/9497] Elapsed 42m 20s (remain 9m 12s) Loss: 0.0101(0.0128) Grad: 59246.2734  LR: 0.00000935  \n","Epoch: [1][7900/9497] Elapsed 42m 52s (remain 8m 39s) Loss: 0.0016(0.0127) Grad: 9301.6338  LR: 0.00000933  \n","Epoch: [1][8000/9497] Elapsed 43m 25s (remain 8m 7s) Loss: 0.0013(0.0126) Grad: 7849.3271  LR: 0.00000932  \n","Epoch: [1][8100/9497] Elapsed 43m 58s (remain 7m 34s) Loss: 0.0002(0.0126) Grad: 3864.7080  LR: 0.00000930  \n","Epoch: [1][8200/9497] Elapsed 44m 30s (remain 7m 2s) Loss: 0.0001(0.0126) Grad: 508.3851  LR: 0.00000928  \n","Epoch: [1][8300/9497] Elapsed 45m 3s (remain 6m 29s) Loss: 0.0046(0.0126) Grad: 25589.7461  LR: 0.00000926  \n","Epoch: [1][8400/9497] Elapsed 45m 35s (remain 5m 56s) Loss: 0.0037(0.0125) Grad: 47979.0000  LR: 0.00000925  \n","Epoch: [1][8500/9497] Elapsed 46m 8s (remain 5m 24s) Loss: 0.0282(0.0125) Grad: 456995.5938  LR: 0.00000923  \n","Epoch: [1][8600/9497] Elapsed 46m 40s (remain 4m 51s) Loss: 0.0043(0.0124) Grad: 57292.7109  LR: 0.00000921  \n","Epoch: [1][8700/9497] Elapsed 47m 13s (remain 4m 19s) Loss: 0.0092(0.0124) Grad: 78411.5078  LR: 0.00000919  \n","Epoch: [1][8800/9497] Elapsed 47m 45s (remain 3m 46s) Loss: 0.0039(0.0123) Grad: 56478.3672  LR: 0.00000918  \n","Epoch: [1][8900/9497] Elapsed 48m 18s (remain 3m 14s) Loss: 0.0146(0.0123) Grad: 134728.7812  LR: 0.00000916  \n","Epoch: [1][9000/9497] Elapsed 48m 50s (remain 2m 41s) Loss: 0.0036(0.0122) Grad: 28924.4512  LR: 0.00000914  \n","Epoch: [1][9100/9497] Elapsed 49m 23s (remain 2m 8s) Loss: 0.0087(0.0122) Grad: 86262.5781  LR: 0.00000912  \n","Epoch: [1][9200/9497] Elapsed 49m 55s (remain 1m 36s) Loss: 0.0352(0.0122) Grad: 160125.4219  LR: 0.00000910  \n","Epoch: [1][9300/9497] Elapsed 50m 28s (remain 1m 3s) Loss: 0.0077(0.0121) Grad: 19235.8379  LR: 0.00000908  \n","Epoch: [1][9400/9497] Elapsed 51m 0s (remain 0m 31s) Loss: 0.0103(0.0121) Grad: 19488.6055  LR: 0.00000906  \n","Epoch: [1][9496/9497] Elapsed 51m 31s (remain 0m 0s) Loss: 0.0003(0.0121) Grad: 2855.8726  LR: 0.00000905  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 18m 13s) Loss: 0.0095(0.0095) \n","EVAL: [100/2375] Elapsed 0m 19s (remain 7m 23s) Loss: 0.1080(0.0125) \n","EVAL: [200/2375] Elapsed 0m 38s (remain 7m 1s) Loss: 0.0328(0.0132) \n","EVAL: [300/2375] Elapsed 0m 58s (remain 6m 41s) Loss: 0.0192(0.0152) \n","EVAL: [400/2375] Elapsed 1m 17s (remain 6m 21s) Loss: 0.0002(0.0146) \n","EVAL: [500/2375] Elapsed 1m 36s (remain 6m 2s) Loss: 0.0614(0.0139) \n","EVAL: [600/2375] Elapsed 1m 56s (remain 5m 43s) Loss: 0.0192(0.0138) \n","EVAL: [700/2375] Elapsed 2m 15s (remain 5m 23s) Loss: 0.0216(0.0143) \n","EVAL: [800/2375] Elapsed 2m 34s (remain 5m 4s) Loss: 0.0097(0.0151) \n","EVAL: [900/2375] Elapsed 2m 54s (remain 4m 45s) Loss: 0.0064(0.0138) \n","EVAL: [1000/2375] Elapsed 3m 13s (remain 4m 25s) Loss: 0.0073(0.0127) \n","EVAL: [1100/2375] Elapsed 3m 33s (remain 4m 6s) Loss: 0.0003(0.0118) \n","EVAL: [1200/2375] Elapsed 3m 52s (remain 3m 47s) Loss: 0.0009(0.0110) \n","EVAL: [1300/2375] Elapsed 4m 11s (remain 3m 27s) Loss: 0.0002(0.0103) \n","EVAL: [1400/2375] Elapsed 4m 31s (remain 3m 8s) Loss: 0.0108(0.0101) \n","EVAL: [1500/2375] Elapsed 4m 50s (remain 2m 49s) Loss: 0.0003(0.0099) \n","EVAL: [1600/2375] Elapsed 5m 9s (remain 2m 29s) Loss: 0.0061(0.0098) \n","EVAL: [1700/2375] Elapsed 5m 29s (remain 2m 10s) Loss: 0.0137(0.0098) \n","EVAL: [1800/2375] Elapsed 5m 48s (remain 1m 51s) Loss: 0.0000(0.0097) \n","EVAL: [1900/2375] Elapsed 6m 7s (remain 1m 31s) Loss: 0.0000(0.0092) \n","EVAL: [2000/2375] Elapsed 6m 27s (remain 1m 12s) Loss: 0.0000(0.0088) \n","EVAL: [2100/2375] Elapsed 6m 46s (remain 0m 53s) Loss: 0.0000(0.0084) \n","EVAL: [2200/2375] Elapsed 7m 5s (remain 0m 33s) Loss: 0.0043(0.0081) \n","EVAL: [2300/2375] Elapsed 7m 25s (remain 0m 14s) Loss: 0.0000(0.0077) \n","EVAL: [2374/2375] Elapsed 7m 39s (remain 0m 0s) Loss: 0.0000(0.0075) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0121  avg_val_loss: 0.0075  time: 3564s\n","Epoch 1 - Score: 0.9450\n","Epoch 1 - Save Best Score: 0.9450 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/9497] Elapsed 0m 0s (remain 137m 26s) Loss: 0.0009(0.0009) Grad: 5300.2183  LR: 0.00000905  \n","Epoch: [2][100/9497] Elapsed 0m 33s (remain 52m 20s) Loss: 0.0077(0.0073) Grad: 31737.8711  LR: 0.00000903  \n","Epoch: [2][200/9497] Elapsed 1m 6s (remain 51m 12s) Loss: 0.0040(0.0072) Grad: 17516.7461  LR: 0.00000901  \n","Epoch: [2][300/9497] Elapsed 1m 39s (remain 50m 29s) Loss: 0.0033(0.0068) Grad: 45345.8867  LR: 0.00000899  \n","Epoch: [2][400/9497] Elapsed 2m 11s (remain 49m 50s) Loss: 0.0066(0.0070) Grad: 44750.9648  LR: 0.00000897  \n","Epoch: [2][500/9497] Elapsed 2m 44s (remain 49m 14s) Loss: 0.0010(0.0074) Grad: 5721.4702  LR: 0.00000895  \n","Epoch: [2][600/9497] Elapsed 3m 17s (remain 48m 39s) Loss: 0.0141(0.0076) Grad: 37421.9531  LR: 0.00000893  \n","Epoch: [2][700/9497] Elapsed 3m 49s (remain 48m 4s) Loss: 0.0077(0.0074) Grad: 68496.6484  LR: 0.00000890  \n","Epoch: [2][800/9497] Elapsed 4m 22s (remain 47m 29s) Loss: 0.0078(0.0074) Grad: 39841.7109  LR: 0.00000888  \n","Epoch: [2][900/9497] Elapsed 4m 55s (remain 46m 54s) Loss: 0.0013(0.0074) Grad: 6472.9067  LR: 0.00000886  \n","Epoch: [2][1000/9497] Elapsed 5m 27s (remain 46m 21s) Loss: 0.0004(0.0075) Grad: 4099.6279  LR: 0.00000884  \n","Epoch: [2][1100/9497] Elapsed 6m 0s (remain 45m 48s) Loss: 0.0078(0.0077) Grad: 6899.7578  LR: 0.00000882  \n","Epoch: [2][1200/9497] Elapsed 6m 33s (remain 45m 15s) Loss: 0.0058(0.0076) Grad: 23372.8574  LR: 0.00000880  \n","Epoch: [2][1300/9497] Elapsed 7m 5s (remain 44m 42s) Loss: 0.0057(0.0075) Grad: 97393.8672  LR: 0.00000878  \n","Epoch: [2][1400/9497] Elapsed 7m 38s (remain 44m 8s) Loss: 0.0001(0.0075) Grad: 927.2800  LR: 0.00000876  \n","Epoch: [2][1500/9497] Elapsed 8m 11s (remain 43m 35s) Loss: 0.0054(0.0074) Grad: 7027.7886  LR: 0.00000873  \n","Epoch: [2][1600/9497] Elapsed 8m 43s (remain 43m 2s) Loss: 0.0131(0.0075) Grad: 57870.9023  LR: 0.00000871  \n","Epoch: [2][1700/9497] Elapsed 9m 16s (remain 42m 29s) Loss: 0.0016(0.0077) Grad: 8337.4902  LR: 0.00000869  \n","Epoch: [2][1800/9497] Elapsed 9m 48s (remain 41m 56s) Loss: 0.0025(0.0076) Grad: 12507.5049  LR: 0.00000867  \n","Epoch: [2][1900/9497] Elapsed 10m 21s (remain 41m 23s) Loss: 0.0029(0.0076) Grad: 28712.3184  LR: 0.00000864  \n","Epoch: [2][2000/9497] Elapsed 10m 54s (remain 40m 50s) Loss: 0.0036(0.0075) Grad: 83315.1797  LR: 0.00000862  \n","Epoch: [2][2100/9497] Elapsed 11m 26s (remain 40m 17s) Loss: 0.0152(0.0074) Grad: 50034.5664  LR: 0.00000860  \n","Epoch: [2][2200/9497] Elapsed 11m 59s (remain 39m 44s) Loss: 0.0231(0.0074) Grad: 262001.9844  LR: 0.00000858  \n","Epoch: [2][2300/9497] Elapsed 12m 32s (remain 39m 13s) Loss: 0.0032(0.0074) Grad: 62144.1211  LR: 0.00000855  \n","Epoch: [2][2400/9497] Elapsed 13m 5s (remain 38m 40s) Loss: 0.0000(0.0073) Grad: 112.0472  LR: 0.00000853  \n","Epoch: [2][2500/9497] Elapsed 13m 37s (remain 38m 7s) Loss: 0.0198(0.0074) Grad: 93082.7344  LR: 0.00000851  \n","Epoch: [2][2600/9497] Elapsed 14m 10s (remain 37m 34s) Loss: 0.0304(0.0073) Grad: 115539.4453  LR: 0.00000848  \n","Epoch: [2][2700/9497] Elapsed 14m 42s (remain 37m 1s) Loss: 0.0080(0.0073) Grad: 118148.3594  LR: 0.00000846  \n","Epoch: [2][2800/9497] Elapsed 15m 15s (remain 36m 28s) Loss: 0.0008(0.0073) Grad: 38475.3789  LR: 0.00000843  \n","Epoch: [2][2900/9497] Elapsed 15m 48s (remain 35m 56s) Loss: 0.0013(0.0073) Grad: 35387.6016  LR: 0.00000841  \n","Epoch: [2][3000/9497] Elapsed 16m 20s (remain 35m 23s) Loss: 0.0233(0.0073) Grad: 216217.9375  LR: 0.00000839  \n","Epoch: [2][3100/9497] Elapsed 16m 53s (remain 34m 50s) Loss: 0.0025(0.0072) Grad: 21175.1445  LR: 0.00000836  \n","Epoch: [2][3200/9497] Elapsed 17m 26s (remain 34m 17s) Loss: 0.0018(0.0072) Grad: 35663.9492  LR: 0.00000834  \n","Epoch: [2][3300/9497] Elapsed 17m 58s (remain 33m 45s) Loss: 0.0103(0.0072) Grad: 126049.1719  LR: 0.00000831  \n","Epoch: [2][3400/9497] Elapsed 18m 31s (remain 33m 12s) Loss: 0.0035(0.0072) Grad: 38936.9492  LR: 0.00000829  \n","Epoch: [2][3500/9497] Elapsed 19m 4s (remain 32m 39s) Loss: 0.0016(0.0072) Grad: 18567.4102  LR: 0.00000826  \n","Epoch: [2][3600/9497] Elapsed 19m 36s (remain 32m 6s) Loss: 0.0078(0.0071) Grad: 136836.9531  LR: 0.00000824  \n","Epoch: [2][3700/9497] Elapsed 20m 9s (remain 31m 34s) Loss: 0.0017(0.0071) Grad: 27058.8555  LR: 0.00000821  \n","Epoch: [2][3800/9497] Elapsed 20m 42s (remain 31m 1s) Loss: 0.0001(0.0071) Grad: 907.4641  LR: 0.00000819  \n","Epoch: [2][3900/9497] Elapsed 21m 14s (remain 30m 28s) Loss: 0.0076(0.0072) Grad: 64638.8672  LR: 0.00000816  \n","Epoch: [2][4000/9497] Elapsed 21m 47s (remain 29m 55s) Loss: 0.0040(0.0072) Grad: 53820.4297  LR: 0.00000814  \n","Epoch: [2][4100/9497] Elapsed 22m 20s (remain 29m 23s) Loss: 0.0040(0.0072) Grad: 62017.5000  LR: 0.00000811  \n","Epoch: [2][4200/9497] Elapsed 22m 52s (remain 28m 50s) Loss: 0.0033(0.0072) Grad: 46884.5508  LR: 0.00000808  \n","Epoch: [2][4300/9497] Elapsed 23m 25s (remain 28m 17s) Loss: 0.0112(0.0072) Grad: 140551.5312  LR: 0.00000806  \n","Epoch: [2][4400/9497] Elapsed 23m 58s (remain 27m 45s) Loss: 0.0066(0.0072) Grad: 93590.8125  LR: 0.00000803  \n","Epoch: [2][4500/9497] Elapsed 24m 30s (remain 27m 12s) Loss: 0.0009(0.0071) Grad: 53092.3047  LR: 0.00000800  \n","Epoch: [2][4600/9497] Elapsed 25m 3s (remain 26m 40s) Loss: 0.0080(0.0071) Grad: 114369.8281  LR: 0.00000798  \n","Epoch: [2][4700/9497] Elapsed 25m 36s (remain 26m 7s) Loss: 0.0236(0.0072) Grad: 478188.4062  LR: 0.00000795  \n","Epoch: [2][4800/9497] Elapsed 26m 9s (remain 25m 34s) Loss: 0.0062(0.0072) Grad: 255127.8438  LR: 0.00000793  \n","Epoch: [2][4900/9497] Elapsed 26m 41s (remain 25m 2s) Loss: 0.0021(0.0072) Grad: 54888.6250  LR: 0.00000790  \n","Epoch: [2][5000/9497] Elapsed 27m 14s (remain 24m 29s) Loss: 0.0041(0.0072) Grad: 72419.8047  LR: 0.00000787  \n","Epoch: [2][5100/9497] Elapsed 27m 47s (remain 23m 56s) Loss: 0.0078(0.0072) Grad: 101736.4453  LR: 0.00000784  \n","Epoch: [2][5200/9497] Elapsed 28m 19s (remain 23m 24s) Loss: 0.0021(0.0072) Grad: 40813.3320  LR: 0.00000782  \n","Epoch: [2][5300/9497] Elapsed 28m 52s (remain 22m 51s) Loss: 0.0130(0.0072) Grad: 56458.5195  LR: 0.00000779  \n","Epoch: [2][5400/9497] Elapsed 29m 25s (remain 22m 18s) Loss: 0.0089(0.0072) Grad: 86933.6719  LR: 0.00000776  \n","Epoch: [2][5500/9497] Elapsed 29m 57s (remain 21m 45s) Loss: 0.0018(0.0072) Grad: 21873.6777  LR: 0.00000773  \n","Epoch: [2][5600/9497] Elapsed 30m 30s (remain 21m 13s) Loss: 0.0018(0.0072) Grad: 44951.1211  LR: 0.00000771  \n","Epoch: [2][5700/9497] Elapsed 31m 3s (remain 20m 40s) Loss: 0.0000(0.0072) Grad: 198.7925  LR: 0.00000768  \n","Epoch: [2][5800/9497] Elapsed 31m 35s (remain 20m 7s) Loss: 0.0109(0.0072) Grad: 65594.6719  LR: 0.00000765  \n","Epoch: [2][5900/9497] Elapsed 32m 8s (remain 19m 35s) Loss: 0.0197(0.0072) Grad: 64229.2344  LR: 0.00000762  \n","Epoch: [2][6000/9497] Elapsed 32m 40s (remain 19m 2s) Loss: 0.0117(0.0072) Grad: 59297.2148  LR: 0.00000759  \n","Epoch: [2][6100/9497] Elapsed 33m 13s (remain 18m 29s) Loss: 0.0099(0.0072) Grad: 37463.6562  LR: 0.00000757  \n","Epoch: [2][6200/9497] Elapsed 33m 46s (remain 17m 56s) Loss: 0.0023(0.0072) Grad: 20966.9219  LR: 0.00000754  \n","Epoch: [2][6300/9497] Elapsed 34m 18s (remain 17m 24s) Loss: 0.0246(0.0072) Grad: 64937.7422  LR: 0.00000751  \n","Epoch: [2][6400/9497] Elapsed 34m 51s (remain 16m 51s) Loss: 0.0079(0.0072) Grad: 38947.2656  LR: 0.00000748  \n","Epoch: [2][6500/9497] Elapsed 35m 24s (remain 16m 18s) Loss: 0.0010(0.0072) Grad: 6555.2515  LR: 0.00000745  \n","Epoch: [2][6600/9497] Elapsed 35m 56s (remain 15m 46s) Loss: 0.0065(0.0072) Grad: 19156.3848  LR: 0.00000742  \n","Epoch: [2][6700/9497] Elapsed 36m 29s (remain 15m 13s) Loss: 0.0000(0.0072) Grad: 146.5741  LR: 0.00000739  \n","Epoch: [2][6800/9497] Elapsed 37m 2s (remain 14m 40s) Loss: 0.0068(0.0072) Grad: 35958.1133  LR: 0.00000736  \n","Epoch: [2][6900/9497] Elapsed 37m 35s (remain 14m 8s) Loss: 0.0304(0.0072) Grad: 73577.5078  LR: 0.00000734  \n","Epoch: [2][7000/9497] Elapsed 38m 7s (remain 13m 35s) Loss: 0.0183(0.0072) Grad: 49711.7188  LR: 0.00000731  \n","Epoch: [2][7100/9497] Elapsed 38m 40s (remain 13m 2s) Loss: 0.0048(0.0072) Grad: 51046.2930  LR: 0.00000728  \n","Epoch: [2][7200/9497] Elapsed 39m 12s (remain 12m 30s) Loss: 0.0003(0.0071) Grad: 3830.5957  LR: 0.00000725  \n","Epoch: [2][7300/9497] Elapsed 39m 45s (remain 11m 57s) Loss: 0.0122(0.0071) Grad: 13443.5879  LR: 0.00000722  \n","Epoch: [2][7400/9497] Elapsed 40m 17s (remain 11m 24s) Loss: 0.0093(0.0071) Grad: 27087.8242  LR: 0.00000719  \n","Epoch: [2][7500/9497] Elapsed 40m 50s (remain 10m 52s) Loss: 0.0032(0.0071) Grad: 54667.5898  LR: 0.00000716  \n","Epoch: [2][7600/9497] Elapsed 41m 22s (remain 10m 19s) Loss: 0.0142(0.0071) Grad: 98094.2969  LR: 0.00000713  \n","Epoch: [2][7700/9497] Elapsed 41m 55s (remain 9m 46s) Loss: 0.0001(0.0071) Grad: 1080.4509  LR: 0.00000710  \n","Epoch: [2][7800/9497] Elapsed 42m 28s (remain 9m 13s) Loss: 0.0099(0.0071) Grad: 60442.4023  LR: 0.00000707  \n","Epoch: [2][7900/9497] Elapsed 43m 0s (remain 8m 41s) Loss: 0.0029(0.0071) Grad: 22564.9023  LR: 0.00000704  \n","Epoch: [2][8000/9497] Elapsed 43m 33s (remain 8m 8s) Loss: 0.0005(0.0071) Grad: 7288.9087  LR: 0.00000701  \n","Epoch: [2][8100/9497] Elapsed 44m 6s (remain 7m 35s) Loss: 0.0018(0.0071) Grad: 39328.4570  LR: 0.00000698  \n","Epoch: [2][8200/9497] Elapsed 44m 38s (remain 7m 3s) Loss: 0.0002(0.0071) Grad: 5860.5811  LR: 0.00000695  \n","Epoch: [2][8300/9497] Elapsed 45m 11s (remain 6m 30s) Loss: 0.0000(0.0071) Grad: 540.1724  LR: 0.00000692  \n","Epoch: [2][8400/9497] Elapsed 45m 43s (remain 5m 57s) Loss: 0.0023(0.0071) Grad: 29126.4805  LR: 0.00000689  \n","Epoch: [2][8500/9497] Elapsed 46m 16s (remain 5m 25s) Loss: 0.0224(0.0071) Grad: 147082.1719  LR: 0.00000686  \n","Epoch: [2][8600/9497] Elapsed 46m 48s (remain 4m 52s) Loss: 0.0000(0.0071) Grad: 525.6246  LR: 0.00000682  \n","Epoch: [2][8700/9497] Elapsed 47m 21s (remain 4m 19s) Loss: 0.0164(0.0071) Grad: 90764.0156  LR: 0.00000679  \n","Epoch: [2][8800/9497] Elapsed 47m 53s (remain 3m 47s) Loss: 0.0001(0.0071) Grad: 1826.3867  LR: 0.00000676  \n","Epoch: [2][8900/9497] Elapsed 48m 26s (remain 3m 14s) Loss: 0.0029(0.0071) Grad: 34392.3398  LR: 0.00000673  \n","Epoch: [2][9000/9497] Elapsed 48m 58s (remain 2m 41s) Loss: 0.0012(0.0071) Grad: 26359.9746  LR: 0.00000670  \n","Epoch: [2][9100/9497] Elapsed 49m 31s (remain 2m 9s) Loss: 0.0032(0.0071) Grad: 26449.5254  LR: 0.00000667  \n","Epoch: [2][9200/9497] Elapsed 50m 3s (remain 1m 36s) Loss: 0.0009(0.0071) Grad: 14375.9463  LR: 0.00000664  \n","Epoch: [2][9300/9497] Elapsed 50m 36s (remain 1m 3s) Loss: 0.0059(0.0071) Grad: 31644.2422  LR: 0.00000661  \n","Epoch: [2][9400/9497] Elapsed 51m 8s (remain 0m 31s) Loss: 0.0055(0.0071) Grad: 34606.9688  LR: 0.00000658  \n","Epoch: [2][9496/9497] Elapsed 51m 39s (remain 0m 0s) Loss: 0.0069(0.0071) Grad: 80718.4531  LR: 0.00000655  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 18m 18s) Loss: 0.0054(0.0054) \n","EVAL: [100/2375] Elapsed 0m 19s (remain 7m 22s) Loss: 0.1139(0.0134) \n","EVAL: [200/2375] Elapsed 0m 38s (remain 7m 0s) Loss: 0.0400(0.0147) \n","EVAL: [300/2375] Elapsed 0m 58s (remain 6m 40s) Loss: 0.0252(0.0173) \n","EVAL: [400/2375] Elapsed 1m 17s (remain 6m 20s) Loss: 0.0001(0.0170) \n","EVAL: [500/2375] Elapsed 1m 36s (remain 6m 1s) Loss: 0.0632(0.0159) \n","EVAL: [600/2375] Elapsed 1m 55s (remain 5m 42s) Loss: 0.0252(0.0155) \n","EVAL: [700/2375] Elapsed 2m 15s (remain 5m 22s) Loss: 0.0145(0.0161) \n","EVAL: [800/2375] Elapsed 2m 34s (remain 5m 3s) Loss: 0.0125(0.0168) \n","EVAL: [900/2375] Elapsed 2m 53s (remain 4m 44s) Loss: 0.0095(0.0153) \n","EVAL: [1000/2375] Elapsed 3m 13s (remain 4m 24s) Loss: 0.0003(0.0140) \n","EVAL: [1100/2375] Elapsed 3m 32s (remain 4m 5s) Loss: 0.0007(0.0130) \n","EVAL: [1200/2375] Elapsed 3m 51s (remain 3m 46s) Loss: 0.0018(0.0121) \n","EVAL: [1300/2375] Elapsed 4m 10s (remain 3m 27s) Loss: 0.0001(0.0113) \n","EVAL: [1400/2375] Elapsed 4m 30s (remain 3m 7s) Loss: 0.0095(0.0110) \n","EVAL: [1500/2375] Elapsed 4m 49s (remain 2m 48s) Loss: 0.0013(0.0109) \n","EVAL: [1600/2375] Elapsed 5m 9s (remain 2m 29s) Loss: 0.0069(0.0107) \n","EVAL: [1700/2375] Elapsed 5m 28s (remain 2m 10s) Loss: 0.0177(0.0107) \n","EVAL: [1800/2375] Elapsed 5m 47s (remain 1m 50s) Loss: 0.0000(0.0106) \n","EVAL: [1900/2375] Elapsed 6m 7s (remain 1m 31s) Loss: 0.0000(0.0100) \n","EVAL: [2000/2375] Elapsed 6m 26s (remain 1m 12s) Loss: 0.0000(0.0096) \n","EVAL: [2100/2375] Elapsed 6m 45s (remain 0m 52s) Loss: 0.0000(0.0091) \n","EVAL: [2200/2375] Elapsed 7m 5s (remain 0m 33s) Loss: 0.0043(0.0088) \n","EVAL: [2300/2375] Elapsed 7m 24s (remain 0m 14s) Loss: 0.0000(0.0084) \n","EVAL: [2374/2375] Elapsed 7m 38s (remain 0m 0s) Loss: 0.0000(0.0082) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0071  avg_val_loss: 0.0082  time: 3590s\n","Epoch 2 - Score: 0.9502\n","Epoch 2 - Save Best Score: 0.9502 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/9497] Elapsed 0m 0s (remain 156m 50s) Loss: 0.0199(0.0199) Grad: 161620.9688  LR: 0.00000655  \n","Epoch: [3][100/9497] Elapsed 0m 34s (remain 53m 41s) Loss: 0.0049(0.0048) Grad: 42249.0078  LR: 0.00000651  \n","Epoch: [3][200/9497] Elapsed 1m 7s (remain 52m 24s) Loss: 0.0004(0.0050) Grad: 4510.6108  LR: 0.00000648  \n","Epoch: [3][300/9497] Elapsed 1m 41s (remain 51m 38s) Loss: 0.0086(0.0055) Grad: 29923.1562  LR: 0.00000645  \n","Epoch: [3][400/9497] Elapsed 2m 14s (remain 50m 54s) Loss: 0.0121(0.0056) Grad: 37602.4883  LR: 0.00000642  \n","Epoch: [3][500/9497] Elapsed 2m 48s (remain 50m 17s) Loss: 0.0033(0.0057) Grad: 27712.3691  LR: 0.00000639  \n","Epoch: [3][600/9497] Elapsed 3m 21s (remain 49m 44s) Loss: 0.0011(0.0056) Grad: 16564.0117  LR: 0.00000636  \n","Epoch: [3][700/9497] Elapsed 3m 55s (remain 49m 9s) Loss: 0.0034(0.0057) Grad: 12509.9629  LR: 0.00000632  \n","Epoch: [3][800/9497] Elapsed 4m 28s (remain 48m 36s) Loss: 0.0137(0.0059) Grad: 71567.6719  LR: 0.00000629  \n","Epoch: [3][900/9497] Elapsed 5m 2s (remain 48m 3s) Loss: 0.0081(0.0059) Grad: 27003.0762  LR: 0.00000626  \n","Epoch: [3][1000/9497] Elapsed 5m 35s (remain 47m 29s) Loss: 0.0082(0.0059) Grad: 34348.8711  LR: 0.00000623  \n","Epoch: [3][1100/9497] Elapsed 6m 9s (remain 46m 55s) Loss: 0.0000(0.0058) Grad: 131.8895  LR: 0.00000620  \n","Epoch: [3][1200/9497] Elapsed 6m 42s (remain 46m 21s) Loss: 0.0020(0.0058) Grad: 15212.1719  LR: 0.00000616  \n","Epoch: [3][1300/9497] Elapsed 7m 16s (remain 45m 48s) Loss: 0.0038(0.0058) Grad: 57064.8594  LR: 0.00000613  \n","Epoch: [3][1400/9497] Elapsed 7m 49s (remain 45m 15s) Loss: 0.0004(0.0058) Grad: 2436.5525  LR: 0.00000610  \n","Epoch: [3][1500/9497] Elapsed 8m 23s (remain 44m 41s) Loss: 0.0138(0.0059) Grad: 27062.8848  LR: 0.00000607  \n","Epoch: [3][1600/9497] Elapsed 8m 57s (remain 44m 9s) Loss: 0.0045(0.0058) Grad: 24579.2168  LR: 0.00000603  \n","Epoch: [3][1700/9497] Elapsed 9m 30s (remain 43m 36s) Loss: 0.0034(0.0058) Grad: 15063.1797  LR: 0.00000600  \n","Epoch: [3][1800/9497] Elapsed 10m 4s (remain 43m 3s) Loss: 0.0066(0.0058) Grad: 29526.3105  LR: 0.00000597  \n","Epoch: [3][1900/9497] Elapsed 10m 38s (remain 42m 30s) Loss: 0.0070(0.0058) Grad: 22836.7402  LR: 0.00000594  \n","Epoch: [3][2000/9497] Elapsed 11m 11s (remain 41m 57s) Loss: 0.0001(0.0058) Grad: 3355.2158  LR: 0.00000590  \n","Epoch: [3][2100/9497] Elapsed 11m 45s (remain 41m 23s) Loss: 0.0119(0.0059) Grad: 53088.2656  LR: 0.00000587  \n","Epoch: [3][2200/9497] Elapsed 12m 19s (remain 40m 50s) Loss: 0.0001(0.0059) Grad: 8933.2129  LR: 0.00000584  \n","Epoch: [3][2300/9497] Elapsed 12m 52s (remain 40m 17s) Loss: 0.0001(0.0060) Grad: 1398.1484  LR: 0.00000581  \n","Epoch: [3][2400/9497] Elapsed 13m 26s (remain 39m 44s) Loss: 0.0039(0.0060) Grad: 32262.6582  LR: 0.00000577  \n","Epoch: [3][2500/9497] Elapsed 14m 0s (remain 39m 11s) Loss: 0.0000(0.0060) Grad: 389.8316  LR: 0.00000574  \n","Epoch: [3][2600/9497] Elapsed 14m 34s (remain 38m 38s) Loss: 0.0005(0.0060) Grad: 12775.4932  LR: 0.00000571  \n","Epoch: [3][2700/9497] Elapsed 15m 7s (remain 38m 4s) Loss: 0.0005(0.0060) Grad: 17418.0820  LR: 0.00000568  \n","Epoch: [3][2800/9497] Elapsed 15m 41s (remain 37m 31s) Loss: 0.0000(0.0060) Grad: 816.9584  LR: 0.00000564  \n","Epoch: [3][2900/9497] Elapsed 16m 15s (remain 36m 57s) Loss: 0.0016(0.0060) Grad: 28377.0293  LR: 0.00000561  \n","Epoch: [3][3000/9497] Elapsed 16m 49s (remain 36m 24s) Loss: 0.0061(0.0060) Grad: 31698.6992  LR: 0.00000558  \n","Epoch: [3][3100/9497] Elapsed 17m 22s (remain 35m 50s) Loss: 0.0048(0.0060) Grad: 52845.1484  LR: 0.00000554  \n","Epoch: [3][3200/9497] Elapsed 17m 56s (remain 35m 17s) Loss: 0.0000(0.0060) Grad: 679.3297  LR: 0.00000551  \n","Epoch: [3][3300/9497] Elapsed 18m 30s (remain 34m 44s) Loss: 0.0071(0.0060) Grad: 97300.6406  LR: 0.00000548  \n","Epoch: [3][3400/9497] Elapsed 19m 3s (remain 34m 10s) Loss: 0.0001(0.0061) Grad: 1111.1614  LR: 0.00000545  \n","Epoch: [3][3500/9497] Elapsed 19m 37s (remain 33m 36s) Loss: 0.0035(0.0061) Grad: 27132.0000  LR: 0.00000541  \n","Epoch: [3][3600/9497] Elapsed 20m 11s (remain 33m 3s) Loss: 0.0030(0.0060) Grad: 28407.1523  LR: 0.00000538  \n","Epoch: [3][3700/9497] Elapsed 20m 45s (remain 32m 29s) Loss: 0.0011(0.0061) Grad: 10671.5957  LR: 0.00000535  \n","Epoch: [3][3800/9497] Elapsed 21m 18s (remain 31m 56s) Loss: 0.0019(0.0061) Grad: 137818.9375  LR: 0.00000531  \n","Epoch: [3][3900/9497] Elapsed 21m 52s (remain 31m 22s) Loss: 0.0000(0.0061) Grad: 665.5153  LR: 0.00000528  \n","Epoch: [3][4000/9497] Elapsed 22m 25s (remain 30m 48s) Loss: 0.0061(0.0061) Grad: 110235.9922  LR: 0.00000525  \n","Epoch: [3][4100/9497] Elapsed 22m 59s (remain 30m 15s) Loss: 0.0107(0.0061) Grad: 214564.0312  LR: 0.00000521  \n","Epoch: [3][4200/9497] Elapsed 23m 33s (remain 29m 41s) Loss: 0.0042(0.0061) Grad: 139603.6562  LR: 0.00000518  \n","Epoch: [3][4300/9497] Elapsed 24m 6s (remain 29m 7s) Loss: 0.0004(0.0061) Grad: 25652.5918  LR: 0.00000515  \n","Epoch: [3][4400/9497] Elapsed 24m 40s (remain 28m 34s) Loss: 0.0207(0.0061) Grad: 257338.7031  LR: 0.00000512  \n","Epoch: [3][4500/9497] Elapsed 25m 13s (remain 28m 0s) Loss: 0.0000(0.0061) Grad: 1787.3533  LR: 0.00000508  \n","Epoch: [3][4600/9497] Elapsed 25m 47s (remain 27m 26s) Loss: 0.0002(0.0061) Grad: 10726.6797  LR: 0.00000505  \n","Epoch: [3][4700/9497] Elapsed 26m 21s (remain 26m 53s) Loss: 0.0336(0.0061) Grad: 979044.0000  LR: 0.00000502  \n","Epoch: [3][4800/9497] Elapsed 26m 54s (remain 26m 19s) Loss: 0.0003(0.0060) Grad: 18907.8242  LR: 0.00000498  \n","Epoch: [3][4900/9497] Elapsed 27m 27s (remain 25m 45s) Loss: 0.0000(0.0060) Grad: 504.6434  LR: 0.00000495  \n","Epoch: [3][5000/9497] Elapsed 28m 1s (remain 25m 11s) Loss: 0.0047(0.0060) Grad: 94520.0000  LR: 0.00000492  \n","Epoch: [3][5100/9497] Elapsed 28m 35s (remain 24m 37s) Loss: 0.0087(0.0060) Grad: 185053.9531  LR: 0.00000488  \n","Epoch: [3][5200/9497] Elapsed 29m 8s (remain 24m 4s) Loss: 0.0019(0.0061) Grad: 91335.5156  LR: 0.00000485  \n","Epoch: [3][5300/9497] Elapsed 29m 41s (remain 23m 30s) Loss: 0.0093(0.0061) Grad: 336421.2812  LR: 0.00000482  \n","Epoch: [3][5400/9497] Elapsed 30m 15s (remain 22m 56s) Loss: 0.0019(0.0061) Grad: 100701.1484  LR: 0.00000478  \n","Epoch: [3][5500/9497] Elapsed 30m 48s (remain 22m 22s) Loss: 0.0027(0.0060) Grad: 98147.4141  LR: 0.00000475  \n","Epoch: [3][5600/9497] Elapsed 31m 22s (remain 21m 49s) Loss: 0.0016(0.0060) Grad: 37414.4805  LR: 0.00000472  \n","Epoch: [3][5700/9497] Elapsed 31m 55s (remain 21m 15s) Loss: 0.0000(0.0060) Grad: 539.3562  LR: 0.00000469  \n","Epoch: [3][5800/9497] Elapsed 32m 28s (remain 20m 41s) Loss: 0.0006(0.0060) Grad: 104625.9062  LR: 0.00000465  \n","Epoch: [3][5900/9497] Elapsed 33m 2s (remain 20m 7s) Loss: 0.0120(0.0060) Grad: 179499.9844  LR: 0.00000462  \n","Epoch: [3][6000/9497] Elapsed 33m 35s (remain 19m 34s) Loss: 0.0020(0.0060) Grad: 90564.3828  LR: 0.00000459  \n","Epoch: [3][6100/9497] Elapsed 34m 9s (remain 19m 0s) Loss: 0.0000(0.0060) Grad: 2062.5256  LR: 0.00000455  \n","Epoch: [3][6200/9497] Elapsed 34m 42s (remain 18m 26s) Loss: 0.0058(0.0060) Grad: 62845.5156  LR: 0.00000452  \n","Epoch: [3][6300/9497] Elapsed 35m 15s (remain 17m 53s) Loss: 0.0000(0.0060) Grad: 213.0810  LR: 0.00000449  \n","Epoch: [3][6400/9497] Elapsed 35m 49s (remain 17m 19s) Loss: 0.0198(0.0060) Grad: 353260.8125  LR: 0.00000445  \n","Epoch: [3][6500/9497] Elapsed 36m 22s (remain 16m 45s) Loss: 0.0063(0.0060) Grad: 137584.6406  LR: 0.00000442  \n","Epoch: [3][6600/9497] Elapsed 36m 56s (remain 16m 12s) Loss: 0.0046(0.0061) Grad: 76623.7891  LR: 0.00000439  \n","Epoch: [3][6700/9497] Elapsed 37m 29s (remain 15m 38s) Loss: 0.0019(0.0061) Grad: 67801.9297  LR: 0.00000436  \n","Epoch: [3][6800/9497] Elapsed 38m 3s (remain 15m 5s) Loss: 0.0004(0.0060) Grad: 15027.0723  LR: 0.00000432  \n","Epoch: [3][6900/9497] Elapsed 38m 36s (remain 14m 31s) Loss: 0.0006(0.0060) Grad: 42206.2031  LR: 0.00000429  \n","Epoch: [3][7000/9497] Elapsed 39m 10s (remain 13m 57s) Loss: 0.0040(0.0061) Grad: 158702.2500  LR: 0.00000426  \n","Epoch: [3][7100/9497] Elapsed 39m 44s (remain 13m 24s) Loss: 0.0001(0.0061) Grad: 8772.7021  LR: 0.00000423  \n","Epoch: [3][7200/9497] Elapsed 40m 17s (remain 12m 50s) Loss: 0.0001(0.0060) Grad: 7723.6616  LR: 0.00000419  \n","Epoch: [3][7300/9497] Elapsed 40m 50s (remain 12m 17s) Loss: 0.0137(0.0061) Grad: 439979.4375  LR: 0.00000416  \n","Epoch: [3][7400/9497] Elapsed 41m 24s (remain 11m 43s) Loss: 0.0208(0.0060) Grad: 1258057.0000  LR: 0.00000413  \n","Epoch: [3][7500/9497] Elapsed 41m 57s (remain 11m 10s) Loss: 0.0054(0.0060) Grad: 82192.0000  LR: 0.00000410  \n","Epoch: [3][7600/9497] Elapsed 42m 31s (remain 10m 36s) Loss: 0.0034(0.0060) Grad: 89960.9141  LR: 0.00000406  \n","Epoch: [3][7700/9497] Elapsed 43m 4s (remain 10m 2s) Loss: 0.0025(0.0060) Grad: 149128.7344  LR: 0.00000403  \n","Epoch: [3][7800/9497] Elapsed 43m 38s (remain 9m 29s) Loss: 0.0006(0.0060) Grad: 22014.2812  LR: 0.00000400  \n","Epoch: [3][7900/9497] Elapsed 44m 12s (remain 8m 55s) Loss: 0.0001(0.0061) Grad: 7125.0229  LR: 0.00000397  \n","Epoch: [3][8000/9497] Elapsed 44m 45s (remain 8m 22s) Loss: 0.0000(0.0060) Grad: 32.7520  LR: 0.00000393  \n","Epoch: [3][8100/9497] Elapsed 45m 19s (remain 7m 48s) Loss: 0.0006(0.0060) Grad: 58364.8594  LR: 0.00000390  \n","Epoch: [3][8200/9497] Elapsed 45m 52s (remain 7m 15s) Loss: 0.0029(0.0061) Grad: 251787.8594  LR: 0.00000387  \n","Epoch: [3][8300/9497] Elapsed 46m 26s (remain 6m 41s) Loss: 0.0000(0.0061) Grad: 941.7806  LR: 0.00000384  \n","Epoch: [3][8400/9497] Elapsed 46m 59s (remain 6m 7s) Loss: 0.0090(0.0061) Grad: 98639.9609  LR: 0.00000380  \n","Epoch: [3][8500/9497] Elapsed 47m 33s (remain 5m 34s) Loss: 0.0098(0.0061) Grad: 127031.8516  LR: 0.00000377  \n","Epoch: [3][8600/9497] Elapsed 48m 7s (remain 5m 0s) Loss: 0.0006(0.0061) Grad: 20237.1074  LR: 0.00000374  \n","Epoch: [3][8700/9497] Elapsed 48m 40s (remain 4m 27s) Loss: 0.0000(0.0061) Grad: 361.6911  LR: 0.00000371  \n","Epoch: [3][8800/9497] Elapsed 49m 14s (remain 3m 53s) Loss: 0.0023(0.0061) Grad: 111061.1406  LR: 0.00000368  \n","Epoch: [3][8900/9497] Elapsed 49m 47s (remain 3m 20s) Loss: 0.0000(0.0061) Grad: 1538.5538  LR: 0.00000364  \n","Epoch: [3][9000/9497] Elapsed 50m 21s (remain 2m 46s) Loss: 0.0002(0.0061) Grad: 7876.4199  LR: 0.00000361  \n","Epoch: [3][9100/9497] Elapsed 50m 54s (remain 2m 12s) Loss: 0.0061(0.0061) Grad: 210181.1250  LR: 0.00000358  \n","Epoch: [3][9200/9497] Elapsed 51m 28s (remain 1m 39s) Loss: 0.0016(0.0061) Grad: 30400.2734  LR: 0.00000355  \n","Epoch: [3][9300/9497] Elapsed 52m 1s (remain 1m 5s) Loss: 0.0022(0.0061) Grad: 98857.4844  LR: 0.00000352  \n","Epoch: [3][9400/9497] Elapsed 52m 34s (remain 0m 32s) Loss: 0.0000(0.0061) Grad: 309.8493  LR: 0.00000349  \n","Epoch: [3][9496/9497] Elapsed 53m 7s (remain 0m 0s) Loss: 0.0000(0.0061) Grad: 945.7148  LR: 0.00000346  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 21m 10s) Loss: 0.0122(0.0122) \n","EVAL: [100/2375] Elapsed 0m 20s (remain 7m 47s) Loss: 0.1411(0.0158) \n","EVAL: [200/2375] Elapsed 0m 41s (remain 7m 23s) Loss: 0.0477(0.0171) \n","EVAL: [300/2375] Elapsed 1m 1s (remain 7m 2s) Loss: 0.0219(0.0192) \n","EVAL: [400/2375] Elapsed 1m 21s (remain 6m 41s) Loss: 0.0000(0.0190) \n","EVAL: [500/2375] Elapsed 1m 41s (remain 6m 21s) Loss: 0.0475(0.0175) \n","EVAL: [600/2375] Elapsed 2m 2s (remain 6m 0s) Loss: 0.0196(0.0169) \n","EVAL: [700/2375] Elapsed 2m 22s (remain 5m 40s) Loss: 0.0151(0.0172) \n","EVAL: [800/2375] Elapsed 2m 42s (remain 5m 19s) Loss: 0.0094(0.0179) \n","EVAL: [900/2375] Elapsed 3m 2s (remain 4m 59s) Loss: 0.0135(0.0162) \n","EVAL: [1000/2375] Elapsed 3m 23s (remain 4m 38s) Loss: 0.0022(0.0149) \n","EVAL: [1100/2375] Elapsed 3m 43s (remain 4m 18s) Loss: 0.0004(0.0138) \n","EVAL: [1200/2375] Elapsed 4m 3s (remain 3m 58s) Loss: 0.0019(0.0129) \n","EVAL: [1300/2375] Elapsed 4m 24s (remain 3m 37s) Loss: 0.0000(0.0121) \n","EVAL: [1400/2375] Elapsed 4m 44s (remain 3m 17s) Loss: 0.0096(0.0117) \n","EVAL: [1500/2375] Elapsed 5m 4s (remain 2m 57s) Loss: 0.0011(0.0115) \n","EVAL: [1600/2375] Elapsed 5m 24s (remain 2m 37s) Loss: 0.0096(0.0113) \n","EVAL: [1700/2375] Elapsed 5m 45s (remain 2m 16s) Loss: 0.0198(0.0112) \n","EVAL: [1800/2375] Elapsed 6m 5s (remain 1m 56s) Loss: 0.0000(0.0111) \n","EVAL: [1900/2375] Elapsed 6m 25s (remain 1m 36s) Loss: 0.0000(0.0105) \n","EVAL: [2000/2375] Elapsed 6m 46s (remain 1m 15s) Loss: 0.0000(0.0100) \n","EVAL: [2100/2375] Elapsed 7m 6s (remain 0m 55s) Loss: 0.0000(0.0096) \n","EVAL: [2200/2375] Elapsed 7m 26s (remain 0m 35s) Loss: 0.0056(0.0092) \n","EVAL: [2300/2375] Elapsed 7m 47s (remain 0m 15s) Loss: 0.0000(0.0089) \n","EVAL: [2374/2375] Elapsed 8m 1s (remain 0m 0s) Loss: 0.0000(0.0086) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0061  avg_val_loss: 0.0086  time: 3682s\n","Epoch 3 - Score: 0.9521\n","Epoch 3 - Save Best Score: 0.9521 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/9497] Elapsed 0m 0s (remain 142m 59s) Loss: 0.0012(0.0012) Grad: 11424.1475  LR: 0.00000346  \n","Epoch: [4][100/9497] Elapsed 0m 33s (remain 52m 34s) Loss: 0.0067(0.0069) Grad: 30127.0078  LR: 0.00000342  \n","Epoch: [4][200/9497] Elapsed 1m 6s (remain 51m 19s) Loss: 0.0060(0.0063) Grad: 35982.2695  LR: 0.00000339  \n","Epoch: [4][300/9497] Elapsed 1m 39s (remain 50m 28s) Loss: 0.0107(0.0059) Grad: 263325.3438  LR: 0.00000336  \n","Epoch: [4][400/9497] Elapsed 2m 11s (remain 49m 47s) Loss: 0.0757(0.0057) Grad: 144500.0781  LR: 0.00000333  \n","Epoch: [4][500/9497] Elapsed 2m 44s (remain 49m 7s) Loss: 0.0033(0.0054) Grad: 16591.7090  LR: 0.00000330  \n","Epoch: [4][600/9497] Elapsed 3m 16s (remain 48m 32s) Loss: 0.0001(0.0053) Grad: 466.4362  LR: 0.00000327  \n","Epoch: [4][700/9497] Elapsed 3m 49s (remain 47m 59s) Loss: 0.0021(0.0057) Grad: 32327.0723  LR: 0.00000324  \n","Epoch: [4][800/9497] Elapsed 4m 21s (remain 47m 23s) Loss: 0.0018(0.0056) Grad: 20516.2227  LR: 0.00000321  \n","Epoch: [4][900/9497] Elapsed 4m 54s (remain 46m 48s) Loss: 0.0074(0.0056) Grad: 45123.7031  LR: 0.00000317  \n","Epoch: [4][1000/9497] Elapsed 5m 26s (remain 46m 13s) Loss: 0.0001(0.0056) Grad: 1312.7949  LR: 0.00000314  \n","Epoch: [4][1100/9497] Elapsed 5m 59s (remain 45m 39s) Loss: 0.0000(0.0054) Grad: 107.2016  LR: 0.00000311  \n","Epoch: [4][1200/9497] Elapsed 6m 31s (remain 45m 5s) Loss: 0.0008(0.0054) Grad: 15722.5059  LR: 0.00000308  \n","Epoch: [4][1300/9497] Elapsed 7m 4s (remain 44m 32s) Loss: 0.0143(0.0054) Grad: 32732.1992  LR: 0.00000305  \n","Epoch: [4][1400/9497] Elapsed 7m 36s (remain 43m 59s) Loss: 0.0046(0.0054) Grad: 36804.6484  LR: 0.00000302  \n","Epoch: [4][1500/9497] Elapsed 8m 9s (remain 43m 26s) Loss: 0.0158(0.0054) Grad: 38681.0469  LR: 0.00000299  \n","Epoch: [4][1600/9497] Elapsed 8m 42s (remain 42m 54s) Loss: 0.0141(0.0055) Grad: 18058.3496  LR: 0.00000296  \n","Epoch: [4][1700/9497] Elapsed 9m 14s (remain 42m 21s) Loss: 0.0024(0.0054) Grad: 63083.2500  LR: 0.00000293  \n","Epoch: [4][1800/9497] Elapsed 9m 47s (remain 41m 48s) Loss: 0.0004(0.0055) Grad: 4873.4097  LR: 0.00000290  \n","Epoch: [4][1900/9497] Elapsed 10m 19s (remain 41m 15s) Loss: 0.0030(0.0054) Grad: 55466.3711  LR: 0.00000287  \n","Epoch: [4][2000/9497] Elapsed 10m 51s (remain 40m 42s) Loss: 0.0054(0.0054) Grad: 60896.3555  LR: 0.00000284  \n","Epoch: [4][2100/9497] Elapsed 11m 24s (remain 40m 9s) Loss: 0.0009(0.0053) Grad: 16398.3164  LR: 0.00000281  \n","Epoch: [4][2200/9497] Elapsed 11m 56s (remain 39m 35s) Loss: 0.0001(0.0053) Grad: 2737.5173  LR: 0.00000278  \n","Epoch: [4][2300/9497] Elapsed 12m 29s (remain 39m 3s) Loss: 0.0000(0.0052) Grad: 114.6963  LR: 0.00000275  \n","Epoch: [4][2400/9497] Elapsed 13m 1s (remain 38m 30s) Loss: 0.0000(0.0053) Grad: 324.8023  LR: 0.00000272  \n","Epoch: [4][2500/9497] Elapsed 13m 34s (remain 37m 58s) Loss: 0.0003(0.0052) Grad: 10126.3389  LR: 0.00000269  \n","Epoch: [4][2600/9497] Elapsed 14m 6s (remain 37m 24s) Loss: 0.0054(0.0053) Grad: 56370.0234  LR: 0.00000266  \n","Epoch: [4][2700/9497] Elapsed 14m 39s (remain 36m 51s) Loss: 0.0153(0.0053) Grad: 108103.7031  LR: 0.00000263  \n","Epoch: [4][2800/9497] Elapsed 15m 11s (remain 36m 18s) Loss: 0.0015(0.0053) Grad: 58976.2344  LR: 0.00000261  \n","Epoch: [4][2900/9497] Elapsed 15m 43s (remain 35m 46s) Loss: 0.0066(0.0053) Grad: 67189.2969  LR: 0.00000258  \n","Epoch: [4][3000/9497] Elapsed 16m 16s (remain 35m 13s) Loss: 0.0077(0.0053) Grad: 81859.8359  LR: 0.00000255  \n","Epoch: [4][3100/9497] Elapsed 16m 49s (remain 34m 41s) Loss: 0.0002(0.0054) Grad: 13509.3369  LR: 0.00000252  \n","Epoch: [4][3200/9497] Elapsed 17m 21s (remain 34m 8s) Loss: 0.0016(0.0053) Grad: 29759.6406  LR: 0.00000249  \n","Epoch: [4][3300/9497] Elapsed 17m 54s (remain 33m 35s) Loss: 0.0000(0.0053) Grad: 682.3526  LR: 0.00000246  \n","Epoch: [4][3400/9497] Elapsed 18m 26s (remain 33m 3s) Loss: 0.0066(0.0053) Grad: 84205.6406  LR: 0.00000243  \n","Epoch: [4][3500/9497] Elapsed 18m 58s (remain 32m 30s) Loss: 0.0684(0.0053) Grad: 75502.2266  LR: 0.00000241  \n","Epoch: [4][3600/9497] Elapsed 19m 31s (remain 31m 57s) Loss: 0.0020(0.0053) Grad: 41092.0039  LR: 0.00000238  \n","Epoch: [4][3700/9497] Elapsed 20m 3s (remain 31m 25s) Loss: 0.0111(0.0053) Grad: 18987.9004  LR: 0.00000235  \n","Epoch: [4][3800/9497] Elapsed 20m 36s (remain 30m 52s) Loss: 0.0001(0.0053) Grad: 4049.3125  LR: 0.00000232  \n","Epoch: [4][3900/9497] Elapsed 21m 9s (remain 30m 20s) Loss: 0.0037(0.0053) Grad: 85258.3594  LR: 0.00000229  \n","Epoch: [4][4000/9497] Elapsed 21m 41s (remain 29m 47s) Loss: 0.0000(0.0053) Grad: 2743.2715  LR: 0.00000227  \n","Epoch: [4][4100/9497] Elapsed 22m 13s (remain 29m 15s) Loss: 0.0064(0.0053) Grad: 136260.2188  LR: 0.00000224  \n","Epoch: [4][4200/9497] Elapsed 22m 46s (remain 28m 42s) Loss: 0.0097(0.0052) Grad: 235699.3438  LR: 0.00000221  \n","Epoch: [4][4300/9497] Elapsed 23m 18s (remain 28m 10s) Loss: 0.0055(0.0052) Grad: 113841.3594  LR: 0.00000218  \n","Epoch: [4][4400/9497] Elapsed 23m 51s (remain 27m 37s) Loss: 0.0080(0.0052) Grad: 85332.8047  LR: 0.00000216  \n","Epoch: [4][4500/9497] Elapsed 24m 24s (remain 27m 5s) Loss: 0.0000(0.0052) Grad: 30.5201  LR: 0.00000213  \n","Epoch: [4][4600/9497] Elapsed 24m 57s (remain 26m 33s) Loss: 0.0000(0.0053) Grad: 42.6949  LR: 0.00000210  \n","Epoch: [4][4700/9497] Elapsed 25m 29s (remain 26m 0s) Loss: 0.0065(0.0053) Grad: 248667.5469  LR: 0.00000207  \n","Epoch: [4][4800/9497] Elapsed 26m 1s (remain 25m 27s) Loss: 0.0094(0.0053) Grad: 145186.8594  LR: 0.00000205  \n","Epoch: [4][4900/9497] Elapsed 26m 34s (remain 24m 55s) Loss: 0.0000(0.0053) Grad: 61.4059  LR: 0.00000202  \n","Epoch: [4][5000/9497] Elapsed 27m 7s (remain 24m 22s) Loss: 0.0009(0.0053) Grad: 33927.6953  LR: 0.00000199  \n","Epoch: [4][5100/9497] Elapsed 27m 39s (remain 23m 50s) Loss: 0.0203(0.0053) Grad: 99551.2500  LR: 0.00000197  \n","Epoch: [4][5200/9497] Elapsed 28m 11s (remain 23m 17s) Loss: 0.0026(0.0053) Grad: 22844.9883  LR: 0.00000194  \n","Epoch: [4][5300/9497] Elapsed 28m 44s (remain 22m 44s) Loss: 0.0015(0.0053) Grad: 12572.0225  LR: 0.00000192  \n","Epoch: [4][5400/9497] Elapsed 29m 16s (remain 22m 12s) Loss: 0.0063(0.0053) Grad: 24329.3535  LR: 0.00000189  \n","Epoch: [4][5500/9497] Elapsed 29m 49s (remain 21m 39s) Loss: 0.0210(0.0053) Grad: 44019.1289  LR: 0.00000186  \n","Epoch: [4][5600/9497] Elapsed 30m 21s (remain 21m 7s) Loss: 0.0000(0.0053) Grad: 167.3223  LR: 0.00000184  \n","Epoch: [4][5700/9497] Elapsed 30m 54s (remain 20m 34s) Loss: 0.0067(0.0053) Grad: 10692.5918  LR: 0.00000181  \n","Epoch: [4][5800/9497] Elapsed 31m 26s (remain 20m 2s) Loss: 0.0000(0.0053) Grad: 11.2444  LR: 0.00000179  \n","Epoch: [4][5900/9497] Elapsed 31m 59s (remain 19m 29s) Loss: 0.0103(0.0053) Grad: 50805.1914  LR: 0.00000176  \n","Epoch: [4][6000/9497] Elapsed 32m 31s (remain 18m 57s) Loss: 0.0009(0.0053) Grad: 15052.7715  LR: 0.00000174  \n","Epoch: [4][6100/9497] Elapsed 33m 4s (remain 18m 24s) Loss: 0.0005(0.0053) Grad: 13690.7568  LR: 0.00000171  \n","Epoch: [4][6200/9497] Elapsed 33m 36s (remain 17m 51s) Loss: 0.0000(0.0053) Grad: 234.4378  LR: 0.00000169  \n","Epoch: [4][6300/9497] Elapsed 34m 8s (remain 17m 19s) Loss: 0.0018(0.0052) Grad: 14681.6094  LR: 0.00000166  \n","Epoch: [4][6400/9497] Elapsed 34m 41s (remain 16m 46s) Loss: 0.0002(0.0052) Grad: 2610.9207  LR: 0.00000164  \n","Epoch: [4][6500/9497] Elapsed 35m 14s (remain 16m 14s) Loss: 0.0001(0.0052) Grad: 859.4341  LR: 0.00000161  \n","Epoch: [4][6600/9497] Elapsed 35m 46s (remain 15m 41s) Loss: 0.0083(0.0052) Grad: 98064.0312  LR: 0.00000159  \n","Epoch: [4][6700/9497] Elapsed 36m 19s (remain 15m 9s) Loss: 0.0047(0.0052) Grad: 53677.4180  LR: 0.00000157  \n","Epoch: [4][6800/9497] Elapsed 36m 51s (remain 14m 36s) Loss: 0.0041(0.0053) Grad: 15998.2598  LR: 0.00000154  \n","Epoch: [4][6900/9497] Elapsed 37m 24s (remain 14m 4s) Loss: 0.0039(0.0053) Grad: 8945.6377  LR: 0.00000152  \n","Epoch: [4][7000/9497] Elapsed 37m 56s (remain 13m 31s) Loss: 0.0053(0.0053) Grad: 21580.0605  LR: 0.00000149  \n","Epoch: [4][7100/9497] Elapsed 38m 29s (remain 12m 59s) Loss: 0.0034(0.0052) Grad: 45870.2695  LR: 0.00000147  \n","Epoch: [4][7200/9497] Elapsed 39m 1s (remain 12m 26s) Loss: 0.0017(0.0052) Grad: 28963.6270  LR: 0.00000145  \n","Epoch: [4][7300/9497] Elapsed 39m 34s (remain 11m 54s) Loss: 0.0049(0.0052) Grad: 120928.4922  LR: 0.00000142  \n","Epoch: [4][7400/9497] Elapsed 40m 6s (remain 11m 21s) Loss: 0.0074(0.0052) Grad: 102086.7578  LR: 0.00000140  \n","Epoch: [4][7500/9497] Elapsed 40m 39s (remain 10m 49s) Loss: 0.0003(0.0052) Grad: 11428.8701  LR: 0.00000138  \n","Epoch: [4][7600/9497] Elapsed 41m 11s (remain 10m 16s) Loss: 0.0013(0.0052) Grad: 33952.5391  LR: 0.00000135  \n","Epoch: [4][7700/9497] Elapsed 41m 44s (remain 9m 44s) Loss: 0.0219(0.0052) Grad: 100903.0625  LR: 0.00000133  \n","Epoch: [4][7800/9497] Elapsed 42m 16s (remain 9m 11s) Loss: 0.0000(0.0052) Grad: 266.7007  LR: 0.00000131  \n","Epoch: [4][7900/9497] Elapsed 42m 49s (remain 8m 39s) Loss: 0.0013(0.0052) Grad: 24124.0469  LR: 0.00000129  \n","Epoch: [4][8000/9497] Elapsed 43m 21s (remain 8m 6s) Loss: 0.0004(0.0052) Grad: 8238.9404  LR: 0.00000127  \n","Epoch: [4][8100/9497] Elapsed 43m 54s (remain 7m 33s) Loss: 0.0000(0.0052) Grad: 2165.0845  LR: 0.00000124  \n","Epoch: [4][8200/9497] Elapsed 44m 26s (remain 7m 1s) Loss: 0.0351(0.0052) Grad: 333646.3750  LR: 0.00000122  \n","Epoch: [4][8300/9497] Elapsed 44m 59s (remain 6m 28s) Loss: 0.0000(0.0053) Grad: 821.2858  LR: 0.00000120  \n","Epoch: [4][8400/9497] Elapsed 45m 31s (remain 5m 56s) Loss: 0.0019(0.0053) Grad: 17640.8770  LR: 0.00000118  \n","Epoch: [4][8500/9497] Elapsed 46m 4s (remain 5m 23s) Loss: 0.0108(0.0052) Grad: 91266.5703  LR: 0.00000116  \n","Epoch: [4][8600/9497] Elapsed 46m 37s (remain 4m 51s) Loss: 0.0009(0.0052) Grad: 32748.2266  LR: 0.00000114  \n","Epoch: [4][8700/9497] Elapsed 47m 9s (remain 4m 18s) Loss: 0.0021(0.0052) Grad: 58518.2852  LR: 0.00000112  \n","Epoch: [4][8800/9497] Elapsed 47m 42s (remain 3m 46s) Loss: 0.0000(0.0052) Grad: 45.8535  LR: 0.00000109  \n","Epoch: [4][8900/9497] Elapsed 48m 14s (remain 3m 13s) Loss: 0.0131(0.0052) Grad: 137796.4531  LR: 0.00000107  \n","Epoch: [4][9000/9497] Elapsed 48m 47s (remain 2m 41s) Loss: 0.0039(0.0053) Grad: 58923.5508  LR: 0.00000105  \n","Epoch: [4][9100/9497] Elapsed 49m 20s (remain 2m 8s) Loss: 0.0001(0.0053) Grad: 8758.6455  LR: 0.00000103  \n","Epoch: [4][9200/9497] Elapsed 49m 52s (remain 1m 36s) Loss: 0.0000(0.0053) Grad: 2293.6057  LR: 0.00000101  \n","Epoch: [4][9300/9497] Elapsed 50m 25s (remain 1m 3s) Loss: 0.0012(0.0053) Grad: 48531.9688  LR: 0.00000099  \n","Epoch: [4][9400/9497] Elapsed 50m 57s (remain 0m 31s) Loss: 0.0006(0.0053) Grad: 22537.2695  LR: 0.00000097  \n","Epoch: [4][9496/9497] Elapsed 51m 29s (remain 0m 0s) Loss: 0.0067(0.0053) Grad: 46925.1250  LR: 0.00000096  \n","EVAL: [0/2375] Elapsed 0m 0s (remain 18m 45s) Loss: 0.0155(0.0155) \n","EVAL: [100/2375] Elapsed 0m 19s (remain 7m 24s) Loss: 0.1412(0.0166) \n","EVAL: [200/2375] Elapsed 0m 38s (remain 7m 1s) Loss: 0.0424(0.0175) \n","EVAL: [300/2375] Elapsed 0m 58s (remain 6m 41s) Loss: 0.0275(0.0195) \n","EVAL: [400/2375] Elapsed 1m 17s (remain 6m 21s) Loss: 0.0000(0.0193) \n","EVAL: [500/2375] Elapsed 1m 36s (remain 6m 2s) Loss: 0.0617(0.0178) \n","EVAL: [600/2375] Elapsed 1m 56s (remain 5m 43s) Loss: 0.0191(0.0174) \n","EVAL: [700/2375] Elapsed 2m 15s (remain 5m 23s) Loss: 0.0123(0.0177) \n","EVAL: [800/2375] Elapsed 2m 35s (remain 5m 4s) Loss: 0.0130(0.0184) \n","EVAL: [900/2375] Elapsed 2m 54s (remain 4m 45s) Loss: 0.0146(0.0167) \n","EVAL: [1000/2375] Elapsed 3m 13s (remain 4m 25s) Loss: 0.0138(0.0154) \n","EVAL: [1100/2375] Elapsed 3m 33s (remain 4m 6s) Loss: 0.0003(0.0142) \n","EVAL: [1200/2375] Elapsed 3m 52s (remain 3m 47s) Loss: 0.0008(0.0132) \n","EVAL: [1300/2375] Elapsed 4m 11s (remain 3m 27s) Loss: 0.0000(0.0124) \n","EVAL: [1400/2375] Elapsed 4m 31s (remain 3m 8s) Loss: 0.0091(0.0120) \n","EVAL: [1500/2375] Elapsed 4m 50s (remain 2m 49s) Loss: 0.0019(0.0118) \n","EVAL: [1600/2375] Elapsed 5m 9s (remain 2m 29s) Loss: 0.0106(0.0116) \n","EVAL: [1700/2375] Elapsed 5m 29s (remain 2m 10s) Loss: 0.0214(0.0115) \n","EVAL: [1800/2375] Elapsed 5m 48s (remain 1m 51s) Loss: 0.0000(0.0114) \n","EVAL: [1900/2375] Elapsed 6m 7s (remain 1m 31s) Loss: 0.0000(0.0108) \n","EVAL: [2000/2375] Elapsed 6m 27s (remain 1m 12s) Loss: 0.0000(0.0103) \n","EVAL: [2100/2375] Elapsed 6m 46s (remain 0m 53s) Loss: 0.0000(0.0099) \n","EVAL: [2200/2375] Elapsed 7m 5s (remain 0m 33s) Loss: 0.0057(0.0095) \n","EVAL: [2300/2375] Elapsed 7m 25s (remain 0m 14s) Loss: 0.0000(0.0091) \n","EVAL: [2374/2375] Elapsed 7m 39s (remain 0m 0s) Loss: 0.0000(0.0089) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0053  avg_val_loss: 0.0089  time: 3580s\n","Epoch 4 - Score: 0.9529\n","Epoch 4 - Save Best Score: 0.9529 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/1906] Elapsed 0m 0s (remain 30m 0s) Loss: 0.0074(0.0074) Grad: 41379.8828  LR: 0.00000096  \n","Epoch: [5][100/1906] Elapsed 0m 34s (remain 10m 24s) Loss: 0.0001(0.0108) Grad: 332.1108  LR: 0.00000094  \n","Epoch: [5][200/1906] Elapsed 1m 8s (remain 9m 39s) Loss: 0.0049(0.0100) Grad: 21520.1465  LR: 0.00000092  \n","Epoch: [5][300/1906] Elapsed 1m 41s (remain 9m 2s) Loss: 0.0000(0.0096) Grad: 70.0576  LR: 0.00000090  \n","Epoch: [5][400/1906] Elapsed 2m 15s (remain 8m 27s) Loss: 0.0261(0.0094) Grad: 24208.3906  LR: 0.00000088  \n","Epoch: [5][500/1906] Elapsed 2m 48s (remain 7m 52s) Loss: 0.0052(0.0093) Grad: 7935.6367  LR: 0.00000086  \n","Epoch: [5][600/1906] Elapsed 3m 22s (remain 7m 18s) Loss: 0.0019(0.0089) Grad: 16941.6230  LR: 0.00000084  \n","Epoch: [5][700/1906] Elapsed 3m 55s (remain 6m 44s) Loss: 0.0006(0.0085) Grad: 11239.1084  LR: 0.00000082  \n","Epoch: [5][800/1906] Elapsed 4m 28s (remain 6m 10s) Loss: 0.0028(0.0086) Grad: 14080.1826  LR: 0.00000081  \n","Epoch: [5][900/1906] Elapsed 5m 2s (remain 5m 37s) Loss: 0.0036(0.0088) Grad: 10493.4678  LR: 0.00000079  \n","Epoch: [5][1000/1906] Elapsed 5m 35s (remain 5m 3s) Loss: 0.0014(0.0087) Grad: 12668.5654  LR: 0.00000077  \n","Epoch: [5][1100/1906] Elapsed 6m 9s (remain 4m 29s) Loss: 0.0127(0.0085) Grad: 22590.5645  LR: 0.00000075  \n","Epoch: [5][1200/1906] Elapsed 6m 42s (remain 3m 56s) Loss: 0.0029(0.0085) Grad: 21952.7812  LR: 0.00000073  \n","Epoch: [5][1300/1906] Elapsed 7m 16s (remain 3m 22s) Loss: 0.0001(0.0085) Grad: 186.7163  LR: 0.00000072  \n","Epoch: [5][1400/1906] Elapsed 7m 49s (remain 2m 49s) Loss: 0.0004(0.0084) Grad: 3291.6401  LR: 0.00000070  \n","Epoch: [5][1500/1906] Elapsed 8m 22s (remain 2m 15s) Loss: 0.0055(0.0084) Grad: 74651.5781  LR: 0.00000068  \n","Epoch: [5][1600/1906] Elapsed 8m 56s (remain 1m 42s) Loss: 0.0003(0.0083) Grad: 2183.6807  LR: 0.00000067  \n","Epoch: [5][1700/1906] Elapsed 9m 29s (remain 1m 8s) Loss: 0.0057(0.0082) Grad: 54715.4609  LR: 0.00000065  \n","Epoch: [5][1800/1906] Elapsed 10m 3s (remain 0m 35s) Loss: 0.0070(0.0081) Grad: 53398.9883  LR: 0.00000063  \n","Epoch: [5][1900/1906] Elapsed 10m 36s (remain 0m 1s) Loss: 0.0029(0.0081) Grad: 14609.5215  LR: 0.00000062  \n","Epoch: [5][1905/1906] Elapsed 10m 38s (remain 0m 0s) Loss: 0.0100(0.0081) Grad: 39206.4453  LR: 0.00000062  \n","EVAL: [0/477] Elapsed 0m 0s (remain 4m 37s) Loss: 0.0105(0.0105) \n","EVAL: [100/477] Elapsed 0m 20s (remain 1m 17s) Loss: 0.0985(0.0117) \n","EVAL: [200/477] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0305(0.0125) \n","EVAL: [300/477] Elapsed 1m 1s (remain 0m 35s) Loss: 0.0159(0.0141) \n","EVAL: [400/477] Elapsed 1m 21s (remain 0m 15s) Loss: 0.0001(0.0139) \n","EVAL: [476/477] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0000(0.0125) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0081  avg_val_loss: 0.0125  time: 738s\n","Epoch 5 - Score: 0.9056\n","========== fold: 3 result ==========\n","Score: 0.9529\n","========== fold: 4 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/9541] Elapsed 0m 0s (remain 97m 48s) Loss: 0.6360(0.6360) Grad: inf  LR: 0.00001000  \n","Epoch: [1][100/9541] Elapsed 0m 32s (remain 51m 18s) Loss: 0.0432(0.1137) Grad: 3654.4280  LR: 0.00001000  \n","Epoch: [1][200/9541] Elapsed 1m 5s (remain 50m 45s) Loss: 0.0161(0.0772) Grad: 1985.5543  LR: 0.00001000  \n","Epoch: [1][300/9541] Elapsed 1m 38s (remain 50m 14s) Loss: 0.0761(0.0611) Grad: 11030.6670  LR: 0.00001000  \n","Epoch: [1][400/9541] Elapsed 2m 10s (remain 49m 38s) Loss: 0.0243(0.0518) Grad: 4298.8516  LR: 0.00001000  \n","Epoch: [1][500/9541] Elapsed 2m 43s (remain 49m 3s) Loss: 0.0134(0.0462) Grad: 5266.0000  LR: 0.00001000  \n","Epoch: [1][600/9541] Elapsed 3m 15s (remain 48m 29s) Loss: 0.0256(0.0418) Grad: 10158.5527  LR: 0.00001000  \n","Epoch: [1][700/9541] Elapsed 3m 48s (remain 47m 57s) Loss: 0.0268(0.0384) Grad: 7218.9424  LR: 0.00000999  \n","Epoch: [1][800/9541] Elapsed 4m 20s (remain 47m 24s) Loss: 0.0205(0.0356) Grad: 2752.0408  LR: 0.00000999  \n","Epoch: [1][900/9541] Elapsed 4m 53s (remain 46m 51s) Loss: 0.0028(0.0334) Grad: 1222.8604  LR: 0.00000999  \n","Epoch: [1][1000/9541] Elapsed 5m 25s (remain 46m 18s) Loss: 0.0133(0.0315) Grad: 2206.1602  LR: 0.00000999  \n","Epoch: [1][1100/9541] Elapsed 5m 58s (remain 45m 45s) Loss: 0.0201(0.0304) Grad: 2587.1912  LR: 0.00000999  \n","Epoch: [1][1200/9541] Elapsed 6m 30s (remain 45m 12s) Loss: 0.0153(0.0291) Grad: 2099.1794  LR: 0.00000998  \n","Epoch: [1][1300/9541] Elapsed 7m 3s (remain 44m 39s) Loss: 0.0290(0.0279) Grad: 5598.5957  LR: 0.00000998  \n","Epoch: [1][1400/9541] Elapsed 7m 35s (remain 44m 8s) Loss: 0.0219(0.0270) Grad: 5194.7334  LR: 0.00000998  \n","Epoch: [1][1500/9541] Elapsed 8m 8s (remain 43m 36s) Loss: 0.0124(0.0261) Grad: 1821.9467  LR: 0.00000998  \n","Epoch: [1][1600/9541] Elapsed 8m 41s (remain 43m 4s) Loss: 0.0046(0.0253) Grad: 659.5280  LR: 0.00000997  \n","Epoch: [1][1700/9541] Elapsed 9m 13s (remain 42m 32s) Loss: 0.0056(0.0246) Grad: 997.6764  LR: 0.00000997  \n","Epoch: [1][1800/9541] Elapsed 9m 46s (remain 41m 59s) Loss: 0.0044(0.0238) Grad: 861.9977  LR: 0.00000996  \n","Epoch: [1][1900/9541] Elapsed 10m 18s (remain 41m 27s) Loss: 0.0328(0.0232) Grad: 4469.0259  LR: 0.00000996  \n","Epoch: [1][2000/9541] Elapsed 10m 51s (remain 40m 54s) Loss: 0.0046(0.0226) Grad: 1726.9143  LR: 0.00000996  \n","Epoch: [1][2100/9541] Elapsed 11m 24s (remain 40m 22s) Loss: 0.0231(0.0220) Grad: 7814.1860  LR: 0.00000995  \n","Epoch: [1][2200/9541] Elapsed 11m 56s (remain 39m 50s) Loss: 0.0360(0.0215) Grad: 3579.2615  LR: 0.00000995  \n","Epoch: [1][2300/9541] Elapsed 12m 29s (remain 39m 17s) Loss: 0.0182(0.0211) Grad: 4188.0137  LR: 0.00000994  \n","Epoch: [1][2400/9541] Elapsed 13m 2s (remain 38m 45s) Loss: 0.0105(0.0207) Grad: 4137.8096  LR: 0.00000994  \n","Epoch: [1][2500/9541] Elapsed 13m 34s (remain 38m 12s) Loss: 0.0089(0.0203) Grad: 2915.7063  LR: 0.00000993  \n","Epoch: [1][2600/9541] Elapsed 14m 7s (remain 37m 40s) Loss: 0.0037(0.0199) Grad: 1419.2808  LR: 0.00000993  \n","Epoch: [1][2700/9541] Elapsed 14m 39s (remain 37m 7s) Loss: 0.0134(0.0195) Grad: 6406.9805  LR: 0.00000992  \n","Epoch: [1][2800/9541] Elapsed 15m 11s (remain 36m 34s) Loss: 0.0044(0.0192) Grad: 1824.1718  LR: 0.00000992  \n","Epoch: [1][2900/9541] Elapsed 15m 44s (remain 36m 1s) Loss: 0.0048(0.0190) Grad: 3391.8967  LR: 0.00000991  \n","Epoch: [1][3000/9541] Elapsed 16m 16s (remain 35m 28s) Loss: 0.0080(0.0187) Grad: 4665.9321  LR: 0.00000990  \n","Epoch: [1][3100/9541] Elapsed 16m 49s (remain 34m 56s) Loss: 0.0501(0.0184) Grad: 8795.3652  LR: 0.00000990  \n","Epoch: [1][3200/9541] Elapsed 17m 21s (remain 34m 23s) Loss: 0.0028(0.0181) Grad: 969.0632  LR: 0.00000989  \n","Epoch: [1][3300/9541] Elapsed 17m 54s (remain 33m 51s) Loss: 0.0169(0.0179) Grad: 4314.4248  LR: 0.00000988  \n","Epoch: [1][3400/9541] Elapsed 18m 27s (remain 33m 18s) Loss: 0.0433(0.0177) Grad: 13947.6270  LR: 0.00000988  \n","Epoch: [1][3500/9541] Elapsed 18m 59s (remain 32m 46s) Loss: 0.0062(0.0175) Grad: 1777.2048  LR: 0.00000987  \n","Epoch: [1][3600/9541] Elapsed 19m 32s (remain 32m 13s) Loss: 0.0032(0.0173) Grad: 876.4181  LR: 0.00000986  \n","Epoch: [1][3700/9541] Elapsed 20m 4s (remain 31m 41s) Loss: 0.0047(0.0172) Grad: 1349.5265  LR: 0.00000985  \n","Epoch: [1][3800/9541] Elapsed 20m 37s (remain 31m 8s) Loss: 0.0051(0.0170) Grad: 1767.7225  LR: 0.00000984  \n","Epoch: [1][3900/9541] Elapsed 21m 9s (remain 30m 35s) Loss: 0.0077(0.0168) Grad: 3594.7078  LR: 0.00000984  \n","Epoch: [1][4000/9541] Elapsed 21m 42s (remain 30m 3s) Loss: 0.0083(0.0166) Grad: 6767.2622  LR: 0.00000983  \n","Epoch: [1][4100/9541] Elapsed 22m 14s (remain 29m 30s) Loss: 0.0085(0.0165) Grad: 4607.5298  LR: 0.00000982  \n","Epoch: [1][4200/9541] Elapsed 22m 47s (remain 28m 58s) Loss: 0.0106(0.0163) Grad: 11378.0898  LR: 0.00000981  \n","Epoch: [1][4300/9541] Elapsed 23m 19s (remain 28m 25s) Loss: 0.0005(0.0161) Grad: 465.5869  LR: 0.00000980  \n","Epoch: [1][4400/9541] Elapsed 23m 52s (remain 27m 53s) Loss: 0.0031(0.0159) Grad: 2118.3157  LR: 0.00000979  \n","Epoch: [1][4500/9541] Elapsed 24m 24s (remain 27m 20s) Loss: 0.0035(0.0158) Grad: 2632.0005  LR: 0.00000978  \n","Epoch: [1][4600/9541] Elapsed 24m 57s (remain 26m 47s) Loss: 0.0052(0.0156) Grad: 2959.7917  LR: 0.00000977  \n","Epoch: [1][4700/9541] Elapsed 25m 29s (remain 26m 14s) Loss: 0.0047(0.0155) Grad: 3687.5693  LR: 0.00000976  \n","Epoch: [1][4800/9541] Elapsed 26m 2s (remain 25m 42s) Loss: 0.0102(0.0154) Grad: 11495.4893  LR: 0.00000975  \n","Epoch: [1][4900/9541] Elapsed 26m 34s (remain 25m 9s) Loss: 0.0022(0.0152) Grad: 3622.9707  LR: 0.00000974  \n","Epoch: [1][5000/9541] Elapsed 27m 6s (remain 24m 36s) Loss: 0.0129(0.0151) Grad: 4645.2183  LR: 0.00000973  \n","Epoch: [1][5100/9541] Elapsed 27m 39s (remain 24m 4s) Loss: 0.0077(0.0150) Grad: 5510.1895  LR: 0.00000972  \n","Epoch: [1][5200/9541] Elapsed 28m 11s (remain 23m 31s) Loss: 0.0158(0.0149) Grad: 18805.6016  LR: 0.00000971  \n","Epoch: [1][5300/9541] Elapsed 28m 44s (remain 22m 59s) Loss: 0.0099(0.0148) Grad: 14719.8330  LR: 0.00000970  \n","Epoch: [1][5400/9541] Elapsed 29m 16s (remain 22m 26s) Loss: 0.0040(0.0147) Grad: 3434.1274  LR: 0.00000969  \n","Epoch: [1][5500/9541] Elapsed 29m 49s (remain 21m 53s) Loss: 0.0016(0.0146) Grad: 1726.1837  LR: 0.00000968  \n","Epoch: [1][5600/9541] Elapsed 30m 21s (remain 21m 21s) Loss: 0.0001(0.0145) Grad: 137.4454  LR: 0.00000966  \n","Epoch: [1][5700/9541] Elapsed 30m 53s (remain 20m 48s) Loss: 0.0025(0.0144) Grad: 4749.3770  LR: 0.00000965  \n","Epoch: [1][5800/9541] Elapsed 31m 26s (remain 20m 16s) Loss: 0.0027(0.0143) Grad: 2572.9939  LR: 0.00000964  \n","Epoch: [1][5900/9541] Elapsed 31m 59s (remain 19m 43s) Loss: 0.0010(0.0142) Grad: 2011.8141  LR: 0.00000963  \n","Epoch: [1][6000/9541] Elapsed 32m 31s (remain 19m 11s) Loss: 0.0008(0.0141) Grad: 1877.8270  LR: 0.00000961  \n","Epoch: [1][6100/9541] Elapsed 33m 3s (remain 18m 38s) Loss: 0.0067(0.0140) Grad: 13634.1973  LR: 0.00000960  \n","Epoch: [1][6200/9541] Elapsed 33m 36s (remain 18m 6s) Loss: 0.0032(0.0140) Grad: 3969.4600  LR: 0.00000959  \n","Epoch: [1][6300/9541] Elapsed 34m 8s (remain 17m 33s) Loss: 0.0005(0.0139) Grad: 1385.1083  LR: 0.00000958  \n","Epoch: [1][6400/9541] Elapsed 34m 41s (remain 17m 1s) Loss: 0.0018(0.0138) Grad: 6843.6489  LR: 0.00000956  \n","Epoch: [1][6500/9541] Elapsed 35m 13s (remain 16m 28s) Loss: 0.0362(0.0137) Grad: 46389.3164  LR: 0.00000955  \n","Epoch: [1][6600/9541] Elapsed 35m 46s (remain 15m 55s) Loss: 0.0208(0.0136) Grad: 61855.4023  LR: 0.00000953  \n","Epoch: [1][6700/9541] Elapsed 36m 18s (remain 15m 23s) Loss: 0.0164(0.0135) Grad: 6105.4854  LR: 0.00000952  \n","Epoch: [1][6800/9541] Elapsed 36m 51s (remain 14m 50s) Loss: 0.0842(0.0135) Grad: 32482.7988  LR: 0.00000951  \n","Epoch: [1][6900/9541] Elapsed 37m 23s (remain 14m 18s) Loss: 0.0233(0.0134) Grad: 23838.0938  LR: 0.00000949  \n","Epoch: [1][7000/9541] Elapsed 37m 56s (remain 13m 45s) Loss: 0.0133(0.0134) Grad: 11848.7480  LR: 0.00000948  \n","Epoch: [1][7100/9541] Elapsed 38m 28s (remain 13m 13s) Loss: 0.0066(0.0133) Grad: 9847.3438  LR: 0.00000946  \n","Epoch: [1][7200/9541] Elapsed 39m 0s (remain 12m 40s) Loss: 0.0000(0.0133) Grad: 55.2123  LR: 0.00000945  \n","Epoch: [1][7300/9541] Elapsed 39m 33s (remain 12m 8s) Loss: 0.0078(0.0132) Grad: 8237.2686  LR: 0.00000943  \n","Epoch: [1][7400/9541] Elapsed 40m 5s (remain 11m 35s) Loss: 0.0030(0.0131) Grad: 10960.5615  LR: 0.00000942  \n","Epoch: [1][7500/9541] Elapsed 40m 38s (remain 11m 3s) Loss: 0.0008(0.0131) Grad: 1893.4181  LR: 0.00000940  \n","Epoch: [1][7600/9541] Elapsed 41m 10s (remain 10m 30s) Loss: 0.0054(0.0130) Grad: 47898.3281  LR: 0.00000939  \n","Epoch: [1][7700/9541] Elapsed 41m 43s (remain 9m 58s) Loss: 0.0043(0.0130) Grad: 3472.0325  LR: 0.00000937  \n","Epoch: [1][7800/9541] Elapsed 42m 15s (remain 9m 25s) Loss: 0.0033(0.0129) Grad: 4497.7866  LR: 0.00000935  \n","Epoch: [1][7900/9541] Elapsed 42m 48s (remain 8m 53s) Loss: 0.0024(0.0128) Grad: 5830.5376  LR: 0.00000934  \n","Epoch: [1][8000/9541] Elapsed 43m 20s (remain 8m 20s) Loss: 0.0016(0.0128) Grad: 9418.7939  LR: 0.00000932  \n","Epoch: [1][8100/9541] Elapsed 43m 53s (remain 7m 48s) Loss: 0.0045(0.0127) Grad: 12209.2354  LR: 0.00000931  \n","Epoch: [1][8200/9541] Elapsed 44m 26s (remain 7m 15s) Loss: 0.0013(0.0127) Grad: 7048.2725  LR: 0.00000929  \n","Epoch: [1][8300/9541] Elapsed 44m 58s (remain 6m 43s) Loss: 0.0012(0.0126) Grad: 4333.0806  LR: 0.00000927  \n","Epoch: [1][8400/9541] Elapsed 45m 30s (remain 6m 10s) Loss: 0.0012(0.0125) Grad: 3967.6260  LR: 0.00000925  \n","Epoch: [1][8500/9541] Elapsed 46m 3s (remain 5m 38s) Loss: 0.0039(0.0125) Grad: 14772.0654  LR: 0.00000924  \n","Epoch: [1][8600/9541] Elapsed 46m 35s (remain 5m 5s) Loss: 0.0265(0.0125) Grad: 37878.0352  LR: 0.00000922  \n","Epoch: [1][8700/9541] Elapsed 47m 8s (remain 4m 33s) Loss: 0.0094(0.0124) Grad: 23447.1641  LR: 0.00000920  \n","Epoch: [1][8800/9541] Elapsed 47m 40s (remain 4m 0s) Loss: 0.0343(0.0124) Grad: 97033.4141  LR: 0.00000918  \n","Epoch: [1][8900/9541] Elapsed 48m 13s (remain 3m 28s) Loss: 0.0002(0.0123) Grad: 2918.1641  LR: 0.00000917  \n","Epoch: [1][9000/9541] Elapsed 48m 45s (remain 2m 55s) Loss: 0.0024(0.0123) Grad: 26349.5586  LR: 0.00000915  \n","Epoch: [1][9100/9541] Elapsed 49m 18s (remain 2m 23s) Loss: 0.0036(0.0122) Grad: 24138.9648  LR: 0.00000913  \n","Epoch: [1][9200/9541] Elapsed 49m 50s (remain 1m 50s) Loss: 0.0057(0.0122) Grad: 15973.5166  LR: 0.00000911  \n","Epoch: [1][9300/9541] Elapsed 50m 22s (remain 1m 18s) Loss: 0.0065(0.0122) Grad: 31142.4824  LR: 0.00000909  \n","Epoch: [1][9400/9541] Elapsed 50m 55s (remain 0m 45s) Loss: 0.0127(0.0121) Grad: 14268.5176  LR: 0.00000907  \n","Epoch: [1][9500/9541] Elapsed 51m 28s (remain 0m 13s) Loss: 0.0112(0.0121) Grad: 25285.8594  LR: 0.00000905  \n","Epoch: [1][9540/9541] Elapsed 51m 41s (remain 0m 0s) Loss: 0.0012(0.0121) Grad: 7042.2231  LR: 0.00000905  \n","EVAL: [0/2386] Elapsed 0m 0s (remain 19m 20s) Loss: 0.0011(0.0011) \n","EVAL: [100/2386] Elapsed 0m 19s (remain 7m 26s) Loss: 0.0222(0.0120) \n","EVAL: [200/2386] Elapsed 0m 38s (remain 7m 3s) Loss: 0.0001(0.0130) \n","EVAL: [300/2386] Elapsed 0m 58s (remain 6m 43s) Loss: 0.0257(0.0152) \n","EVAL: [400/2386] Elapsed 1m 17s (remain 6m 23s) Loss: 0.0000(0.0148) \n","EVAL: [500/2386] Elapsed 1m 36s (remain 6m 4s) Loss: 0.0415(0.0141) \n","EVAL: [600/2386] Elapsed 1m 56s (remain 5m 45s) Loss: 0.0099(0.0143) \n","EVAL: [700/2386] Elapsed 2m 15s (remain 5m 25s) Loss: 0.0079(0.0153) \n","EVAL: [800/2386] Elapsed 2m 34s (remain 5m 6s) Loss: 0.0006(0.0161) \n","EVAL: [900/2386] Elapsed 2m 54s (remain 4m 47s) Loss: 0.0000(0.0147) \n","EVAL: [1000/2386] Elapsed 3m 13s (remain 4m 27s) Loss: 0.0067(0.0135) \n","EVAL: [1100/2386] Elapsed 3m 32s (remain 4m 8s) Loss: 0.0005(0.0126) \n","EVAL: [1200/2386] Elapsed 3m 52s (remain 3m 49s) Loss: 0.0001(0.0118) \n","EVAL: [1300/2386] Elapsed 4m 11s (remain 3m 29s) Loss: 0.0001(0.0112) \n","EVAL: [1400/2386] Elapsed 4m 31s (remain 3m 10s) Loss: 0.0039(0.0108) \n","EVAL: [1500/2386] Elapsed 4m 50s (remain 2m 51s) Loss: 0.0113(0.0106) \n","EVAL: [1600/2386] Elapsed 5m 9s (remain 2m 31s) Loss: 0.0241(0.0104) \n","EVAL: [1700/2386] Elapsed 5m 28s (remain 2m 12s) Loss: 0.0114(0.0103) \n","EVAL: [1800/2386] Elapsed 5m 48s (remain 1m 53s) Loss: 0.0003(0.0102) \n","EVAL: [1900/2386] Elapsed 6m 7s (remain 1m 33s) Loss: 0.0000(0.0097) \n","EVAL: [2000/2386] Elapsed 6m 26s (remain 1m 14s) Loss: 0.0000(0.0093) \n","EVAL: [2100/2386] Elapsed 6m 46s (remain 0m 55s) Loss: 0.0000(0.0090) \n","EVAL: [2200/2386] Elapsed 7m 5s (remain 0m 35s) Loss: 0.0000(0.0086) \n","EVAL: [2300/2386] Elapsed 7m 24s (remain 0m 16s) Loss: 0.0004(0.0083) \n","EVAL: [2385/2386] Elapsed 7m 41s (remain 0m 0s) Loss: 0.0000(0.0081) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0121  avg_val_loss: 0.0081  time: 3575s\n","Epoch 1 - Score: 0.9433\n","Epoch 1 - Save Best Score: 0.9433 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/9541] Elapsed 0m 0s (remain 137m 7s) Loss: 0.0006(0.0006) Grad: 7239.3369  LR: 0.00000904  \n","Epoch: [2][100/9541] Elapsed 0m 33s (remain 52m 38s) Loss: 0.0027(0.0074) Grad: 55272.2461  LR: 0.00000903  \n","Epoch: [2][200/9541] Elapsed 1m 6s (remain 51m 18s) Loss: 0.0220(0.0071) Grad: 37707.7031  LR: 0.00000901  \n","Epoch: [2][300/9541] Elapsed 1m 38s (remain 50m 33s) Loss: 0.0101(0.0069) Grad: 8776.3672  LR: 0.00000899  \n","Epoch: [2][400/9541] Elapsed 2m 11s (remain 49m 50s) Loss: 0.0042(0.0069) Grad: 18626.5488  LR: 0.00000897  \n","Epoch: [2][500/9541] Elapsed 2m 43s (remain 49m 12s) Loss: 0.0096(0.0071) Grad: 45694.9609  LR: 0.00000895  \n","Epoch: [2][600/9541] Elapsed 3m 16s (remain 48m 36s) Loss: 0.0009(0.0071) Grad: 5071.2778  LR: 0.00000893  \n","Epoch: [2][700/9541] Elapsed 3m 48s (remain 48m 1s) Loss: 0.0305(0.0070) Grad: 30595.6387  LR: 0.00000891  \n","Epoch: [2][800/9541] Elapsed 4m 20s (remain 47m 27s) Loss: 0.0065(0.0069) Grad: 15133.4170  LR: 0.00000888  \n","Epoch: [2][900/9541] Elapsed 4m 53s (remain 46m 53s) Loss: 0.0000(0.0067) Grad: 176.6653  LR: 0.00000886  \n","Epoch: [2][1000/9541] Elapsed 5m 25s (remain 46m 21s) Loss: 0.0157(0.0068) Grad: 26575.1641  LR: 0.00000884  \n","Epoch: [2][1100/9541] Elapsed 5m 58s (remain 45m 47s) Loss: 0.0006(0.0067) Grad: 29614.1992  LR: 0.00000882  \n","Epoch: [2][1200/9541] Elapsed 6m 30s (remain 45m 14s) Loss: 0.0037(0.0068) Grad: 15731.7725  LR: 0.00000880  \n","Epoch: [2][1300/9541] Elapsed 7m 3s (remain 44m 40s) Loss: 0.0006(0.0069) Grad: 2161.2405  LR: 0.00000878  \n","Epoch: [2][1400/9541] Elapsed 7m 35s (remain 44m 7s) Loss: 0.0001(0.0068) Grad: 4384.9741  LR: 0.00000876  \n","Epoch: [2][1500/9541] Elapsed 8m 7s (remain 43m 33s) Loss: 0.0024(0.0067) Grad: 9375.8945  LR: 0.00000874  \n","Epoch: [2][1600/9541] Elapsed 8m 40s (remain 43m 1s) Loss: 0.0010(0.0067) Grad: 6836.2290  LR: 0.00000871  \n","Epoch: [2][1700/9541] Elapsed 9m 12s (remain 42m 28s) Loss: 0.0010(0.0067) Grad: 8866.9541  LR: 0.00000869  \n","Epoch: [2][1800/9541] Elapsed 9m 45s (remain 41m 55s) Loss: 0.0011(0.0066) Grad: 24432.9199  LR: 0.00000867  \n","Epoch: [2][1900/9541] Elapsed 10m 17s (remain 41m 22s) Loss: 0.0067(0.0068) Grad: 22826.2031  LR: 0.00000865  \n","Epoch: [2][2000/9541] Elapsed 10m 50s (remain 40m 50s) Loss: 0.0014(0.0068) Grad: 4093.4795  LR: 0.00000862  \n","Epoch: [2][2100/9541] Elapsed 11m 22s (remain 40m 17s) Loss: 0.0015(0.0069) Grad: 5130.3823  LR: 0.00000860  \n","Epoch: [2][2200/9541] Elapsed 11m 54s (remain 39m 44s) Loss: 0.0067(0.0069) Grad: 10943.5381  LR: 0.00000858  \n","Epoch: [2][2300/9541] Elapsed 12m 27s (remain 39m 11s) Loss: 0.0024(0.0069) Grad: 6314.2778  LR: 0.00000856  \n","Epoch: [2][2400/9541] Elapsed 13m 0s (remain 38m 39s) Loss: 0.0048(0.0069) Grad: 7547.8320  LR: 0.00000853  \n","Epoch: [2][2500/9541] Elapsed 13m 32s (remain 38m 7s) Loss: 0.0035(0.0068) Grad: 5800.6484  LR: 0.00000851  \n","Epoch: [2][2600/9541] Elapsed 14m 4s (remain 37m 34s) Loss: 0.0125(0.0069) Grad: 40964.4883  LR: 0.00000848  \n","Epoch: [2][2700/9541] Elapsed 14m 37s (remain 37m 2s) Loss: 0.0113(0.0069) Grad: 17942.2695  LR: 0.00000846  \n","Epoch: [2][2800/9541] Elapsed 15m 10s (remain 36m 30s) Loss: 0.0028(0.0069) Grad: 11236.6357  LR: 0.00000844  \n","Epoch: [2][2900/9541] Elapsed 15m 42s (remain 35m 57s) Loss: 0.0129(0.0070) Grad: 15989.3682  LR: 0.00000841  \n","Epoch: [2][3000/9541] Elapsed 16m 15s (remain 35m 24s) Loss: 0.0001(0.0069) Grad: 877.3895  LR: 0.00000839  \n","Epoch: [2][3100/9541] Elapsed 16m 47s (remain 34m 52s) Loss: 0.0037(0.0069) Grad: 8110.8223  LR: 0.00000837  \n","Epoch: [2][3200/9541] Elapsed 17m 20s (remain 34m 19s) Loss: 0.0016(0.0069) Grad: 4034.3362  LR: 0.00000834  \n","Epoch: [2][3300/9541] Elapsed 17m 52s (remain 33m 47s) Loss: 0.0001(0.0069) Grad: 233.9763  LR: 0.00000832  \n","Epoch: [2][3400/9541] Elapsed 18m 24s (remain 33m 14s) Loss: 0.0122(0.0070) Grad: 59037.9375  LR: 0.00000829  \n","Epoch: [2][3500/9541] Elapsed 18m 57s (remain 32m 42s) Loss: 0.0069(0.0070) Grad: 20904.4766  LR: 0.00000827  \n","Epoch: [2][3600/9541] Elapsed 19m 30s (remain 32m 10s) Loss: 0.0002(0.0070) Grad: 494.2678  LR: 0.00000824  \n","Epoch: [2][3700/9541] Elapsed 20m 2s (remain 31m 37s) Loss: 0.0038(0.0069) Grad: 8259.2520  LR: 0.00000822  \n","Epoch: [2][3800/9541] Elapsed 20m 35s (remain 31m 5s) Loss: 0.0059(0.0070) Grad: 12275.3350  LR: 0.00000819  \n","Epoch: [2][3900/9541] Elapsed 21m 7s (remain 30m 32s) Loss: 0.0041(0.0070) Grad: 8022.8179  LR: 0.00000817  \n","Epoch: [2][4000/9541] Elapsed 21m 39s (remain 30m 0s) Loss: 0.0006(0.0070) Grad: 1780.8190  LR: 0.00000814  \n","Epoch: [2][4100/9541] Elapsed 22m 12s (remain 29m 27s) Loss: 0.0486(0.0070) Grad: 30339.1133  LR: 0.00000811  \n","Epoch: [2][4200/9541] Elapsed 22m 44s (remain 28m 54s) Loss: 0.0200(0.0070) Grad: 10117.8682  LR: 0.00000809  \n","Epoch: [2][4300/9541] Elapsed 23m 17s (remain 28m 22s) Loss: 0.0121(0.0070) Grad: 41410.0820  LR: 0.00000806  \n","Epoch: [2][4400/9541] Elapsed 23m 49s (remain 27m 49s) Loss: 0.0055(0.0070) Grad: 37068.7148  LR: 0.00000804  \n","Epoch: [2][4500/9541] Elapsed 24m 22s (remain 27m 17s) Loss: 0.0011(0.0071) Grad: 2195.4880  LR: 0.00000801  \n","Epoch: [2][4600/9541] Elapsed 24m 54s (remain 26m 44s) Loss: 0.0000(0.0071) Grad: 29.2061  LR: 0.00000798  \n","Epoch: [2][4700/9541] Elapsed 25m 27s (remain 26m 12s) Loss: 0.0010(0.0070) Grad: 2823.7891  LR: 0.00000796  \n","Epoch: [2][4800/9541] Elapsed 25m 59s (remain 25m 40s) Loss: 0.0097(0.0071) Grad: 9511.6064  LR: 0.00000793  \n","Epoch: [2][4900/9541] Elapsed 26m 32s (remain 25m 7s) Loss: 0.0070(0.0071) Grad: 16786.7793  LR: 0.00000790  \n","Epoch: [2][5000/9541] Elapsed 27m 4s (remain 24m 35s) Loss: 0.0003(0.0071) Grad: 1298.5764  LR: 0.00000788  \n","Epoch: [2][5100/9541] Elapsed 27m 37s (remain 24m 2s) Loss: 0.0110(0.0070) Grad: 20173.1719  LR: 0.00000785  \n","Epoch: [2][5200/9541] Elapsed 28m 9s (remain 23m 30s) Loss: 0.0035(0.0071) Grad: 6086.2466  LR: 0.00000782  \n","Epoch: [2][5300/9541] Elapsed 28m 42s (remain 22m 57s) Loss: 0.0049(0.0071) Grad: 8614.7002  LR: 0.00000780  \n","Epoch: [2][5400/9541] Elapsed 29m 15s (remain 22m 25s) Loss: 0.0003(0.0071) Grad: 1325.3383  LR: 0.00000777  \n","Epoch: [2][5500/9541] Elapsed 29m 48s (remain 21m 53s) Loss: 0.0128(0.0071) Grad: 12190.3223  LR: 0.00000774  \n","Epoch: [2][5600/9541] Elapsed 30m 20s (remain 21m 20s) Loss: 0.0001(0.0071) Grad: 303.2025  LR: 0.00000771  \n","Epoch: [2][5700/9541] Elapsed 30m 53s (remain 20m 48s) Loss: 0.0040(0.0071) Grad: 3478.8840  LR: 0.00000769  \n","Epoch: [2][5800/9541] Elapsed 31m 25s (remain 20m 15s) Loss: 0.0159(0.0071) Grad: 14080.4121  LR: 0.00000766  \n","Epoch: [2][5900/9541] Elapsed 31m 58s (remain 19m 43s) Loss: 0.0002(0.0071) Grad: 591.7693  LR: 0.00000763  \n","Epoch: [2][6000/9541] Elapsed 32m 30s (remain 19m 10s) Loss: 0.0033(0.0071) Grad: 19387.0723  LR: 0.00000760  \n","Epoch: [2][6100/9541] Elapsed 33m 3s (remain 18m 38s) Loss: 0.0042(0.0071) Grad: 18694.8750  LR: 0.00000757  \n","Epoch: [2][6200/9541] Elapsed 33m 36s (remain 18m 5s) Loss: 0.0105(0.0071) Grad: 21275.9492  LR: 0.00000755  \n","Epoch: [2][6300/9541] Elapsed 34m 8s (remain 17m 33s) Loss: 0.0212(0.0071) Grad: 69543.0703  LR: 0.00000752  \n","Epoch: [2][6400/9541] Elapsed 34m 41s (remain 17m 1s) Loss: 0.0065(0.0071) Grad: 51899.2578  LR: 0.00000749  \n","Epoch: [2][6500/9541] Elapsed 35m 14s (remain 16m 28s) Loss: 0.0036(0.0071) Grad: 14102.2627  LR: 0.00000746  \n","Epoch: [2][6600/9541] Elapsed 35m 46s (remain 15m 56s) Loss: 0.0008(0.0071) Grad: 6895.6528  LR: 0.00000743  \n","Epoch: [2][6700/9541] Elapsed 36m 19s (remain 15m 23s) Loss: 0.0010(0.0071) Grad: 9562.5352  LR: 0.00000740  \n","Epoch: [2][6800/9541] Elapsed 36m 52s (remain 14m 51s) Loss: 0.0003(0.0071) Grad: 3003.1902  LR: 0.00000737  \n","Epoch: [2][6900/9541] Elapsed 37m 24s (remain 14m 18s) Loss: 0.0083(0.0071) Grad: 44907.9883  LR: 0.00000734  \n","Epoch: [2][7000/9541] Elapsed 37m 57s (remain 13m 46s) Loss: 0.0001(0.0071) Grad: 259.3426  LR: 0.00000732  \n","Epoch: [2][7100/9541] Elapsed 38m 30s (remain 13m 13s) Loss: 0.0162(0.0071) Grad: 66268.1562  LR: 0.00000729  \n","Epoch: [2][7200/9541] Elapsed 39m 2s (remain 12m 41s) Loss: 0.0033(0.0071) Grad: 9245.0264  LR: 0.00000726  \n","Epoch: [2][7300/9541] Elapsed 39m 35s (remain 12m 8s) Loss: 0.0046(0.0071) Grad: 16330.5410  LR: 0.00000723  \n","Epoch: [2][7400/9541] Elapsed 40m 8s (remain 11m 36s) Loss: 0.0132(0.0070) Grad: 15465.2070  LR: 0.00000720  \n","Epoch: [2][7500/9541] Elapsed 40m 40s (remain 11m 3s) Loss: 0.0116(0.0070) Grad: 30164.1074  LR: 0.00000717  \n","Epoch: [2][7600/9541] Elapsed 41m 13s (remain 10m 31s) Loss: 0.0064(0.0070) Grad: 14855.3057  LR: 0.00000714  \n","Epoch: [2][7700/9541] Elapsed 41m 45s (remain 9m 58s) Loss: 0.0162(0.0070) Grad: 21337.6758  LR: 0.00000711  \n","Epoch: [2][7800/9541] Elapsed 42m 18s (remain 9m 26s) Loss: 0.0032(0.0070) Grad: 24707.4609  LR: 0.00000708  \n","Epoch: [2][7900/9541] Elapsed 42m 51s (remain 8m 53s) Loss: 0.0126(0.0070) Grad: 95610.5234  LR: 0.00000705  \n","Epoch: [2][8000/9541] Elapsed 43m 23s (remain 8m 21s) Loss: 0.0047(0.0070) Grad: 39617.6367  LR: 0.00000702  \n","Epoch: [2][8100/9541] Elapsed 43m 56s (remain 7m 48s) Loss: 0.0051(0.0070) Grad: 50547.0195  LR: 0.00000699  \n","Epoch: [2][8200/9541] Elapsed 44m 29s (remain 7m 16s) Loss: 0.0111(0.0070) Grad: 109515.5547  LR: 0.00000696  \n","Epoch: [2][8300/9541] Elapsed 45m 1s (remain 6m 43s) Loss: 0.0087(0.0070) Grad: 62512.4375  LR: 0.00000693  \n","Epoch: [2][8400/9541] Elapsed 45m 34s (remain 6m 11s) Loss: 0.0004(0.0070) Grad: 22733.4512  LR: 0.00000690  \n","Epoch: [2][8500/9541] Elapsed 46m 6s (remain 5m 38s) Loss: 0.0219(0.0069) Grad: 392781.4062  LR: 0.00000687  \n","Epoch: [2][8600/9541] Elapsed 46m 39s (remain 5m 5s) Loss: 0.0028(0.0070) Grad: 21801.7051  LR: 0.00000684  \n","Epoch: [2][8700/9541] Elapsed 47m 11s (remain 4m 33s) Loss: 0.0062(0.0069) Grad: 34709.6055  LR: 0.00000681  \n","Epoch: [2][8800/9541] Elapsed 47m 44s (remain 4m 0s) Loss: 0.0331(0.0069) Grad: 160306.6094  LR: 0.00000677  \n","Epoch: [2][8900/9541] Elapsed 48m 16s (remain 3m 28s) Loss: 0.0006(0.0069) Grad: 17047.0352  LR: 0.00000674  \n","Epoch: [2][9000/9541] Elapsed 48m 49s (remain 2m 55s) Loss: 0.0026(0.0069) Grad: 25780.2422  LR: 0.00000671  \n","Epoch: [2][9100/9541] Elapsed 49m 22s (remain 2m 23s) Loss: 0.0081(0.0069) Grad: 53904.3398  LR: 0.00000668  \n","Epoch: [2][9200/9541] Elapsed 49m 54s (remain 1m 50s) Loss: 0.0220(0.0069) Grad: 157591.5000  LR: 0.00000665  \n","Epoch: [2][9300/9541] Elapsed 50m 27s (remain 1m 18s) Loss: 0.0070(0.0069) Grad: 51678.0078  LR: 0.00000662  \n","Epoch: [2][9400/9541] Elapsed 51m 0s (remain 0m 45s) Loss: 0.0000(0.0069) Grad: 37.3854  LR: 0.00000659  \n","Epoch: [2][9500/9541] Elapsed 51m 32s (remain 0m 13s) Loss: 0.0104(0.0069) Grad: 67096.8281  LR: 0.00000656  \n","Epoch: [2][9540/9541] Elapsed 51m 45s (remain 0m 0s) Loss: 0.0000(0.0069) Grad: 87.3965  LR: 0.00000655  \n","EVAL: [0/2386] Elapsed 0m 0s (remain 18m 42s) Loss: 0.0004(0.0004) \n","EVAL: [100/2386] Elapsed 0m 19s (remain 7m 26s) Loss: 0.0237(0.0136) \n","EVAL: [200/2386] Elapsed 0m 39s (remain 7m 4s) Loss: 0.0000(0.0148) \n","EVAL: [300/2386] Elapsed 0m 58s (remain 6m 43s) Loss: 0.0319(0.0175) \n","EVAL: [400/2386] Elapsed 1m 17s (remain 6m 24s) Loss: 0.0001(0.0171) \n","EVAL: [500/2386] Elapsed 1m 36s (remain 6m 4s) Loss: 0.0416(0.0161) \n","EVAL: [600/2386] Elapsed 1m 56s (remain 5m 45s) Loss: 0.0152(0.0161) \n","EVAL: [700/2386] Elapsed 2m 15s (remain 5m 26s) Loss: 0.0136(0.0164) \n","EVAL: [800/2386] Elapsed 2m 35s (remain 5m 6s) Loss: 0.0049(0.0174) \n","EVAL: [900/2386] Elapsed 2m 54s (remain 4m 47s) Loss: 0.0000(0.0159) \n","EVAL: [1000/2386] Elapsed 3m 13s (remain 4m 28s) Loss: 0.0079(0.0146) \n","EVAL: [1100/2386] Elapsed 3m 33s (remain 4m 8s) Loss: 0.0001(0.0136) \n","EVAL: [1200/2386] Elapsed 3m 52s (remain 3m 49s) Loss: 0.0000(0.0127) \n","EVAL: [1300/2386] Elapsed 4m 11s (remain 3m 30s) Loss: 0.0028(0.0120) \n","EVAL: [1400/2386] Elapsed 4m 31s (remain 3m 10s) Loss: 0.0033(0.0115) \n","EVAL: [1500/2386] Elapsed 4m 50s (remain 2m 51s) Loss: 0.0093(0.0113) \n","EVAL: [1600/2386] Elapsed 5m 10s (remain 2m 32s) Loss: 0.0239(0.0110) \n","EVAL: [1700/2386] Elapsed 5m 29s (remain 2m 12s) Loss: 0.0128(0.0109) \n","EVAL: [1800/2386] Elapsed 5m 48s (remain 1m 53s) Loss: 0.0064(0.0107) \n","EVAL: [1900/2386] Elapsed 6m 8s (remain 1m 33s) Loss: 0.0000(0.0102) \n","EVAL: [2000/2386] Elapsed 6m 27s (remain 1m 14s) Loss: 0.0000(0.0097) \n","EVAL: [2100/2386] Elapsed 6m 46s (remain 0m 55s) Loss: 0.0000(0.0094) \n","EVAL: [2200/2386] Elapsed 7m 6s (remain 0m 35s) Loss: 0.0000(0.0090) \n","EVAL: [2300/2386] Elapsed 7m 25s (remain 0m 16s) Loss: 0.0039(0.0087) \n","EVAL: [2385/2386] Elapsed 7m 41s (remain 0m 0s) Loss: 0.0000(0.0084) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.0069  avg_val_loss: 0.0084  time: 3599s\n","Epoch 2 - Score: 0.9486\n","Epoch 2 - Save Best Score: 0.9486 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/9541] Elapsed 0m 0s (remain 149m 13s) Loss: 0.0010(0.0010) Grad: 12987.0693  LR: 0.00000654  \n","Epoch: [3][100/9541] Elapsed 0m 35s (remain 54m 40s) Loss: 0.0001(0.0044) Grad: 597.6246  LR: 0.00000651  \n","Epoch: [3][200/9541] Elapsed 1m 9s (remain 53m 29s) Loss: 0.0000(0.0050) Grad: 30.5726  LR: 0.00000648  \n","Epoch: [3][300/9541] Elapsed 1m 42s (remain 52m 37s) Loss: 0.0056(0.0049) Grad: 15725.4414  LR: 0.00000645  \n","Epoch: [3][400/9541] Elapsed 2m 16s (remain 51m 55s) Loss: 0.0068(0.0050) Grad: 51739.4727  LR: 0.00000642  \n","Epoch: [3][500/9541] Elapsed 2m 50s (remain 51m 17s) Loss: 0.0024(0.0051) Grad: 29844.3301  LR: 0.00000639  \n","Epoch: [3][600/9541] Elapsed 3m 24s (remain 50m 41s) Loss: 0.0001(0.0050) Grad: 845.7736  LR: 0.00000636  \n","Epoch: [3][700/9541] Elapsed 3m 58s (remain 50m 5s) Loss: 0.0000(0.0052) Grad: 53.7279  LR: 0.00000632  \n","Epoch: [3][800/9541] Elapsed 4m 32s (remain 49m 30s) Loss: 0.0038(0.0052) Grad: 21172.8008  LR: 0.00000629  \n","Epoch: [3][900/9541] Elapsed 5m 6s (remain 48m 56s) Loss: 0.0028(0.0053) Grad: 27257.2617  LR: 0.00000626  \n","Epoch: [3][1000/9541] Elapsed 5m 40s (remain 48m 22s) Loss: 0.0042(0.0054) Grad: 22604.3008  LR: 0.00000623  \n","Epoch: [3][1100/9541] Elapsed 6m 14s (remain 47m 49s) Loss: 0.0222(0.0056) Grad: 59586.5391  LR: 0.00000620  \n","Epoch: [3][1200/9541] Elapsed 6m 48s (remain 47m 15s) Loss: 0.0019(0.0055) Grad: 18278.3242  LR: 0.00000616  \n","Epoch: [3][1300/9541] Elapsed 7m 22s (remain 46m 41s) Loss: 0.0158(0.0055) Grad: 111254.1328  LR: 0.00000613  \n","Epoch: [3][1400/9541] Elapsed 7m 56s (remain 46m 7s) Loss: 0.0005(0.0054) Grad: 3177.9285  LR: 0.00000610  \n","Epoch: [3][1500/9541] Elapsed 8m 30s (remain 45m 34s) Loss: 0.0010(0.0055) Grad: 11427.8330  LR: 0.00000607  \n","Epoch: [3][1600/9541] Elapsed 9m 4s (remain 45m 0s) Loss: 0.0025(0.0056) Grad: 36915.8516  LR: 0.00000604  \n","Epoch: [3][1700/9541] Elapsed 9m 38s (remain 44m 26s) Loss: 0.0002(0.0055) Grad: 7798.3379  LR: 0.00000600  \n","Epoch: [3][1800/9541] Elapsed 10m 12s (remain 43m 52s) Loss: 0.0010(0.0056) Grad: 15604.3203  LR: 0.00000597  \n","Epoch: [3][1900/9541] Elapsed 10m 46s (remain 43m 18s) Loss: 0.0153(0.0056) Grad: 41509.9727  LR: 0.00000594  \n","Epoch: [3][2000/9541] Elapsed 11m 20s (remain 42m 44s) Loss: 0.0105(0.0056) Grad: 65304.3438  LR: 0.00000591  \n","Epoch: [3][2100/9541] Elapsed 11m 54s (remain 42m 10s) Loss: 0.0114(0.0056) Grad: 56449.7305  LR: 0.00000587  \n","Epoch: [3][2200/9541] Elapsed 12m 28s (remain 41m 36s) Loss: 0.0013(0.0056) Grad: 9120.7783  LR: 0.00000584  \n","Epoch: [3][2300/9541] Elapsed 13m 2s (remain 41m 2s) Loss: 0.0108(0.0056) Grad: 35572.0664  LR: 0.00000581  \n","Epoch: [3][2400/9541] Elapsed 13m 36s (remain 40m 28s) Loss: 0.0009(0.0056) Grad: 8798.0225  LR: 0.00000578  \n","Epoch: [3][2500/9541] Elapsed 14m 10s (remain 39m 54s) Loss: 0.0084(0.0056) Grad: 4916.2476  LR: 0.00000574  \n","Epoch: [3][2600/9541] Elapsed 14m 44s (remain 39m 20s) Loss: 0.0012(0.0057) Grad: 5205.6963  LR: 0.00000571  \n","Epoch: [3][2700/9541] Elapsed 15m 18s (remain 38m 46s) Loss: 0.0013(0.0057) Grad: 10516.5977  LR: 0.00000568  \n","Epoch: [3][2800/9541] Elapsed 15m 52s (remain 38m 12s) Loss: 0.0026(0.0057) Grad: 18733.7246  LR: 0.00000565  \n","Epoch: [3][2900/9541] Elapsed 16m 26s (remain 37m 37s) Loss: 0.0000(0.0057) Grad: 88.8313  LR: 0.00000561  \n","Epoch: [3][3000/9541] Elapsed 17m 0s (remain 37m 3s) Loss: 0.0079(0.0057) Grad: 47094.2109  LR: 0.00000558  \n","Epoch: [3][3100/9541] Elapsed 17m 34s (remain 36m 29s) Loss: 0.0001(0.0057) Grad: 2715.1184  LR: 0.00000555  \n","Epoch: [3][3200/9541] Elapsed 18m 8s (remain 35m 55s) Loss: 0.0004(0.0057) Grad: 7475.2158  LR: 0.00000552  \n","Epoch: [3][3300/9541] Elapsed 18m 41s (remain 35m 20s) Loss: 0.0030(0.0057) Grad: 21181.7383  LR: 0.00000548  \n","Epoch: [3][3400/9541] Elapsed 19m 15s (remain 34m 46s) Loss: 0.0073(0.0057) Grad: 208830.5312  LR: 0.00000545  \n","Epoch: [3][3500/9541] Elapsed 19m 49s (remain 34m 12s) Loss: 0.0039(0.0057) Grad: 39736.6484  LR: 0.00000542  \n","Epoch: [3][3600/9541] Elapsed 20m 23s (remain 33m 38s) Loss: 0.0104(0.0057) Grad: 32917.4609  LR: 0.00000538  \n","Epoch: [3][3700/9541] Elapsed 20m 57s (remain 33m 4s) Loss: 0.0016(0.0057) Grad: 18846.0840  LR: 0.00000535  \n","Epoch: [3][3800/9541] Elapsed 21m 31s (remain 32m 30s) Loss: 0.0003(0.0057) Grad: 4955.5249  LR: 0.00000532  \n","Epoch: [3][3900/9541] Elapsed 22m 5s (remain 31m 56s) Loss: 0.0009(0.0057) Grad: 8083.9380  LR: 0.00000529  \n","Epoch: [3][4000/9541] Elapsed 22m 39s (remain 31m 22s) Loss: 0.0089(0.0057) Grad: 26410.5938  LR: 0.00000525  \n","Epoch: [3][4100/9541] Elapsed 23m 13s (remain 30m 48s) Loss: 0.0000(0.0057) Grad: 77.5843  LR: 0.00000522  \n","Epoch: [3][4200/9541] Elapsed 23m 47s (remain 30m 13s) Loss: 0.0019(0.0057) Grad: 44264.0039  LR: 0.00000519  \n","Epoch: [3][4300/9541] Elapsed 24m 21s (remain 29m 39s) Loss: 0.0094(0.0057) Grad: 102539.9297  LR: 0.00000515  \n","Epoch: [3][4400/9541] Elapsed 24m 54s (remain 29m 6s) Loss: 0.0040(0.0057) Grad: 43288.3867  LR: 0.00000512  \n","Epoch: [3][4500/9541] Elapsed 25m 28s (remain 28m 32s) Loss: 0.0021(0.0057) Grad: 30087.6816  LR: 0.00000509  \n","Epoch: [3][4600/9541] Elapsed 26m 2s (remain 27m 57s) Loss: 0.0002(0.0057) Grad: 6929.7881  LR: 0.00000506  \n","Epoch: [3][4700/9541] Elapsed 26m 36s (remain 27m 23s) Loss: 0.0207(0.0057) Grad: 54767.9805  LR: 0.00000502  \n","Epoch: [3][4800/9541] Elapsed 27m 10s (remain 26m 49s) Loss: 0.0029(0.0057) Grad: 40004.7188  LR: 0.00000499  \n","Epoch: [3][4900/9541] Elapsed 27m 44s (remain 26m 15s) Loss: 0.0442(0.0057) Grad: 273961.3125  LR: 0.00000496  \n","Epoch: [3][5000/9541] Elapsed 28m 18s (remain 25m 42s) Loss: 0.0008(0.0057) Grad: 44930.8398  LR: 0.00000492  \n","Epoch: [3][5100/9541] Elapsed 28m 52s (remain 25m 8s) Loss: 0.0129(0.0056) Grad: 171621.0938  LR: 0.00000489  \n","Epoch: [3][5200/9541] Elapsed 29m 26s (remain 24m 34s) Loss: 0.0227(0.0056) Grad: 106022.9141  LR: 0.00000486  \n","Epoch: [3][5300/9541] Elapsed 30m 0s (remain 23m 59s) Loss: 0.0035(0.0056) Grad: 55648.3164  LR: 0.00000483  \n","Epoch: [3][5400/9541] Elapsed 30m 34s (remain 23m 26s) Loss: 0.0087(0.0056) Grad: 68781.8359  LR: 0.00000479  \n","Epoch: [3][5500/9541] Elapsed 31m 8s (remain 22m 52s) Loss: 0.0006(0.0056) Grad: 11616.6807  LR: 0.00000476  \n","Epoch: [3][5600/9541] Elapsed 31m 42s (remain 22m 18s) Loss: 0.0002(0.0056) Grad: 4341.8857  LR: 0.00000473  \n","Epoch: [3][5700/9541] Elapsed 32m 16s (remain 21m 44s) Loss: 0.0026(0.0056) Grad: 31441.7656  LR: 0.00000469  \n","Epoch: [3][5800/9541] Elapsed 32m 50s (remain 21m 10s) Loss: 0.0000(0.0056) Grad: 300.7881  LR: 0.00000466  \n","Epoch: [3][5900/9541] Elapsed 33m 24s (remain 20m 36s) Loss: 0.0000(0.0056) Grad: 36.7538  LR: 0.00000463  \n","Epoch: [3][6000/9541] Elapsed 33m 57s (remain 20m 2s) Loss: 0.0069(0.0056) Grad: 54878.8320  LR: 0.00000460  \n","Epoch: [3][6100/9541] Elapsed 34m 31s (remain 19m 28s) Loss: 0.0181(0.0056) Grad: 125561.8828  LR: 0.00000456  \n","Epoch: [3][6200/9541] Elapsed 35m 5s (remain 18m 54s) Loss: 0.0003(0.0056) Grad: 24413.9746  LR: 0.00000453  \n","Epoch: [3][6300/9541] Elapsed 35m 39s (remain 18m 20s) Loss: 0.0175(0.0056) Grad: 109525.4531  LR: 0.00000450  \n","Epoch: [3][6400/9541] Elapsed 36m 13s (remain 17m 46s) Loss: 0.0037(0.0056) Grad: 98709.3516  LR: 0.00000446  \n","Epoch: [3][6500/9541] Elapsed 36m 47s (remain 17m 12s) Loss: 0.0001(0.0055) Grad: 3620.9775  LR: 0.00000443  \n","Epoch: [3][6600/9541] Elapsed 37m 21s (remain 16m 38s) Loss: 0.0080(0.0055) Grad: 56396.0195  LR: 0.00000440  \n","Epoch: [3][6700/9541] Elapsed 37m 55s (remain 16m 4s) Loss: 0.0047(0.0055) Grad: 117665.0156  LR: 0.00000437  \n","Epoch: [3][6800/9541] Elapsed 38m 29s (remain 15m 30s) Loss: 0.0002(0.0055) Grad: 18388.0859  LR: 0.00000433  \n","Epoch: [3][6900/9541] Elapsed 39m 3s (remain 14m 56s) Loss: 0.0001(0.0055) Grad: 2519.9409  LR: 0.00000430  \n","Epoch: [3][7000/9541] Elapsed 39m 38s (remain 14m 22s) Loss: 0.0050(0.0055) Grad: 105159.6250  LR: 0.00000427  \n","Epoch: [3][7100/9541] Elapsed 40m 12s (remain 13m 48s) Loss: 0.0011(0.0055) Grad: 45635.2148  LR: 0.00000424  \n","Epoch: [3][7200/9541] Elapsed 40m 46s (remain 13m 14s) Loss: 0.0107(0.0055) Grad: 403695.6562  LR: 0.00000420  \n","Epoch: [3][7300/9541] Elapsed 41m 20s (remain 12m 40s) Loss: 0.0011(0.0055) Grad: 10689.3525  LR: 0.00000417  \n","Epoch: [3][7400/9541] Elapsed 41m 54s (remain 12m 7s) Loss: 0.0043(0.0056) Grad: 19956.6777  LR: 0.00000414  \n","Epoch: [3][7500/9541] Elapsed 42m 28s (remain 11m 33s) Loss: 0.0031(0.0056) Grad: 29339.3574  LR: 0.00000411  \n","Epoch: [3][7600/9541] Elapsed 43m 2s (remain 10m 59s) Loss: 0.0066(0.0055) Grad: 34918.8633  LR: 0.00000407  \n","Epoch: [3][7700/9541] Elapsed 43m 36s (remain 10m 25s) Loss: 0.0001(0.0055) Grad: 1594.2516  LR: 0.00000404  \n","Epoch: [3][7800/9541] Elapsed 44m 10s (remain 9m 51s) Loss: 0.0000(0.0055) Grad: 139.7321  LR: 0.00000401  \n","Epoch: [3][7900/9541] Elapsed 44m 44s (remain 9m 17s) Loss: 0.0000(0.0055) Grad: 127.8129  LR: 0.00000398  \n","Epoch: [3][8000/9541] Elapsed 45m 18s (remain 8m 43s) Loss: 0.0001(0.0055) Grad: 608.6686  LR: 0.00000394  \n","Epoch: [3][8100/9541] Elapsed 45m 52s (remain 8m 9s) Loss: 0.0108(0.0055) Grad: 147073.4688  LR: 0.00000391  \n","Epoch: [3][8200/9541] Elapsed 46m 26s (remain 7m 35s) Loss: 0.0042(0.0055) Grad: 45844.3516  LR: 0.00000388  \n","Epoch: [3][8300/9541] Elapsed 47m 0s (remain 7m 1s) Loss: 0.0000(0.0055) Grad: 60.1178  LR: 0.00000385  \n","Epoch: [3][8400/9541] Elapsed 47m 34s (remain 6m 27s) Loss: 0.0218(0.0055) Grad: 83860.3594  LR: 0.00000382  \n","Epoch: [3][8500/9541] Elapsed 48m 8s (remain 5m 53s) Loss: 0.0321(0.0055) Grad: 23902.4062  LR: 0.00000378  \n","Epoch: [3][8600/9541] Elapsed 48m 42s (remain 5m 19s) Loss: 0.0015(0.0055) Grad: 22454.4336  LR: 0.00000375  \n","Epoch: [3][8700/9541] Elapsed 49m 16s (remain 4m 45s) Loss: 0.0139(0.0055) Grad: 103889.5469  LR: 0.00000372  \n","Epoch: [3][8800/9541] Elapsed 49m 50s (remain 4m 11s) Loss: 0.0000(0.0055) Grad: 158.2219  LR: 0.00000369  \n","Epoch: [3][8900/9541] Elapsed 50m 24s (remain 3m 37s) Loss: 0.0000(0.0055) Grad: 538.7862  LR: 0.00000366  \n","Epoch: [3][9000/9541] Elapsed 50m 58s (remain 3m 3s) Loss: 0.0000(0.0055) Grad: 1347.6577  LR: 0.00000362  \n","Epoch: [3][9100/9541] Elapsed 51m 31s (remain 2m 29s) Loss: 0.0011(0.0055) Grad: 35637.6016  LR: 0.00000359  \n","Epoch: [3][9200/9541] Elapsed 52m 6s (remain 1m 55s) Loss: 0.0048(0.0055) Grad: 62327.5273  LR: 0.00000356  \n","Epoch: [3][9300/9541] Elapsed 52m 40s (remain 1m 21s) Loss: 0.0096(0.0055) Grad: 121821.1484  LR: 0.00000353  \n","Epoch: [3][9400/9541] Elapsed 53m 14s (remain 0m 47s) Loss: 0.0006(0.0055) Grad: 24728.9980  LR: 0.00000350  \n","Epoch: [3][9500/9541] Elapsed 53m 48s (remain 0m 13s) Loss: 0.0115(0.0055) Grad: 181341.8906  LR: 0.00000347  \n","Epoch: [3][9540/9541] Elapsed 54m 1s (remain 0m 0s) Loss: 0.0021(0.0055) Grad: 37065.9180  LR: 0.00000345  \n","EVAL: [0/2386] Elapsed 0m 0s (remain 21m 40s) Loss: 0.0001(0.0001) \n","EVAL: [100/2386] Elapsed 0m 20s (remain 7m 53s) Loss: 0.0260(0.0142) \n","EVAL: [200/2386] Elapsed 0m 41s (remain 7m 28s) Loss: 0.0000(0.0153) \n","EVAL: [300/2386] Elapsed 1m 1s (remain 7m 6s) Loss: 0.0340(0.0185) \n","EVAL: [400/2386] Elapsed 1m 21s (remain 6m 45s) Loss: 0.0000(0.0178) \n","EVAL: [500/2386] Elapsed 1m 42s (remain 6m 24s) Loss: 0.0537(0.0167) \n","EVAL: [600/2386] Elapsed 2m 2s (remain 6m 4s) Loss: 0.0180(0.0166) \n","EVAL: [700/2386] Elapsed 2m 23s (remain 5m 43s) Loss: 0.0099(0.0169) \n","EVAL: [800/2386] Elapsed 2m 43s (remain 5m 23s) Loss: 0.0033(0.0177) \n","EVAL: [900/2386] Elapsed 3m 3s (remain 5m 2s) Loss: 0.0000(0.0161) \n","EVAL: [1000/2386] Elapsed 3m 24s (remain 4m 42s) Loss: 0.0052(0.0148) \n","EVAL: [1100/2386] Elapsed 3m 44s (remain 4m 21s) Loss: 0.0000(0.0137) \n","EVAL: [1200/2386] Elapsed 4m 4s (remain 4m 1s) Loss: 0.0000(0.0129) \n","EVAL: [1300/2386] Elapsed 4m 25s (remain 3m 41s) Loss: 0.0000(0.0121) \n","EVAL: [1400/2386] Elapsed 4m 45s (remain 3m 20s) Loss: 0.0031(0.0117) \n","EVAL: [1500/2386] Elapsed 5m 6s (remain 3m 0s) Loss: 0.0051(0.0115) \n","EVAL: [1600/2386] Elapsed 5m 26s (remain 2m 40s) Loss: 0.0219(0.0112) \n","EVAL: [1700/2386] Elapsed 5m 47s (remain 2m 19s) Loss: 0.0128(0.0111) \n","EVAL: [1800/2386] Elapsed 6m 7s (remain 1m 59s) Loss: 0.0052(0.0109) \n","EVAL: [1900/2386] Elapsed 6m 27s (remain 1m 38s) Loss: 0.0000(0.0104) \n","EVAL: [2000/2386] Elapsed 6m 48s (remain 1m 18s) Loss: 0.0000(0.0099) \n","EVAL: [2100/2386] Elapsed 7m 8s (remain 0m 58s) Loss: 0.0000(0.0096) \n","EVAL: [2200/2386] Elapsed 7m 29s (remain 0m 37s) Loss: 0.0000(0.0092) \n","EVAL: [2300/2386] Elapsed 7m 49s (remain 0m 17s) Loss: 0.0033(0.0089) \n","EVAL: [2385/2386] Elapsed 8m 6s (remain 0m 0s) Loss: 0.0000(0.0086) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0055  avg_val_loss: 0.0086  time: 3742s\n","Epoch 3 - Score: 0.9508\n","Epoch 3 - Save Best Score: 0.9508 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/9541] Elapsed 0m 0s (remain 140m 15s) Loss: 0.0000(0.0000) Grad: 297.0885  LR: 0.00000345  \n","Epoch: [4][100/9541] Elapsed 0m 34s (remain 52m 59s) Loss: 0.0094(0.0084) Grad: 29714.2246  LR: 0.00000342  \n","Epoch: [4][200/9541] Elapsed 1m 6s (remain 51m 49s) Loss: 0.0034(0.0065) Grad: 31784.2109  LR: 0.00000339  \n","Epoch: [4][300/9541] Elapsed 1m 39s (remain 51m 1s) Loss: 0.0059(0.0055) Grad: 23087.5156  LR: 0.00000336  \n","Epoch: [4][400/9541] Elapsed 2m 12s (remain 50m 18s) Loss: 0.0010(0.0053) Grad: 13740.9951  LR: 0.00000333  \n","Epoch: [4][500/9541] Elapsed 2m 45s (remain 49m 40s) Loss: 0.0014(0.0051) Grad: 15740.1406  LR: 0.00000330  \n","Epoch: [4][600/9541] Elapsed 3m 18s (remain 49m 5s) Loss: 0.0042(0.0052) Grad: 25013.7852  LR: 0.00000327  \n","Epoch: [4][700/9541] Elapsed 3m 50s (remain 48m 29s) Loss: 0.0005(0.0051) Grad: 3932.1245  LR: 0.00000324  \n","Epoch: [4][800/9541] Elapsed 4m 23s (remain 47m 55s) Loss: 0.0000(0.0051) Grad: 155.8620  LR: 0.00000321  \n","Epoch: [4][900/9541] Elapsed 4m 56s (remain 47m 19s) Loss: 0.0001(0.0050) Grad: 2591.4976  LR: 0.00000318  \n","Epoch: [4][1000/9541] Elapsed 5m 28s (remain 46m 46s) Loss: 0.0026(0.0051) Grad: 15647.9189  LR: 0.00000315  \n","Epoch: [4][1100/9541] Elapsed 6m 1s (remain 46m 12s) Loss: 0.0005(0.0050) Grad: 4531.7319  LR: 0.00000311  \n","Epoch: [4][1200/9541] Elapsed 6m 34s (remain 45m 39s) Loss: 0.0000(0.0050) Grad: 47.7575  LR: 0.00000308  \n","Epoch: [4][1300/9541] Elapsed 7m 7s (remain 45m 6s) Loss: 0.0160(0.0050) Grad: 60089.8008  LR: 0.00000305  \n","Epoch: [4][1400/9541] Elapsed 7m 40s (remain 44m 34s) Loss: 0.0010(0.0050) Grad: 3259.3040  LR: 0.00000302  \n","Epoch: [4][1500/9541] Elapsed 8m 13s (remain 44m 1s) Loss: 0.0002(0.0049) Grad: 3613.8921  LR: 0.00000299  \n","Epoch: [4][1600/9541] Elapsed 8m 45s (remain 43m 27s) Loss: 0.0034(0.0049) Grad: 23497.1914  LR: 0.00000296  \n","Epoch: [4][1700/9541] Elapsed 9m 18s (remain 42m 54s) Loss: 0.0074(0.0049) Grad: 3829.0776  LR: 0.00000293  \n","Epoch: [4][1800/9541] Elapsed 9m 51s (remain 42m 20s) Loss: 0.0002(0.0049) Grad: 2052.2402  LR: 0.00000290  \n","Epoch: [4][1900/9541] Elapsed 10m 23s (remain 41m 47s) Loss: 0.0008(0.0049) Grad: 10252.3584  LR: 0.00000287  \n","Epoch: [4][2000/9541] Elapsed 10m 56s (remain 41m 14s) Loss: 0.0001(0.0050) Grad: 3279.7952  LR: 0.00000284  \n","Epoch: [4][2100/9541] Elapsed 11m 29s (remain 40m 41s) Loss: 0.0024(0.0050) Grad: 35236.7773  LR: 0.00000281  \n","Epoch: [4][2200/9541] Elapsed 12m 2s (remain 40m 8s) Loss: 0.0086(0.0050) Grad: 64520.8750  LR: 0.00000278  \n","Epoch: [4][2300/9541] Elapsed 12m 34s (remain 39m 35s) Loss: 0.0005(0.0049) Grad: 8402.8408  LR: 0.00000275  \n","Epoch: [4][2400/9541] Elapsed 13m 8s (remain 39m 3s) Loss: 0.0024(0.0049) Grad: 28126.1758  LR: 0.00000273  \n","Epoch: [4][2500/9541] Elapsed 13m 41s (remain 38m 31s) Loss: 0.0042(0.0049) Grad: 48575.4844  LR: 0.00000270  \n","Epoch: [4][2600/9541] Elapsed 14m 13s (remain 37m 57s) Loss: 0.0080(0.0049) Grad: 48036.6836  LR: 0.00000267  \n","Epoch: [4][2700/9541] Elapsed 14m 46s (remain 37m 24s) Loss: 0.0044(0.0049) Grad: 38906.2227  LR: 0.00000264  \n","Epoch: [4][2800/9541] Elapsed 15m 19s (remain 36m 51s) Loss: 0.0000(0.0049) Grad: 189.6205  LR: 0.00000261  \n","Epoch: [4][2900/9541] Elapsed 15m 51s (remain 36m 18s) Loss: 0.0001(0.0049) Grad: 4604.6021  LR: 0.00000258  \n","Epoch: [4][3000/9541] Elapsed 16m 24s (remain 35m 45s) Loss: 0.0013(0.0048) Grad: 39005.1602  LR: 0.00000255  \n","Epoch: [4][3100/9541] Elapsed 16m 57s (remain 35m 12s) Loss: 0.0001(0.0048) Grad: 2921.9534  LR: 0.00000252  \n","Epoch: [4][3200/9541] Elapsed 17m 29s (remain 34m 39s) Loss: 0.0000(0.0049) Grad: 90.4044  LR: 0.00000249  \n","Epoch: [4][3300/9541] Elapsed 18m 2s (remain 34m 6s) Loss: 0.0398(0.0049) Grad: 50235.2344  LR: 0.00000247  \n","Epoch: [4][3400/9541] Elapsed 18m 35s (remain 33m 33s) Loss: 0.0014(0.0048) Grad: 23483.8906  LR: 0.00000244  \n","Epoch: [4][3500/9541] Elapsed 19m 8s (remain 33m 0s) Loss: 0.0012(0.0048) Grad: 28817.0273  LR: 0.00000241  \n","Epoch: [4][3600/9541] Elapsed 19m 40s (remain 32m 27s) Loss: 0.0096(0.0048) Grad: 104676.1328  LR: 0.00000238  \n","Epoch: [4][3700/9541] Elapsed 20m 13s (remain 31m 54s) Loss: 0.0000(0.0049) Grad: 264.6465  LR: 0.00000235  \n","Epoch: [4][3800/9541] Elapsed 20m 46s (remain 31m 21s) Loss: 0.0005(0.0049) Grad: 7242.5415  LR: 0.00000233  \n","Epoch: [4][3900/9541] Elapsed 21m 18s (remain 30m 48s) Loss: 0.0001(0.0049) Grad: 1411.2389  LR: 0.00000230  \n","Epoch: [4][4000/9541] Elapsed 21m 51s (remain 30m 15s) Loss: 0.0022(0.0048) Grad: 48733.0703  LR: 0.00000227  \n","Epoch: [4][4100/9541] Elapsed 22m 24s (remain 29m 42s) Loss: 0.0069(0.0048) Grad: 246463.0625  LR: 0.00000224  \n","Epoch: [4][4200/9541] Elapsed 22m 56s (remain 29m 10s) Loss: 0.0055(0.0048) Grad: 65543.0625  LR: 0.00000221  \n","Epoch: [4][4300/9541] Elapsed 23m 29s (remain 28m 37s) Loss: 0.0047(0.0048) Grad: 86889.2891  LR: 0.00000219  \n","Epoch: [4][4400/9541] Elapsed 24m 2s (remain 28m 4s) Loss: 0.0030(0.0048) Grad: 43777.3789  LR: 0.00000216  \n","Epoch: [4][4500/9541] Elapsed 24m 34s (remain 27m 31s) Loss: 0.0001(0.0048) Grad: 3199.9155  LR: 0.00000213  \n","Epoch: [4][4600/9541] Elapsed 25m 7s (remain 26m 58s) Loss: 0.0000(0.0048) Grad: 414.5596  LR: 0.00000211  \n","Epoch: [4][4700/9541] Elapsed 25m 40s (remain 26m 25s) Loss: 0.0001(0.0048) Grad: 2795.3242  LR: 0.00000208  \n","Epoch: [4][4800/9541] Elapsed 26m 13s (remain 25m 53s) Loss: 0.0015(0.0048) Grad: 37663.3477  LR: 0.00000205  \n","Epoch: [4][4900/9541] Elapsed 26m 46s (remain 25m 20s) Loss: 0.0006(0.0048) Grad: 70476.8906  LR: 0.00000203  \n","Epoch: [4][5000/9541] Elapsed 27m 19s (remain 24m 48s) Loss: 0.0017(0.0048) Grad: 23100.4648  LR: 0.00000200  \n","Epoch: [4][5100/9541] Elapsed 27m 51s (remain 24m 15s) Loss: 0.0031(0.0048) Grad: 56451.1328  LR: 0.00000197  \n","Epoch: [4][5200/9541] Elapsed 28m 24s (remain 23m 42s) Loss: 0.0000(0.0048) Grad: 21.4695  LR: 0.00000195  \n","Epoch: [4][5300/9541] Elapsed 28m 57s (remain 23m 9s) Loss: 0.0099(0.0048) Grad: 95085.3438  LR: 0.00000192  \n","Epoch: [4][5400/9541] Elapsed 29m 29s (remain 22m 36s) Loss: 0.0132(0.0049) Grad: 186802.0938  LR: 0.00000190  \n","Epoch: [4][5500/9541] Elapsed 30m 2s (remain 22m 3s) Loss: 0.0000(0.0048) Grad: 47.0592  LR: 0.00000187  \n","Epoch: [4][5600/9541] Elapsed 30m 35s (remain 21m 30s) Loss: 0.0042(0.0049) Grad: 44368.2422  LR: 0.00000184  \n","Epoch: [4][5700/9541] Elapsed 31m 7s (remain 20m 58s) Loss: 0.0105(0.0048) Grad: 112500.9844  LR: 0.00000182  \n","Epoch: [4][5800/9541] Elapsed 31m 40s (remain 20m 25s) Loss: 0.0000(0.0048) Grad: 22.6360  LR: 0.00000179  \n","Epoch: [4][5900/9541] Elapsed 32m 13s (remain 19m 52s) Loss: 0.0029(0.0048) Grad: 75644.2500  LR: 0.00000177  \n","Epoch: [4][6000/9541] Elapsed 32m 45s (remain 19m 19s) Loss: 0.0000(0.0048) Grad: 22.6707  LR: 0.00000174  \n","Epoch: [4][6100/9541] Elapsed 33m 18s (remain 18m 46s) Loss: 0.0009(0.0048) Grad: 37360.3047  LR: 0.00000172  \n","Epoch: [4][6200/9541] Elapsed 33m 51s (remain 18m 14s) Loss: 0.0418(0.0048) Grad: 86837.2344  LR: 0.00000169  \n","Epoch: [4][6300/9541] Elapsed 34m 23s (remain 17m 41s) Loss: 0.0183(0.0048) Grad: 110120.2031  LR: 0.00000167  \n","Epoch: [4][6400/9541] Elapsed 34m 56s (remain 17m 8s) Loss: 0.0015(0.0048) Grad: 89967.6875  LR: 0.00000164  \n","Epoch: [4][6500/9541] Elapsed 35m 29s (remain 16m 35s) Loss: 0.0011(0.0047) Grad: 68404.9219  LR: 0.00000162  \n","Epoch: [4][6600/9541] Elapsed 36m 2s (remain 16m 3s) Loss: 0.0016(0.0048) Grad: 35477.0352  LR: 0.00000160  \n","Epoch: [4][6700/9541] Elapsed 36m 34s (remain 15m 30s) Loss: 0.0100(0.0048) Grad: 368669.6875  LR: 0.00000157  \n","Epoch: [4][6800/9541] Elapsed 37m 7s (remain 14m 57s) Loss: 0.0000(0.0048) Grad: 564.3828  LR: 0.00000155  \n","Epoch: [4][6900/9541] Elapsed 37m 40s (remain 14m 24s) Loss: 0.0057(0.0048) Grad: 110244.7891  LR: 0.00000152  \n","Epoch: [4][7000/9541] Elapsed 38m 12s (remain 13m 51s) Loss: 0.0099(0.0047) Grad: 302062.0312  LR: 0.00000150  \n","Epoch: [4][7100/9541] Elapsed 38m 45s (remain 13m 19s) Loss: 0.0054(0.0047) Grad: 160040.8594  LR: 0.00000148  \n","Epoch: [4][7200/9541] Elapsed 39m 18s (remain 12m 46s) Loss: 0.0862(0.0048) Grad: 463434.3438  LR: 0.00000145  \n","Epoch: [4][7300/9541] Elapsed 39m 51s (remain 12m 13s) Loss: 0.0003(0.0048) Grad: 19122.3789  LR: 0.00000143  \n","Epoch: [4][7400/9541] Elapsed 40m 24s (remain 11m 40s) Loss: 0.0024(0.0048) Grad: 88671.8594  LR: 0.00000141  \n","Epoch: [4][7500/9541] Elapsed 40m 56s (remain 11m 8s) Loss: 0.0003(0.0048) Grad: 19568.8418  LR: 0.00000139  \n","Epoch: [4][7600/9541] Elapsed 41m 29s (remain 10m 35s) Loss: 0.0000(0.0048) Grad: 327.1899  LR: 0.00000136  \n","Epoch: [4][7700/9541] Elapsed 42m 2s (remain 10m 2s) Loss: 0.0074(0.0048) Grad: 138861.6562  LR: 0.00000134  \n","Epoch: [4][7800/9541] Elapsed 42m 34s (remain 9m 29s) Loss: 0.0051(0.0048) Grad: 111358.1250  LR: 0.00000132  \n","Epoch: [4][7900/9541] Elapsed 43m 7s (remain 8m 57s) Loss: 0.0000(0.0048) Grad: 24.8817  LR: 0.00000130  \n","Epoch: [4][8000/9541] Elapsed 43m 40s (remain 8m 24s) Loss: 0.0071(0.0048) Grad: 398564.5938  LR: 0.00000127  \n","Epoch: [4][8100/9541] Elapsed 44m 13s (remain 7m 51s) Loss: 0.0089(0.0048) Grad: 810157.1250  LR: 0.00000125  \n","Epoch: [4][8200/9541] Elapsed 44m 45s (remain 7m 18s) Loss: 0.0000(0.0048) Grad: 133.5129  LR: 0.00000123  \n","Epoch: [4][8300/9541] Elapsed 45m 18s (remain 6m 46s) Loss: 0.0000(0.0048) Grad: 112.0761  LR: 0.00000121  \n","Epoch: [4][8400/9541] Elapsed 45m 51s (remain 6m 13s) Loss: 0.0000(0.0048) Grad: 2999.9556  LR: 0.00000119  \n","Epoch: [4][8500/9541] Elapsed 46m 23s (remain 5m 40s) Loss: 0.0000(0.0048) Grad: 113.8697  LR: 0.00000117  \n","Epoch: [4][8600/9541] Elapsed 46m 56s (remain 5m 7s) Loss: 0.0019(0.0048) Grad: 61032.7422  LR: 0.00000114  \n","Epoch: [4][8700/9541] Elapsed 47m 29s (remain 4m 35s) Loss: 0.0000(0.0048) Grad: 2202.6606  LR: 0.00000112  \n","Epoch: [4][8800/9541] Elapsed 48m 2s (remain 4m 2s) Loss: 0.0025(0.0048) Grad: 89696.9844  LR: 0.00000110  \n","Epoch: [4][8900/9541] Elapsed 48m 35s (remain 3m 29s) Loss: 0.0045(0.0048) Grad: 184652.6719  LR: 0.00000108  \n","Epoch: [4][9000/9541] Elapsed 49m 7s (remain 2m 56s) Loss: 0.0000(0.0048) Grad: 2852.6677  LR: 0.00000106  \n","Epoch: [4][9100/9541] Elapsed 49m 40s (remain 2m 24s) Loss: 0.0111(0.0048) Grad: 124798.5938  LR: 0.00000104  \n","Epoch: [4][9200/9541] Elapsed 50m 13s (remain 1m 51s) Loss: 0.0000(0.0048) Grad: 46.3475  LR: 0.00000102  \n","Epoch: [4][9300/9541] Elapsed 50m 45s (remain 1m 18s) Loss: 0.0001(0.0048) Grad: 18665.7988  LR: 0.00000100  \n","Epoch: [4][9400/9541] Elapsed 51m 18s (remain 0m 45s) Loss: 0.0000(0.0048) Grad: 632.2903  LR: 0.00000098  \n","Epoch: [4][9500/9541] Elapsed 51m 51s (remain 0m 13s) Loss: 0.0000(0.0049) Grad: 156.2241  LR: 0.00000096  \n","Epoch: [4][9540/9541] Elapsed 52m 5s (remain 0m 0s) Loss: 0.0052(0.0049) Grad: 108364.8594  LR: 0.00000095  \n","EVAL: [0/2386] Elapsed 0m 0s (remain 19m 10s) Loss: 0.0000(0.0000) \n","EVAL: [100/2386] Elapsed 0m 19s (remain 7m 31s) Loss: 0.0306(0.0157) \n","EVAL: [200/2386] Elapsed 0m 39s (remain 7m 8s) Loss: 0.0000(0.0168) \n","EVAL: [300/2386] Elapsed 0m 58s (remain 6m 47s) Loss: 0.0415(0.0201) \n","EVAL: [400/2386] Elapsed 1m 18s (remain 6m 27s) Loss: 0.0000(0.0195) \n","EVAL: [500/2386] Elapsed 1m 37s (remain 6m 7s) Loss: 0.0660(0.0183) \n","EVAL: [600/2386] Elapsed 1m 57s (remain 5m 47s) Loss: 0.0213(0.0182) \n","EVAL: [700/2386] Elapsed 2m 16s (remain 5m 28s) Loss: 0.0162(0.0184) \n","EVAL: [800/2386] Elapsed 2m 36s (remain 5m 8s) Loss: 0.0090(0.0193) \n","EVAL: [900/2386] Elapsed 2m 55s (remain 4m 49s) Loss: 0.0000(0.0176) \n","EVAL: [1000/2386] Elapsed 3m 14s (remain 4m 29s) Loss: 0.0046(0.0161) \n","EVAL: [1100/2386] Elapsed 3m 34s (remain 4m 10s) Loss: 0.0000(0.0150) \n","EVAL: [1200/2386] Elapsed 3m 53s (remain 3m 50s) Loss: 0.0000(0.0140) \n","EVAL: [1300/2386] Elapsed 4m 13s (remain 3m 31s) Loss: 0.0000(0.0132) \n","EVAL: [1400/2386] Elapsed 4m 32s (remain 3m 11s) Loss: 0.0027(0.0127) \n","EVAL: [1500/2386] Elapsed 4m 52s (remain 2m 52s) Loss: 0.0032(0.0124) \n","EVAL: [1600/2386] Elapsed 5m 11s (remain 2m 32s) Loss: 0.0196(0.0121) \n","EVAL: [1700/2386] Elapsed 5m 31s (remain 2m 13s) Loss: 0.0147(0.0120) \n","EVAL: [1800/2386] Elapsed 5m 50s (remain 1m 53s) Loss: 0.0050(0.0118) \n","EVAL: [1900/2386] Elapsed 6m 9s (remain 1m 34s) Loss: 0.0000(0.0112) \n","EVAL: [2000/2386] Elapsed 6m 29s (remain 1m 14s) Loss: 0.0000(0.0108) \n","EVAL: [2100/2386] Elapsed 6m 48s (remain 0m 55s) Loss: 0.0000(0.0104) \n","EVAL: [2200/2386] Elapsed 7m 8s (remain 0m 35s) Loss: 0.0000(0.0100) \n","EVAL: [2300/2386] Elapsed 7m 27s (remain 0m 16s) Loss: 0.0025(0.0096) \n","EVAL: [2385/2386] Elapsed 7m 43s (remain 0m 0s) Loss: 0.0000(0.0093) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0049  avg_val_loss: 0.0093  time: 3602s\n","Epoch 4 - Score: 0.9518\n","Epoch 4 - Save Best Score: 0.9518 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/1906] Elapsed 0m 0s (remain 27m 14s) Loss: 0.0250(0.0250) Grad: 47714.1641  LR: 0.00000095  \n","Epoch: [5][100/1906] Elapsed 0m 33s (remain 10m 4s) Loss: 0.0354(0.0091) Grad: 111528.6094  LR: 0.00000094  \n","Epoch: [5][200/1906] Elapsed 1m 6s (remain 9m 24s) Loss: 0.0038(0.0103) Grad: 19327.2031  LR: 0.00000092  \n","Epoch: [5][300/1906] Elapsed 1m 39s (remain 8m 49s) Loss: 0.0000(0.0099) Grad: 30.1937  LR: 0.00000090  \n","Epoch: [5][400/1906] Elapsed 2m 11s (remain 8m 15s) Loss: 0.0073(0.0096) Grad: 29071.0703  LR: 0.00000088  \n","Epoch: [5][500/1906] Elapsed 2m 44s (remain 7m 41s) Loss: 0.0031(0.0092) Grad: 19855.6309  LR: 0.00000086  \n","Epoch: [5][600/1906] Elapsed 3m 17s (remain 7m 8s) Loss: 0.0010(0.0093) Grad: 7127.5581  LR: 0.00000084  \n","Epoch: [5][700/1906] Elapsed 3m 49s (remain 6m 35s) Loss: 0.0009(0.0090) Grad: 7361.2422  LR: 0.00000082  \n","Epoch: [5][800/1906] Elapsed 4m 22s (remain 6m 2s) Loss: 0.0021(0.0093) Grad: 18654.8340  LR: 0.00000081  \n","Epoch: [5][900/1906] Elapsed 4m 55s (remain 5m 29s) Loss: 0.0000(0.0089) Grad: 127.3827  LR: 0.00000079  \n","Epoch: [5][1000/1906] Elapsed 5m 27s (remain 4m 56s) Loss: 0.0193(0.0088) Grad: 213868.5156  LR: 0.00000077  \n","Epoch: [5][1100/1906] Elapsed 6m 0s (remain 4m 23s) Loss: 0.0094(0.0087) Grad: 32839.2969  LR: 0.00000075  \n","Epoch: [5][1200/1906] Elapsed 6m 33s (remain 3m 50s) Loss: 0.0045(0.0086) Grad: 13678.7021  LR: 0.00000074  \n","Epoch: [5][1300/1906] Elapsed 7m 5s (remain 3m 17s) Loss: 0.0000(0.0084) Grad: 44.1575  LR: 0.00000072  \n","Epoch: [5][1400/1906] Elapsed 7m 38s (remain 2m 45s) Loss: 0.0007(0.0085) Grad: 6476.0317  LR: 0.00000070  \n","Epoch: [5][1500/1906] Elapsed 8m 11s (remain 2m 12s) Loss: 0.0104(0.0084) Grad: 20367.3496  LR: 0.00000068  \n","Epoch: [5][1600/1906] Elapsed 8m 43s (remain 1m 39s) Loss: 0.0003(0.0084) Grad: 1034.0361  LR: 0.00000067  \n","Epoch: [5][1700/1906] Elapsed 9m 16s (remain 1m 7s) Loss: 0.0294(0.0084) Grad: 55961.1445  LR: 0.00000065  \n","Epoch: [5][1800/1906] Elapsed 9m 49s (remain 0m 34s) Loss: 0.0028(0.0083) Grad: 18645.5859  LR: 0.00000064  \n","Epoch: [5][1900/1906] Elapsed 10m 21s (remain 0m 1s) Loss: 0.0082(0.0081) Grad: 17136.0859  LR: 0.00000062  \n","Epoch: [5][1905/1906] Elapsed 10m 23s (remain 0m 0s) Loss: 0.0002(0.0081) Grad: 4069.6218  LR: 0.00000062  \n","EVAL: [0/477] Elapsed 0m 0s (remain 3m 47s) Loss: 0.0002(0.0002) \n","EVAL: [100/477] Elapsed 0m 19s (remain 1m 14s) Loss: 0.0329(0.0114) \n","EVAL: [200/477] Elapsed 0m 39s (remain 0m 54s) Loss: 0.0000(0.0121) \n","EVAL: [300/477] Elapsed 0m 58s (remain 0m 34s) Loss: 0.0290(0.0143) \n","EVAL: [400/477] Elapsed 1m 18s (remain 0m 14s) Loss: 0.0000(0.0139) \n","EVAL: [476/477] Elapsed 1m 33s (remain 0m 0s) Loss: 0.0120(0.0127) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0081  avg_val_loss: 0.0127  time: 719s\n","Epoch 5 - Score: 0.9013\n","========== fold: 4 result ==========\n","Score: 0.9518\n","========== CV ==========\n","Score: 0.9522\n"]}],"source":["if CFG.train:\n","    oof_df = pd.DataFrame()\n","    for fold in range(CFG.n_fold):\n","        if fold in CFG.trn_fold:\n","            _oof_df = train_loop(train, fold, CFG.n_fold)\n","            oof_df = pd.concat([oof_df, _oof_df])\n","            LOGGER.info(f\"========== fold: {fold} result ==========\")\n","            get_result(_oof_df)\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","    oof_df = oof_df.reset_index(drop=True)\n","    LOGGER.info(f\"========== CV ==========\")\n","    get_result(oof_df)\n","    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rTZw09JT0N_N"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4rR3p2rHRYpN"},"outputs":[{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e01eba16daa64be194dc6edaedfab651","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁▂▂█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e█▂▁▁▃▂▁▂▂▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▃▁▄▁▂▆▁▁▁▄▁▂▁▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e▇███▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▂▂▁▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁▂▂█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e▂▁▂▂█▂▁▁▂▂▃▁▁▁▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e▇███▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁▁▂█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e█▅▃▁▄▆▂▅▁▆▁▄▃▁▁▇▃▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▅▁▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e▇███▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▂▃▃█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e█▅▄▂▃▁▁▁▂▁▂▁▁▃▁▂▁▁▃▁▁▁▁▁▂▁▁▂▁▂▁▁▁▁▂█▂▆▂▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e▇███▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▂▂▃█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e▁▃▅▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e▂▂▂▁█▂▁▁▁▁▁▂▂▁▄▁▁▁▁▁▁▁▁▂▁▂▁▅▁▂▁▁▁▂▂▁▂▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e▇███▁\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00814\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.01649\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e0.0067\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e0.88487\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00848\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.01288\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e0.00575\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e0.90376\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00806\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.01151\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e0.00831\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e0.9065\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00805\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.01249\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e0.00999\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e0.90561\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.00808\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.01273\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e0.00021\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e0.90128\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced \u003cstrong style=\"color:#cdcd00\"\u003emicrosoft/deberta-v3-large\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/bluehills/NBME-Public2/runs/3oznab0v\" target=\"_blank\"\u003ehttps://wandb.ai/bluehills/NBME-Public2/runs/3oznab0v\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20220502_123804-3oznab0v/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["if CFG.wandb:\n","    wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dLEhCWQC0f5D"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP50nhvsorhS+LeL02JrYS6","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"NBME training with PL.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06fc0a7a5e7743efa334b03212654573":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c861c88f2ef4f53889501e9031c1e13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2daf91a02b6a4598b36259067d5c37b5","placeholder":"​","style":"IPY_MODEL_212c082a849e4520be0fb57520486170","value":" 143/143 [00:00\u0026lt;00:00, 3263.30it/s]"}},"0f59d1c11ab34fc196b0c29f60125d04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18cac28641d44cfaad5b5548c4ba6a7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_577a791389c14090b332f10b5215c798","IPY_MODEL_e3258303faf24d7b8ebb85bee31826f2","IPY_MODEL_5bdee31e0d9b45feb65e5e6f1c13ad33"],"layout":"IPY_MODEL_f3e04b071b39483eb9fcbb7e8963c687"}},"1cd176ec80ed4901af32af29969f8e9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d720c48bec147d88355601b3b989b10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"212c082a849e4520be0fb57520486170":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26f959c2d9954cdaa34f2ecfae715fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29d44b7cfd7e4f1583f549873293c407":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b05b1163e2d4fd7b3b71d7417efc431":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75b395dc16ea4f37af8fd80ebb0349d1","IPY_MODEL_dca08d46d9fd484f830858d668c59b04","IPY_MODEL_721f6e42fc344e259bd94b2f3b25e499"],"layout":"IPY_MODEL_8e49c6edf69546f3b24bcc920b926fe8"}},"2daf91a02b6a4598b36259067d5c37b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db08b5c02a948679dcc50a5a57585e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42fcded147a54a54adffd789567d1a69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eca942e21bd497b9804f57f057a5793","placeholder":"​","style":"IPY_MODEL_7b0abb3e75c54dcc977981a0ca136ee2","value":"Downloading: 100%"}},"4f8c874bc0134ea2812e36a14410266c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526add8a09f7416c8915b92162839bca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54758462401e4a82ac40429000e78d0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"577a791389c14090b332f10b5215c798":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fdea069863e47869f0e7506800fe80e","placeholder":"​","style":"IPY_MODEL_1d720c48bec147d88355601b3b989b10","value":"Downloading: 100%"}},"5bdee31e0d9b45feb65e5e6f1c13ad33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_526add8a09f7416c8915b92162839bca","placeholder":"​","style":"IPY_MODEL_26f959c2d9954cdaa34f2ecfae715fed","value":" 833M/833M [00:13\u0026lt;00:00, 70.6MB/s]"}},"5c328618aa32425689701c22b2e8be27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cd176ec80ed4901af32af29969f8e9c","placeholder":"​","style":"IPY_MODEL_29d44b7cfd7e4f1583f549873293c407","value":" 580/580 [00:00\u0026lt;00:00, 24.7kB/s]"}},"63800ddb94164fa88bc12de0543dcc20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c50709207574b6697f12281290ec1e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dff35c147b148d3a8b7fb012167fd68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2db08b5c02a948679dcc50a5a57585e8","max":143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df65d11f059b4227a211ef2b27f794d0","value":143}},"6eca942e21bd497b9804f57f057a5793":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fdea069863e47869f0e7506800fe80e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"721f6e42fc344e259bd94b2f3b25e499":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb5b3baaa04f4238b826ff2a0ffbc81b","placeholder":"​","style":"IPY_MODEL_6c50709207574b6697f12281290ec1e9","value":" 42146/42146 [00:21\u0026lt;00:00, 1984.50it/s]"}},"75b395dc16ea4f37af8fd80ebb0349d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fe651ad7e3e4c259accd2e011917211","placeholder":"​","style":"IPY_MODEL_06fc0a7a5e7743efa334b03212654573","value":"100%"}},"7a1307624cc741a39e0341b12511bb95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b0abb3e75c54dcc977981a0ca136ee2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fe651ad7e3e4c259accd2e011917211":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844ad32c62774ec2bc8efa07dcb4706b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b16c4f70efc4000af83a48e584c7a1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e49c6edf69546f3b24bcc920b926fe8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e34e50c8bc047c19c192ba3eff3e163":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab2964caf4c040e98bb89f7d6da55884","IPY_MODEL_6dff35c147b148d3a8b7fb012167fd68","IPY_MODEL_0c861c88f2ef4f53889501e9031c1e13"],"layout":"IPY_MODEL_bc43de6869ee40d2bebd47e60c4b6af5"}},"ab2964caf4c040e98bb89f7d6da55884":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd872f2e44974f24b99f10bfc5f88d91","placeholder":"​","style":"IPY_MODEL_844ad32c62774ec2bc8efa07dcb4706b","value":"100%"}},"b2f2f19c297549368070ee54ae0edd91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc43de6869ee40d2bebd47e60c4b6af5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd872f2e44974f24b99f10bfc5f88d91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb5b3baaa04f4238b826ff2a0ffbc81b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2cab3cee8da46d6bab1c08c765b07aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42fcded147a54a54adffd789567d1a69","IPY_MODEL_dcf583135990493092327d6e4879a996","IPY_MODEL_5c328618aa32425689701c22b2e8be27"],"layout":"IPY_MODEL_b2f2f19c297549368070ee54ae0edd91"}},"dca08d46d9fd484f830858d668c59b04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f59d1c11ab34fc196b0c29f60125d04","max":42146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63800ddb94164fa88bc12de0543dcc20","value":42146}},"dcf583135990493092327d6e4879a996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b16c4f70efc4000af83a48e584c7a1a","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54758462401e4a82ac40429000e78d0f","value":580}},"df65d11f059b4227a211ef2b27f794d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3258303faf24d7b8ebb85bee31826f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8c874bc0134ea2812e36a14410266c","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a1307624cc741a39e0341b12511bb95","value":873673253}},"f3e04b071b39483eb9fcbb7e8963c687":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}