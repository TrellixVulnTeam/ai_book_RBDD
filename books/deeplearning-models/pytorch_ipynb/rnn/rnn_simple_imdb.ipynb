{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_simple_imdb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqHUkfQSthQM",
        "colab_type": "text"
      },
      "source": [
        "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
        "- Author: Sebastian Raschka\n",
        "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqSqtWpZtrHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q IPython\n",
        "!pip install -q ipykernel\n",
        "!pip install -q watermark\n",
        "!pip install -q matplotlib\n",
        "!pip install -q sklearn\n",
        "!pip install -q pandas\n",
        "!pip install -q pydot\n",
        "!pip install -q hiddenlayer\n",
        "!pip install -q graphviz"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vY4SK0xKAJgm"
      },
      "source": [
        "# Model Zoo -- Simple RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sc6xejhY-NzZ"
      },
      "source": [
        "Demo of a simple RNN for sentiment classification (here: a binary classification problem with two labels, positive and negative). Note that a simple RNN usually doesn't work very well due to vanishing and exploding gradient problems. Also, this implementation uses padding for dealing with variable size inputs. Hence, the shorter the sentence, the more `<pad>` placeholders will be added to match the length of the longest sentence in a batch.\n",
        "\n",
        "Note that this RNN trains about 4 times slower than the equivalent with packed sequences, [./rnn-simple-packed-imdb.ipynb](./rnn-simple-packed-imdb.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "moNmVfuvnImW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "baed4d07-4528-4be5-8f7e-afb2d90a8523"
      },
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka' -v -p torch\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import time\n",
        "import random\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sebastian Raschka \n",
            "\n",
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "torch 1.5.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GSRL42Qgy8I8"
      },
      "source": [
        "## General Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OvW1RgfepCBq",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 1e-4\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 15\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mQMmKUEisW4W"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4GnH64XvsV8n"
      },
      "source": [
        "Load the IMDB Movie Review dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZ_4jiHVnMxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ae166e17-313d-486d-e028-476ea926129c"
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(RANDOM_SEED),\n",
        "                                          split_ratio=0.8)\n",
        "\n",
        "print(f'Num Train: {len(train_data)}')\n",
        "print(f'Num Valid: {len(valid_data)}')\n",
        "print(f'Num Test: {len(test_data)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:04<00:00, 20.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Num Train: 20000\n",
            "Num Valid: 5000\n",
            "Num Test: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L-TBwKWPslPa"
      },
      "source": [
        "Build the vocabulary based on the top \"VOCABULARY_SIZE\" words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e8uNrjdtn4A8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d5c3e6e9-652d-4fe5-e8ac-8f18dee25dcd"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=VOCABULARY_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
        "print(f'Number of classes: {len(LABEL.vocab)}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 20002\n",
            "Number of classes: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JpEMNInXtZsb"
      },
      "source": [
        "The TEXT.vocab dictionary will contain the word counts and indices. The reason why the number of words is VOCABULARY_SIZE + 2 is that it contains to special tokens for padding and unknown words: `<unk>` and `<pad>`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eIQ_zfKLwjKm"
      },
      "source": [
        "Make dataset iterators:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i7JiHR1stHNF",
        "colab": {}
      },
      "source": [
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=DEVICE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R0pT_dMRvicQ"
      },
      "source": [
        "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y8SP_FccutT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "14424986-2248-41f0-ac79-44544802180f"
      },
      "source": [
        "print('Train')\n",
        "for batch in train_loader:\n",
        "    print(f'Text matrix size: {batch.text.size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for batch in valid_loader:\n",
        "    print(f'Text matrix size: {batch.text.size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for batch in test_loader:\n",
        "    print(f'Text matrix size: {batch.text.size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([1076, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([61, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([42, 128])\n",
            "Target vector size: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G_grdW3pxCzz"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nQIUm5EjxFNa",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #[sentence len, batch size] => [sentence len, batch size, embedding size]\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #[sentence len, batch size, embedding size] => \n",
        "        #  output: [sentence len, batch size, hidden size]\n",
        "        #  hidden: [1, batch size, hidden size]\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0)).view(-1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ik3NF3faxFmZ",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9LW0watzfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "8f1921a4-9215-4bbc-9b97-f631d1b7f635"
      },
      "source": [
        "import hiddenlayer as hl\n",
        "batch = next(iter(train_loader))\n",
        "print(batch.text.shape)\n",
        "hl.build_graph(model, batch.text.to(DEVICE))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1117, 128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/onnx/symbolic_opset9.py:1586: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with RNN_TANH can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  \"or define the initial states (h0/c0) as inputs of the model. \")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hiddenlayer.graph.Graph at 0x7fbdfcedcf60>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"1271pt\" height=\"371pt\"\n viewBox=\"0.00 0.00 1271.00 371.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 335)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-335 1199,-335 1199,36 -72,36\"/>\n<!-- /outputs/8 -->\n<g id=\"node1\" class=\"node\">\n<title>/outputs/8</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-293 0,-293 0,-257 54,-257 54,-293\"/>\n<text text-anchor=\"start\" x=\"13\" y=\"-272\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n</g>\n<!-- /outputs/9 -->\n<g id=\"node2\" class=\"node\">\n<title>/outputs/9</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"202,-260 148,-260 148,-224 202,-224 202,-260\"/>\n<text text-anchor=\"start\" x=\"163\" y=\"-239\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Shape</text>\n</g>\n<!-- /outputs/8&#45;&gt;/outputs/9 -->\n<g id=\"edge1\" class=\"edge\">\n<title>/outputs/8&#45;&gt;/outputs/9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0619,-267.5043C59.9582,-265.9494 66.1755,-264.3691 72,-263 93.6852,-257.9028 118.1076,-252.8921 137.7269,-249.0443\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"138.6467,-252.4311 147.7959,-247.0885 137.312,-245.5595 138.6467,-252.4311\"/>\n<text text-anchor=\"middle\" x=\"101\" y=\"-266\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1117x128x64</text>\n</g>\n<!-- /outputs/24/25 -->\n<g id=\"node17\" class=\"node\">\n<title>/outputs/24/25</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"745,-171 691,-171 691,-135 745,-135 745,-171\"/>\n<text text-anchor=\"start\" x=\"708\" y=\"-150\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">RNN</text>\n</g>\n<!-- /outputs/8&#45;&gt;/outputs/24/25 -->\n<g id=\"edge2\" class=\"edge\">\n<title>/outputs/8&#45;&gt;/outputs/24/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.2148,-278.8301C83.8568,-282.6648 132.6989,-288 175,-288 175,-288 175,-288 563,-288 628.0827,-288 679.1018,-219.4823 703.0636,-180.0733\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"706.2282,-181.5974 708.2982,-171.2067 700.2003,-178.0386 706.2282,-181.5974\"/>\n<text text-anchor=\"middle\" x=\"360.5\" y=\"-291\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1117x128x64</text>\n</g>\n<!-- /outputs/11 -->\n<g id=\"node4\" class=\"node\">\n<title>/outputs/11</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"293,-252 239,-252 239,-216 293,-216 293,-252\"/>\n<text text-anchor=\"start\" x=\"252\" y=\"-231\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n</g>\n<!-- /outputs/9&#45;&gt;/outputs/11 -->\n<g id=\"edge3\" class=\"edge\">\n<title>/outputs/9&#45;&gt;/outputs/11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M202.303,-239.5997C210.5813,-238.872 219.8217,-238.0596 228.6405,-237.2844\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.0612,-240.761 238.7163,-236.3986 228.4481,-233.7879 229.0612,-240.761\"/>\n</g>\n<!-- /outputs/10 -->\n<g id=\"node3\" class=\"node\">\n<title>/outputs/10</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"202,-206 148,-206 148,-170 202,-170 202,-206\"/>\n<text text-anchor=\"start\" x=\"157\" y=\"-185\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/10&#45;&gt;/outputs/11 -->\n<g id=\"edge4\" class=\"edge\">\n<title>/outputs/10&#45;&gt;/outputs/11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M202.303,-201.8015C210.9412,-206.1681 220.6271,-211.0642 229.7882,-215.6952\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.2127,-218.8205 238.7163,-220.2082 231.3707,-212.5732 228.2127,-218.8205\"/>\n</g>\n<!-- /outputs/15 -->\n<g id=\"node8\" class=\"node\">\n<title>/outputs/15</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"391,-252 330,-252 330,-216 391,-216 391,-252\"/>\n<text text-anchor=\"start\" x=\"338.5\" y=\"-231\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/11&#45;&gt;/outputs/15 -->\n<g id=\"edge5\" class=\"edge\">\n<title>/outputs/11&#45;&gt;/outputs/15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293.0799,-234C301.3121,-234 310.5498,-234 319.4848,-234\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.7564,-237.5001 329.7563,-234 319.7563,-230.5001 319.7564,-237.5001\"/>\n</g>\n<!-- /outputs/12 -->\n<g id=\"node5\" class=\"node\">\n<title>/outputs/12</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"293,-144 239,-144 239,-108 293,-108 293,-144\"/>\n<text text-anchor=\"start\" x=\"248\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/14 -->\n<g id=\"node7\" class=\"node\">\n<title>/outputs/14</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"391,-144 330,-144 330,-108 391,-108 391,-144\"/>\n<text text-anchor=\"start\" x=\"338.5\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/12&#45;&gt;/outputs/14 -->\n<g id=\"edge6\" class=\"edge\">\n<title>/outputs/12&#45;&gt;/outputs/14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293.0799,-126C301.3121,-126 310.5498,-126 319.4848,-126\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.7564,-129.5001 329.7563,-126 319.7563,-122.5001 319.7564,-129.5001\"/>\n</g>\n<!-- /outputs/13 -->\n<g id=\"node6\" class=\"node\">\n<title>/outputs/13</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"293,-198 239,-198 239,-162 293,-162 293,-198\"/>\n<text text-anchor=\"start\" x=\"248\" y=\"-177\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/16 -->\n<g id=\"node9\" class=\"node\">\n<title>/outputs/16</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"391,-198 330,-198 330,-162 391,-162 391,-198\"/>\n<text text-anchor=\"start\" x=\"338.5\" y=\"-177\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/13&#45;&gt;/outputs/16 -->\n<g id=\"edge7\" class=\"edge\">\n<title>/outputs/13&#45;&gt;/outputs/16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293.0799,-180C301.3121,-180 310.5498,-180 319.4848,-180\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.7564,-183.5001 329.7563,-180 319.7563,-176.5001 319.7564,-183.5001\"/>\n</g>\n<!-- /outputs/17 -->\n<g id=\"node10\" class=\"node\">\n<title>/outputs/17</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"482,-228 428,-228 428,-192 482,-192 482,-228\"/>\n<text text-anchor=\"start\" x=\"440\" y=\"-207\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n</g>\n<!-- /outputs/14&#45;&gt;/outputs/17 -->\n<g id=\"edge8\" class=\"edge\">\n<title>/outputs/14&#45;&gt;/outputs/17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M380.8511,-144.0006C384.2419,-147.0041 387.7214,-150.0888 391,-153 402.7283,-163.414 415.6495,-174.9163 426.7926,-184.845\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"424.7555,-187.7178 434.5497,-191.7584 429.413,-182.492 424.7555,-187.7178\"/>\n</g>\n<!-- /outputs/15&#45;&gt;/outputs/17 -->\n<g id=\"edge9\" class=\"edge\">\n<title>/outputs/15&#45;&gt;/outputs/17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M391.1814,-226.2079C399.796,-224.0201 409.2518,-221.6186 418.184,-219.3501\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"419.1427,-222.7178 427.9735,-216.8639 417.4196,-215.9332 419.1427,-222.7178\"/>\n</g>\n<!-- /outputs/16&#45;&gt;/outputs/17 -->\n<g id=\"edge10\" class=\"edge\">\n<title>/outputs/16&#45;&gt;/outputs/17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M391.1814,-189.7401C399.796,-192.4749 409.2518,-195.4768 418.184,-198.3124\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"417.3832,-201.7302 427.9735,-201.4201 419.5013,-195.0584 417.3832,-201.7302\"/>\n</g>\n<!-- /outputs/18 -->\n<g id=\"node11\" class=\"node\">\n<title>/outputs/18</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"607,-252 519,-252 519,-216 607,-216 607,-252\"/>\n<text text-anchor=\"start\" x=\"527\" y=\"-231\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">ConstantOfShape</text>\n</g>\n<!-- /outputs/17&#45;&gt;/outputs/18 -->\n<g id=\"edge11\" class=\"edge\">\n<title>/outputs/17&#45;&gt;/outputs/18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M482.253,-216.0562C490.4214,-217.8714 499.6822,-219.9294 508.9452,-221.9878\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"508.4246,-225.4574 518.9457,-224.2102 509.9431,-218.6241 508.4246,-225.4574\"/>\n</g>\n<!-- /outputs/18&#45;&gt;/outputs/24/25 -->\n<g id=\"edge12\" class=\"edge\">\n<title>/outputs/18&#45;&gt;/outputs/24/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M599.3371,-215.9157C620.8549,-205.1037 648.5956,-190.9855 673,-178 675.9192,-176.4467 678.9346,-174.8201 681.9574,-173.174\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"683.8789,-176.1119 690.9592,-168.2303 680.5092,-169.9763 683.8789,-176.1119\"/>\n<text text-anchor=\"middle\" x=\"649\" y=\"-204\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x128x128</text>\n</g>\n<!-- /outputs/19 -->\n<g id=\"node12\" class=\"node\">\n<title>/outputs/19</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"602,-198 524,-198 524,-162 602,-162 602,-198\"/>\n<text text-anchor=\"start\" x=\"532\" y=\"-177\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">prim::Constant</text>\n</g>\n<!-- /outputs/19&#45;&gt;/outputs/24/25 -->\n<g id=\"edge13\" class=\"edge\">\n<title>/outputs/19&#45;&gt;/outputs/24/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M602.113,-173.1868C626.1746,-168.9954 656.8407,-163.6536 680.5824,-159.5179\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"681.3727,-162.933 690.6237,-157.7688 680.1713,-156.0369 681.3727,-162.933\"/>\n</g>\n<!-- /outputs/20 -->\n<g id=\"node13\" class=\"node\">\n<title>/outputs/20</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"482,-36 428,-36 428,0 482,0 482,-36\"/>\n<text text-anchor=\"start\" x=\"440\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n</g>\n<!-- /outputs/23 -->\n<g id=\"node16\" class=\"node\">\n<title>/outputs/23</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"593.5,-36 532.5,-36 532.5,0 593.5,0 593.5,-36\"/>\n<text text-anchor=\"start\" x=\"541\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/20&#45;&gt;/outputs/23 -->\n<g id=\"edge14\" class=\"edge\">\n<title>/outputs/20&#45;&gt;/outputs/23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M482.253,-18C494.2839,-18 508.6847,-18 521.9718,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"522.3224,-21.5001 532.3224,-18 522.3224,-14.5001 522.3224,-21.5001\"/>\n</g>\n<!-- /outputs/21 -->\n<g id=\"node14\" class=\"node\">\n<title>/outputs/21</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"593.5,-144 532.5,-144 532.5,-108 593.5,-108 593.5,-144\"/>\n<text text-anchor=\"start\" x=\"541\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/21&#45;&gt;/outputs/24/25 -->\n<g id=\"edge15\" class=\"edge\">\n<title>/outputs/21&#45;&gt;/outputs/24/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M593.623,-131.3343C618.6248,-135.6895 654.0524,-141.8607 680.7058,-146.5036\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"680.3589,-149.9958 690.8112,-148.2639 681.5602,-143.0996 680.3589,-149.9958\"/>\n</g>\n<!-- /outputs/22 -->\n<g id=\"node15\" class=\"node\">\n<title>/outputs/22</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"593.5,-90 532.5,-90 532.5,-54 593.5,-54 593.5,-90\"/>\n<text text-anchor=\"start\" x=\"541\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/22&#45;&gt;/outputs/24/25 -->\n<g id=\"edge16\" class=\"edge\">\n<title>/outputs/22&#45;&gt;/outputs/24/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M593.623,-88.003C618.9566,-101.2419 654.9948,-120.0747 681.7625,-134.063\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"680.3274,-137.2621 690.8112,-138.7917 683.5695,-131.0581 680.3274,-137.2621\"/>\n</g>\n<!-- /outputs/23&#45;&gt;/outputs/24/25 -->\n<g id=\"edge17\" class=\"edge\">\n<title>/outputs/23&#45;&gt;/outputs/24/25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M593.6934,-35.9968C598.2299,-38.8963 602.7905,-41.9501 607,-45 638.1523,-67.5707 645.6658,-73.9308 673,-101 681.1,-109.0215 689.418,-118.2933 696.6644,-126.7668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"694.1238,-129.1836 703.2417,-134.5795 699.4788,-124.6753 694.1238,-129.1836\"/>\n</g>\n<!-- /outputs/26 -->\n<g id=\"node18\" class=\"node\">\n<title>/outputs/26</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"883,-171 829,-171 829,-135 883,-135 883,-171\"/>\n<text text-anchor=\"start\" x=\"839\" y=\"-150\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Squeeze</text>\n</g>\n<!-- /outputs/24/25&#45;&gt;/outputs/26 -->\n<g id=\"edge18\" class=\"edge\">\n<title>/outputs/24/25&#45;&gt;/outputs/26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M745.2644,-153C766.2445,-153 795.4706,-153 818.6299,-153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"818.7923,-156.5001 828.7923,-153 818.7922,-149.5001 818.7923,-156.5001\"/>\n<text text-anchor=\"middle\" x=\"787\" y=\"-156\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x128x128</text>\n</g>\n<!-- /outputs/27 -->\n<g id=\"node19\" class=\"node\">\n<title>/outputs/27</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1010,-171 956,-171 956,-135 1010,-135 1010,-171\"/>\n<text text-anchor=\"start\" x=\"970\" y=\"-150\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n</g>\n<!-- /outputs/26&#45;&gt;/outputs/27 -->\n<g id=\"edge19\" class=\"edge\">\n<title>/outputs/26&#45;&gt;/outputs/27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M883.2447,-153C901.492,-153 925.746,-153 945.7693,-153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"945.8004,-156.5001 955.8004,-153 945.8003,-149.5001 945.8004,-156.5001\"/>\n<text text-anchor=\"middle\" x=\"919.5\" y=\"-156\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x128</text>\n</g>\n<!-- /outputs/29 -->\n<g id=\"node21\" class=\"node\">\n<title>/outputs/29</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1127,-133 1073,-133 1073,-97 1127,-97 1127,-133\"/>\n<text text-anchor=\"start\" x=\"1083\" y=\"-112\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Reshape</text>\n</g>\n<!-- /outputs/27&#45;&gt;/outputs/29 -->\n<g id=\"edge20\" class=\"edge\">\n<title>/outputs/27&#45;&gt;/outputs/29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1010.1362,-144.1865C1025.824,-139.0914 1045.784,-132.6086 1062.9061,-127.0476\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1064.1759,-130.3152 1072.6056,-123.8973 1062.0135,-123.6576 1064.1759,-130.3152\"/>\n<text text-anchor=\"middle\" x=\"1041.5\" y=\"-140\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x1</text>\n</g>\n<!-- /outputs/28 -->\n<g id=\"node20\" class=\"node\">\n<title>/outputs/28</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1010,-117 956,-117 956,-81 1010,-81 1010,-117\"/>\n<text text-anchor=\"start\" x=\"965\" y=\"-96\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/28&#45;&gt;/outputs/29 -->\n<g id=\"edge21\" class=\"edge\">\n<title>/outputs/28&#45;&gt;/outputs/29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1010.1362,-102.7109C1025.6773,-104.8362 1045.4112,-107.5349 1062.4253,-109.8616\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1062.2236,-113.3665 1072.6056,-111.2538 1063.1721,-106.431 1062.2236,-113.3665\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lv9Ny9di6VcI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5t1Afn4xO11",
        "colab": {}
      },
      "source": [
        "def compute_binary_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(data_loader):\n",
        "            logits = model(batch_data.text)\n",
        "            predicted_labels = (torch.sigmoid(logits) > 0.5).long()\n",
        "            num_examples += batch_data.label.size(0)\n",
        "            correct_pred += (predicted_labels == batch_data.label.long()).sum()\n",
        "        return correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EABZM8Vo0ilB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a465344-6c26-4da0-9719-4c337f3d46bd"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "        \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits = model(batch_data.text)\n",
        "        cost = F.binary_cross_entropy_with_logits(logits, batch_data.label)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
        "                   f'Cost: {cost:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_binary_accuracy(model, train_loader, DEVICE):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_binary_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "    \n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_binary_accuracy(model, test_loader, DEVICE):.2f}%')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/015 | Batch 000/157 | Cost: 0.6869\n",
            "Epoch: 001/015 | Batch 050/157 | Cost: 0.6922\n",
            "Epoch: 001/015 | Batch 100/157 | Cost: 0.6951\n",
            "Epoch: 001/015 | Batch 150/157 | Cost: 0.6941\n",
            "training accuracy: 50.02%\n",
            "valid accuracy: 49.48%\n",
            "Time elapsed: 6.24 min\n",
            "Epoch: 002/015 | Batch 000/157 | Cost: 0.6873\n",
            "Epoch: 002/015 | Batch 050/157 | Cost: 0.6935\n",
            "Epoch: 002/015 | Batch 100/157 | Cost: 0.7009\n",
            "Epoch: 002/015 | Batch 150/157 | Cost: 0.6931\n",
            "training accuracy: 50.12%\n",
            "valid accuracy: 49.28%\n",
            "Time elapsed: 12.17 min\n",
            "Epoch: 003/015 | Batch 000/157 | Cost: 0.6934\n",
            "Epoch: 003/015 | Batch 050/157 | Cost: 0.6919\n",
            "Epoch: 003/015 | Batch 100/157 | Cost: 0.6906\n",
            "Epoch: 003/015 | Batch 150/157 | Cost: 0.6893\n",
            "training accuracy: 49.99%\n",
            "valid accuracy: 49.92%\n",
            "Time elapsed: 18.21 min\n",
            "Epoch: 004/015 | Batch 000/157 | Cost: 0.6921\n",
            "Epoch: 004/015 | Batch 050/157 | Cost: 0.6949\n",
            "Epoch: 004/015 | Batch 100/157 | Cost: 0.6941\n",
            "Epoch: 004/015 | Batch 150/157 | Cost: 0.6913\n",
            "training accuracy: 50.10%\n",
            "valid accuracy: 49.68%\n",
            "Time elapsed: 24.65 min\n",
            "Epoch: 005/015 | Batch 000/157 | Cost: 0.6879\n",
            "Epoch: 005/015 | Batch 050/157 | Cost: 0.6917\n",
            "Epoch: 005/015 | Batch 100/157 | Cost: 0.6943\n",
            "Epoch: 005/015 | Batch 150/157 | Cost: 0.6967\n",
            "training accuracy: 50.02%\n",
            "valid accuracy: 49.82%\n",
            "Time elapsed: 31.32 min\n",
            "Epoch: 006/015 | Batch 000/157 | Cost: 0.6971\n",
            "Epoch: 006/015 | Batch 050/157 | Cost: 0.6927\n",
            "Epoch: 006/015 | Batch 100/157 | Cost: 0.6932\n",
            "Epoch: 006/015 | Batch 150/157 | Cost: 0.6915\n",
            "training accuracy: 50.02%\n",
            "valid accuracy: 49.94%\n",
            "Time elapsed: 38.06 min\n",
            "Epoch: 007/015 | Batch 000/157 | Cost: 0.6908\n",
            "Epoch: 007/015 | Batch 050/157 | Cost: 0.6930\n",
            "Epoch: 007/015 | Batch 100/157 | Cost: 0.6964\n",
            "Epoch: 007/015 | Batch 150/157 | Cost: 0.6922\n",
            "training accuracy: 50.05%\n",
            "valid accuracy: 49.58%\n",
            "Time elapsed: 44.92 min\n",
            "Epoch: 008/015 | Batch 000/157 | Cost: 0.6938\n",
            "Epoch: 008/015 | Batch 050/157 | Cost: 0.6995\n",
            "Epoch: 008/015 | Batch 100/157 | Cost: 0.6928\n",
            "Epoch: 008/015 | Batch 150/157 | Cost: 0.6922\n",
            "training accuracy: 50.08%\n",
            "valid accuracy: 50.00%\n",
            "Time elapsed: 51.83 min\n",
            "Epoch: 009/015 | Batch 000/157 | Cost: 0.6886\n",
            "Epoch: 009/015 | Batch 050/157 | Cost: 0.6950\n",
            "Epoch: 009/015 | Batch 100/157 | Cost: 0.6921\n",
            "Epoch: 009/015 | Batch 150/157 | Cost: 0.6935\n",
            "training accuracy: 50.08%\n",
            "valid accuracy: 50.24%\n",
            "Time elapsed: 58.82 min\n",
            "Epoch: 010/015 | Batch 000/157 | Cost: 0.6935\n",
            "Epoch: 010/015 | Batch 050/157 | Cost: 0.6908\n",
            "Epoch: 010/015 | Batch 100/157 | Cost: 0.6942\n",
            "Epoch: 010/015 | Batch 150/157 | Cost: 0.6910\n",
            "training accuracy: 50.08%\n",
            "valid accuracy: 49.78%\n",
            "Time elapsed: 65.94 min\n",
            "Epoch: 011/015 | Batch 000/157 | Cost: 0.6929\n",
            "Epoch: 011/015 | Batch 050/157 | Cost: 0.6923\n",
            "Epoch: 011/015 | Batch 100/157 | Cost: 0.6911\n",
            "Epoch: 011/015 | Batch 150/157 | Cost: 0.6927\n",
            "training accuracy: 50.09%\n",
            "valid accuracy: 50.14%\n",
            "Time elapsed: 73.21 min\n",
            "Epoch: 012/015 | Batch 000/157 | Cost: 0.6965\n",
            "Epoch: 012/015 | Batch 050/157 | Cost: 0.6931\n",
            "Epoch: 012/015 | Batch 100/157 | Cost: 0.6929\n",
            "Epoch: 012/015 | Batch 150/157 | Cost: 0.6973\n",
            "training accuracy: 50.22%\n",
            "valid accuracy: 50.18%\n",
            "Time elapsed: 80.71 min\n",
            "Epoch: 013/015 | Batch 000/157 | Cost: 0.6919\n",
            "Epoch: 013/015 | Batch 050/157 | Cost: 0.6905\n",
            "Epoch: 013/015 | Batch 100/157 | Cost: 0.6926\n",
            "Epoch: 013/015 | Batch 150/157 | Cost: 0.6962\n",
            "training accuracy: 50.23%\n",
            "valid accuracy: 49.88%\n",
            "Time elapsed: 88.20 min\n",
            "Epoch: 014/015 | Batch 000/157 | Cost: 0.6926\n",
            "Epoch: 014/015 | Batch 050/157 | Cost: 0.6922\n",
            "Epoch: 014/015 | Batch 100/157 | Cost: 0.6982\n",
            "Epoch: 014/015 | Batch 150/157 | Cost: 0.6941\n",
            "training accuracy: 50.12%\n",
            "valid accuracy: 50.58%\n",
            "Time elapsed: 95.85 min\n",
            "Epoch: 015/015 | Batch 000/157 | Cost: 0.6920\n",
            "Epoch: 015/015 | Batch 050/157 | Cost: 0.6949\n",
            "Epoch: 015/015 | Batch 100/157 | Cost: 0.6926\n",
            "Epoch: 015/015 | Batch 150/157 | Cost: 0.6936\n",
            "training accuracy: 50.23%\n",
            "valid accuracy: 49.84%\n",
            "Time elapsed: 103.84 min\n",
            "Total Training Time: 103.84 min\n",
            "Test accuracy: 49.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0fFkgUdUJOzD",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    # based on:\n",
        "    # https://github.com/bentrevett/pytorch-sentiment-analysis/blob/\n",
        "    # master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WE9axsgOJQaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71dd4944-19b2-41b9-97af-f14bebd27f64"
      },
      "source": [
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"I really love this movie. This movie is so great!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability positive:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5337774157524109"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}