{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "convnet-vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "371px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4e034bbe83a4c6492508a5742385c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93e07b50ebe444f4a4891dd034801472",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34a18bda6b6e40c5ac91442796c8ef1f",
              "IPY_MODEL_a7a90fb0b5d944f18ae07207fb05cfc7"
            ]
          }
        },
        "93e07b50ebe444f4a4891dd034801472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34a18bda6b6e40c5ac91442796c8ef1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5845f486eb49433c9c8f6ed94b2aec70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_449f6628b8454619ad3a6b9e61c73892"
          }
        },
        "a7a90fb0b5d944f18ae07207fb05cfc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95a9b23bd9cd415ebea7d01d624a125e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 17478174.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be725d1cad564b0f827df7e90b0bdc68"
          }
        },
        "5845f486eb49433c9c8f6ed94b2aec70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "449f6628b8454619ad3a6b9e61c73892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95a9b23bd9cd415ebea7d01d624a125e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be725d1cad564b0f827df7e90b0bdc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UEBilEjLj5wY"
      },
      "source": [
        "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
        "- Author: Sebastian Raschka\n",
        "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF7EVqSAC1ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q IPython\n",
        "!pip install -q ipykernel\n",
        "!pip install -q watermark\n",
        "!pip install -q matplotlib\n",
        "!pip install -q sklearn\n",
        "!pip install -q pandas\n",
        "!pip install -q pydot\n",
        "!pip install -q hiddenlayer\n",
        "!pip install -q graphviz"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GOzuY8Yvj5wb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "94cb7192-f6ff-467c-e895-72618b2b8f40"
      },
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka' -v -p torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sebastian Raschka \n",
            "\n",
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "torch 1.5.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MEu9MiOxj5wk"
      },
      "source": [
        "- Runs on CPU (not recommended here) or GPU (if available)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rH4XmErYj5wm"
      },
      "source": [
        "# Model Zoo -- Convolutional Neural Network (VGG19 Architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQudkoq4CtYE",
        "colab_type": "text"
      },
      "source": [
        "Implementation of the VGG-19 architecture on Cifar10.  \n",
        "\n",
        "\n",
        "Reference for VGG-19:\n",
        "    \n",
        "- Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n",
        "\n",
        "\n",
        "The following table (taken from Simonyan & Zisserman referenced above) summarizes the VGG19 architecture:\n",
        "\n",
        "![](https://github.com/DeepSE/deeplearning-models/blob/master/pytorch_ipynb/images/vgg19/vgg19-arch-table.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MkoGLH_Tj5wn"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ORj09gnrj5wp",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PvgJ_0i7j5wt"
      },
      "source": [
        "## Settings and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NnT0sZIwj5wu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "a4e034bbe83a4c6492508a5742385c6d",
            "93e07b50ebe444f4a4891dd034801472",
            "34a18bda6b6e40c5ac91442796c8ef1f",
            "a7a90fb0b5d944f18ae07207fb05cfc7",
            "5845f486eb49433c9c8f6ed94b2aec70",
            "449f6628b8454619ad3a6b9e61c73892",
            "95a9b23bd9cd415ebea7d01d624a125e",
            "be725d1cad564b0f827df7e90b0bdc68"
          ]
        },
        "outputId": "e50f6a2d-c776-4237-fefc-6347c5eb1f9a"
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', DEVICE)\n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "# Architecture\n",
        "num_features = 784\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "##########################\n",
        "### MNIST DATASET\n",
        "##########################\n",
        "\n",
        "# Note transforms.ToTensor() scales input images\n",
        "# to 0-1 range\n",
        "train_dataset = datasets.CIFAR10(root='data', \n",
        "                                 train=True, \n",
        "                                 transform=transforms.ToTensor(),\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=batch_size, \n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size, \n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e034bbe83a4c6492508a5742385c6d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6hghKPxj5w0"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_lza9t_uj5w1",
        "colab": {}
      },
      "source": [
        "##########################\n",
        "### MODEL\n",
        "##########################\n",
        "\n",
        "\n",
        "class VGG16(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(VGG16, self).__init__()\n",
        "        \n",
        "        # calculate same padding:\n",
        "        # (w - k + 2*p)/s + 1 = o\n",
        "        # => p = (s(o-1) - w + k)/2\n",
        "        \n",
        "        self.block_1 = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=3,\n",
        "                          out_channels=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          # (1(32-1)- 32 + 3)/2 = 1\n",
        "                          padding=1), \n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=64,\n",
        "                          out_channels=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.block_2 = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=64,\n",
        "                          out_channels=128,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=128,\n",
        "                          out_channels=128,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.block_3 = nn.Sequential(        \n",
        "                nn.Conv2d(in_channels=128,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),        \n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "          \n",
        "        self.block_4 = nn.Sequential(   \n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),        \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),        \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),   \n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.block_5 = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),            \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),            \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),   \n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))             \n",
        "        )\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "                nn.Linear(512, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(4096, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(4096, num_classes)\n",
        "        )\n",
        "            \n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d):\n",
        "                #n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                #m.weight.data.normal_(0, np.sqrt(2. / n))\n",
        "                m.weight.detach().normal_(0, 0.05)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.detach().zero_()\n",
        "            elif isinstance(m, torch.nn.Linear):\n",
        "                m.weight.detach().normal_(0, 0.05)\n",
        "                m.bias.detach().detach().zero_()\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        x = self.block_4(x)\n",
        "        x = self.block_5(x)\n",
        "        logits = self.classifier(x.view(-1, 512))\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "\n",
        "        return logits, probas\n",
        "\n",
        "    \n",
        "torch.manual_seed(random_seed)\n",
        "model = VGG16(num_features=num_features,\n",
        "              num_classes=num_classes)\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7UxGnbHC64x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "689a42f4-bbc2-4f23-be77-0f458c990a83"
      },
      "source": [
        "import hiddenlayer as hl\n",
        "hl.build_graph(model, torch.zeros([128, 3, 32, 32]).to(DEVICE))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hiddenlayer.graph.Graph at 0x7f07071d5240>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"2331pt\" height=\"166pt\"\n viewBox=\"0.00 0.00 2331.00 166.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 130)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-130 2259,-130 2259,36 -72,36\"/>\n<!-- /outputs/43 -->\n<g id=\"node1\" class=\"node\">\n<title>/outputs/43</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"254,-40 184,-40 184,-4 254,-4 254,-40\"/>\n<text text-anchor=\"start\" x=\"192\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n</g>\n<!-- 13759945506048259258 -->\n<g id=\"node11\" class=\"node\">\n<title>13759945506048259258</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"438,-44 354,-44 354,0 438,0 438,-44\"/>\n<text text-anchor=\"start\" x=\"362\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv3x3 &gt; Relu</text>\n<text text-anchor=\"start\" x=\"423\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x2</text>\n</g>\n<!-- /outputs/43&#45;&gt;13759945506048259258 -->\n<g id=\"edge5\" class=\"edge\">\n<title>/outputs/43&#45;&gt;13759945506048259258</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M254.3932,-22C279.9108,-22 314.7758,-22 343.525,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"343.8114,-25.5001 353.8114,-22 343.8114,-18.5001 343.8114,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"304\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x64x16x16</text>\n</g>\n<!-- /outputs/48 -->\n<g id=\"node2\" class=\"node\">\n<title>/outputs/48</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"613,-40 543,-40 543,-4 613,-4 613,-40\"/>\n<text text-anchor=\"start\" x=\"551\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n</g>\n<!-- 5952610958276041882 -->\n<g id=\"node13\" class=\"node\">\n<title>5952610958276041882</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"791,-44 707,-44 707,0 791,0 791,-44\"/>\n<text text-anchor=\"start\" x=\"715\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv3x3 &gt; Relu</text>\n<text text-anchor=\"start\" x=\"776\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x4</text>\n</g>\n<!-- /outputs/48&#45;&gt;5952610958276041882 -->\n<g id=\"edge9\" class=\"edge\">\n<title>/outputs/48&#45;&gt;5952610958276041882</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M613.017,-22C637.1037,-22 669.5182,-22 696.6582,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"696.7732,-25.5001 706.7732,-22 696.7732,-18.5001 696.7732,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"660\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x128x8x8</text>\n</g>\n<!-- /outputs/57 -->\n<g id=\"node3\" class=\"node\">\n<title>/outputs/57</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"955,-40 885,-40 885,-4 955,-4 955,-40\"/>\n<text text-anchor=\"start\" x=\"893\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n</g>\n<!-- 11066391339901431287 -->\n<g id=\"node14\" class=\"node\">\n<title>11066391339901431287</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1133,-44 1049,-44 1049,0 1133,0 1133,-44\"/>\n<text text-anchor=\"start\" x=\"1057\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv3x3 &gt; Relu</text>\n<text text-anchor=\"start\" x=\"1118\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x4</text>\n</g>\n<!-- /outputs/57&#45;&gt;11066391339901431287 -->\n<g id=\"edge11\" class=\"edge\">\n<title>/outputs/57&#45;&gt;11066391339901431287</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M955.017,-22C979.1037,-22 1011.5182,-22 1038.6582,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1038.7732,-25.5001 1048.7732,-22 1038.7732,-18.5001 1038.7732,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"1002\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x256x4x4</text>\n</g>\n<!-- /outputs/66 -->\n<g id=\"node4\" class=\"node\">\n<title>/outputs/66</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1297,-40 1227,-40 1227,-4 1297,-4 1297,-40\"/>\n<text text-anchor=\"start\" x=\"1235\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n</g>\n<!-- 5251318902769903755 -->\n<g id=\"node15\" class=\"node\">\n<title>5251318902769903755</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1475,-44 1391,-44 1391,0 1475,0 1475,-44\"/>\n<text text-anchor=\"start\" x=\"1399\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv3x3 &gt; Relu</text>\n<text text-anchor=\"start\" x=\"1460\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x4</text>\n</g>\n<!-- /outputs/66&#45;&gt;5251318902769903755 -->\n<g id=\"edge13\" class=\"edge\">\n<title>/outputs/66&#45;&gt;5251318902769903755</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1297.017,-22C1321.1037,-22 1353.5182,-22 1380.6582,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1380.7732,-25.5001 1390.7732,-22 1380.7732,-18.5001 1380.7732,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"1344\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x512x2x2</text>\n</g>\n<!-- /outputs/75 -->\n<g id=\"node5\" class=\"node\">\n<title>/outputs/75</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1639,-40 1569,-40 1569,-4 1639,-4 1639,-40\"/>\n<text text-anchor=\"start\" x=\"1577\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n</g>\n<!-- /outputs/77 -->\n<g id=\"node7\" class=\"node\">\n<title>/outputs/77</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1787,-67 1733,-67 1733,-31 1787,-31 1787,-67\"/>\n<text text-anchor=\"start\" x=\"1743\" y=\"-46\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Reshape</text>\n</g>\n<!-- /outputs/75&#45;&gt;/outputs/77 -->\n<g id=\"edge1\" class=\"edge\">\n<title>/outputs/75&#45;&gt;/outputs/77</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1639.0094,-28.0593C1663.9589,-32.3775 1697.4424,-38.1727 1722.8599,-42.5719\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1722.4127,-46.0465 1732.8631,-44.3032 1723.6065,-39.149 1722.4127,-46.0465\"/>\n<text text-anchor=\"middle\" x=\"1686\" y=\"-44\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x512x1x1</text>\n</g>\n<!-- /outputs/76 -->\n<g id=\"node6\" class=\"node\">\n<title>/outputs/76</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1631,-94 1577,-94 1577,-58 1631,-58 1631,-94\"/>\n<text text-anchor=\"start\" x=\"1586\" y=\"-73\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/76&#45;&gt;/outputs/77 -->\n<g id=\"edge2\" class=\"edge\">\n<title>/outputs/76&#45;&gt;/outputs/77</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1631.1731,-71.297C1656.5964,-66.8968 1694.7796,-60.2881 1722.9808,-55.4072\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1723.6204,-58.8486 1732.877,-53.6944 1722.4266,-51.9511 1723.6204,-58.8486\"/>\n</g>\n<!-- 3422091343757813889 -->\n<g id=\"node12\" class=\"node\">\n<title>3422091343757813889</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1932,-71 1860,-71 1860,-27 1932,-27 1932,-71\"/>\n<text text-anchor=\"start\" x=\"1868\" y=\"-55\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n<text text-anchor=\"start\" x=\"1917\" y=\"-34\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x2</text>\n</g>\n<!-- /outputs/77&#45;&gt;3422091343757813889 -->\n<g id=\"edge7\" class=\"edge\">\n<title>/outputs/77&#45;&gt;3422091343757813889</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1787.1948,-49C1805.0329,-49 1828.8159,-49 1849.5963,-49\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1849.8287,-52.5001 1859.8287,-49 1849.8286,-45.5001 1849.8287,-52.5001\"/>\n<text text-anchor=\"middle\" x=\"1823.5\" y=\"-52\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x512</text>\n</g>\n<!-- /outputs/82 -->\n<g id=\"node8\" class=\"node\">\n<title>/outputs/82</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2065,-67 2011,-67 2011,-31 2065,-31 2065,-67\"/>\n<text text-anchor=\"start\" x=\"2025\" y=\"-46\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n</g>\n<!-- /outputs/83 -->\n<g id=\"node9\" class=\"node\">\n<title>/outputs/83</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"2187,-67 2133,-67 2133,-31 2187,-31 2187,-67\"/>\n<text text-anchor=\"start\" x=\"2143\" y=\"-46\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Softmax</text>\n</g>\n<!-- /outputs/82&#45;&gt;/outputs/83 -->\n<g id=\"edge3\" class=\"edge\">\n<title>/outputs/82&#45;&gt;/outputs/83</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2065.0758,-49C2082.0553,-49 2104.1767,-49 2122.7924,-49\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2123,-52.5001 2132.9999,-49 2122.9999,-45.5001 2123,-52.5001\"/>\n<text text-anchor=\"middle\" x=\"2099\" y=\"-52\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x10</text>\n</g>\n<!-- 12071460654965370937 -->\n<g id=\"node10\" class=\"node\">\n<title>12071460654965370937</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"84,-44 0,-44 0,0 84,0 84,-44\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv3x3 &gt; Relu</text>\n<text text-anchor=\"start\" x=\"69\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x2</text>\n</g>\n<!-- 12071460654965370937&#45;&gt;/outputs/43 -->\n<g id=\"edge4\" class=\"edge\">\n<title>12071460654965370937&#45;&gt;/outputs/43</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M84.3959,-22C111.3301,-22 146.1688,-22 173.6543,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.7966,-25.5001 183.7965,-22 173.7965,-18.5001 173.7966,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"134\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x64x32x32</text>\n</g>\n<!-- 13759945506048259258&#45;&gt;/outputs/48 -->\n<g id=\"edge6\" class=\"edge\">\n<title>13759945506048259258&#45;&gt;/outputs/48</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M438.2119,-22C466.4561,-22 503.6027,-22 532.5038,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"532.7468,-25.5001 542.7468,-22 532.7467,-18.5001 532.7468,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"490.5\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x128x16x16</text>\n</g>\n<!-- 3422091343757813889&#45;&gt;/outputs/82 -->\n<g id=\"edge8\" class=\"edge\">\n<title>3422091343757813889&#45;&gt;/outputs/82</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1932.2,-49C1953.1476,-49 1979.4645,-49 2000.6106,-49\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2000.8349,-52.5001 2010.8349,-49 2000.8348,-45.5001 2000.8349,-52.5001\"/>\n<text text-anchor=\"middle\" x=\"1971.5\" y=\"-52\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x4096</text>\n</g>\n<!-- 5952610958276041882&#45;&gt;/outputs/57 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5952610958276041882&#45;&gt;/outputs/57</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M791.2697,-22C816.5651,-22 848.7113,-22 874.5519,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"874.8392,-25.5001 884.8391,-22 874.8391,-18.5001 874.8392,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"838\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x256x8x8</text>\n</g>\n<!-- 11066391339901431287&#45;&gt;/outputs/66 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11066391339901431287&#45;&gt;/outputs/66</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1133.2697,-22C1158.5651,-22 1190.7113,-22 1216.5519,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1216.8392,-25.5001 1226.8391,-22 1216.8391,-18.5001 1216.8392,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"1180\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x512x4x4</text>\n</g>\n<!-- 5251318902769903755&#45;&gt;/outputs/75 -->\n<g id=\"edge14\" class=\"edge\">\n<title>5251318902769903755&#45;&gt;/outputs/75</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1475.2697,-22C1500.5651,-22 1532.7113,-22 1558.5519,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1558.8392,-25.5001 1568.8391,-22 1558.8391,-18.5001 1558.8392,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"1522\" y=\"-25\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">128x512x2x2</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RAodboScj5w6"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dzh3ROmRj5w7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eadd1dfe-bf23-4af3-f2ce-054bc41adebc"
      },
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "            \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "def compute_epoch_loss(model, data_loader):\n",
        "    model.eval()\n",
        "    curr_loss, num_examples = 0., 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "            logits, probas = model(features)\n",
        "            loss = F.cross_entropy(logits, targets, reduction='sum')\n",
        "            num_examples += targets.size(0)\n",
        "            curr_loss += loss\n",
        "\n",
        "        curr_loss = curr_loss / num_examples\n",
        "        return curr_loss\n",
        "    \n",
        "    \n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "            \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
        "                   %(epoch+1, num_epochs, batch_idx, \n",
        "                     len(train_loader), cost))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%% | Loss: %.3f' % (\n",
        "              epoch+1, num_epochs, \n",
        "              compute_accuracy(model, train_loader),\n",
        "              compute_epoch_loss(model, train_loader)))\n",
        "\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "    \n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/020 | Batch 0000/0391 | Cost: 1061.4154\n",
            "Epoch: 001/020 | Batch 0050/0391 | Cost: 2.3029\n",
            "Epoch: 001/020 | Batch 0100/0391 | Cost: 1.9784\n",
            "Epoch: 001/020 | Batch 0150/0391 | Cost: 1.9533\n",
            "Epoch: 001/020 | Batch 0200/0391 | Cost: 1.8397\n",
            "Epoch: 001/020 | Batch 0250/0391 | Cost: 1.7760\n",
            "Epoch: 001/020 | Batch 0300/0391 | Cost: 1.8241\n",
            "Epoch: 001/020 | Batch 0350/0391 | Cost: 1.7632\n",
            "Epoch: 001/020 | Train: 32.588% | Loss: 1.733\n",
            "Time elapsed: 4.61 min\n",
            "Epoch: 002/020 | Batch 0000/0391 | Cost: 1.8287\n",
            "Epoch: 002/020 | Batch 0050/0391 | Cost: 1.8992\n",
            "Epoch: 002/020 | Batch 0100/0391 | Cost: 1.5520\n",
            "Epoch: 002/020 | Batch 0150/0391 | Cost: 1.5686\n",
            "Epoch: 002/020 | Batch 0200/0391 | Cost: 1.4790\n",
            "Epoch: 002/020 | Batch 0250/0391 | Cost: 1.4339\n",
            "Epoch: 002/020 | Batch 0300/0391 | Cost: 1.5641\n",
            "Epoch: 002/020 | Batch 0350/0391 | Cost: 1.5211\n",
            "Epoch: 002/020 | Train: 49.878% | Loss: 1.369\n",
            "Time elapsed: 9.21 min\n",
            "Epoch: 003/020 | Batch 0000/0391 | Cost: 1.3988\n",
            "Epoch: 003/020 | Batch 0050/0391 | Cost: 1.2016\n",
            "Epoch: 003/020 | Batch 0100/0391 | Cost: 1.3821\n",
            "Epoch: 003/020 | Batch 0150/0391 | Cost: 1.3700\n",
            "Epoch: 003/020 | Batch 0200/0391 | Cost: 1.4340\n",
            "Epoch: 003/020 | Batch 0250/0391 | Cost: 1.4271\n",
            "Epoch: 003/020 | Batch 0300/0391 | Cost: 1.3866\n",
            "Epoch: 003/020 | Batch 0350/0391 | Cost: 1.4448\n",
            "Epoch: 003/020 | Train: 53.490% | Loss: 1.274\n",
            "Time elapsed: 13.82 min\n",
            "Epoch: 004/020 | Batch 0000/0391 | Cost: 1.2869\n",
            "Epoch: 004/020 | Batch 0050/0391 | Cost: 1.2983\n",
            "Epoch: 004/020 | Batch 0100/0391 | Cost: 1.2728\n",
            "Epoch: 004/020 | Batch 0150/0391 | Cost: 1.1564\n",
            "Epoch: 004/020 | Batch 0200/0391 | Cost: 1.0972\n",
            "Epoch: 004/020 | Batch 0250/0391 | Cost: 1.1532\n",
            "Epoch: 004/020 | Batch 0300/0391 | Cost: 1.1784\n",
            "Epoch: 004/020 | Batch 0350/0391 | Cost: 1.1819\n",
            "Epoch: 004/020 | Train: 56.634% | Loss: 1.204\n",
            "Time elapsed: 18.43 min\n",
            "Epoch: 005/020 | Batch 0000/0391 | Cost: 1.1228\n",
            "Epoch: 005/020 | Batch 0050/0391 | Cost: 1.1564\n",
            "Epoch: 005/020 | Batch 0100/0391 | Cost: 1.0147\n",
            "Epoch: 005/020 | Batch 0150/0391 | Cost: 1.1273\n",
            "Epoch: 005/020 | Batch 0200/0391 | Cost: 0.9425\n",
            "Epoch: 005/020 | Batch 0250/0391 | Cost: 1.0747\n",
            "Epoch: 005/020 | Batch 0300/0391 | Cost: 1.1276\n",
            "Epoch: 005/020 | Batch 0350/0391 | Cost: 1.2110\n",
            "Epoch: 005/020 | Train: 62.844% | Loss: 1.038\n",
            "Time elapsed: 23.03 min\n",
            "Epoch: 006/020 | Batch 0000/0391 | Cost: 0.9599\n",
            "Epoch: 006/020 | Batch 0050/0391 | Cost: 0.9764\n",
            "Epoch: 006/020 | Batch 0100/0391 | Cost: 0.9482\n",
            "Epoch: 006/020 | Batch 0150/0391 | Cost: 1.1014\n",
            "Epoch: 006/020 | Batch 0200/0391 | Cost: 1.0980\n",
            "Epoch: 006/020 | Batch 0250/0391 | Cost: 0.7146\n",
            "Epoch: 006/020 | Batch 0300/0391 | Cost: 1.0462\n",
            "Epoch: 006/020 | Batch 0350/0391 | Cost: 1.0740\n",
            "Epoch: 006/020 | Train: 68.248% | Loss: 0.882\n",
            "Time elapsed: 27.64 min\n",
            "Epoch: 007/020 | Batch 0000/0391 | Cost: 1.0146\n",
            "Epoch: 007/020 | Batch 0050/0391 | Cost: 1.0388\n",
            "Epoch: 007/020 | Batch 0100/0391 | Cost: 1.1543\n",
            "Epoch: 007/020 | Batch 0150/0391 | Cost: 1.0155\n",
            "Epoch: 007/020 | Batch 0200/0391 | Cost: 0.8197\n",
            "Epoch: 007/020 | Batch 0250/0391 | Cost: 1.0015\n",
            "Epoch: 007/020 | Batch 0300/0391 | Cost: 1.0565\n",
            "Epoch: 007/020 | Batch 0350/0391 | Cost: 0.9709\n",
            "Epoch: 007/020 | Train: 64.582% | Loss: 0.963\n",
            "Time elapsed: 32.24 min\n",
            "Epoch: 008/020 | Batch 0000/0391 | Cost: 1.0335\n",
            "Epoch: 008/020 | Batch 0050/0391 | Cost: 1.0126\n",
            "Epoch: 008/020 | Batch 0100/0391 | Cost: 0.7439\n",
            "Epoch: 008/020 | Batch 0150/0391 | Cost: 1.0409\n",
            "Epoch: 008/020 | Batch 0200/0391 | Cost: 1.0831\n",
            "Epoch: 008/020 | Batch 0250/0391 | Cost: 1.0905\n",
            "Epoch: 008/020 | Batch 0300/0391 | Cost: 0.9062\n",
            "Epoch: 008/020 | Batch 0350/0391 | Cost: 0.9048\n",
            "Epoch: 008/020 | Train: 69.984% | Loss: 0.847\n",
            "Time elapsed: 36.85 min\n",
            "Epoch: 009/020 | Batch 0000/0391 | Cost: 0.7430\n",
            "Epoch: 009/020 | Batch 0050/0391 | Cost: 0.7811\n",
            "Epoch: 009/020 | Batch 0100/0391 | Cost: 0.8621\n",
            "Epoch: 009/020 | Batch 0150/0391 | Cost: 0.8378\n",
            "Epoch: 009/020 | Batch 0200/0391 | Cost: 0.7797\n",
            "Epoch: 009/020 | Batch 0250/0391 | Cost: 0.8398\n",
            "Epoch: 009/020 | Batch 0300/0391 | Cost: 0.7331\n",
            "Epoch: 009/020 | Batch 0350/0391 | Cost: 0.7951\n",
            "Epoch: 009/020 | Train: 73.738% | Loss: 0.751\n",
            "Time elapsed: 41.46 min\n",
            "Epoch: 010/020 | Batch 0000/0391 | Cost: 0.6359\n",
            "Epoch: 010/020 | Batch 0050/0391 | Cost: 0.7745\n",
            "Epoch: 010/020 | Batch 0100/0391 | Cost: 0.7155\n",
            "Epoch: 010/020 | Batch 0150/0391 | Cost: 0.5714\n",
            "Epoch: 010/020 | Batch 0200/0391 | Cost: 0.7268\n",
            "Epoch: 010/020 | Batch 0250/0391 | Cost: 0.5820\n",
            "Epoch: 010/020 | Batch 0300/0391 | Cost: 0.5438\n",
            "Epoch: 010/020 | Batch 0350/0391 | Cost: 0.7152\n",
            "Epoch: 010/020 | Train: 77.590% | Loss: 0.648\n",
            "Time elapsed: 46.06 min\n",
            "Epoch: 011/020 | Batch 0000/0391 | Cost: 0.6412\n",
            "Epoch: 011/020 | Batch 0050/0391 | Cost: 0.7381\n",
            "Epoch: 011/020 | Batch 0100/0391 | Cost: 0.6997\n",
            "Epoch: 011/020 | Batch 0150/0391 | Cost: 0.8753\n",
            "Epoch: 011/020 | Batch 0200/0391 | Cost: 0.7835\n",
            "Epoch: 011/020 | Batch 0250/0391 | Cost: 0.6201\n",
            "Epoch: 011/020 | Batch 0300/0391 | Cost: 0.5879\n",
            "Epoch: 011/020 | Batch 0350/0391 | Cost: 0.6144\n",
            "Epoch: 011/020 | Train: 76.562% | Loss: 0.688\n",
            "Time elapsed: 50.67 min\n",
            "Epoch: 012/020 | Batch 0000/0391 | Cost: 0.5913\n",
            "Epoch: 012/020 | Batch 0050/0391 | Cost: 0.7521\n",
            "Epoch: 012/020 | Batch 0100/0391 | Cost: 0.5401\n",
            "Epoch: 012/020 | Batch 0150/0391 | Cost: 0.5681\n",
            "Epoch: 012/020 | Batch 0200/0391 | Cost: 0.7862\n",
            "Epoch: 012/020 | Batch 0250/0391 | Cost: 0.8259\n",
            "Epoch: 012/020 | Batch 0300/0391 | Cost: 0.8741\n",
            "Epoch: 012/020 | Batch 0350/0391 | Cost: 0.7649\n",
            "Epoch: 012/020 | Train: 80.436% | Loss: 0.572\n",
            "Time elapsed: 55.28 min\n",
            "Epoch: 013/020 | Batch 0000/0391 | Cost: 0.5254\n",
            "Epoch: 013/020 | Batch 0050/0391 | Cost: 0.5755\n",
            "Epoch: 013/020 | Batch 0100/0391 | Cost: 0.5229\n",
            "Epoch: 013/020 | Batch 0150/0391 | Cost: 0.6322\n",
            "Epoch: 013/020 | Batch 0200/0391 | Cost: 0.5999\n",
            "Epoch: 013/020 | Batch 0250/0391 | Cost: 0.5342\n",
            "Epoch: 013/020 | Batch 0300/0391 | Cost: 0.4578\n",
            "Epoch: 013/020 | Batch 0350/0391 | Cost: 0.5497\n",
            "Epoch: 013/020 | Train: 78.690% | Loss: 0.611\n",
            "Time elapsed: 59.89 min\n",
            "Epoch: 014/020 | Batch 0000/0391 | Cost: 0.6422\n",
            "Epoch: 014/020 | Batch 0050/0391 | Cost: 0.4704\n",
            "Epoch: 014/020 | Batch 0100/0391 | Cost: 0.5061\n",
            "Epoch: 014/020 | Batch 0150/0391 | Cost: 0.5354\n",
            "Epoch: 014/020 | Batch 0200/0391 | Cost: 0.5494\n",
            "Epoch: 014/020 | Batch 0250/0391 | Cost: 0.6403\n",
            "Epoch: 014/020 | Batch 0300/0391 | Cost: 0.6411\n",
            "Epoch: 014/020 | Batch 0350/0391 | Cost: 0.6156\n",
            "Epoch: 014/020 | Train: 84.104% | Loss: 0.477\n",
            "Time elapsed: 64.50 min\n",
            "Epoch: 015/020 | Batch 0000/0391 | Cost: 0.5557\n",
            "Epoch: 015/020 | Batch 0050/0391 | Cost: 0.3461\n",
            "Epoch: 015/020 | Batch 0100/0391 | Cost: 0.4598\n",
            "Epoch: 015/020 | Batch 0150/0391 | Cost: 0.6011\n",
            "Epoch: 015/020 | Batch 0200/0391 | Cost: 0.6190\n",
            "Epoch: 015/020 | Batch 0250/0391 | Cost: 0.5742\n",
            "Epoch: 015/020 | Batch 0300/0391 | Cost: 0.5892\n",
            "Epoch: 015/020 | Batch 0350/0391 | Cost: 0.6255\n",
            "Epoch: 015/020 | Train: 85.278% | Loss: 0.433\n",
            "Time elapsed: 69.11 min\n",
            "Epoch: 016/020 | Batch 0000/0391 | Cost: 0.4109\n",
            "Epoch: 016/020 | Batch 0050/0391 | Cost: 0.5074\n",
            "Epoch: 016/020 | Batch 0100/0391 | Cost: 0.4900\n",
            "Epoch: 016/020 | Batch 0150/0391 | Cost: 0.5656\n",
            "Epoch: 016/020 | Batch 0200/0391 | Cost: 0.5251\n",
            "Epoch: 016/020 | Batch 0250/0391 | Cost: 0.5022\n",
            "Epoch: 016/020 | Batch 0300/0391 | Cost: 0.6132\n",
            "Epoch: 016/020 | Batch 0350/0391 | Cost: 0.4384\n",
            "Epoch: 016/020 | Train: 83.444% | Loss: 0.494\n",
            "Time elapsed: 73.71 min\n",
            "Epoch: 017/020 | Batch 0000/0391 | Cost: 0.6602\n",
            "Epoch: 017/020 | Batch 0050/0391 | Cost: 0.3956\n",
            "Epoch: 017/020 | Batch 0100/0391 | Cost: 0.4275\n",
            "Epoch: 017/020 | Batch 0150/0391 | Cost: 0.4977\n",
            "Epoch: 017/020 | Batch 0200/0391 | Cost: 0.4128\n",
            "Epoch: 017/020 | Batch 0250/0391 | Cost: 0.4469\n",
            "Epoch: 017/020 | Batch 0300/0391 | Cost: 0.3838\n",
            "Epoch: 017/020 | Batch 0350/0391 | Cost: 0.4705\n",
            "Epoch: 017/020 | Train: 88.050% | Loss: 0.347\n",
            "Time elapsed: 78.32 min\n",
            "Epoch: 018/020 | Batch 0000/0391 | Cost: 0.2744\n",
            "Epoch: 018/020 | Batch 0050/0391 | Cost: 0.4708\n",
            "Epoch: 018/020 | Batch 0100/0391 | Cost: 0.6125\n",
            "Epoch: 018/020 | Batch 0150/0391 | Cost: 0.3646\n",
            "Epoch: 018/020 | Batch 0200/0391 | Cost: 0.4439\n",
            "Epoch: 018/020 | Batch 0250/0391 | Cost: 0.4294\n",
            "Epoch: 018/020 | Batch 0300/0391 | Cost: 0.4744\n",
            "Epoch: 018/020 | Batch 0350/0391 | Cost: 0.4866\n",
            "Epoch: 018/020 | Train: 86.888% | Loss: 0.393\n",
            "Time elapsed: 82.93 min\n",
            "Epoch: 019/020 | Batch 0000/0391 | Cost: 0.3776\n",
            "Epoch: 019/020 | Batch 0050/0391 | Cost: 0.3887\n",
            "Epoch: 019/020 | Batch 0100/0391 | Cost: 0.4949\n",
            "Epoch: 019/020 | Batch 0150/0391 | Cost: 0.2877\n",
            "Epoch: 019/020 | Batch 0200/0391 | Cost: 0.3119\n",
            "Epoch: 019/020 | Batch 0250/0391 | Cost: 0.5047\n",
            "Epoch: 019/020 | Batch 0300/0391 | Cost: 0.6944\n",
            "Epoch: 019/020 | Batch 0350/0391 | Cost: 0.5497\n",
            "Epoch: 019/020 | Train: 88.150% | Loss: 0.357\n",
            "Time elapsed: 87.53 min\n",
            "Epoch: 020/020 | Batch 0000/0391 | Cost: 0.2804\n",
            "Epoch: 020/020 | Batch 0050/0391 | Cost: 0.3506\n",
            "Epoch: 020/020 | Batch 0100/0391 | Cost: 0.6187\n",
            "Epoch: 020/020 | Batch 0150/0391 | Cost: 0.3379\n",
            "Epoch: 020/020 | Batch 0200/0391 | Cost: 0.4413\n",
            "Epoch: 020/020 | Batch 0250/0391 | Cost: 0.4734\n",
            "Epoch: 020/020 | Batch 0300/0391 | Cost: 0.4052\n",
            "Epoch: 020/020 | Batch 0350/0391 | Cost: 0.3718\n",
            "Epoch: 020/020 | Train: 87.506% | Loss: 0.393\n",
            "Time elapsed: 92.14 min\n",
            "Total Training Time: 92.14 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "paaeEQHQj5xC"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gzQMWKq5j5xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a54eeaf-f910-46f0-c976-94fa150b52fa"
      },
      "source": [
        "with torch.set_grad_enabled(False): # save memory during inference\n",
        "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 74.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zvIpD9-CtYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6a4565d1-2682-4a04-ed14-b047f6f1e154"
      },
      "source": [
        "%watermark -iv"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy 1.18.5\n",
            "torch 1.5.1+cu101\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}